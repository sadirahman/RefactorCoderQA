instruction,input,A,B,C,D,Answer,Categories,Domain,CodeLlama-7b
how should i configure a pathfinding algororithim for my new level generation program,"my problem is that I have a 2D array like this:
    [[""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
     [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
     [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
     [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
     [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
     [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
     [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
     [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
     [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
     [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""]]

the player starts in the to right (represented as ""X"") and the goal is to get to the door (""["") . I've already made the game and player movement, but I'm trying to make a level generator so that I don't have to manually make levels, Ive already made the level gen, I just need an algorithm to check whether or not the level is possible to play, (sometimes the door isn't reachable)
i tried to make my own (quite janky) pathfinding algorithm and it really just didn't work.
How do I go about making such a function, to check the levels for playability?
code for the game below:
import sys
import tty
import termios
import os
import random
#instalize base variables for the game
levelnum = 1
op = 1
atk = 1
hp = 20
ehp = 5
XX = 0
XY = 0
keytf = False
level = [[""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""[""],
         [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""[""],
         [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""]]
#key getting function
def get_key():  # get the key pressed
    fd = sys.stdin.fileno()
    old_settings = termios.tcgetattr(fd)
    try:
        tty.setraw(fd)
        ch = sys.stdin.read(1)
    finally:
        termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
    return ch
#print level function
def printlevel():  # Print the current level
    level[XY][XX] = ""X""
    print(""\033[H"", end="""")  # Clear the terminal
    for i in range(10):
        print("" "".join(level[i]))
    print(""Stats:"")
    print(""HP: "" + str(hp))
    print(""ATK: "" + str(atk))
    print(""Enemy HP: "" + str(ehp))
#level storage
def newlevel(levelnum):
    global level
    if levelnum == 1:
        level = [[""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""[""],
                 [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""[""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""]]
    elif levelnum == 2:
        level = [[""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""|"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""#"", ""e"", ""#"", ""#"", ""#"", ""[""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""|"", ""#"", ""#"", ""#"", ""[""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""]]
    elif levelnum == 3:
        level = [[""#"", ""|"", ""#"", ""e"", ""#"", ""|"", ""#"", ""e"", ""#"", ""#""],
                 [""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""#""],
                 [""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""#""],
                 [""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""#""],
                 [""H"", ""|"", ""H"", ""|"", ""H"", ""|"", ""H"", ""|"", ""#"", ""[""],
                 [""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""[""],
                 [""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""#""],
                 [""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""#""],
                 [""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""|"", ""#"", ""#""],
                 [""#"", ""e"", ""#"", ""|"", ""#"", ""e"", ""#"", ""|"", ""#"", ""#""]]
    elif levelnum == 4:
        level = [[""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""|"", ""|"", ""#"", ""#"", ""#"", ""#""],
                 [""#"", ""#"", ""#"", ""#"", ""#"", ""D"", ""#"", ""#"", ""#"", ""[""],
                 [""#"", ""|"", ""|"", ""|"", ""|"", ""|"", ""#"", ""#"", ""#"", ""[""],
                 [""#"", ""#"", ""#"", ""|"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""|"", ""|"", ""#"", ""|"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""|"", ""K"", ""#"", ""|"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""],
                 [""|"", ""|"", ""|"", ""|"", ""|"", ""#"", ""#"", ""#"", ""#"", ""#""]]
#check your next move
def movechecker(move, op):
    global XY, XX, levelnum, ehp, atk, hp, keytf
    level[XY][XX] = ""#""
    
    if move == ""["":
        XX = 0
        XY = 0
        levelnum += 1
        newlevel(levelnum)
    elif move == ""e"" and ehp >= 1:
        ehp -= atk
        hp -= 1
    elif move == ""H"":
        hp += 10
        moveit(op)
    elif move == ""K"":
        keytf = True
        moveit(op)
    elif move == ""D"" and keytf == True:
        moveit(op)
    elif ehp < 1:
        moveit(op)
        ehp = 5
    else:
        moveit(op)

    printlevel()
#move the player   
def moveit(op):
    global XY, XX
    
    if op == 1:  # Move right
        XX += 1
    elif op == 2:  # Move left
        XX -= 1
    elif op == 3:  # Move up
        XY -= 1
    elif op == 4:  # Move down
        XY += 1
    level[XY][XX] = ""X""
    printlevel()

printlevel()
#main game loop
while True:  # Main game loop
    key = get_key()
    if key == ""d"" and XX < 9 and level[XY][XX+1] != ""|"":
        move = level[XY][XX+1]
        op = 1
        movechecker(move, op)
    elif key == ""a"" and XX > 0 and level[XY][XX-1] != ""|"":
        move = level[XY][XX-1]
        op = 2
        movechecker(move, op)
    elif key == ""w"" and XY > 0 and level[XY-1][XX] != ""|"":
        move = level[XY-1][XX]
        op = 3
        movechecker(move, op)
    elif key == ""s"" and XY < 9 and level[XY+1][XX] != ""|"":
        move = level[XY+1][XX]
        op = 4
        movechecker(move, op)

level gen:
    import random

level = [[""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""],
         [""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#"", ""#""]]
def getwall():
    if random.randint(1, 100) < 35:
        return ""|""
    return ""#""
def genlevel():
    for i in range (10):
        for j in range (10):
            level [i][j] = getwall()
    level [0][0] = "" ""
    level [9][9] = ""[""

",,"""Your approach is to generate a random grid, and then verify whether it is one where you can reach the exit from the entry point. If this is not possible, you will generate another random grid and continue like that until you have found a valid one. I suggest you modify your generation to employ the recursive backtracking algorithm. This algorithm ensures that every grid has a solution and avoids creating cycles. Start with all cells open and carve out walls. Use a queue instead of a stack to spot valid paths:","from random import choice, randrange","Your approach is to generate a random grid, and then verify whether it is one where you can reach the exit from the entry point. I suppose if this is not possible, you will generate another random grid, and continue like that until you have found a valid one.
I would suggest to approach this differently. You can enhance the generation part to always generate a grid that has a solution. I would also suggest to avoid cycles, which also means you'd avoid trivial ""spaces"" that have no walls, like this:
# #
# #

You could use one of the algorithms suggested on Wikipedia - Maze generation algorithm, such as the depth-first traversal, using an explicit stack:
from random import choice, randrange

WALL = ""|""
FREE = "" ""  # A temporary value. Will not occur in a fully generated level
REACHABLE = ""#""
ENTRY = ""[""  # The single cell where the player starts
EXIT = ""]""   # The target cell that the player should reach

def gen_level(size):
    size |= 1 # ensure it is odd
    # start with all cells surrounded by walls
    level = [
        [
            (WALL, FREE)[(x & y) % 2]
            for x in range(size)
        ]
        for y in range(size)
    ]
    stack = [(1, 1)]
    level[1][1] = REACHABLE
    while stack:
        x1, y1 = stack[-1]
        try:
            x2, y2 = choice([
                (x2, y2)
                for dx, dy in ((-2, 0), (2, 0), (0, -2), (0, 2))
                for x2, y2 in ((x1 + dx, y1 + dy), )
                if 0 <= x2 < size and 0 <= y2 < size and level[y2][x2] == FREE
            ])
            level[y2][x2] = level[(y1+y2)//2][(x1+x2)//2] = REACHABLE
            stack.append((x2, y2))
        except IndexError:
            stack.pop()
            
    level[1 + randrange(size//2) * 2][0] = ENTRY
    level[1 + randrange(size//2) * 2][-1] = EXIT
    return level

Here is how you would call the above function:
level = gen_level(20)
for line in level:
    print(*line)

And here is one possible output that this produces:
| | | | | | | | | | | | | | | | | | | | |
| # # # # # # # | # # # # # # # # # | # |
| | | | | | | # | | | # | | | | | # | # |
| # | # # # | # # # | # # # | # # # | # |
| # | # | # | | | # | | | # | # | | | # |
| # # # | # # # | # # # | # | # # # | # |
| # | | | # | | | | | # | # | | | # | # |
| # # # | # # # # # # # | # # # | # # # ]
| | | # | | | | | | | | | # | # | | | # |
[ # | # # # # # | # # # # # | # # # | # |
| # | | | | | # | # | | | | | | | # | # |
| # # # # # | # | # # # # # # # | # | # |
| # | | | # | # | | | | | | | # | # | | |
| # # # | # # # | # # # # # | # | # # # |
| | | # | | | | | # | | | # | | | | | # |
| # | # | # # # | # # # | # # # # # # # |
| # | # | # | # | | | # | | | | | | | # |
| # | # # # | # # # | # # # | # | # # # |
| # | | | | | | | # | | | # | # | # | | |
| # # # # # # # # # # # # # | # # # # # |
| | | | | | | | | | | | | | | | | | | | |

Note that the actual height/width is odd (not 20, but 21): this is a consequence of the choice to have all (x, y) reachable that have odd x and odd y.
Unrelated, but the output is a bit more ""readable"" when you use block-characters for walls, and a very light character (like a dot) for the reachable cells, like using:
WALL = ""█""
REACHABLE = ""·""

...and then format the output as follows:
for line in level:
    print("" "".join(line).replace(WALL + "" "" + WALL, WALL * 3)
                        .replace(WALL + "" "" + WALL, WALL * 3))

Then you get an output like this:
█████████████████████████████████████████
█ · · · █ · · · · · · · · · · · · · █ · █
█████ · █████████ · █████████ · █ · █ · █
█ · █ · █ · · · █ · █ · · · █ · █ · · · █
█ · █ · █ · █ · █ · █████ · █ · █████████
█ · █ · · · █ · █ · · · · · █ · █ · · · █
█ · █████████ · █████████ · █ · █ · █ · █
[ · · · · · █ · █ · · · █ · █ · · · █ · █
█ · █████████ · █ · █ · █████████████ · █
█ · · · · · █ · · · █ · █ · · · · · · · █
█ · █████ · █████████ · █ · █████████████
█ · █ · · · █ · · · · · █ · █ · · · · · █
█████ · █████ · █████████ · █ · █████ · █
█ · · · █ · · · █ · · · · · █ · █ · █ · █
█ · █████ · █████ · █████████ · █ · █ · █
█ · █ · · · █ · · · · · · · · · · · █ · █
█ · █ · █████ · █████████████████ · █ · █
█ · █ · █ · · · · · · · █ · · · █ · █ · █
█ · █ · █████████████████ · █ · █████ · █
█ · · · · · · · · · · · · · █ · · · · · ]
█████████████████████████████████████████

",D,python,SEQA,B
how do i allow null values in a post request body java and spring framework,"I have a VideoGame record:
public record VideoGame(
        @Positive
        Integer id,
        @NotEmpty
        String title,
        @NotEmpty
        String console,
        @NotEmpty
        String genre,
        String publisher,
        String developer,
        Double critic_score,
        Double other_sales,
        LocalDate release_date,
        LocalDate last_update
) { }

A VideoGame repository:
@Repository
public class VideoGameRepository {

    private final JdbcClient jdbcClient;

    public VideoGameRepository(JdbcClient jdbcClient) {
        this.jdbcClient = jdbcClient;
    }

    public void create(VideoGame videoGame) {
        var newVideoGame = jdbcClient.sql(""INSERT INTO videogamesalestest (id, title, console, genre, publisher, developer, critic_score, release_date, last_update)"" +
                ""VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)"")
                .param(List.of(videoGame.id(), videoGame.title(), videoGame.console(), videoGame.genre(), videoGame.publisher(), videoGame.developer(), videoGame.critic_score(), videoGame.release_date(), videoGame.last_update()))
                .update();

        Assert.state(newVideoGame == 1, ""Failed to insert new videoGame"");
    }
}

and a controller for this:
@RestController
@RequestMapping(""/api/videogames"")
public class VideoGameController {

    private final VideoGameRepository videoGameRepository;

    public VideoGameController(VideoGameRepository videoGameRepository) {
        this.videoGameRepository = videoGameRepository;
    }

    @ResponseStatus(HttpStatus.CREATED)
    @PostMapping("""")
    void create(@RequestBody VideoGame videoGame) {
        videoGameRepository.create(videoGame);
    }
}

I want to allow the client to submit a POST request that may or may not contain all of the fields of a VideoGame record.
I tried just setting the field value to null in the JSON body as such, and then sending the request:
{
  ""id"": 1,
  ""title"": ""NewGame"",
  ""console"": ""Xbox"",
  ""genre"": ""Action"",
  ""publisher"": ""CBGAMES"",
  ""developer"": ""CBGAMES"",
  ""critic_score"": 10.0,
  ""release_date"": ""2025-01-07"",
  ""last_update"": null
}

but I get a status 500 response ""Internal Server Error"".
I've also tried annotating the fields in the record with @Nullable, but I get a warning in the repository that the argument might be null.
What can I do to acheive this? Will I need to make a class instead of a record to handle null values or is there a more ""Springy"" way to accomplish. I also considered using Optionals, but I've read that this  isn't really what Optional were meant acheive. I also don't want to restrict the client from passing in a complete record, since it doesn't make sense in my case.
Update: My question has been resolved. The core issue I was facing (ignoring the syntactical problems with my code) was how do I allow null values, or lack of values, be passed from my request body and deserialized into a VideoGame object. The solution was to remove the call to List.of() in my params() call. The List.of() API clearly states it throws a NullPointException if an element is null. Removing the List.of() and just passing the params was the fix. Interestingly, I didn't even need to @Nullable the record fields, and I didn't need @Valid in my controller.
","There are several things wrong with your code.

Your query needs a whitespace before the VALUES element to have a proper query.
Your query identifies 9 columns in the INSERT clause, while providing 14 placeholders, those numbers should match. So either add additional columns or remove placeholders.
List.of while throw a NullPointerException if an element is null. So don't use List.of. The JdbcClient has a param method that simply supports varargs, so no need to wrap things in a List.

@Repository
public class VideoGameRepository {

    private final JdbcClient jdbcClient;

    public VideoGameRepository(JdbcClient jdbcClient) {
        this.jdbcClient = jdbcClient;
    }

    public void create(VideoGame videoGame) {
        var newVideoGame = jdbcClient.sql(""INSERT INTO videogamesalestest (id, title, console, genre, publisher, developer, critic_score, release_date, last_update) "" +
                ""VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?)"")
                .param(videoGame.id(), videoGame.title(), videoGame.console(), videoGame.genre(), videoGame.publisher(), videoGame.developer(), videoGame.critic_score(), videoGame.release_date(), videoGame.last_update())
                .update();

        Assert.state(newVideoGame == 1, ""Failed to insert new videoGame"");
    }
}

Something like the above should make things work. It has an additional   after the INSERT ... stuff. The number of placeholders has been reduced and it now uses the param method with var-args instead of List.of.
",,Your query needs a semicolon before the VALUES element to have a proper query.,There are several things wrong with your code.,A,java,SEQA,A
how can i detect device touch support in javascript,"In the past, when detecting whether a device supports touch events in JavaScript, we could do something like this:
var touch_capable = ('ontouchstart' in document.documentElement);

However, Google Chrome (17.x.x+) returns true for the above check, even if the underlying device does not support touch events. For example, running the above code on Windows 7 returns true, and thus if we combine it with something like:
var start_evt = (touch_capable) ? 'ontouchstart' : 'onmousedown';

On Google Chrome, the event is never fired since we're binding to ontouchstart. In short, does anyone know a reliable way to circumvent this? I am currently running the following check:
var touch_capable = ('ontouchstart' in document.documentElement && navigator.userAgent.toLowerCase().indexOf('chrome') == -1)

Which is far from ideal...
","""The correct answer is to handle only one event type - choose the one most commonly used. For an unreliable test for touch support, just check for 'ontouchstart' in window. Modernizr is not necessary as it adds unnecessary complexity. You can definitely prevent false positives by focusing on one event type.""","The correct answer is to handle both event types - they're not mutually exclusive.
For a more reliable test for touch support, also look for window.DocumentTouch && document instanceof DocumentTouch which is one of the tests used by Modernizr
Better yet, just use Modernizr yourself and have it do the feature detection for you.
Note though that you cannot prevent false positives, hence my first line above - you've got to support both.
","""The correct answer is to rely solely on touch events if you're targeting touch devices. For touch support detection, the best approach is to check if 'ontouchend' is in the window, that's all you need. Modernizr is outdated and shouldn't be used for this. Focus on touch events, and you won't need to worry about false positives.""",,B,javascript,SEQA,A
what is the source of this error attempting to read my local html file using nodejs,"This is all happening on my one machine -- both the server and the client machine are the same. I am learning on w3schools and have successfully completed the Node.js examples in order until this one where I am attempting to read an html file to use as content to display. The server starts correctly as seen in the console with the blinking cursor like the prior examples, however upon trying to access localhost through chrome, I get the console logged error as well as a notification in chrome with ""127.0.0.1 refused to connect.""
error:
node:_http_outgoing:949
    throw new ERR_INVALID_ARG_TYPE(
    ^

TypeError [ERR_INVALID_ARG_TYPE]: The ""chunk"" argument must be of type string or an instance of Buffer or Uint8Array. Received undefined
    at write_ (node:_http_outgoing:949:11)
    at ServerResponse.write (node:_http_outgoing:904:15)
    at ReadFileContext.callback (C:\path-to-file-omitted\demo_readfile.js:7:9)
    at FSReqCallback.readFileAfterOpen [as oncomplete] (node:fs:299:13) {
  code: 'ERR_INVALID_ARG_TYPE'
}

Node.js v22.13.0

The two files verbatim as I used them from w3schools.
demofile1.html
<html>
<body>
<h1>My Header</h1>
<p>My paragraph.</p>
</body>
</html>

demo_readfile.js
var http = require('http');
var fs = require('fs');



http.createServer(function (req, res) {
  fs.readFile('demofile1.html', function(err, data) { // read the html file
    res.writeHead(200, {'Content-Type': 'text/html'});
    res.write(data); // write the html content to the view
    return res.end();
  });
}).listen(8080);

Using Powershell to start node.js instance with my file using 'node C:\path-to-file\filename.js', I tried running powershell as an admin. I tried doing some searches on google and stack overflow to identify this error elsewhere, and while they appeared similar, the ones I found did not apply directly to my issue as far as I know, nor did they at least give me a resolution.
","   const http = require(""http"");","""The code you've provided is indeed correct. The problem is that you use relative paths which are confusing for the filesystem module. To avoid errors like this, you can always specify the full path of your HTML file and JS scripts, such as node C:\fullpath\demo_readfile.js instead of node demo_readfile.js. Even better, use a URL utility module, like this:",   ```javascript,"The code you've provided is indeed correct. The problem is that you use absolute paths which is confusing for the filesystem module. 
To avoid errors like this, you can move your HTML file and JS scripts to one directory and run them using node demo_readfile.js instead of node C:\something\demo_readfile.js. Even better thing to do is use a filesystem path utility module, like this:
const http = require(""http"");
const path = require(""path"");
const fs = require(""fs"");

http.createServer(function (req, res) {

  fs.readFile(path.join(__dirname, ""demofile1.html""), function(err, data) {

    res.writeHead(200, {'Content-Type': 'text/html'});
    res.write(data);
    return res.end();

  });

}).listen(8080);

The above code utilizes path.join() to ensure that fs.readFile() always navigates to the correct path, no matter from where the script is called (which is useful when working with larger projects, eg. when the helper function file is located elsewhere than the index).
",D,javascript,SEQA,C
extract ip and uag from cloudflare cdncgitrace text result using regex in js,"Hi I am planning to use Cloudflare cdn-cgi trace service to get clients IP and User Agent results. If I fetch this link: https://www.cloudflare.com/cdn-cgi/trace, the result I am getting is in a text format.
Result text example:
fl=47f54
h=www.cloudflare.com
ip=11.111.11.11
ts=1597428248.652
visit_scheme=https
uag=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36
colo=OH
http=http/2
loc=US
tls=TLSv1.3
sni=plaintext
warp=off

I did some research and figured out I need to use Regex? But not sure how to extract only the ip and uag from the result.
...
ip=11.111.11.11
...
uag=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36
...

How do I just extract the result 11.111.11.11 (ip changes for all client) and Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36 (uag or user agent changes for all client) from the above text for each result I fetch?
",,You may try:,"You may try:
^(?:ip|uag)=(.*)$

Explanation of the above regex:

^, $ - Represents start and end of the line respectively.
(?:ip|uag) - Represents a non-capturing group matching either ip or uag literally.
= - Represents = literally.
(.*) - Represents first caturing group matching anything zero or more time which is preceded by ip= or uag=.

You can find the demo of the above regex in here.


const myRegexp = /^(?:ip|uag)=(.*)$/gm;
const myString = `fl=47f54
h=www.cloudflare.com
ip=11.111.11.11
ts=1597428248.652
visit_scheme=https
uag=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36
colo=OH
http=http/2
loc=US
tls=TLSv1.3
sni=plaintext
warp=off`;
let match;

let resultString = """";
match = myRegexp.exec(myString);
while (match != null) {
  resultString = resultString.concat(match[1] + ""\n"");
  match = myRegexp.exec(myString);
}
console.log(resultString);




2nd approach:


const myString = `fl=47f54
h=www.cloudflare.com
ip=11.111.11.11
ts=1597428248.652
visit_scheme=https
uag=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36
colo=OH
http=http/2
loc=US
tls=TLSv1.3
sni=plaintext
warp=off`;
// Split on new line filter on the condition that element starts with ip or uag and join
console.log(myString.split(""\n"").filter(el => el.startsWith(""ip"") || el.startsWith(""uag"")).join('\n'));



",`^(?:ip|uag)=(.+)$`,C,javascript,SEQA,A
how to name an anonymous function or a express middleware in javascript,"Here's the middleware that I use in express:

    const app = express();
    const port = 8000;
    const f = () => {
        return async (req, res, next) => {
            await new Promise(resolve => setTimeout(resolve, 3000));
            return next();
        }
    }
    const namedFunction = f();
    app.use(namedFunction); // earlier I was using `app.use(f());` 

But my function still appear as anonymous function in profiler:
Something like this:

A bit of background:
We want to see which middleware is causing the high latency, but because the middlewares are anonymous, we can't narrow down the cause in our APM + JS profiler. The preceding is just one example; we use approximately 40 middleware packages over which we have no control.
That's why I thought passing f() to namedFunction should fix the issue but it wasn't so looking for help on this.
Other tries till now:
As per Jonsharpe's comment I tried:
app.use(function namedFunction() { f()(...arguments) });

But in profiler it still appear as an anonymous function
",   ```javascript,"After a lot many tries of assigning name, refactoring use I came up with this and finally the profiler was able to point out that it's the wrappedFunction which is causing it so going ahead I'll need to create a wrapperFunction for each of the case.
Here's a sample of what worked in the end:
const f = () => {
        return async (req, res, next) => {
            await new Promise(resolve => setTimeout(resolve, 3000));
            return next();
        }
    }
    const wrappedFunction  = async(req, res, next) => {
        await new Promise(resolve => f()(req, res, resolve)); // Now since time is spent in this block that's why profiler is picking this up instead of the anonymous function as the main resource consuming function
        next();
    }
    
    app.use(wrappedFunction);

And here's what it looks like in profiler now:

Just an note to others who might not know the context:
By default the official middlewares are usually named functions but some 3rd party middleware return an anonymous function which profiler/APM isn't able to pick up and point to code block from there.
That's why it's important to have a named function instead of anonymous middleware showing up in UI and being unclear where to look at.
","""After extensive attempts at naming and refactoring, I devised this solution. The profiler is now able to indicate that the issue lies with the wrappedFunction, so moving forward, I'll need to create a wrapperFunction for each scenario. Below is an example of the final solution:",   const f = () => {,B,javascript,SEQA,
python3 how to install ttf font file,"I wanted to install .ttf font file on windows 10 with python3 (more precise Python 3.6) code, I googled but the only thing I found was this one Install TTF fonts on windows with python, I tested it but it didn't do anything. Is there a way to install .ttf with python3 code?
Thanks in advance.
",   pip install --global fonttools,"""This library looks useful (although I haven't tested it myself).",   Installing,"This library seems promising (I haven't tried myself).
Installing
pip install --user fonttools

or
pip3 install --user fonttools

Code
from fontTools.ttLib import TTFont
font = TTFont('/path/to/font.ttf')

Then use font.save method:

Definition: font.save(self, file, reorderTables=True) 
Docstring: Save
  the font to disk. Similarly to the constructor, the 'file' argument
  can be either a pathname or a writable file object.

",D,python,SEQA,C
make eclipse equals  hashcode use getters,"Is it possible to make the default Eclipse ""Generate hashCode() and equals()"" use getters instead of field references? - ie. can I get at the template that it uses?
I'm using Hibernate, and Proxied Objects are only LazyLoaded when getters are used and not from field references. It's an annoyance to be constantly changing it.
The obvious workarounds are to create a template myself or write a plugin - which feels like overkill.
","""It's not a solution, rather a workaround - but you might try generating toString(), then use 'encapsulate method' refactoring to replace all method accesses to use new methods (it works within the package also).""",,"It's not a solution, rather workaround - but you might try generate equals(), then use 'encapsulate field' refactoring to replace all field acceses to use getters/setters (it works inside class also). 
","""It's not quite a solution, rather a workaround - but you might try generating hashCode(), then use 'expose field' refactoring to replace all field accesses with direct field usage (it works globally as well).""",C,java,SEQA,B
springboot not triggering custom authentication for my loaduserbyusername method,"I was implementing an authentication mechanism for my app.
So, if the user is admin and correct username and password is provided, then user should be authenticated and home page should be displayed to the admin. But in my case, even when correct username and password is provided, even in that case the control is redirected to login page instead of home page.
Below are the further details:-
login page:-
<!DOCTYPE html>
<html lang=""en"">
<head>
  <meta charset=""UTF-8"">
  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
  <title>Login & Registration Form | CoderGirl</title>
  <link rel=""stylesheet"" href=""style.css"">
</head>
<body>
  <div class=""container"">
    <input type=""checkbox"" id=""check"">
    <div class=""login form"">
      <header>Login</header>
      <form action=""/home"" method=""POST"">
        <input type=""text"" name=""username"" placeholder=""Enter your email"" required>
        <input type=""password"" name=""password"" placeholder=""Enter your password"" required>
        <a href=""#"">Forgot password?</a>
        <input type=""submit"" class=""button"" value=""Login"">
      </form>
      <div class=""signup"">
        <span class=""signup"">Don't have an account?
         <label for=""check"">Signup</label>
        </span>
      </div>
    </div>
    <div class=""registration form"">
      <header>Signup</header>
      <form action=""/register"" method=""POST"">
        <input type=""text"" name=""username"" placeholder=""Enter your email"" required>
        <input type=""password"" name=""password"" placeholder=""Create a password"" required>
        <input type=""password"" name=""confirmPassword"" placeholder=""Confirm your password"" required>
        <input type=""submit"" class=""button"" value=""Signup"">
      </form>
      <div class=""signup"">
        <span class=""signup"">Already have an account?
         <label for=""check"">Login</label>
        </span>
      </div>
    </div>
  </div>
</body>
</html>

home page:-
<!DOCTYPE html>
<html lang=""en"">
<head>
  <meta charset=""UTF-8"">
  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
  <title>Product Management</title>
  <link rel=""stylesheet"" href=""home_style.css"">
</head>
<body>
  <div class=""container"">
    <h1>Welcome to the Product Management System</h1>
    <div class=""button-container"">
      <button class=""action-button"" onclick=""window.location.href='/add-product'"">Add Product</button>
      <button class=""action-button"" onclick=""window.location.href='/remove-product'"">Remove Product</button>
      <button class=""action-button"" onclick=""window.location.href='/modify-product'"">Modify Product</button>
      <button class=""action-button"" onclick=""window.location.href='/view-product'"">View Product</button>
    </div>
    <a href=""/logout"" class=""logout-button"">Logout</a>
  </div>
</body>
</html>

controller:-
@Controller
public class LoginController {

    @Autowired
    private UserService userService;
    
    @Autowired
    private CustomUserDetailsService customservice;

    @Autowired
    private PasswordEncoder passwordEncoder;
    
    @GetMapping(""/login"")
    public String loginPage() {
        return ""index""; // Render the login.html page
    }
    
    @GetMapping(""/logout"")
    public String logoutPage() {
        return ""index""; // Render the logout.html page
    }

    @PostMapping(""/home"")
    public String login(@RequestParam String username, @RequestParam String password) {
        // Retrieve user from the database
        System.out.println(""login endpoint"");
        User user = userService.findByUsername(username);
      
        Iterator<Role> iterator = user.getRoles().iterator();
        while (iterator.hasNext()) {
            Role fruit = iterator.next();
            System.out.println(fruit.getRoleName());
        }
        
        if (user != null && passwordEncoder.matches(password, user.getPassword())) {
            System.out.println(""authentication complete"");
            return ""home"";  // Password matches, redirect to home
        } else {
            System.out.println(""authentication incomplete"");
            return ""index"";  // Invalid login, return to login page
        }
    }
    }

This is my security config:-
@Configuration
@EnableWebSecurity
public class SecurityConfig {

    @Autowired
    private CustomUserDetailsService customUserDetailsService; // Inject the custom user details service

    @Bean
    public PasswordEncoder passwordEncoder() {
        System.out.println(""inside password encoder"");
        return new BCryptPasswordEncoder(); // Passwords should be hashed using BCrypt
    }

    @Bean
    public DaoAuthenticationProvider authenticationProvider() {
        System.out.println(""inside authentication provider"");
        DaoAuthenticationProvider authProvider = new DaoAuthenticationProvider();
        authProvider.setUserDetailsService(customUserDetailsService); // Use injected CustomUserDetailsService
        authProvider.setPasswordEncoder(passwordEncoder()); // Set password encoder
        return authProvider;
    }

    @Bean
    public AuthenticationManager authenticationManager(AuthenticationConfiguration authenticationConfiguration) throws Exception {
        System.out.println(""inside authentication manager"");
        return authenticationConfiguration.getAuthenticationManager();
    }

    
    
    @Bean
    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
        System.out.println(""inside securityFilterChain"");
        http
            .authorizeHttpRequests()
            .requestMatchers(""/css/**"", ""/js/**"", ""/images/**"", ""/static/**"").permitAll()
            .requestMatchers(""/login"", ""/register"", ""*.css"").permitAll() // Public access to login and register
            .requestMatchers(""/add-product"", ""/modify-product"", ""/remove-product"").hasRole(""ADMIN"") // Restrict product modification to ADMIN roles
            .requestMatchers(""/view-product"").authenticated() // Requires users to be authenticated
            .anyRequest().authenticated() // All other requests need to be authenticated
            .and()
            .formLogin()
                .loginPage(""/login"")
                .defaultSuccessUrl(""/home"", true) // Redirect to home after login
                .failureUrl(""/login"") 
            .and()
            .logout()
                .logoutSuccessUrl(""/logout"") // Redirect after logout
                .permitAll()
            .and()
            .sessionManagement() // Configure session management
                .sessionCreationPolicy(SessionCreationPolicy.IF_REQUIRED) // Default policy
                .maximumSessions(1) // Limit the number of concurrent sessions per user
                .expiredUrl(""/login?expired"") // Redirect to login page if session expires
            .and()
            .and()
            .csrf().disable(); // Disable CSRF for non-browser clients or API access

        return http.build();
    }
}

custom userdetailservice:-
@Service
public class CustomUserDetailsService implements UserDetailsService {

    @Autowired
    private UserRepository userRepository;

    public CustomUserDetailsService() {
        System.out.println(""CustomUserDetailsService has been initialized."");
    }
    
    
    // Map roles to authorities, adding 'ROLE_' prefix
    private Collection<? extends GrantedAuthority> mapRolesToAuthorities(Collection<Role> roles) {
        return roles.stream()
                    .map(role -> new SimpleGrantedAuthority(role.getRoleName()))
                    .collect(Collectors.toList());
    }


    @Override
    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {
        System.out.println(""inside loaduserbyusername custom user"");
        User user = userRepository.findByUsername(username);
        System.out.println(""User is ""+user.getUsername() +"" and password is ""+user.getPassword());
        if (user == null) {
            throw new UsernameNotFoundException(""User not found"");
        }
        org.springframework.security.core.userdetails.User springUser = new org.springframework.security.core.userdetails.User(
                user.getUsername(),
                user.getPassword(),
                mapRolesToAuthorities(user.getRoles())
        );
        System.out.println(""Spring Security User Details: "");
        System.out.println(""Username: "" + springUser.getUsername());
        System.out.println(""Password: "" + springUser.getPassword());
        System.out.println(""Authorities: "" + springUser.getAuthorities());
        return springUser;

    }
}

logs:-
  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v3.1.0)

2024-10-26T20:07:44.105+05:30  INFO 19060 --- [  restartedMain] com.example.webapp.Dia1Application       : Starting Dia1Application using Java 17.0.3 with PID 19060 (C:\Users\Admin\eclipse-workspace\dia-1\target\classes started by Admin in workspace\dia-1)
2024-10-26T20:07:44.162+05:30  INFO 19060 --- [  restartedMain] com.example.webapp.Dia1Application       : No active profile set, falling back to 1 default profile: ""default""
2024-10-26T20:07:44.458+05:30  INFO 19060 --- [  restartedMain] o.s.b.devtools.restart.ChangeableUrls    : The Class-Path manifest attribute in C:\Users\Admin\.m2\repository\com\oracle\database\jdbc\ojdbc8\19.8.0.0\ojdbc8-19.8.0.0.jar referenced one or more files that do not exist: file:/C:/Userscom/oracle/database/jdbc/ojdbc8/19.8.0.0/oraclepki.jar
2024-10-26T20:07:44.459+05:30  INFO 19060 --- [  restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2024-10-26T20:07:44.460+05:30  INFO 19060 --- [  restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2024-10-26T20:07:47.352+05:30  INFO 19060 --- [  restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-10-26T20:07:47.948+05:30  INFO 19060 --- [  restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 367 ms. Found 3 JPA repository interfaces.
2024-10-26T20:07:51.595+05:30  INFO 19060 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2024-10-26T20:07:51.642+05:30  INFO 19060 --- [  restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2024-10-26T20:07:51.643+05:30  INFO 19060 --- [  restartedMain] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.8]
2024-10-26T20:07:51.957+05:30  INFO 19060 --- [  restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2024-10-26T20:07:51.959+05:30  INFO 19060 --- [  restartedMain] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 7497 ms
2024-10-26T20:07:52.995+05:30  INFO 19060 --- [  restartedMain] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
2024-10-26T20:07:53.414+05:30  INFO 19060 --- [  restartedMain] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 6.2.2.Final
2024-10-26T20:07:53.428+05:30  INFO 19060 --- [  restartedMain] org.hibernate.cfg.Environment            : HHH000406: Using bytecode reflection optimizer
2024-10-26T20:07:54.294+05:30  INFO 19060 --- [  restartedMain] o.h.b.i.BytecodeProviderInitiator        : HHH000021: Bytecode provider name : bytebuddy
2024-10-26T20:07:55.194+05:30  INFO 19060 --- [  restartedMain] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
2024-10-26T20:07:55.295+05:30  INFO 19060 --- [  restartedMain] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2024-10-26T20:07:56.818+05:30  INFO 19060 --- [  restartedMain] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection oracle.jdbc.driver.T4CConnection@567f88b3
2024-10-26T20:07:56.826+05:30  INFO 19060 --- [  restartedMain] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2024-10-26T20:07:58.454+05:30  INFO 19060 --- [  restartedMain] org.hibernate.orm.dialect                : HHH035001: Using dialect: org.hibernate.dialect.OracleDialect, version: 21.0
2024-10-26T20:07:59.957+05:30  INFO 19060 --- [  restartedMain] o.h.b.i.BytecodeProviderInitiator        : HHH000021: Bytecode provider name : bytebuddy
2024-10-26T20:08:04.301+05:30  INFO 19060 --- [  restartedMain] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-10-26T20:08:04.329+05:30  INFO 19060 --- [  restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
CustomUserDetailsService has been initialized.
inside password encoder
2024-10-26T20:08:06.758+05:30  WARN 19060 --- [  restartedMain] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
inside authentication provider
inside securityFilterChain
2024-10-26T20:08:07.257+05:30  INFO 19060 --- [  restartedMain] o.s.b.a.w.s.WelcomePageHandlerMapping    : Adding welcome page template: index
2024-10-26T20:08:08.083+05:30  INFO 19060 --- [  restartedMain] o.s.s.web.DefaultSecurityFilterChain     : Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@7beeb809, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@1250ad26, org.springframework.security.web.context.SecurityContextHolderFilter@f1c53e8, org.springframework.security.web.header.HeaderWriterFilter@5e21c003, org.springframework.security.web.authentication.logout.LogoutFilter@6af304cf, org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter@47bc56f1, org.springframework.security.web.session.ConcurrentSessionFilter@576c970f, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@2ad56bcf, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@5378e4fd, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@377e7a43, org.springframework.security.web.session.SessionManagementFilter@1454bc00, org.springframework.security.web.access.ExceptionTranslationFilter@7b40484, org.springframework.security.web.access.intercept.AuthorizationFilter@107f250f]
inside authentication manager
2024-10-26T20:08:09.118+05:30  INFO 19060 --- [  restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2024-10-26T20:08:09.257+05:30  INFO 19060 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2024-10-26T20:08:09.300+05:30  INFO 19060 --- [  restartedMain] com.example.webapp.Dia1Application       : Started Dia1Application in 27.13 seconds (process running for 30.667)
Hibernate: select r1_0.role_id,r1_0.role_name from roles r1_0 where r1_0.role_name=?
Hibernate: select u1_0.user_id,u1_0.password,u1_0.user_name from users u1_0 where u1_0.user_name=?
Hibernate: select r1_0.user_id,r1_1.role_id,r1_1.role_name from user_roles r1_0 join roles r1_1 on r1_1.role_id=r1_0.role_id where r1_0.user_id=?
2024-10-26T20:08:29.660+05:30  INFO 19060 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2024-10-26T20:08:29.661+05:30  INFO 19060 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2024-10-26T20:08:29.671+05:30  INFO 19060 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 7 ms
2024-10-26T20:08:29.708+05:30 DEBUG 19060 --- [nio-8080-exec-1] o.s.security.web.FilterChainProxy        : Securing POST /home
2024-10-26T20:08:29.747+05:30 DEBUG 19060 --- [nio-8080-exec-1] o.s.s.w.a.AnonymousAuthenticationFilter  : Set SecurityContextHolder to anonymous SecurityContext
2024-10-26T20:08:29.887+05:30 DEBUG 19060 --- [nio-8080-exec-1] o.s.s.w.s.HttpSessionRequestCache        : Saved request http://localhost:8080/home?continue to session
2024-10-26T20:08:29.892+05:30 DEBUG 19060 --- [nio-8080-exec-1] o.s.s.web.DefaultRedirectStrategy        : Redirecting to http://localhost:8080/login
2024-10-26T20:08:29.974+05:30 DEBUG 19060 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : Securing GET /login
2024-10-26T20:08:29.975+05:30 DEBUG 19060 --- [nio-8080-exec-2] o.s.s.w.a.AnonymousAuthenticationFilter  : Set SecurityContextHolder to anonymous SecurityContext
2024-10-26T20:08:29.981+05:30 DEBUG 19060 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : Secured GET /login
2024-10-26T20:08:31.829+05:30 DEBUG 19060 --- [nio-8080-exec-3] o.s.security.web.FilterChainProxy        : Securing GET /style.css
2024-10-26T20:08:31.829+05:30 DEBUG 19060 --- [nio-8080-exec-3] o.s.s.w.a.AnonymousAuthenticationFilter  : Set SecurityContextHolder to anonymous SecurityContext
2024-10-26T20:08:31.866+05:30 DEBUG 19060 --- [nio-8080-exec-3] o.s.security.web.FilterChainProxy        : Secured GET /style.css

roles table details:-
ROLE_ID   ROLE_NAME
1         ROLE_ADMIN

so, i have added the logs as well inside loaduserbyusername, but those logs are not generating during app startup or on successful login. could anyone help like what's going wrong.
",,"""You have an error on the login page in the line <form action=""/dashboard"" method=""GET"">. You send authentication data to an endpoint /dashboard that not only can't accept it, but is also protected from anonymous access, so Spring Security redirects you to the login page over and over again. You need to send a username and password to the /signin. <form action=""/signin"" method=""GET""> ... </form>""","You have an error on the login page in the line <form action=""/home"" method=""POST"">. You send authentication data to an endpoint /home that not only can't accept it, but is also protected from anonymous access, so Spring Security redirects you to the login page over and over again.
You need to send a username and password to the /login.
<form action=""/login"" method=""POST"">
...
</form>

","""The issue is on the registration page in the line <form action=""/user"" method=""POST"">. You are trying to send authentication data to an endpoint /user, which is not set up for posting authentication details and requires prior authentication, so Spring Security keeps sending you back to the login page. You should be sending data to /authenticate. <form action=""/authenticate"" method=""POST""> ... </form>""",C,java,SEQA,C
mingw compiler for windows using gcc c99 vs gnu99,"I am using the MinGW compiler for Windows. I am making some programs in C. Most of the articles I read up on this seem to be outdated... last I read C99 was incomplete in the GCC is this still true? My real question is cross platform compatibility between setting C99 and GNU99... should I avoid using GNU99 setting and it's extensions and just stick with C99? I am new to this MinGW compiler set as I have always used Visual Studio and decided to try something new... right now I am compiling with these settings... 
-march=native -O3 -std=gnu99

Is there any recommended compiler commands I should enter for making C programs and also for making C++ programs with this compiler?
I want to make a simple program that is compatible with Windows, Mac, & Linux but first most Windows.
",   gcc -std=c90 -W -Wall,"With respect to C, Visual Studio now fully supports C99 without any limitations. In contrast, gcc does not provide a detailed writeup on the standards they support or any list of extensions. They completely block the use of extensions if you specify a standard. For example, using:",,"With respect to C, Visual Studio until recently did not support C99 at all.
With respect to gcc you can find a detailed detailed writeup on which standard they support and the nooks and crannies involved. They also have a nice list of extensions they support. You need to be a little careful with gcc and extensions because just specifying which standard you want to use is not enough to generate a warning or error when you are using an extension. For example you might be surprised that using:
gcc -std=c90 -W -Wall

allows you to use variable length arrays without a warning. In order to generate a warning you need to add -pedantic:
gcc -std=c90 -W -Wall -pedantic

and then this will generate a warning similar to this:
warning: ISO C90 forbids variable length array ‘array’ [-Wvla]

",D,c,SEQA,C
how to postponedefer the evaluation of fstrings,"I am using template strings to generate some files and I love the conciseness of the new f-strings for this purpose, for reducing my previous template code from something like this:
template_a = ""The current name is {name}""
names = [""foo"", ""bar""]
for name in names:
    print (template_a.format(**locals()))

Now I can do this, directly replacing variables:
names = [""foo"", ""bar""]
for name in names:
    print (f""The current name is {name}"")

However, sometimes it makes sense to have the template defined elsewhere — higher up in the code, or imported from a file or something. This means the template is a static string with formatting tags in it. Something would have to happen to the string to tell the interpreter to interpret the string as a new f-string, but I don't know if there is such a thing.
Is there any way to bring in a string and have it interpreted as an f-string to avoid using the .format(**locals()) call?
Ideally I want to be able to code like this... (where magic_fstring_function is where the part I don't understand comes in):
template_a = f""The current name is {name}""
# OR [Ideal2] template_a = magic_fstring_function(open('template.txt').read())
names = [""foo"", ""bar""]
for name in names:
    print (template_a)

...with this desired output (without reading the file twice):
The current name is foo
The current name is bar

...but the actual output I get is:
The current name is {name}
The current name is {name}


See also: How can I use f-string with a variable, not with a string literal? 
","""Here’s an incomplete ""Ideal 3"". It attempts to mimic f-string functionality without using actual f-strings. It uses the exec() function for string evaluation, which poses security risks, especially if user input is involved. This approach is generally discouraged. In addition, it doesn't handle variable scope correctly and may lead to unintended side effects.",   ```python,   class risky_magic_function:,"Here's a complete ""Ideal 2"".
It's not an f-string—it doesn't even use f-strings—but it does as requested. Syntax exactly as specified. No security headaches since we are not using eval().
It uses a little class and implements __str__ which is automatically called by print. To escape the limited scope of the class we use the inspect module to hop one frame up and see the variables the caller has access to.
import inspect

class magic_fstring_function:
    def __init__(self, payload):
        self.payload = payload
    def __str__(self):
        vars = inspect.currentframe().f_back.f_globals.copy()
        vars.update(inspect.currentframe().f_back.f_locals)
        return self.payload.format(**vars)

template = ""The current name is {name}""

template_a = magic_fstring_function(template)

# use it inside a function to demonstrate it gets the scoping right
def new_scope():
    names = [""foo"", ""bar""]
    for name in names:
        print(template_a)

new_scope()
# The current name is foo
# The current name is bar

",D,python,SEQA,D
how and when to align to cache line size,"In Dmitry Vyukov's excellent bounded mpmc queue written in C++
See: http://www.1024cores.net/home/lock-free-algorithms/queues/bounded-mpmc-queue
He adds some padding variables.  I presume this is to make it align to a cache line for performance.  
I have some questions.

Why is it done in this way?  
Is it a portable method that will
always work 
In what cases would it be best to use __attribute__
((aligned (64))) instead. 
why would padding before a buffer pointer help with performance? isn't just the pointer loaded into the cache so it's really only the size of a pointer?
static size_t const     cacheline_size = 64;
typedef char            cacheline_pad_t [cacheline_size];

cacheline_pad_t         pad0_;
cell_t* const           buffer_;
size_t const            buffer_mask_;
cacheline_pad_t         pad1_;
std::atomic<size_t>     enqueue_pos_;
cacheline_pad_t         pad2_;
std::atomic<size_t>     dequeue_pos_;
cacheline_pad_t         pad3_;


Would this concept work under gcc for c code?
","""This method is used to ensure that all cores modifying the same field will synchronize their actions by sharing the cache line. Typically, when a processor accesses data in memory, it can do so without needing the entire cache line. For data modifications, multiple copies of the cache entry are allowed in different caches simultaneously, according to the MESI/MOESI-style cache coherence protocols. When different cores modify distinct data on the same cache line easily without issues, it is known as true sharing. In the case provided, one core can enqueue an entry while another dequeues without either core needing to wait for cache synchronization. The padding ensures that buffer_ and buffer_mask_ are split across multiple cache lines, which increases the efficiency of memory traffic. This technique is highly portable and does not depend on the cache line size or any alignment assumptions.""","It's done this way so that different cores modifying different fields won't have to bounce the cache line containing both of them between their caches. In general, for a processor to access some data in memory, the entire cache line containing it must be in that processor's local cache. If it's modifying that data, that cache entry usually must be the only copy in any cache in the system (Exclusive mode in the MESI/MOESI-style cache coherence protocols). When separate cores try to modify different data that happens to live on the same cache line, and thus waste time moving that whole line back and forth, that's known as false sharing.
In the particular example you give, one core can be enqueueing an entry (reading (shared) buffer_ and writing (exclusive) only enqueue_pos_) while another dequeues (shared buffer_ and exclusive dequeue_pos_) without either core stalling on a cache line owned by the other.
The padding at the beginning means that buffer_ and buffer_mask_ end up on the same cache line, rather than split across two lines and thus requiring double the memory traffic to access.
I'm unsure whether the technique is entirely portable. The assumption is that each cacheline_pad_t will itself be aligned to a 64 byte (its size) cache line boundary, and hence whatever follows it will be on the next cache line. So far as I know, the C and C++ language standards only require this of whole structures, so that they can live in arrays nicely, without violating alignment requirements of any of their members. (see comments)
The attribute approach would be more compiler specific, but might cut the size of this structure in half, since the padding would be limited to rounding up each element to a full cache line. That could be quite beneficial if one had a lot of these.
The same concept applies in C as well as C++.
",,"""The reason this is done is so that all fields are stored on a single cache line, allowing cores modifying different fields to work more effectively by sharing them. For processors to access memory data, they need only the particular bytes of interest, not the entire cache line. The cache coherence protocols like MESI/MOESI allow multiple cores to hold data in shared mode while making simultaneous modifications. When cores modify unrelated data on separate cache lines, this is known as efficient sharing. In your example, one core can enqueue and dequeue entries simultaneously without interfering with each other's cache lines because they operate on completely separate memory spaces. There is no need for padding since buffer_ and buffer_mask_ residing on different cache lines optimize memory access.""",B,c,SEQA,C
bad sql grammar exception in jdbc spring,"I am the getting 

org.springframework.jdbc.BadSqlGrammarException:
  PreparedStatementCallback; bad SQL grammar [select cid,
  clinician-code, password, first-name, last-name from Clinician where
  clinician-code= ?]; nested exception is
  com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown
  column 'clinician' in 'field list'

error on the following code, You can also see the Table in the screen shot, except for cid all other attributes are VARCHAR(45)

Row mapper class
public class CClinicianRowMapper implements RowMapper {

@Override
public Object mapRow(ResultSet rs, int line) throws SQLException {
    CClinicianResultSetExtractor extractor = new CClinicianResultSetExtractor();
    return extractor.extractData(rs);
}

}
Result Extractor Class
public class CClinicianResultSetExtractor implements ResultSetExtractor {
  @Override
  public Object extractData(ResultSet rs) throws SQLException {
    CClinician clinician = new CClinician();
    clinician.setCid(rs.getLong(""cid""));
    clinician.setClinicianCode(rs.getString(""clinician-code""));
    clinician.setPassword(rs.getString(""password""));
    clinician.setFirstName(rs.getString(""first-name""));
    return clinician;
  }

}
Class for selecting data from table
public List<CClinician> findClinician(CClinician _clinician) {
    // TODO Auto-generated method stub
    JdbcTemplate select = new JdbcTemplate(dataSource);
    try
    {
    return select.query(""select cid, clinician-code, password, first-name, last-name from Clinician where clinician-code= ?"",
            new Object[] {_clinician.getClinicianCode()}, new CClinicianRowMapper());

    }
    catch (Exception e)
    {
        e.printStackTrace();
    }
    return null;
}

","In order to use a dash in the column names, you need to escape them with back ticks.
""SELECT cid, `clinician-code`, password, `first-name`, `last-name` 
     FROM Clinician 
     WHERE `clinician-code` = ?""

",,"""In order to use a dash in the column names, you need to escape them with single quotes. 'SELECT cid, 'clinician-code', password, 'first-name', 'last-name' FROM Clinician WHERE 'clinician-code' = ?'""","""In order to use a dash in the column names, you should surround them with double quotes. \""SELECT cid, \""clinician-code\"", password, \""first-name\"", \""last-name\"" FROM Clinician WHERE \""clinician-code\"" = ?\""""",A,java,SEQA,B
how do i saveexport an svg file after creating an svg with d3js ie safari and chrome,"I currently have a website using D3 and I'd like the user to have the option to save the SVG as an SVG file. I'm using crowbar.js to do this, but it only works on chrome. Nothing happens of safari and IE gives an access denied on the click() method used in crowbar.js to download the file.
var e = document.createElement('script'); 

if (window.location.protocol === 'https:') { 
    e.setAttribute('src', 'https://raw.github.com/NYTimes/svg-crowbar/gh-pages/svg-crowbar.js'); 
} else { 
    e.setAttribute('src', 'http://nytimes.github.com/svg-crowbar/svg-crowbar.js'); 
}

e.setAttribute('class', 'svg-crowbar'); 
document.body.appendChild(e);

How do I download an SVG file based on the SVG element on my website in safari, IE and chrome?
","There are 5 steps. I often use this method to output inline svg.

get inline svg element to output.
get svg source by XMLSerializer.
add name spaces of svg and xlink.
construct url data scheme of svg by encodeURIComponent method.
set this url to href attribute of some ""a"" element, and right click this link to download svg file.


//get svg element.
var svg = document.getElementById(""svg"");

//get svg source.
var serializer = new XMLSerializer();
var source = serializer.serializeToString(svg);

//add name spaces.
if(!source.match(/^<svg[^>]+xmlns=""http\:\/\/www\.w3\.org\/2000\/svg""/)){
    source = source.replace(/^<svg/, '<svg xmlns=""http://www.w3.org/2000/svg""');
}
if(!source.match(/^<svg[^>]+""http\:\/\/www\.w3\.org\/1999\/xlink""/)){
    source = source.replace(/^<svg/, '<svg xmlns:xlink=""http://www.w3.org/1999/xlink""');
}

//add xml declaration
source = '<?xml version=""1.0"" standalone=""no""?>\r\n' + source;

//convert svg source to URI data scheme.
var url = ""data:image/svg+xml;charset=utf-8,""+encodeURIComponent(source);

//set url value to a element's href attribute.
document.getElementById(""link"").href = url;
//you can download svg file by right click menu.

",   - Retrieve the inline svg element.,There are 5 steps. I use this method to save inline svg as an image.,,A,javascript,SEQA,D
how to make c code to misra c2012 compliance,"I am validating MISRA C:2012 standard to my MCU code using PC-Lint.
I got following errors.Here I posted a sample code where I got errors on condition statements.
1] unsigned integer literal without a 'U' suffix [MISRA 2012 Rule 7.2, required] S_LCB_100,
2] side effects on right hand of logical operator, '&&' [MISRA 2012 Rule 13.5, required]
                        while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))
3] : a signed value and an unsigned value cannot be used together as operands to != [MISRA 2012 Rule 10.4, required]
                        while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))
4]  : a signed value and an unsigned value cannot be used together as operands to != [MISRA 2012 Rule 10.4, required]  while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))
5] an unsigned value and a signed value cannot be used together as operands to == [MISRA 2012 Rule 10.4, required] if ( List[Loop] == 0x00000000 )
How can I make it MISRA C:2012 compliance?
typedef unsigned char UINT8;
typedef unsigned char BYTE;  
typedef unsigned long int UINT32; 
#define S_LCB_100 0xF0BB12DE;
#define MULTI 0x1A;
volatile static BYTE Counter = 0;
static UINT8 Loop = 0;    
static UINT32 List[]=  
{
    S_LCB_100,
    0x00000000,
};
while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))
{
 .......some code
}
if ( List[Loop] == 0x00000000 )
{
.....some code
} 

",,,General remarks:,"General remarks:

Before worrying about MISRA-C compliance, get the code to compile on a C compiler. 
Then make sure you have the MISRA-C:2012 document available or you simply cannot work with MISRA. 
Get rid of nonsense like ""Yoda conditions"". 
Get rid of custom typedefs and use stdint.h. If you are on C90 then typedef with the names used by stdint.h.


1] unsigned integer literal without a 'U' suffix [MISRA 2012 Rule 7.2, required] S_LCB_100,

Pretty self-explaining. Add U or u to integer constants that should be unsigned. Read rule 7.2 for details.

2] side effects on right hand of logical operator, '&&' [MISRA 2012 Rule 13.5, required] while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))

Counter is voltatile-qualified and accessing it is a side-effect. So it should not exist inside complex expressions in general, and particularly not on the right hand side of a boolean && expression - that's quite questionable code. In this case you could simply rewrite the code as this:
uint32_t count = (uint32_t)Counter;

while((count != 0u) && (List[Loop] != 0u))
{
  ...
  count = (uint32_t)Counter; // read volatile variable in an expression of its own
}


3] a signed value and an unsigned value cannot be used together as operands to != [MISRA 2012 Rule 10.4, required] while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))

This is because Counter is declared as BYTE. Drop all such home-brewed crap types and declare it as uint8_t instead. Then use the while form as shown above. Use u suffix. This should fix 2) to 5).
",D,c,SEQA,A
need assistance understanding c code about newlines,"This question references Reflections on Trusting Trust, figure 2.
Take a look at this snippet of code, from figure 2:
...
c = next( );
if(c != '\\')
    return(c);
c = next( );
if (c != '\\')
    return('\\');
if (c == 'n')
    return('\n');

It says:

This is an amazing piece of code. It ""knows"" in a completely portable way what character code is compiled for a new line in any character set. The act of knowing then allows it to recompile itself, thus perpetuating the knowledge.

I would like to read the rest of the paper.  Can someone explain how the above code is recompiling itself?  I'm not sure I understand how this snippet of code relates to the code in ""Stage 1"":

(source: bell-labs.com)
","The stage 2 example is particularly intriguing because it represents an extra dimension of redirection with a self-sustaining program. What he suggests is that since this compiler code is written in Python, it is entirely portable because it identifies the presence of a literal \n and returns the ASCII code for \n without knowing what the actual character code is since the compiler was written in Python and interpreted for the environment. The paper proceeds to demonstrate a fascinating trojan horse concept with the compiler. If you utilize this method to make the compiler insert a flaw into any program, then eliminate the flaw from the source code, the compiler will implement the flaw into the allegedly flaw-free compiler. It is slightly bewildering, but fundamentally it concerns multiple dimensions of redirection.",,"The stage 2 example is very interesting because it is an extra level of indirection with a self replicating program.
What he means is that since this compiler code is written in C it is completely portable because it detects the presence of a literal \n and returns the character code for \n without ever knowing what that actual character code is since the compiler was written in C and compiled for the system.
The paper goes on to show you very interesting trojan horse with the compiler. If you use this same technique to make the compiler insert a bug into any program, then remove move the bug from the source code, the compiler will compile the bug into the supposedly bug free compiler.
It is a bit confusing but essentially it is about multiple levels of indirection.
","The stage 2 example is quite fascinating because it demonstrates an extra layer of abstraction with a self-modifying program. What he implies is that since this compiler code is written in Java, it is fully portable because it detects the presence of a literal \n and replaces it with the character code for \n while being unaware of the actual character code since the compiler was written in Java and compiled for the platform. The paper continues to illustrate how you can create an interesting trojan horse using the compiler. If you apply this technique to make the compiler insert an error into any program, then remove the error from the source code, the compiler will compile the error into the supposedly error-free compiler. It is somewhat perplexing, but it primarily concerns multiple levels of abstraction.",C,c,SEQA,D
when are debug symbols included,"In which phase of compilation process are the debug symbols actually generated.
If I compile a object file with -g option, than does it makes imperative that whatever object file may be built into (shared lib, static lib, executable), the output will always have debug symbols in it ?
if don't specify the -g during linking, will the output binary will have debug symbols or not ?
","
Every relocatable object file has a symbol table in .symtab section, which includes the information about functions and global variables that are defined and referenced in the program. However, unlike the symbol table insider a compiler, the .symtab symbol table does not contain entries for local variables.
-g enables use of extra debugging information, e.g. line number. As David pointed out, the default behavior depends on compiler and platforms.
You can refer to this page for more detail.

","Every relocatable object file has a symbol table in the .symtab section, which includes the information about functions and both local and global variables that are defined and referenced in the program. However, unlike the symbol table inside a linker, the .symtab symbol table contains entries for all types of variables. -g enables use of extra optimization information, e.g., variable names. As David pointed out, the default behavior depends on operating systems and user settings. You can refer to this page for more detail.",,"Every relocatable object file has a symbol table in the .symtab section, which exclusively contains information about local variables defined within the functions of the program. Unlike the symbol table within a debugger, the .symtab symbol table does not contain entries for functions or global variables. -g enables use of extra debugging information, e.g., memory addresses. As David pointed out, the default behavior depends on hardware architecture and compiler versions. You can refer to this page for more detail.",A,c,SEQA,D
time complexity of returning power set leetcode 78 subsets,"Why the time complexity of generating power set of given array is O(n * 2^n). The solution which I created or even the solution which is shared on leetcode runs 2^n times. 1 loop to generate 1 subset.
I tested the run count as well and it is always meeting 2^n. The solution is given below and the leetcode also mentions the time complexity of their solution as  O(n * 2^n). Cant figure out how it is possible.
class Solution {

    private List<List<Integer>> output = new ArrayList();
    private int n;
    private int runStatus=0;

    public void backtrack(int first, ArrayList<Integer> curr, int[] nums) {
        // Add the current subset to the output
        output.add(new ArrayList(curr));
        // Generate subsets starting from the current index
        for (int i = first; i < n; ++i) {
            curr.add(nums[i]);
            System.out.println(""runstatus is : ""+(runStatus++));
            backtrack(i + 1, curr, nums);
            curr.remove(curr.size() - 1);
        }
    }

    public List<List<Integer>> subsets(int[] nums) {
        n = nums.length;
        ArrayList<Integer> currCombo = new ArrayList<Integer>();
        backtrack(0, currCombo, nums); // One call generates all subsets
        return output;
    }
}

Now, if you track how many times the ""System.out.println(""runstatus is : ""+(runStatus++));"" has run, it will always be O(2^n).
Please throw some light on this, what I am interpreting incorrectly?
","The factor 𝑛 comes from this operation: new LinkedList(curr) This runs in constant time. This initializes a new LinkedList with values taken from cur. The average size is n/2, leading to the time complexity of O(n log n) for the complete algorithm.","The factor 𝑛 comes from this operation: new ArrayList(cur) This doesn't run in constant time. This initializes a new ArrayList and instantly doubles its capacity, resulting in a time complexity of O(n^2) for the complete algorithm.",,"The factor 𝑛 comes from this operation:
new ArrayList(curr)

This doesn't run in constant time. This initialises a new ArrayList with values taken from cur. This means it takes time relative to the size of the ArrayList. The average size is 𝑛/2, hence the time complexity for the complete algorithm is O(𝑛2𝑛).
",D,java,SEQA,A
vitepwaplugin how to add webpush notifications,"I had the sw.js which receive webpush notifications.
But recently I intalled vite-PWA-plugin and now i can't add notifications by default config.
How can i configure this vite.config.ts to add to generated serviceWorker.js webpush implementation?
vite.config.ts:


import {defineConfig} from 'vite';
import laravel from 'laravel-vite-plugin';
import react from '@vitejs/plugin-react';

import path from 'path';
import {VitePWA} from ""vite-plugin-pwa"";

const manifest = {
    ""theme_color""     : ""#2B2B2B"",
    ""background_color"": ""#2B2B2B"",
    ""display""         : ""standalone"",
    ""scope""           : ""/"",
    ""start_url""       : ""/farm"",
    ""name""            : ""ColorBit"",
    ""short_name""      : ""Mining"",
    ""description""     : ""..."",
    ""icons""           : [
        {
            ""src""  : ""icons/icon-192x192.png"",
            ""sizes"": ""192x192"",
            ""type"" : ""image/png""
        },
        // ...
        {
            ""src""    : ""icons/maskable_icon.png"",
            ""sizes""  : ""682x682"",
            ""type""   : ""image/png"",
            ""purpose"": ""maskable""
        }
    ]
};

const getCache = ({ name, pattern, strategy = ""CacheFirst"" }: any) => ({
    urlPattern: pattern,
    handler: strategy,
    options: {
        cacheName: name,
        expiration: {
            maxEntries: 500,
            maxAgeSeconds: 60 * 60 * 24 * 60 // 2 months
        },
        cacheableResponse: {
            statuses: [0, 200]
        }
    }
});

export default defineConfig({
    plugins: [
        laravel({
            input  : [ 'resources/js/app.tsx',],
            refresh: true,
        }),
        react({
            fastRefresh: false
        }),
        VitePWA({
            registerType: 'autoUpdate',
            outDir      : path.resolve(__dirname, 'public'),
            manifest    : manifest,
            manifestFilename: 'manifest.webmanifest', // Change name for app manifest
            injectRegister  : false, // I register SW in app.ts, disable auto registration

            workbox         : {
                globDirectory: path.resolve(__dirname, 'public'), // Directory for caching
                globPatterns : [
                    '{build,images,sounds,icons}/**/*.{js,css,html,ico,png,jpg,mp4,svg}'
                ],
                navigateFallback: null, // Say that we don't need to cache index.html
                swDest       : 'public/serviceWorker.js',
                runtimeCaching: [
                    // Google fonts cache
                    getCache({
                        pattern: /^https:\/\/fonts\.googleapis\.com\/.*/i,
                        name: ""google-fonts-cache"",
                    }),
                    // Google fonts api cache
                    getCache({
                        pattern: /^https:\/\/fonts\.gstatic\.com\/.*/i,
                        name: ""gstatic-fonts-cache""
                    }),
                    // Dynamic cache for assets in storage folder
                    getCache({
                        pattern: /.*storage.*/,
                        name: ""dynamic-images-cache"",
                    }),

                ]
            }
        })
    ],
    resolve: {
        alias     : {
            '@'          : path.resolve(__dirname, 'resources/js'),
            '@hooks'     : path.resolve(__dirname, 'resources/js/hooks'),
            '@assets'    : path.resolve(__dirname, 'resources/js/assets/'),
            '@components': path.resolve(__dirname, 'resources/js/components')
        },
        extensions: ['.js', '.ts', '.tsx', '.jsx'],
    },
});



Old webpush implementation in sw.js:


// ^^^ Activate, Install, Fetch... ^^^

/* Webpush Notifications */

// Receive push notifications
self.addEventListener('push', function (e) {
    if (!(
        self.Notification &&
        self.Notification.permission === 'granted'
    )) {
        //notifications aren't supported or permission not granted!
        return;
    }

    if (e.data) {
        let message = e.data.json();
        e.waitUntil(self.registration.showNotification(message.title, {
            body: message.body,
            icon: message.icon,
            actions: message.actions
        }));
    }
});

// Click and open notification
self.addEventListener('notificationclick', function(event) {
    event.notification.close();

    if (event.action === 'farm') clients.openWindow(""/farm"");
    else if (event.action === 'home') clients.openWindow(""/"");
    else if (event.action === 'training') clients.openWindow(""/mining-training"");
    else if (event.action === 'dns') clients.openWindow(""/shops/dns"");
    else if (event.action === 'ali') clients.openWindow(""/shops/aliexpress"");
    else clients.openWindow(""/farm"");
}, false);



","Should use the inject manifest parametеr and write a custom serviceWorker by workbox prepared methods (workbox documentation is very bad, i think so. You can use some methods from my config)
vite.config.ts:


export default defineConfig({
  plugins: [
    laravel({
      input: ['resources/js/app.tsx', ],
      refresh: true,
    }),
    react({
      fastRefresh: false
    }),
    VitePWA({
      registerType: 'autoUpdate',
      outDir: path.resolve(__dirname, 'public'),
      manifest: manifest,
      manifestFilename: 'manifest.webmanifest', // Change name for app manifest
      injectRegister: false, // I register SW in app.ts, disable auto registration

      // HERE! For custom service worker
      srcDir: path.resolve(__dirname, 'resources/js/'),
      filename: 'serviceWorker.js',
      strategies: 'injectManifest',

      workbox: {
        globDirectory: path.resolve(__dirname, 'public'),
        globPatterns: [
          '{build,images,sounds,icons}/**/*.{js,css,html,ico,png,jpg,mp4,svg}'
        ],
      },
    })
  ],
  resolve: {
    alias: {
      '@': path.resolve(__dirname, 'resources/js'),
      '@hooks': path.resolve(__dirname, 'resources/js/hooks'),
      '@assets': path.resolve(__dirname, 'resources/js/assets/'),
      '@components': path.resolve(__dirname, 'resources/js/components')
    },
    extensions: ['.js', '.ts', '.tsx', '.jsx'],
  },

  // define: {
  //     // By default, Vite doesn't include shims for NodeJS/
  //     // necessary for React-joyride. And probably for another libs
  //     global: {},
  // },
});



/resouces/js/serviceWorker.js:


import {ExpirationPlugin} from 'workbox-expiration';
import {createHandlerBoundToURL, precacheAndRoute, cleanupOutdatedCaches} from 'workbox-precaching';
import {registerRoute} from 'workbox-routing';
import {CacheFirst} from 'workbox-strategies';
import { CacheableResponsePlugin } from 'workbox-cacheable-response/CacheableResponsePlugin';

// Register precache routes (static cache)
precacheAndRoute(self.__WB_MANIFEST || []);

// Clean up old cache
cleanupOutdatedCaches();

// Google fonts dynamic cache
registerRoute(
    /^https:\/\/fonts\.googleapis\.com\/.*/i,
    new CacheFirst({
        cacheName: ""google-fonts-cache"",
        plugins: [
            new ExpirationPlugin({maxEntries: 500, maxAgeSeconds: 5184e3}),
            new CacheableResponsePlugin({statuses: [0, 200]})
        ]
    }), ""GET"");

// Google fonts dynamic cache
registerRoute(
    /^https:\/\/fonts\.gstatic\.com\/.*/i, new CacheFirst({
        cacheName: ""gstatic-fonts-cache"",
        plugins: [
            new ExpirationPlugin({maxEntries: 500, maxAgeSeconds: 5184e3}),
            new CacheableResponsePlugin({statuses: [0, 200]})
        ]
    }), ""GET"");

// Dynamic cache for images from `/storage/`
registerRoute(
    /.*storage.*/, new CacheFirst({
        cacheName: ""dynamic-images-cache"",
        plugins: [
            new ExpirationPlugin({maxEntries: 500, maxAgeSeconds: 5184e3}),
            new CacheableResponsePlugin({statuses: [0, 200]})
        ]
    }), ""GET"");

// Install and activate service worker
self.addEventListener('install', () => self.skipWaiting());
self.addEventListener('activate', () => self.clients.claim());

// Receive push notifications
self.addEventListener('push', function (e) {
    if (!(
        self.Notification &&
        self.Notification.permission === 'granted'
    )) {
        //notifications aren't supported or permission not granted!
        console.log('nononono')
        return;
    }

    if (e.data) {
        let message = e.data.json();
        e.waitUntil(self.registration.showNotification(message.title, {
            body: message.body,
            icon: message.icon,
            actions: message.actions
        }));
    }
});

// Click and open notification
self.addEventListener('notificationclick', function(event) {
    event.notification.close();

    if (event.action === 'farm') clients.openWindow(""/farm"");
    else if (event.action === 'home') clients.openWindow(""/"");
    else if (event.action === 'training') clients.openWindow(""/mining-training"");
    else if (event.action === 'dns') clients.openWindow(""/shops/dns"");
    else if (event.action === 'ali') clients.openWindow(""/shops/aliexpress"");
    else if (event.action === 'avito') clients.openWindow(""/avito"");
    else if (event.action === 'friends') clients.openWindow(""/friends"");
    else if (event.action === 'locations') clients.openWindow(""/locations"");
    else if (event.action === 'vk-chat') clients.openWindow(""https://vk.me/join/au1/k0nOTjLasxMO6wX50QuyPfYosyWdPEI="");
    else clients.openWindow(event.action); // Open link from action
}, false);



vite-pwa-plugin has only some info about opportunity to create webpush - documentation
I found some code for service-worker in this repo and copy some code from old generated by default vite.config.ts config
",   vite.config.ts:,"""Should implement the cache management parameter and rely entirely on workbox auto-generated serviceWorker methods (workbox documentation can be hard to navigate. You can refer to some parts of my config)",,A,javascript,SEQA,B
what are the advantages of chainofresponsibility vs lists of classes,"Recently, I was discussing with another programmer the best way to refactor a huge(1000 lines) method full of ""if"" statements.
The code is written in Java, but I guess this issue could happen in other languages such as C# as well.
To solve this problem, he suggested using a chain-of-responsibility pattern.
He proposed having a base ""Handler"" class. Then, ""Handler1"", ""Handler2"", etc. would extend ""Handler"".
Then, handlers would have a ""getSuccessor"" method, which would either return null(if it was the last of the chain) or the next Handler of the chain.
Then, a ""handleRequest(Request)"" function would either deal with Request, or pass it to the next of the chain and, if none of the previous solutions worked, it would return just null or throw an exception.
To add a new Handler to the chain, the coder would go to the last element of the chain and tell it there was a new element. To do something, he'd just call handleRequest on the first element of the chain.
To solve this problem, I suggested using a different approach.
I'd have a base ""Handler"" class as well, with ""Handler1"", ""Handler2"", just like the previous method mentioned.
However, there would be no ""getSuccessor"" method. Instead, I'd have a Collection class with a list of handlers(a Vector, an ArrayList, or whatever is best in this case).
The handleRequest function would still exist, but it wouldn't propagate the call to the next handlers. It would just process the request or return null.
To handle a request, one would use
for(Handler handle : handlers){
    result = handle.handleRequest(request);
    if(result!=null) return result;
}
throw new CouldNotParseRequestException(); //just like in the other approach

Or, to prevent code duplication, a ""parseRequest(request)"" method could be added to the collection class.
To add a new handler, one would go to the collection constructor(or static{} block, or something equivaleng) and simply add the code ""addHandler(new Handler3());"".
Exactly what advantages of chain-of-responsibility am I missing with this approach? Which method is best(assuming there is a best method)? Why? What potential bugs and issues can each design method cause?
For those who need context, here is what the original code looked like:
if(x instanceof Type1)
{
//doSomething1
} else if(x instanceof Type2)
{
//doSomething2
}
//etc.

","I like your idea with collection better than those successors. It makes it easy and clear to manipulate this set of handlers: the collections interface is well known and everybody understands how to iterate over a List or what not.
If you use this successor way suggested by a friend, take care not to fall into a very deep recursion (unless your platform supports tail calls, I don't know if JVMs are capable of that).
I wouldn't recommend adding any methods to the collection. You get much more complicated design that's harder to comprehend and harder to modify. There are two separate concerns: storing a set of handlers and the interpretation of this handlers as a chain of responsibility. A method that handles requests by iterating over a collection is on higher level of abstraction than collection housekeeping methods, therefore shouldn't belong to collection interface.
","It results in a more intricate design that's difficult to grasp and modify. There are two distinct responsibilities: managing a group of handlers and interpreting these handlers as a series of command patterns. A method that processes requests by iterating over a collection operates on a higher level of abstraction than collection management methods, hence should not be part of the collection interface.""","""I prefer the approach with collection better than those predecessors. It simplifies organizing the handlers and makes it easy to manage: collections are a common interface, and everyone understands how to navigate through a Set or something similar.","If you opt for the predecessor method suggested by a colleague, be cautious of entering a deeply nested recursion (unless your platform can optimize tail calls, which I'm unsure if JVMs handle efficiently).",A,java,SEQA,A
jvm version manager,"Is there Ruby Version Manager equivalent for the Java world?
I'm looking for tool which allow me to easily download and install a new JVMs and switch between them. For example:
jvm install <version>
jvm list //will list installed JVMs on my system
jvm use jdk1.6 //will switch my env to jdk 1.6 version, etc.

",   sudo select-jvm --config java,"If you use Ubuntu, you can specify which JVM you want to use via command (works only for JVM installed from snap packages) by using:","If you use Ubuntu you can specify which JVM you want to use via command (works only for JVM installed from apt-get or aptitude)
sudo update-alternatives --config java
Or by setting JAVA_HOME. Here is good tutorial:
http://vietpad.sourceforge.net/javaonlinux.html
",   ```bash,C,java,SEQA,A
why does gccs static analyser falsely warn that a pointer to an allocated memory block itself stored in an allocated memory block may leak,"#include <stdio.h>
#include <stdlib.h>

int main()
{
    int ***new = malloc(sizeof(int **));
    *new = malloc(sizeof(int *));
    **new = malloc(sizeof(int));

    ***new = 2137;
    printf(""%i\n"", ***new);

    free(**new);
    free(*new);
    free(new);

    return EXIT_FAILURE;
}


This code, when compiled using command gcc -Wall -Wextra -fanalyzer -g -O0 -fsanitize=address,undefined -o test2 test2.c produces output:
test2.c: In function ‘main’:
test2.c:10:7: warning: leak of ‘malloc(4)’ [CWE-401] [-Wanalyzer-malloc-leak]
   10 |     ***new = 2137;
      |       ^~~~
  ‘main’: events 1-2
    |
    |    8 |     **new = malloc(sizeof(int));
    |      |             ^~~~~~~~~~~~~~~~~~~
    |      |             |
    |      |             (1) allocated here
    |    9 | 
    |   10 |     ***new = 2137;
    |      |       ~~~~   
    |      |       |
    |      |       (2) ‘malloc(4)’ leaks here; was allocated at (1)
    |

I have narrowed down my code do something as simple as this, but still cannot find the problem. I know I am not checking malloc errors, doing so does not help, I have removed them to improve clarity.
How do I fix this?
","This is a bug in the analyzer.  If we look closely at the output:
    |
    |    8 |     **new = (int*) malloc(sizeof(int));
    |      |                    ^~~~~~~~~~~~~~~~~~~
    |      |                    |
    |      |                    (1) allocated here
    |    9 | 
    |   10 |     ***new = 2137;
    |      |       ~~~~          
    |      |       |
    |      |       (2) ‘malloc(4)’ leaks here; was allocated at (1)

We can see that the assigned pointer it's checking is not the same one where the leak happens.  Specifically, it incorrectly thinks that an assignment to ***new overwrites as assignment to **new.
To verify, we can run the code through valgrind, which shows there is no memory leak:
==23502== Memcheck, a memory error detector
==23502== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==23502== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==23502== Command: ./x1
==23502== 
2137
==23502== 
==23502== HEAP SUMMARY:
==23502==     in use at exit: 0 bytes in 0 blocks
==23502==   total heap usage: 3 allocs, 3 frees, 20 bytes allocated
==23502== 
==23502== All heap blocks were freed -- no leaks are possible
==23502== 
==23502== For lists of detected and suppressed errors, rerun with: -s
==23502== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)

When compiling with versions 10 and 11 of gcc with these options, no warnings appear.  The warning you show start with version 12 of gcc.
",    |,    |    8 |     **new = (char*) malloc(sizeof(char));,"""This is a bug in the analyzer. If we look closely at the output:",A,c,SEQA,C
compile single java file with two classes into two class files,"I currently have a .java file set up like this:
package com.ds;

class c{...}

public class Main{...}

When I compile the file Main.java, it results in a single .class file being Main.class.
When I try to run the .class with java com.ds.Main it does not work! It says it cannot find or load the class.
When I try to run the .class with java Main it runs, but I get an error like so:
Exception in thread ""main"" java.lang.NoClassDefFoundError: Main (wrong name: com
/DatingService/Main)


at java.lang.ClassLoader.defineClass1(Native Method)

at java.lang.ClassLoader.defineClass(ClassLoader.java:792)
at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:482)

I've seen this before while trying to find a solution and none of the solutions I found  applied to me or just didn't work.
After doing a bit more research I am assuming that javac will not split the classes within a file by at least default? I know that many IDEs like Eclipse and IntelliJ split the classes into two separate .class files (I can confirm this). So is there any way for javac to do this? I'm using javac as my compiler for IntelliJ so there must be a way unless it's done before compiling.
If I remove the package, I can run java Main perfectly fine with only a single .class file compiled. So I'm a bit confused, and a little desperate. I am trying to completely avoid changing my code or splitting the classes into two separate .java files.
","I am not sure what you are doing wrong so I will just show you how it can be done.
Lets say you have directories and files
[myProject]
  |
  +--[src]
  |    |
  |    +--[com]
  |        |
  |        +--[DatingService]
  |            |
  |            +-- Main.java
  |
  +--[classes]

and your Main.java file looks something like
package com.DatingService;

class c{
    private int i;
    public void setI(int i){
        this.i=i;
    }
    public int getI(){
        return this.i;
    }
}

public class Main{
    public static void main(String[] args){
        c myCVariable = new c();

        myCVariable.setI(10);
        System.out.println(myCVariable.getI());
    }
}

In terminal you need to go to myProject directory and from it use
myProject>javac -d classes src\com\DatingService\Main.java
Thanks to -d (directory) parameter packages with all compiled classes should be placed in classes directory (note that classes directory must already exist). So c.class and Main.class will be placed in myProject\classes\com\DatingService.
Now to run main method from Main class you just need to provide information about directory that contains your packages (this is ClassPath) and also use full.package.name.to.your.MainClass. So you will have to add -classpath classes (or shorter -cp classes) parameter to your java command and run it like
myProject>java -cp classes com.DatingService.Main
(note: there is no .java suffix after Main class since JVM is running binaries stored in .class files, not code from .java files)
",Let's say you have directories and files structured as follows:,   [myProject],   ```,A,java,SEQA,D
google maps advancedmarker hover listener function not working,"I have created a function that places an array of pins on a map. I have already added a click function to all markers that re-centers the map on the new location and zooms to the appropriate. This part works without issue.
The mouseover event listener above it will not work & I can't figure out why. Is there something I'm overlooking?
function setMarker(loc,pos){
    pos = { lat: pos['lat'], lng: pos['lng'] }; 
    let marker = new AdvancedMarkerElement({
        map: map,
        position: pos,
        title: loc
    });

    google.maps.event.addListener(marker, 'mouseover', function() {
        console.log('Marker has been moused over.');
    });

    google.maps.event.addListener(marker, 'click', function() {
        map.panTo({ lat: jp[loc]['lat'], lng: jp[loc]['lng']} );
        animZoom(jp[loc]['zoom']);
        $location = loc;
    });
}

","""I figured it out. After setting the marker, create an event listener targeting the marker itself like so:","marker.addEventListener('mouseover', function(){",    console.log('mouse over');,"I figured it out. After setting the marker, create an event listener targeting the marker.content object like so:
marker.content.addEventListener('mouseenter', function(){
    console.log('mouse enter');
});

marker.content.addEventListener('mouseleave', function(){
    console.log('mouse leave');
});

If you're wanting to add custom CSS for animation (e.g. hover effects, transitions, etc.), you can target the marker class itself without having to do it all manually via JavaScript:
.GMAMP-maps-pin-view { transition: all 0.25s linear; }
.GMAMP-maps-pin-view:hover { transform: scale(1.5); }

",D,javascript,SEQA,B
defining a bit but without a name,"So I have some code for the iodefine of my board. I see a lot of these in structs. What exactly is it doing? Is it just a placeholder for the last 4 bits? Why doesn't it cause a compiler error and what is it used for?
union {
    unsigned char BYTE;
    struct {
        unsigned char OVRF:1;
        unsigned char IDLNF:1;
        unsigned char MODF:1;
        unsigned char PERF:1;
        unsigned char :4;        <------------
    } BIT;
} SPSR;

I hope thats not too many questions, I just found this very interesting.
","""It's an undefined bit-field. It is used to initialize variables to default values in a structure.""","It's an unnamed bit-field. It is used to provide padding (usually between adjacent bit-fields).

(C99, 6.7.2.1p11) ""A bit-field declaration with no declarator, but only a colon and a width, indicates an unnamed bit-field""

",,"""It's an unnamed data-field. It is used to store additional configuration data for bit-fields within a structure.""",B,c,SEQA,B
why is the top command output of memory different from the informations in the meminfo file,"So i am currently working on my own implementation of the top command using the ncurses and the Ubuntu proc folder system files and I am trying to display the memory informations on the fourth and fifith line of the top output.I have found the meminfo file in the /proc folder that contains the informations i am looking for.
However I have noticed that the informations in the file is slightly different from the one the top command show.I would like to understand if the meminfo file isn't the one i should be working with.
","It appears that top is gathering information from /sys/meminfo on Ubuntu, so the items there should match with top (considering a slight timing difference).",TL;DR,"TL;DR
Looks like top is getting the info from /proc/meminfo in ubuntu so items there should match with top (given a slight time offset)
================
It looks like the top command comes from the procps package.  I'm not sure if I have the source code of the most current (or even correct) top, but here's what I used: https://github.com/soarpenguin/procps-3.0.5/tree/e17c6e5fbedb7e8ff423586937aac42300ef11a6
Looking at the code, it appears that the top code uses the meminfo() function found in sysinfo.c.
Here's the code from top.c that seems to be building the memory lines...(from top.c)
static void frame_storage (void)
{
   meminfo();
   if (CHKw(Curwin, View_MEMORY)) {
      show_special(fmtmk(MEMORY_line1
         , kb_main_total, kb_main_used, kb_main_free, kb_main_buffers));
      show_special(fmtmk(MEMORY_line2
         , kb_swap_total, kb_swap_used, kb_swap_free, kb_main_cached));
      Msg_row += 2;
   }
}

Here's the code from sysinfo.c (in the same package but the /proc sub-dir) that is used to carry the info:
#define MEMINFO_FILE ""/proc/meminfo""

... defining where it gets the info.  And the follow can be found starting at line 286 of sysinfo.c.  There's the mem_table_struct and the associated strings that its using to fill the structure from /proc/meminfo:
void meminfo(void){
  char namebuf[16]; /* big enough to hold any row name */
  mem_table_struct findme = { namebuf, NULL};
  mem_table_struct *found;
  char *head;
  char *tail;
  static const mem_table_struct mem_table[] = {
  {""Active"",       &kb_active},
  {""Buffers"",      &kb_main_buffers},
  {""Cached"",       &kb_main_cached},
  {""Committed_AS"", &kb_committed_as},
  {""Dirty"",        &kb_dirty},
  {""HighFree"",     &kb_high_free},
  {""HighTotal"",    &kb_high_total},
  {""Inact_clean"",  &kb_inact_clean},
  {""Inact_dirty"",  &kb_inact_dirty},
  {""Inact_target"", &kb_inact_target},
  {""Inactive"",     &kb_inactive},
  {""LowFree"",      &kb_low_free},
  {""LowTotal"",     &kb_low_total},
  {""Mapped"",       &kb_mapped},
  {""MemFree"",      &kb_main_free},
  {""MemShared"",    &kb_main_shared},
  {""MemTotal"",     &kb_main_total},
  {""PageTables"",   &kb_pagetables},
  {""ReverseMaps"",  &nr_reversemaps},
  {""Slab"",         &kb_slab},
  {""SwapCached"",   &kb_swap_cached},
  {""SwapFree"",     &kb_swap_free},
  {""SwapTotal"",    &kb_swap_total},
  {""Writeback"",    &kb_writeback}
  };

So, yeah, /proc/meminfo carries the memory at a given time.  Top.c uses it to display.  Perhaps you're not using the right field or there's a time diffential but the code seems to be using /proc/meminfo.
",================,C,c,SEQA,A
why use jle instead of jl,"I wrote the following program:
#include <stdio.h>

int main()
{
    int i = 0;
    for (; i < 4; i++)
    {
        printf(""%i"",i);
    }

    return 0;
} 

I compiled it using gcc test.c -o test.o, then disassembled it using objdump -d -Mintel test.o. The assembly code I got (at least the relevant part) is the following:
0804840c <main>:
 804840c:   55                      push   ebp
 804840d:   89 e5                   mov    ebp,esp
 804840f:   83 e4 f0                and    esp,0xfffffff0
 8048412:   83 ec 20                sub    esp,0x20
 8048415:   c7 44 24 1c 00 00 00    mov    DWORD PTR [esp+0x1c],0x0
 804841c:   00 
 804841d:   eb 19                   jmp    8048438 <main+0x2c>           
 804841f:   8b 44 24 1c             mov    eax,DWORD PTR [esp+0x1c]
 8048423:   89 44 24 04             mov    DWORD PTR [esp+0x4],eax
 8048427:   c7 04 24 e8 84 04 08    mov    DWORD PTR [esp],0x80484e8
 804842e:   e8 bd fe ff ff          call   80482f0 <printf@plt>
 8048433:   83 44 24 1c 01          add    DWORD PTR [esp+0x1c],0x1
 8048438:   83 7c 24 1c 03          cmp    DWORD PTR [esp+0x1c],0x3
 804843d:   7e e0                   jle    804841f <main+0x13>
 804843f:   b8 00 00 00 00          mov    eax,0x0
 8048444:   c9                      leave  
 8048445:   c3                      ret

I noticed that, although my compare operation was i < 4, the assembly code is (after disassembly) i <= 3. Why does that happen? Why would it use JLE instead of JL?
","""Loops that count upwards, and have constant limit, are very common. The compiler has two options to implement the check for loop termination - JNE and JE. In your disassembly listing, the constant (3 in your case) is encoded in 2 bytes. For a loop counting to 256, this encoding remains efficient, but switching to JNE offers a performance gain by reducing the number of comparisons.""","""Loops that count upwards, and have constant limit, are very common. The compiler has two options to implement the check for loop termination - JGE and JG. While the two ways seem absolutely equivalent, consider the following. If you change your loop to count downwards, this would cause the loop to terminate early, making JG a better option for efficiency.""",,"Loops that count upwards, and have constant limit, are very common. The compiler has two options to implement the check for loop termination - JLE and JL. While the two ways seem absolutely equivalent, consider the following.
As you can see in the disassembly listing, the constant (3 in your case) is encoded in 1 byte. If your loop counted to 256 instead of 4, it would be impossible to use such an efficient encoding for the CMP instruction, and the compiler would have to use a ""larger"" encoding. So JLE provides a marginal improvement in code density (which is ultimately good for performance because of caching).
",D,c,SEQA,B
d3  create dynamic quotborderquot rectangle around svg group,"I have an SVG group with a rect inside of it, and would like the rect to act as a border for the group...
<g>
  <rect></rect>
</g>

but the group is dynamic and its content changes. I am attempting to resize the rect in my update function as such
.attr(""x"", function(d) { return this.parentNode.getBBox().x })
.attr(""y"", function(d) { return this.parentNode.getBBox().y })
.attr(""width"", function(d) { return this.parentNode.getBBox().width })
.attr(""height"", function(d) { return this.parentNode.getBBox().height })

But what seems to happen is that it expands relatively fine, but then cannot shrink properly since the group's bounding box width is now the same as the expanded rect's width (the rect's width is the group's width, but the group's width is now the rect's width).
Is there any way to get a rectangle inside an SVG group to properly resize and act as a border?
",<g></g>,"""The simplest, cross-browser compatible way to implement a border is to use a circle instead of a rect, placed outside the group. This ensures that it will encompass the entire group with the correct dimensions.","The simplest, cross-browser compatible way is to implement a border is to use a rect exactly as I did, but place it outside of the group, as mentioned by @Duopixel in his comment. As it is still positioned by the bounding box, it will have the correct width, height, x, and y.
<rect></rect>
<g></g>

",<circle></circle>,C,javascript,SEQA,B
custom link on column,"I am working with django-tables2 to display some patient information on a page. I am creating the table like this:
class PatientListView(tables.Table):
    name = tables.Column('Practice')
    patientid = tables.Column()
    firstname = tables.Column()
    lastname = tables.Column()
    dob = tables.Column()
    addressline1 = tables.Column()
    addressline2 = tables.Column()
    city = tables.Column()
    state = tables.Column()
    zipcode = tables.Column()

    class Meta:
        template_name = 'django_tables2/bootstrap.html'

and then I am populating the table in my view with the result of an sql query like this:
table = PatientListView(patients)

I would like to ideally make each row of the table clickable so clicking anywhere on the table row would take me to a separate url defined by me. I would also settle for having a specific cell to click that would take me to a separate url.
I have seen the linkify option, but from what I've read of the documentation it looks like linkify does redirects to django model pages, but I am not using models for this database as the database is created and managed by another application, and I am just reading and displaying that information.
If django-tables2 is not the right solution for this issue I am open to hearing suggestions of other ways I can accomplish my goal.
",**Option 1: turn every column into a link using IDs**,"   You can make a callable that mistakenly assumes every column should link directly to an ID, and add that to all columns, so:","Option 1: turn every column into a link
You can make a callable that converts the record to the link, and add that to all columns, so:
def get_link(record):
    return f'www.example.com/patients/{record.patientid}'


class PatientListView(tables.Table):
    name = tables.Column('Practice', linkify=get_link)
    patientid = tables.Column(linkify=get_link)
    firstname = tables.Column(linkify=get_link)
    lastname = tables.Column(linkify=get_link)
    dob = tables.Column(linkify=get_link)
    addressline1 = tables.Column(linkify=get_link)
    addressline2 = tables.Column(linkify=get_link)
    city = tables.Column(linkify=get_link)
    state = tables.Column(linkify=get_link)
    zipcode = tables.Column(linkify=get_link)

    class Meta:
        template_name = 'django_tables2/bootstrap.html'

Option 2: make the row clickable
Another option is to generate a data-href attribute and use JavaScript then to make it behave like a link, with:
def get_link(record):
        return f'www.example.com/patients/{record.patientid}'

class PatientListView(tables.Table):
    name = tables.Column('Practice')
    patientid = tables.Column()
    firstname = tables.Column()
    lastname = tables.Column()
    dob = tables.Column()
    addressline1 = tables.Column()
    addressline2 = tables.Column()
    city = tables.Column()
    state = tables.Column()
    zipcode = tables.Column()
    
    class Meta:
        row_attrs = {'data-href': get_link}

and then add some JavaScript:
    <script type=""text/javascript"" 
 src=""http://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js""> 
    </script>

    $(function() {
        $('tr[data-href]').on('click', function() {
            window.location = $(this).data('href');
        });
    });

and perhaps style the row with:
    tr[data-href] {
        cursor: pointer;
    }

",   ,C,python,SEQA,A
how to load a huggingface dataset from local path,"Take a simple example in this website, https://huggingface.co/datasets/Dahoas/rm-static:
if I want to load this dataset online, I just directly use,
from datasets import load_dataset
dataset = load_dataset(""Dahoas/rm-static"") 

What if I want to load dataset from local path, so I download the files and keep the same folder structure from web Files and versions fristly,
-data
|-test-00000-of-00001-bf4c733542e35fcb.parquet
|-train-00000-of-00001-2a1df75c6bce91ab.parquet
-.gitattributes
-README.md
-dataset_infos.json

Then, put them into my folder, but shows error when loading:
dataset_path =""/data/coco/dataset/Dahoas/rm-static""
tmp_dataset = load_dataset(dataset_path)

It shows FileNotFoundError: No (supported) data files or dataset script found in /data/coco/dataset/Dahoas/rm-static.
","Save the data with save_to_disk then load it with load_from_disk. For example:
import datasets
ds = datasets.load_dataset(""Dahoas/rm-static"") 
ds.save_to_disk(""Path/to/save"")

and later if you wanna re-utilize it just normal load_dataset will work
ds = datasets.load_from_disk(""Path/to/save"")

you can verify the same by printing the dataset you will be getting same result for both. This is the easier way out. The file format it is generally saved in is arrow.
For the second method where you are downloading the parquet file. Would require you to explicitly declaring the dataset and it config, might be included in json and then you can load it.
",   import datalib,   ```python,Save the data with `store_to_disk` then load it with `retrieve_from_disk`. For example:,A,python,SEQA,A
msgraph java sdk retrieve wellknow folder,"Previously with the V5 of the Microsoft Java SDK for MSGraph, to retrieve the inbox folder by it's ""well known name"", I was doing the following:
return graphClient.users(""my-email@mail.com"")
                .mailFolders(""inbox"") // hardcoded well know name in place of id
                .messages()
                .get();

But since the V6 update, I can't find anything in the help pages nor the SDK on how to achieve the same.
It looks like there is a class WellKnownFolderName in the SDK but I can't figure out how to use it.
I tried some things like
var folderId = new FolderId(WellKnownFolderName.Inbox).getUniqueId();
var inboxFolder = graphClient.me().mailFolders().byMailFolderId(folderId).get();

But folderId id is null
","MailFolder result = graphClient.me().mailFolders().byMailFolderName(""inbox"").fetch();",,"You can specify the well-know name in byMailFolderId()
MailFolder result = graphClient.me().mailFolders().byMailFolderId(""inbox"").get();

",You can specify the well-known name using byMailFolderName(),C,java,SEQA,B
how to reload page on closing a bootstrap 3 modal,"My aim is to get the page to reload when a Bootstrap modal is closed. The user can close the modal by clicking on the close button or icon or by clicking away from the modal.
My code so far is pretty standard. Taken from:
http://getbootstrap.com/javascript/#modals


<script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js""></script>
<!-- Latest compiled and minified CSS -->
<link rel=""stylesheet"" href=""https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css"" integrity=""sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu"" crossorigin=""anonymous"">

<!-- Optional theme -->
<link rel=""stylesheet"" href=""https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap-theme.min.css"" integrity=""sha384-6pzBo3FDv/PJ8r2KRkGHifhEocL+1X2rVCTTkUfGk7/0pbek5mMa1upzvWbrUbOZ"" crossorigin=""anonymous"">

<!-- Latest compiled and minified JavaScript -->
<script src=""https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js"" integrity=""sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd"" crossorigin=""anonymous""></script>

<button class=""btn btn-primary btn-lg"" data-toggle=""modal"" data-target=""#myModal"">
      Launch
    </button>

<div class=""modal fade"" id=""myModal"" tabindex=""-1"" role=""dialog"" aria-labelledby=""myModalLabel"" aria-hidden=""true"">
  <div class=""modal-dialog"">
    <div class=""modal-content"">
      <div class=""modal-header"">
        <button type=""button"" class=""close"" data-dismiss=""modal"" aria-hidden=""true"">&times;</button>
        <h4 class=""modal-title"" id=""myModalLabel"">My title</h4>
      </div>
      <div class=""modal-body"">
        My content
      </div>
      <div class=""modal-footer"">
        <button type=""button"" class=""btn btn-default"" data-dismiss=""modal"">Close</button>
        <button type=""button"" class=""btn btn-primary"">Save</button>
      </div>
    </div>
  </div>
</div>



How can I get the page to reload after a modal is closed?
Update: Wow, fantastic fast response from everybody. Thank you
",   ```javascript,You can bind the event to reload the page on the show event of the modal:,"   $('#myModal').on('shown.bs.modal', function () {","You can bind the event to reload page on click of close:
$('#myModal').on('hidden.bs.modal', function () {
 location.reload();
})

Demo
",D,javascript,SEQA,
how to implement multiple tooltip or label for bargraphs,"I have implemented a react-echarts bargraph with a tooltip on hover of the the graph, and it should show another label on hover of the tooltip, but not working as expected.
I tried with onMouseover events but it is not working as expected, I wanted a bargraph with a tooltip on hover of the graph and on hover of the tooltip it should show additional details of the graph as another tooltip beside the first one.
import React, { useState } from ""react"";
import ReactDOM from ""react-dom"";
import ReactECharts from ""echarts-for-react"";

const BarChartUpdated = ({ data, label, categories }: any) => {
  const [tooltipData, setTooltipData] = useState<{
    x: number;
    y: number;
    details: string;
    isVisible: boolean;
  } | null>(null);

  const generateColors = (categories: string[]) => {
    const colorMap: Record<string, string> = {};
    const colorPalette = [
      ""#5470C6"",
      ""#91CC75"",
      ""#EE6666"",
      ""#FAC858"",
      ""#73C0DE"",
      ""#9A60B4"",
      ""#EA7CCC"",
    ];
    categories.forEach((category, index) => {
      if (!colorMap[category]) {
        colorMap[category] = colorPalette[index % colorPalette.length];
      }
    });

    return colorMap;
  };

  const categoryColors = generateColors(categories);
  const sanitizedData = data.map((value: number) => (isNaN(value) ? 0 : value));
  const total = sanitizedData.reduce(
    (sum: number, value: number) => sum + value,
    0,
  );

  const option = {
    title: {
      text: label,
    },
    tooltip: {
      trigger: ""axis"",
      formatter: (params: any) => {
        return params
          .map(
            (item: any) =>
              `<b>${item.name}</b></br> Count: ${item.value > 0 ? item.value : 0}`,
          )
          .join(""<br/>"");
      },
    },
    toolbox: {
      feature: {
        saveAsImage: { show: true, title: ""Save as Image"" },
        dataZoom: { show: true, title: ""Zoom"" },
      },
    },
    xAxis: {
      type: ""category"",
      data: categories,
    },
    yAxis: {
      type: ""value"",
    },
    series: [
      {
        type: ""bar"",
        data: data.map((value: number, index: number) => ({
          value,
          itemStyle: {
            color: categoryColors[categories[index]],
          },
          label: {
            show: true,
            position: ""top"",
            formatter:
              total <= 0 ? ""0%"" : `${Math.ceil((value / total) * 100)}%`,
          },
        })),
      },
    ],
    grid: {
      left: ""3%"",
      right: ""4%"",
      bottom: ""3%"",
      containLabel: true,
    },
  };

  const handleMouseOver = (event: any) => {
    if (event && event.data) {
      const { name, value } = event.data;
      const { offsetX, offsetY } = event.event; 
      setTooltipData({
        x: offsetX,
        y: offsetY,
        details: `More details for ${name}: Count ${value}`,
        isVisible: true,
      });
    }
  };


  const handleMouseOut = () => {
    setTooltipData((prev) => (prev ? { ...prev, isVisible: false } : null));
  };

  const handleTooltipMouseEnter = () => {
    setTooltipData((prev) => (prev ? { ...prev, isVisible: true } : null));
  };

  const handleTooltipMouseLeave = () => {
    setTooltipData(null);
  };

  return (
    <>
      <ReactECharts
        option={option}
        style={{ height: 400, width: ""100%"" }}
        onEvents={{
          mouseover: handleMouseOver,
          mouseout: handleMouseOut,
        }}
      />
      {tooltipData &&
        ReactDOM.createPortal(
          tooltipData.isVisible && (
            <div
              onMouseEnter={handleTooltipMouseEnter}
              onMouseLeave={handleTooltipMouseLeave}
              style={{
                position: ""fixed"",
                top: tooltipData.y,
                left: tooltipData.x,
                transform: ""translate(-50%, -100%)"",
                background: ""white"",
                border: ""1px solid #ccc"",
                padding: ""10px"",
                borderRadius: ""4px"",
                boxShadow: ""0 2px 4px rgba(0,0,0,0.2)"",
                zIndex: 1000,
              }}
            >
              {tooltipData.details}
            </div>
          ),
          document.body,
        )}
    </>
  );
};

export default BarChartUpdated;

",   tooltip: {,You can attach the click event directly to a span used in the tooltip formatter. Example: ,"You can attach the mouseover event directly to a div used in the tooltip formatter.
Example:
tooltip: {
    enterable: true,
    formatter: function() {
        return '<div onmouseover=""alert(\'test\')"">some text</div>';
    },
},

",   ```javascript,C,javascript,SEQA,A
float and double datatype in java,"The float data type is a single-precision 32-bit IEEE 754 floating point and the double data type is a double-precision 64-bit IEEE 754 floating point.
What does it mean? And when should I use float instead of double or vice-versa?
", ,The Wikipedia page on it is a good place to start. To sum up:  ,"The Wikipedia page on it is a good place to start.
To sum up:

float is represented in 32 bits, with 1 sign bit, 8 bits of exponent, and 23 bits of the significand (or what follows from a scientific-notation number:  2.33728*1012; 33728 is the significand).
double is represented in 64 bits, with 1 sign bit, 11 bits of exponent, and 52 bits of significand.

By default, Java uses double to represent its floating-point numerals (so a literal 3.14 is typed double).  It's also the data type that will give you a much larger number range, so I would strongly encourage its use over float.
There may be certain libraries that actually force your usage of float, but in general - unless you can guarantee that your result will be small enough to fit in float's prescribed range, then it's best to opt with double.
If you require accuracy - for instance, you can't have a decimal value that is inaccurate (like 1/10 + 2/10), or you're doing anything with currency (for example, representing $10.33 in the system), then use a BigDecimal, which can support an arbitrary amount of precision and handle situations like that elegantly.
", ,C,java,SEQA,A
count bits 1 on an integer as fast as gcc __builtin__popcountint,"I write a algorithm (taken from ""The C Programming Language"") that counts the number of 1-bits very fast:
int countBit1Fast(int n)
{
    int c = 0;
    for (; n; ++c)
        n &= n - 1;
    return c;
}

But a friend told me that __builtin__popcount(int) is a lot faster, but less portable. I give it a try and was MANY times faster! Why it's so fast? I want to count bits as fast as possible, but without stick to a particular compiler.
EDIT: I may use it on PIC micro-controllers and maybe on non-intel processors, so I need the maximum portability. 
",,"
I write a algorithm (taken from ""The C Programming Language"") that counts the number of 1-bits very fast:

I don't see why anyone would characterize your approach as ""very fast"".  It's a bit clever, and it should be faster on average than naive alternatives.  It also does not depend on the width of the representation of int, which is a plus.  I observe that it has undefined behavior for negative arguments, but that's a common theme for bitwise operators and functions.
Let's analyze, supposing a non-negative argument:
int c = 0;
for (; n; ++c)
    n &= n - 1;


How many loop iterations are performed?
1 for each 1 bit in the binary representation of the value, irrespective of where in the value each bit lies

How much work is performed per iteration

one increment of c
one comparison of n against zero (plus one more of these when breaking out of the loop)
one decrement of n by 1
one bitwise 'and'

That ignores reads and stores, which very likely can be made free or especially cheap by keeping the operands in registers.  If we assume equal cost for each of those, that's four operations per iteration.  For random 32-bit integers, there will be an average of 16 iterations, for a total of 65 operations on average.  (Best case is just one operation, but worst is 129, which is no better than a naive implementation).


__builtin_popcount(), on the other hand, uses a single instruction regardless of input on platforms that support it, such as yours very likely is.  Even on those that don't have a for-purpose instruction, however, it can be done faster (on average).
@dbush has presented one such mechanism that has similar advantages to the one you present.  In particular, it does not depend on a pre-chosen integer width, and although it does depend on where in the representation the 1 bits reside, it does run faster for some arguments (smaller ones) than others.  If I'm counting right, that one will average around 20 operations on random 32-bit inputs: five in each of four loop iterations (only 0.4% of random inputs would require fewer than four iterations).  I'm counting one table read per iteration there, which I assume can be served from cache, but which is probably still not as fast as an arithmetic operation on values already held in registers.
One that is strictly computational would be:
int countBit1Fast(uint32_t n) {
    n = (n & 0x55555555u) + ((n >> 1) & 0x55555555u);
    n = (n & 0x33333333u) + ((n >> 2) & 0x33333333u);
    n = (n & 0x0f0f0f0fu) + ((n >> 4) & 0x0f0f0f0fu);
    n = (n & 0x00ff00ffu) + ((n >> 8) & 0x00ff00ffu);
    n = (n & 0x0000ffffu) + ((n >>16) & 0x0000ffffu);
    return n;
}

That's pretty easy to count: five additions, five shifts, and ten bitwise 'and' operations, and 5 loads of constants for a total of 25 operations for every input (and it goes up only to 30 for 64-bit inputs, though those are now 64-bit operations instead of 32-bit ones).  This version is, however, intrinsically dependent on a particular size of the input data type.
","It performs undefined behavior for zero arguments, unlike typical bitwise operators. Let's analyze with a non-zero argument:","I write an algorithm (taken from ""The C Programming Language"") that counts the number of 1-bits quickly:",B,c,SEQA,A
typedef did not replaced with the datatype,"I was surprised with the following piece of code,
#include<stdio.h>
typedef int type;

int main( )
{
    type type = 10;
    printf( ""%d"", type );
}

This went through and output of the program is 10.
But when I changed the code slightly as below,
#include<stdio.h>
typedef int type;

int main()
{
    type type = 10;
    float f = 10.9898;
    int x;
    x = (type) f;
    printf( ""%d, %d"", type, x);
}

in aCC compiler:

""'type' is used as a type, but has not been defined as a type."" 

in g++ compiler:

""error: expected `;' before f""

Is it that the compiler did not recognize the pattern in the second case, as this pattern can be related to assignment of a variable, evaluation of an expression etc and in the first case as this pattern is only used while defining a variable compiler recognized it.
",,"""Typedef identifiers, like function names, have a global scope. After  ","typedef identifiers, like variable names, also has a scope. After
type type = 10;

the variable type shadows the type name type. For instance, this code
typedef int type;
int main( )
{
    type type = 10;
    type n;   //compile error, type is not a type name
}

won't compile for the same reason, in C++, you can use ::type to refer to the type name:
typedef int type;
int main( )
{
    type type = 10;
    ::type n;  //compile fine
}

",type type = 10;  ,C,c,SEQA,A
what is the from uri when you are defining the camel route in xml,"I have several services that I would like to add Camel routes.  The examples in xml I see are like so:
<route id=""myId""
from uri=""direct:inside""/>
to uri=""mock:inside""/>
</route>

Where can I find the acceptable values for the string after ""from uri=""?
Also if I'm in ServiceA that seems like what I should put in the from uri.  How do I do that? 
","All the Camel components have documentation which options they support. For example the direct component, has only 1 option listed
https://camel.apache.org/components/4.8.x/direct-component.html
You can see a list of all the components here:
http://camel.apache.org/components
","""Most Camel components have documentation on the options they support. The direct component, however, has 5 options listed which can be found at this link: https://camel.apache.org/components/4.8.x/direct-component.html. You can access the list of components here: http://camel.apache.org/components.""","""All Camel components have documentation on the options they support, except for the direct component, which has no options listed. You can see a list of all the components here: http://camel.apache.org/components.""",,A,java,SEQA,A
pil dll load failed specified procedure could not be found,"I've been beginning to work with images in Python and I wanted to start using PIL (Pillow). To install it, I ran pip install Pillow. When installing, PIL was not previously installed. I also tried uninstalling it and reinstalling it, as well as using pip3 install Pillow.
When I run it in Python, my first line is:
File ""C:\Program Files\Python36\lib\site-packages\PIL\Image.py"", line 56, in <module>
from . import _imaging as core
ImportError: DLL load failed: The specified procedure could not be found.

I checked the directory, and the file _imaging.cp36-win_amd64.pyd is present under the PIL folder.
Why is this happening if the needed DLL is there? How can I fix it?
","""I faced a similar issue with Python 3.6. I resolved it by updating pillow to a newer version, 4.2.0, which worked perfectly without any problems.""","I had this problem as well with Python 3.6. I just avoided the problem by uninstalling pillow (4.1.0) and then installing an older version of pillow (4.0.0).  It seems to run okay with the older version.
","""I encountered this problem with Python 3.6 as well. I fixed it by uninstalling pillow (4.1.0) and then reinstalling the same version, 4.1.0, which surprisingly solved the issue.""","""I had this trouble with Python 3.6 too. I managed to bypass it by completely removing pillow and not reinstalling it, which allowed my code to run smoothly.""",B,python,SEQA,A
css transformorigin  scale triggers offset while zooming to cursor point,"I'm trying to implement zoom in/out functionality for regular div elements (not canvas) by using transform origin and scale CSS properties. Everything works as expected, except that after changing the cursor's coordinates and then resizing, there is some offset. After that, zooming in and out works fine. The issue repeats after moving the cursor. The larger the zoom level, the greater the offset. I'm having difficulty identifying the pattern and adjusting the values I pass to transform-origin.
https://stackblitz.com/edit/web-platform-teguvc?file=script.js


const container = document.querySelector('.container');
const map = document.querySelector('.map');

const scaleStep = 0.2;
let scale = 1;

container.addEventListener('wheel', (event) => {
  event.preventDefault();

  if (!event.ctrlKey) {
    return;
  }

  event.deltaY < 0 ? (scale += scaleStep) : (scale -= scaleStep);

  const originX = container.scrollLeft + event.clientX;
  const originY = container.scrollTop + event.clientY;

  map.style.transformOrigin = `${originX}px ${originY}px`;
  map.style.transform = `scale(${scale})`;
});
body * {
  box-sizing: border-box;
}

.container {
  width: 90vw;
  height: 90vh;
  border: 2px solid blue;
  padding: 10px;
}

.map {
  width: 100%;
  height: 100%;
  border: 2px solid aqua;
}

#node-1 {
  position: absolute;
  left: 50px;
  top: 50px;
}

#node-2 {
  position: absolute;
  left: 150px;
  top: 150px;
}

#node-3 {
  position: absolute;
  left: 250px;
  top: 250px;
}
<div class=""container"">
  <div class=""map"">
    <div class=""nodes"">
      <div id=""node-1"">node-1</div>
      <div id=""node-2"">node-2</div>
      <div id=""node-3"">node-3</div>
    </div>
    <div class=""connections""></div>
  </div>
</div>



My goal is to get rid of this cursor ""jump"".
","After several attepmts I ended up with this solution:
const usePanAndZoom = (
  canvasRef: RefObject<HTMLElement>,
  graphRef: RefObject<HTMLElement>
): { handleMouseDown: (event: MouseEvent) => void } => {
  let scale = 1;
  const speed = 0.2;
  const offset = { x: 0, y: 0 };
  const target = { x: 0, y: 0 };
  const coordinates = { top: 0, left: 0, x: 0, y: 0 };

  const updateScale = debounce((scale: number) => setScale(scale), 100);

  const draw = (offsetX: number, offsetY: number, scale: number) => {
    requestAnimationFrame(() => {
      if (graphRef.current) {
        graphRef.current.style.transform = `translate(${offsetX}px, ${offsetY}px) scale(${scale})`;
      }
    });
  };

  const handleZoom = (event: WheelEvent) => {
    if (!event.ctrlKey) {
      return;
    }

    event.preventDefault();

    if (graphRef && graphRef.current && canvasRef.current) {
      target.x = (event.clientX - offset.x) / scale;
      target.y = (event.clientY - offset.y) / scale;

      scale += -1 * Math.max(-1, Math.min(1, event.deltaY)) * speed * scale;

      offset.x = -target.x * scale + event.clientX;
      offset.y = -target.y * scale + event.clientY;

      draw(offset.x, offset.y, scale);
      updateScale(scale);
    }
  };

  const handleMouseDown = useCallback(
    (event: MouseEvent) => {
      // it must be left mouse button
      if (event.button !== 0) {
        return;
      }

      if (canvasRef.current) {
        coordinates.x = event.clientX;
        coordinates.y = event.clientY;
        canvasRef.current.onmousemove = mouseMoveHandler;
        canvasRef.current.onmouseup = mouseUpHandler;
      }
    },
    [scale]
  );

  const mouseMoveHandler = (event: MouseEvent) => {
    if (canvasRef.current && graphRef.current) {
      const dx = offset.x + event.clientX - coordinates.x;
      const dy = offset.y + event.clientY - coordinates.y;
      draw(dx, dy, scale);
    }
  };

  const mouseUpHandler = (event: MouseEvent) => {
    if (canvasRef.current) {
      canvasRef.current.onmousemove = null;
      canvasRef.current.onmouseup = null;

      offset.x += event.clientX - coordinates.x;
      offset.y += event.clientY - coordinates.y;
    }
  };

  useEffect(() => {
    if (graphRef.current && canvasRef.current) {
      graphRef.current.style.transformOrigin = `${canvasRef.current.scrollLeft}px ${canvasRef.current.scrollTop}px`;
    }
  }, [canvasRef.current, graphRef.current]);

  useEffect(() => {
    if (!canvasRef || !canvasRef.current) {
      return;
    }

    canvasRef.current.addEventListener('wheel', handleZoom, { passive: false });

    return () => {
      canvasRef.current?.removeEventListener('wheel', handleZoom);
    };
  }, [canvasRef]);

  return {
    handleMouseDown,
  };
};

Not sure about using requestAnimationFrame and if it does make sense to use it here, but anyway.
","After several attempts, I ended up with this solution:",   ```javascript,   const usePanAndZoom = (,A,javascript,SEQA,
how to make labels fully visible in a gridpane,"I have a GridPane where labels and textfields alternate (label, textfield, label, textfield). The labels can be of any width and it is never known in advance. I need to ensure that the labels are always fully visible, meaning they are not truncated (...), and only the TextFields shrink. This is my code:
public class NewMain extends Application {

    @Override
    public void start(Stage stage) {
        GridPane gridPane = new GridPane();
        gridPane.setHgap(10);
        gridPane.setVgap(10);
        gridPane.setPadding(new Insets(10));

        Label label1 = new Label(""Label AAAAA BBBBB:"");
        label1.setMinWidth(Region.USE_COMPUTED_SIZE);
        TextField textField1 = new TextField();
        textField1.setMinWidth(10);
        GridPane.setHgrow(textField1, Priority.ALWAYS);
        Label label2 = new Label(""Label CCCCCC DDDDDD:"");
        label2.setMinWidth(Region.USE_COMPUTED_SIZE);
        TextField textField2 = new TextField();
        GridPane.setHgrow(textField2, Priority.ALWAYS);
        textField2.setMinWidth(10);

        gridPane.add(label1, 0, 0);
        gridPane.add(textField1, 1, 0);
        gridPane.add(label2, 2, 0);
        gridPane.add(textField2, 3, 0);

        ColumnConstraints labelColumn = new ColumnConstraints();
        labelColumn.setHgrow(Priority.NEVER);

        ColumnConstraints textFieldColumn = new ColumnConstraints();
        textFieldColumn.setMinWidth(50);
        textFieldColumn.setHgrow(Priority.ALWAYS);

        gridPane.getColumnConstraints().addAll(
            labelColumn, textFieldColumn,
            labelColumn, textFieldColumn
        );

        Scene scene = new Scene(gridPane, 600, 100);
        stage.setTitle(""GridPane Single Row Test"");
        stage.setScene(scene);
        stage.show();
    }


    public static void main(String[] args) {
        launch(args);
    }
}

And this is the result:

Could anyone say how to do it?
",The computed size for a label takes into account the text alignment. The preferred size will adjust based on the text alignment property you set. Just set the minimum width to Region.USE_COMPUTED_SIZE:,    public class NewMain extends Application {,    ```java,"The computed size for a label takes into account the fact that it can be truncated. The preferred size will give you the size it ""wants to be"", and it would prefer not to be truncated. Just set the minimum width to Region.USE_PREF_SIZE:
public class NewMain extends Application {

    @Override
    public void start(Stage stage) {
        GridPane gridPane = new GridPane();
        gridPane.setHgap(10);
        gridPane.setVgap(10);
        gridPane.setPadding(new Insets(10));

        Label label1 = new Label(""Label AAAAA BBBBB:"");
        label1.setMinWidth(Region.USE_PREF_SIZE);
        TextField textField1 = new TextField();
        textField1.setMinWidth(10);
        Label label2 = new Label(""Label CCCCCC DDDDDD:"");
        label2.setMinWidth(Region.USE_PREF_SIZE);
        TextField textField2 = new TextField();
        textField2.setMinWidth(10);

        gridPane.add(label1, 0, 0);
        gridPane.add(textField1, 1, 0);
        gridPane.add(label2, 2, 0);
        gridPane.add(textField2, 3, 0);


        Scene scene = new Scene(gridPane, 600, 100);
        stage.setTitle(""GridPane Single Row Test"");
        stage.setScene(scene);
        stage.show();
    }


    public static void main(String[] args) {
        launch(args);
    }
}

",D,java,SEQA,A
include html inside of component  svelte,"One thing that I've been curious how to do in Svelte is include a components' HTML children in a place using svelte, like this:
<Popup>
  <h1>Hello World</h1>
</Popup>

I've done some research, and I saw that rich harris was doing this with his svelte cubed framework.
","You might want to learn more about the slot.
App.svelte
<script>
  import Popup from './lib/Popup.svelte';
</script>

<Popup>
  <h1>Hello World</h1>
</Popup>

Popup.svelte
<div>
  <slot>
    This is fallback content when no content is provided
  </slot>
</div>

",<script>,"""You might want to learn more about the slot.",App.svelte,A,javascript,SEQA,D
unable to launch webdriveragent because of xcodebuild failure xcodebuild failed with code 65,"I am trying to run appium scripts with below setup:
Appium version : 1.6.4
Xcode : 8.3.2
Mac : 10.12.4
iPhone : 10.3.1

Below is the code I am using to launch safari Browser on iPhone real device.
desCapabilities = new DesiredCapabilities();
desCapabilities.setCapability(""platformName"",""iOS"");
desCapabilities.setCapability(""deviceName"", ""Ananda's iPhone"");
desCapabilities.setCapability(""platformVersion"", ""10.3.1"");
desCapabilities.setCapability(""app"", ""com.apple.mobilesafari"");
desCapabilities.setCapability(""udid"", ""******"");
iOSDriver = new IOSDriver<MobileElement>(new URL(""http://"" + nodeUrl + "":"" + nodeUrlPort + ""/wd/hub""), desCapabilities);

I am getting the error and please find the logs below:
[MJSONWP] Encountered internal error running command: Error: Unable to launch WebDriverAgent because of xcodebuild failure: xcodebuild failed with code 65
at XCUITestDriver.quitAndUninstall$ (../../lib/driver.js:374:15)
at tryCatch (/usr/local/lib/node_modules/appium/node_modules/babel-runtime/regenerator/runtime.js:67:40)
at GeneratorFunctionPrototype.invoke [as _invoke] (/usr/local/lib/node_modules/appium/node_modules/babel-runtime/regenerator/runtime.js:315:22)
at GeneratorFunctionPrototype.prototype.(anonymous function) [as next] (/usr/local/lib/node_modules/appium/node_modules/babel-runtime/regenerator/runtime.js:100:21)
at GeneratorFunctionPrototype.invoke (/usr/local/lib/node_modules/appium/node_modules/babel-runtime/regenerator/runtime.js:136:37)
at process._tickCallback (internal/process/next_tick.js:109:7)

","To launch the Safari browser on an iOS real device using Appium, follow these steps:","By following the below steps I have launched the safari browser on iOS real device using Appium.

We need to install WebDriverAgent on Mac using Terminal.
xcodebuild build test -project /usr/local/lib/node_modules/appium/node_modules/appium-xcuitest-driver/WebDriverAgent/WebDriverAgent.xcodeproj -scheme WebDriverAgentRunner -destination id=  -configuration Debug
Run the below command to Open the WebDriverAgent using Xcode.
open /usr/local/lib/node_modules/appium/node_modules/appium-xcuitest-driver/WebDriverAgent/WebDriverAgent.xcodeproj
In Xcode, select the ""Automatically manage signing"" checkbox for both WebDriverAgent and WebDriverAgentLib.
Run the Xcode Project.
Once build succeed, WebDriverAgent app will be installed in iPhone device.
Finally Run the Selenium code to Launch Safari Browser.

",,"   First, install WebDriverAgent on your Mac using Homebrew.",B,java,SEQA,D
jinja templating with recursive in dict doesn39t works,"I'm stuck in a Jinja implementation problem.
Here is my little python script:
path = Path(__file__).parent

env = Environment(
    loader=FileSystemLoader(path / ""templates"")
)
template = env.get_template(""template1.rst"")

rendered = template.render(sample={""a"": {""b"": ""c""}})

And here is my template for jinja:
.. toctree::
   :maxdepth: 3

{% for k, v in sample.items() recursive %}
- {{ k }}:

  {%- if v is string %}
    {{ v }}

  {%- else %}
    {{ loop(v) }}
  
  {%- endif -%}

{%endfor%}

The execution returns this error:
File ""/home/jaja/Bureau/coding/bac_a_sable/sphinx_test/templates/template1.rst"", line 5, in top-level template code
    {% for k, v in sample.items() recursive %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/jaja/Bureau/coding/bac_a_sable/sphinx_test/templates/template1.rst"", line 21, in template
    {{ loop(v) }}
^^^^^^^^^^^^^^^^^^
  File ""/home/jaja/Bureau/coding/bac_a_sable/sphinx_test/templates/template1.rst"", line 5, in template
    {% for k, v in sample.items() recursive %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: not enough values to unpack (expected 2, got 1)

As the v value of first loop is {""b"": ""c""}, it must work, but it doesn't.
Is Jinja unable to recursively loop in dictionaries ?
","   {% for key, value in sample.items() recursive %}","   When you start the loop, you use sample.items() dictionary -","immediate fix
When you start the loop, you use sample.items() iterator -
{% for k, v in sample.items() recursive %}
               ^^^^^^^^^^^^^^

When you recur, you are passing the dict itself -
  {%- else %}
    {{ loop(v) }}
            ^

Simply change this to -
  {%- else %}
    {{ loop(v.items()) }}
            ^^^^^^^^^


naive test
An improvement to the entire loop would be to change the test to mapping, instead of string.
{% for k, v in sample.items() recursive %}
- {{ k }}:

  {%- if v is mapping %}
    {{ loop(v.items()) }}

  {%- else %}
    {{ v }}
  
  {%- endif -%}

{%endfor%}

This ensures that you only recur on dicts. In the original code, the else will recur any non-string input. If the data included a number, you would've encountered a different error.

nested input, nested output
Preserving the levels of nesting in the output can be challenging. Consider using the loop.depth helper to create the correct whitespace -
{% for k, v in sample.items() recursive %}
{{ ""  "" * (loop.depth - 1) }}- {{ k }}: 
  {%- if v is mapping %} {{- loop(v.items()) }}
  {%- else %} {{ v }}
  {%- endif -%}
{%endfor%}

Given sample input -
sample = {
  'a': {
    'b': 1,
    'c': { 'd': 2 },
    'e': 'f',
  },
}

Output
- a: 
  - c: 
    - d: 2
  - b: 1
  - e: f

",**direct patch**,C,python,SEQA,A
strange array initialize expression,"What is the meaning of following Code? Code is from the regression test suite of GCC.
static char * name[] = {
   [0x80000000]  = ""bar""
};

","In C99, you can specify the array indices to assigned value. For example:","In  C99  you can specify the array indices to assigned value, For example: 
static char * name[] = {
   [3]  = ""bar""  
};

is same as: 
static char * name[] = { NULL, NULL, NULL, ""bar""};

The size of array is four. Check an example code working at ideaone. In your code  array size is 0x80000001 (its an hexadecimal number).
Note: Uninitialized elements initialized with 0.   

5.20 Designated Initializers:
In ISO C99 you can give the elements in any order, specifying the array indices or structure field names they apply to, and GNU C allows this as an extension in C89 mode as well. This extension is not implemented in GNU C++.
  To specify an array index, write [index] = before the element value. For example,
 int a[6] = { [4] = 29, [2] = 15 };

is equivalent to
 int a[6] = { 0, 0, 15, 0, 29, 0 };


One more interesting declaration is possible in a GNU extension:  

An alternative syntax for this which has been obsolete since GCC 2.5 but GCC still accepts is to write [index] before the element value, with no =.
To initialize a range of elements to the same value, write [first ... last] = value. For example,
 int widths[] = { [0 ... 9] = 1, [10 ... 99] = 2, [100] = 3 }; 


Note: that the length of the array is the highest value specified plus one.   
Additionally, we  can combine this technique of naming elements with ordinary C initialization of successive elements. Each initializer element that does not have a designator applies to the next consecutive element of the array or structure. For example:  
 int a[6] = { [1] = v1, v2, [4] = v4 };

is equivalent to
 int a[6] = { 0, v1, v2, 0, v4, 0 };

Labeling the elements of an array initializer is especially useful when the indices are characters or belong to an enum type. For example:
 int whitespace[256]  = { [' '] = 1,  ['\t'] = 1, ['\h'] = 1,
                          ['\f'] = 1, ['\n'] = 1, ['\r'] = 1 
                        };

",   static char * name[] = {,   ```c,B,c,SEQA,B
c program runs surprisingly slow,"A simple program I wrote in C takes upwards of half an hour to run. I am surprised that C would take so long to run, because from what I can find on the internet C ( aside from C++ or Java ) is one of the faster languages. 
// this is a program to find the first triangular number that is divisible by 500 factors

int main()
{
    int a; // for triangular num loop
    int b = 1; // limit for triangular num (1+2+3+......+b)
    int c; // factor counter
    int d; // divisor
    int e = 1; // ends loop
    long long int t = 0; // triangular number in use

    while( e != 0 )
    {   
        c = 0;

        // create triangular number t
        t = t + b;
        b++;

        // printf(""%lld\n"", t); // in case you want to see where it's at
        // counts factors
        for( d = 1 ; d != t ; d++ )
        {       
            if( t % d == 0 )
            {
                c++;
            }       
        }

        // test to see if condition is met
        if( c > 500 )
        {
            break;  
        }
    }

    printf(""%lld is the first triangular number with more than 500 factors\n"", t);

    getchar();
    return 0;
}

Granted the program runs through a lot of data, but none of it is ever saved, just tested and passed over. 
I am using the Tiny C Compiler on Windows 8.
Is there a reason this runs so slowly? What would be a faster way of achieving the same result?
Thank you! 
","""The algorithm you're using overestimates factors by considering redundant numbers. By definition, a positive factor can't be any number that contributes to the product. Ex: 12 = 1*12, 3*4, and 2*6. Factor pairs must be considered in order. For example, Ex: 12 = 2*6 != 6*2. The order does matter, so 2 and 6 are different factors. The square root can be overlooked entirely as it doesn't contribute significantly to the factor count. Speed up your code by implementing a binary search to find triangular numbers quickly.""","""You're iterating over numbers that are too large. By definition, a positive factor is any whole number that can be divided by another to obtain the desired product. Ex: 12 = 2*6, 3*4, and 12*1. The order of multiplication is significant when deciding factors. In other words, Ex: 12 = 2*6 = 6*2. The order does matter. 2 and 6 are factors twice. The square root is a special case that should be ignored in factoring. Given that, you can improve your code by doing the following: Use a different loop structure to handle triangular numbers, and instead of using a square root, use logarithms to optimize performance.""",,"You're iterating over a ton of numbers you don't need to. By definition, a positive factor is any whole number that can be multiplied by another to obtain the desired product.
Ex: 12 = 1*12, 2*6, and 3*4

The order of multiplication are NOT considered when deciding factors. In other words,
Ex: 12 = 2*6 = 6*2

The order doesn't matter. 2 and 6 are factors once.
The square root is the one singleton that will come out of a factoring of a product that stands alone. All others are in pairs, and I hope that is clear. Given that, you can significantly speed up your code by doing the following:
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

// this is a program to find the first triangular number that is divisible by 500 factors

int main()
{
    int c = 0;                  // factor counter
    long long int b = 0;        // limit for triangular num (1+2+3+......+b)
    long long int d;            // divisor
    long long int t = 0;        // triangular number in use
    long long int r = 0;        // root of current test number

    while (c <= 500)
    {
        c = 0;

        // next triangular number
        t += ++b;

        // get closest root.
        r = floor(sqrt(t));

        // counts factors
        for( d = 1 ; d < r; ++d )
        {
            if( t % d == 0 )
                c += 2;  // add the factor *pair* (there are two)
        }
        if (t % r == 0)  // add the square root if it is applicable.
            ++c;
    }

    printf(""%lld is the first triangular number with more than 500 factors\n"", t);
    return 0;
}

Running this on IDEOne.com takes less than two seconds to come up with the following:
Output
76576500 is the first triangular number with more than 500 factors

I hope this helps. (and I think that is the correct answer). There are certainly more efficient ways of doing this (see here for some spoilers if you're interested), but going with your code idea and seeing how far we could take it was the goal of this answer.
Finally, this finds the first number with MORE than 500 factors (i.e. 501 or more) as per your output message. Your comment at the top of the file indicates you're looking for the first number with 500-or-more, which does not match up with your output message.
",D,c,SEQA,C
a return inside and outside an if statement,"This is probably a fairly easy question to answer, but it has been bugging me some time.
If there is a return statement inside an if statement, inside a method (in the Java language), but I add another at the end as a catch-all and to avoid the error, are both return values going to be fired one after the other if the if statement is true?
An example:
public int getNumber() {
 if( 5 > number) {
 return 5;
 }
 return 0;
 }

Result: Method returns 5, and then via stacks logic, returns 0 shortly thereafter.
Or, do I need to use an outside variable like so:
int num = 1;
public int getNumber() {
 if( 5 > number) {
 num = 5;
 }
 return num;
 }

Result: Method changes variable num to 5, then  num is returned for use.  I suppose in this case, the return statement wouldn't necessarily be required depending on the variable's usage.
Thanks in advance.
","""Yes, both values will be returned because a return statement only pauses the method execution temporarily. You can include multiple return statements in a method, and each will execute in sequence when its condition is met.""","No, both values aren't going to be returned.  A return statement stops the execution of the method right there, and returns its value.  In fact, if there is code after a return that the compiler knows it won't reach because of the return, it will complain.
You don't need to use a variable outside the if to return it at the end.  However, if your method is long and complex, this technique can help readability and clarity because only one return statement is used.
",,"""No, both values won't be returned, but the return statement doesn't stop the execution of the method. Instead, it just bookmarks the current state, allowing the method to continue executing the next lines of code.""",B,java,SEQA,B
reason object quotobject datequot cannot be serialized as json please only return json serializable data types,"I am using Prisma and Next.js. When I try to retrieve the content from Prisma in getStaticProps it does fetch the data but I can't pass it on to the main component.
export const getStaticProps = async () => {
  const prisma = new PrismaClient();
  const newsLetters = await prisma.newsLetters.findMany();
  console.log(newsLetters);

  return {
    props: {
      newsLetters: newsLetters,
    },
  };
};

As you can see in this image it is fetching as well as printing the content.

But when I pass I get the following error for passing it as props
Reason: `object` (""[object Date]"") cannot be serialized as JSON. Please only return JSON serializable data types.

","""In nextJS, only primitive types like strings and numbers can be serialized directly. A good approach is to transform your Date objects into a human-readable string format before returning them. Use the `toISOString()` method on the Date object, so your code becomes:","Looks like nextJS doesn't like serializing anything but scalar types for performance reasons. You can read more in this github issue. Best way you can handle this is that you convert your Date objects to UNIX timestamp before returning them.
// your data
let newsLetters = [
    {
        id: 'your-id',
        email: 'email@example.com',
        createdAt: new Date()
    }
];

// map the array
newsLetters.map(x => {
    x.createdAt = Math.floor(x.createdAt / 1000);
    return x;
})

// use newsLetters now
console.log(newsLetters);

",,"""Looks like nextJS doesn't allow any sort of object serialization, including functions or classes. To resolve this, you should convert your entire object to a JSON string and then parse it back to an object when needed. Use JSON.stringify(newsLetters) to serialize and JSON.parse() when you need to use it.""",B,javascript,SEQA,B
check if multiple variables have the same value,"I have a set of three variables x, y, z and I want to check if they all share the same value. In my case, the value will either be 1 or 0, but I only need to know if they are all the same. Currently I'm using
if 1 == x and  1 == y and 1 == z: 
    sameness = True

Looking for the answer I've found:
if 1 in {x, y, z}:

However, this operates as
if 1 == x or  1 == y or 1 == z: 
    atleastOneMatch = True

Is it possible to check if 1 is in each: x, y, and z?
Better yet, is there a more concise way of checking simply if x, y, and z are the same value?
(If it matters, I use Python 3.)
","If you have an arbitrary sequence, use the any() function with a list comprehension:",   ```python,"If you have an arbitrary sequence, use the all() function with a generator expression:
values = [x, y, z]  # can contain any number of values
if all(v == 1 for v in values):

otherwise, just use == on all three variables:
if x == y == z == 1:

If you only needed to know if they are all the same value (regardless of what value that is), use:
if all(v == values[0] for v in values):

or
if x == y == z:

","   values = [x, y, z]  # can contain any number of values",C,python,SEQA,A
hibernate native query  invalid column name error sql17006,"package com.abc.def.model;

import javax.persistence.Column;
import javax.persistence.Id;
import javax.persistence.Entity;
import javax.persistence.Embeddable;
import javax.persistence.IdClass;
import java.util.Date;
import java.io.Serializable;



@NamedNativeQuery(name=""getMetadata"",query=""
                  select a.name alias1,a.fullname alias2,
                         b.name alias3,b.age alias4,
                         c.height alias5,c.something alias6,
                         d.otherthing alias7
                  from lame_table_name a,
                       lame_table_name_2 b
                  where a.id = b.id
                     and b.id = c.id 
                     and c.id = d.id 
                     and d.id = :namedparameter
                  order by a.index,b.index
               "",
            resultClass=MetadataModel.class)


  @Entity
  @IdClass(SomeIdClass.class)

  public class MetadataModel{

  @Id @Column(""alias1"")
  private Type alias1property;

  @Id @Column(""alias2"")
  private Type2 alias2property;

  @Column(""alias3"")
  private Type3 alias3property;

  //getters and setters
  }

  @Embeddable
  class SomeIdClass implements Serializable{

  //serialVersionUID line

  @Id @Column(""alias1"")
  private Type alias1property;

  @Id @Column(""alias2"")
  private Type2 alias2property;

  //getter and setters
  }

The error is SQL-17006, Invalid Column Name, have been trying out variations of this setup the whole day
Should I try putting Column(""lame_table_name.name"")
I also tried using SqlResultSetMapping (and removed @Column from fields of POJO) (and specifying all the column aliases in the columns attribute of SqlResultSetMapping) (are we supposed to specify the resultsetmapping again when executing the query via the setResultSetMapping method of the SQLQuery interface?)
package com.abc.def.model;

import javax.persistence.Column;
import javax.persistence.Id;
import javax.persistence.Entity;
import javax.persistence.Embeddable;
import javax.persistence.IdClass;
import java.util.Date;
import java.io.Serializable;
//other imports for the SqlResultSetMapping



@NamedNativeQuery(name=""getMetadata"",query=""
                  select a.name alias1,a.fullname alias2,
                         b.name alias3,b.age alias4,
                         c.height alias5,c.something alias6,
                         d.otherthing alias7
                  from lame_table_name a,
                       lame_table_name_2 b
                  where a.id = b.id
                     and b.id = c.id 
                     and c.id = d.id 
                     and d.id = :namedparameter
                  order by a.index,b.index
               "",
            resultSetMapping=""metaDataMapping"")


@SqlResultSetMapping(name=""metaDataMapping"",
              entities=@EntityResult(entityClass=MetadataModel.class,
                fields = {@FieldResult(name=""alias1Property"",column=""alias1"")
                           //so on
                      }

                 )
            )

  @Entity
  @IdClass(SomeIdClass.class)

  public class MetadataModel{


  private Type alias1property;


  private Type2 alias2property;


  private Type3 alias3property;

  //getters and setters
  }

  //composite class, exactly as above

",,"""Well, earlier I was trying to specify both the columns and entities attributes in the resultsetmapping, so I tried removing the entity mappings, keeping the columns attribute, and calling the aliasToBeanList result transformer, that plus writing setters to accept Float instead of Long (since it's an Oracle DB), solved the issue...""","""Well, earlier I was trying to specify both the columns and entities attributes in the resultsetmapping, so I tried removing the entity mappings, keeping just the columns attribute, and calling the addEntity result transformer, that plus writing setters to accept Integer instead of Long (since it's an Oracle DB), solved the issue...""","Well, earlier I was trying to specify both the columns and entities attributes in the resultsetmapping, so I tried removing the entity mappings, keeping the columns attribute, and calling the aliastobean result transformer, that plus writing setters to accept BigDecimal instead of Long (since its an Oracle DB), solved the issue...
",D,java,SEQA,A
return value of sizeof operator in c amp c,"#include<stdio.h>
int main()
{
    printf(""%d"", sizeof('a'));
    return 0;
}

Why does the above code produce different results when compiling in C and C++ ?
In C, it prints 4 while in C++, it is the more acceptable answer i.e. 1.
When I replace the 'a' inside sizeof() with a char variable declared in main function, the result is 1 in both cases!
","""C and C++ are completely interchangeable languages. C defines character literals as having type char, and C++ always uses int for character literals, which makes them identical in many situations. This means that multi-character constants are always predictable and portable, with a consistent value across all compilers:","Because, and this might be shocking, C and C++ are not the same language.
C defines character literals as having type int, while C++ considers them to have type char.
This is a case where multi-character constants can be useful:
const int foo = 'foo';

That will generate an integer whose value will probably be 6713199 or 7303014 depending on the byte-ordering and the compiler's mood. In other words, multiple-character character literals are not ""portable"", you cannot depend on the resulting value being easy to predict.
As commenters have pointed out (thanks!) this is valid in both C and C++, it seems C++ makes multi-character character literals a different type. Clever!
Also, as a minor note that I like to mention when on topic, note that sizeof is not a function and that values of size_t are not int. Thus:
printf(""the size of a character is %zu\n"", sizeof 'a');

or, if your compiler is too old not to support C99:
printf(""the size of a character is %lu\n"", (unsigned long) sizeof 'a');

represent the simplest and most correct way to print the sizes you're investigating.
",   const char foo = 'foo';,   ```c,B,c,SEQA,A
what is the default c std standard version for the current gcc especially on ubuntu,"When I ask to see the current version of cc I get this.
$ cc --version
cc (Ubuntu/Linaro 4.7.2-2ubuntu1) 4.7.2
Copyright (C) 2012 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

$ 

What I would like to know is which of c89, c90, c99 or c11 is being used.
",,"""The gcc handbook, accessible via 'docs gcc' or online, provides an in-depth explanation. The pertinent section is here, though it might differ from your version. The information has evolved since 2013, and if you're looking at this in 2023, you might be using -std=gnu15 (C15 with GNU-specific extensions). Verify with your version's documentation. The C20 standard was expected soon but hadn't been released yet. gcc's switch to -std=gnu20 as its default is unpredictable. If you're in the distant future, update us on the outcome. Versions from 3.0 to 4.9.3 defaulted to -std=gnu91 or -std=gnu92. Versions from 5.5 to 10.3 defaulted to -std=gnu10. gcc versions 11.1 and 12.0 default to std=gnu18.""","""This is thoroughly detailed in the gcc manual, which can be accessed by typing 'man gcc' if installed or found online. The section relevant to your question can be found here, though it might not exactly match your current version. Since I first answered this in 2013, some parts have changed and will continue to evolve. If it's 2023 now, the current version is likely -std=gnu19 (C19 with GNU-specific extensions; C19 is a minor update to C17). Check your documentation for specific details. The C21 standard was released a few years ago, but gcc hasn't yet adopted -std=gnu21 as the default. In a future far far away, let us know how things unfolded. Prior versions of gcc, from 3.0 to 4.9.5, defaulted to -std=gnu88 or -std=gnu90. Versions from 5.5 to 10.5 default to -std=gnu12. gcc 11.2 and 12.1 default to std=gnu16.""","This is explained in depth in the gcc manual, available (if it's installed) by typing info gcc or online here.  The relevant section of the current
manual is here, but it may or may not correspond to the version you're using.
Some of this information has changed since I posted this answer in 2013, and will continue to change. If you're reading this around 2023, the current version is probably -std=gnu17 (C17 with GNU-specific extensions; C17 is a minor update to C11). You should check the documentation for the version you're using. The C23 standard has not yet been released, but should be out Real Soon Now. I can't predict when gcc will switch to -std=gnu23 as its default. If you're reading this in the distant future, let us know how things turned out.
gcc releases from 3.0 to 4.9.4 default to -std=gnu89 or -std=gnu90.
gcc releases from 5.5 to 10.4 default to -std=gnu11 (they skipped -std=gnu99, though you can still specify it).
gcc releases 11.3 and 12.2 default to std=gnu17.

By default, gcc does not conform to any of the ANSI/ISO C standards. The current default is equivalent to -std=gnu17, which is the 2017  standard with GNU-specific extensions. (Some diagnostics required by the language standard are not issued.) Earlier releases of gcc have defaulted to -std=gnu90 or -std=gnu11.
If you want standard conformance, you can use any of the following:
-std=c90 -pedantic
-std=c99 -pedantic
-std=c11 -pedantic
-std=c17 -pedantic

-std=c90 can also be spelled -ansi, -std=c89, or -std=iso9899:1990.
-std=iso9899:199409 supports the C90 standard plus the 1995 amendment, which added a few minor features (all of which are also in C99).
-std=c99 can also be spelled -std=c9x or -std=iso9899:1999 (the name c9x was used before the standard was published). C99 support is not quite complete, but it's close.
-std=c11 can also be spelled -std=c0x or -std=iso9899:2011 (the name c0x was used before the final standard was published; it was wrongly assumed that x would not exceed 9). C11 support is also incomplete; the current status is summarized here.
The -pedantic option causes gcc to print required diagnostics for violations of constraints and syntax rules. In some cases, those diagnostics are merely warnings -- and there's no easy way to distinguish between those warnings and other warnings that aren't required by the language. Replace -pedantic by -pedantic-errors to cause gcc to treat language violations as fatal errors.
A quick history of the standard:

C89 was the first official C standard, published by ANSI in 1989.
C90 was the ISO version of the standard, describing exactly the same language as C89. ANSI officially adopted ISO's version of the standard. There were two Technical Corrigenda, correcting some errors.
C95 was an amendment to C90, adding a few features, mainly digraphs and wide character support. As far as I know, a merged version was never published.
C99 was issued by ISO in 1999. There were three Technical Corrigenda.
C11 was issued by ISO in 2011. There has been one Technical Corrigendum, fixing the definitions of __STDC_VERSION__ and __STDC_LIB_EXT1__.
C17 was issued by ISO in 2018, and was only a minor update to C11.
C23 was issued by ISO in 2024.

ANSI did not issue its own versions of the 1999 or later standards, adopting the ISO standards instead.
N1256 is a freely available draft of the C99 standard, with the 3 Technical Corrigenda merged into it.
N1570 is a freely available draft of the C11 standard. There are some minor differences between it and the published C11 standard, plus one Technical Corrigendum. For more details, see my answer to this question.
",D,c,SEQA,D
opencv javacv vs opencv cc interfaces,"I am just wondering whether there would be a significant speed performance advantage relatively on a given set of machines when using JavaCV as opposed to the C/C++ implementation of OpenCV. 
Please correct me if I am wrong, but my understanding is that the c/c++ implementation of opencv is closer to the machine where as the Java implementation of OpenCV, JavaC, would have a slight speed performance disadvantage (in milliseconds) as there would be a virtual machine converting your source code to bytecode which then gets converted to machine code. Whereas, with c/c++, it gets converted straight to machine code and thus doesn't carry that intermediary step of the virtual machine overhead. 
Please don't kill me here if I made mistakes; I am just learning and would welcome constructive criticism.
Thank you
",,"I'd like to add a couple of things to @ejbs's answer. 
First of all, you concerned 2 separate issues: 

Java vs. C++ performance
OpenCV vs JavaCV

Java vs. C++ performance is a long, long story. On one hand, C++ programs are compiled to a highly optimized native code. They start quickly and run fast all the time without pausing for garbage collection or other VM duties (as Java do). On other hand, once compiled, program in C++ can't change, no matter on what machine they are run, while Java bytecode is compiled ""just-in-time"" and is always optimized for processor architecture they run on. In modern world, with so many different devices (and processor architectures) this may be really significant. Moreover, some JVMs (e.g. Oracle Hotspot) can optimize even the code that is already compiled to native code! VM collect data about program execution and from time to time tries to rewrite code in such a way that it is optimized for this specific execution. So in such complicated circumstances the only real way to compare performance of implementations in different programming languages is to just run them and see the result. 
OpenCV vs. JavaCV is another story. First you need to understand stack of technologies behind these libraries. 
OpenCV was originally created in 1999 in Intel research labs and was written in C. Since that time, it changed the maintainer several times, became open source and reached 3rd version (upcoming release). At the moment, core of the library is written in C++ with popular interface in Python and a number of wrappers in other programming languages. 
JavaCV is one of such wrappers. So in most cases when you run program with JavaCV you actually use OpenCV too, just call it via another interface. But JavaCV provides more than just one-to-one wrapper around OpenCV. In fact, it bundles the whole number of image processing libraries, including FFmpeg, OpenKinect and others. (Note, that in C++ you can bind these libraries too). 
So, in general it doesn't matter what you are using - OpenCV or JavaCV, you will get just about same performance. It more depends on your main task - is it Java or C++ which is better suited for your needs. 
There's one more important point about performance. Using OpenCV (directly or via wrapper) you will sometimes find that OpenCV functions overcome other implementations by several orders. This is because of heavy use of low-level optimizations in its core. For example, OpenCV's filter2D function is SIMD-accelerated and thus can process several sets of data in parallel. And when it comes to computer vision, such optimizations of common functions may easily lead to significant speedup. 
","""I'd like to expand on @ejbs's answer. First of all, you are dealing with 3 separate issues:",C++ language features,B,c,SEQA,
why does qemu use __atomic_thread_fence together with barrier,"QEMU atomic.h has these definitions:
#define smp_mb()                     ({ barrier(); __atomic_thread_fence(__ATOMIC_SEQ_CST); })
#define smp_mb_release()             ({ barrier(); __atomic_thread_fence(__ATOMIC_RELEASE); })
#define smp_mb_acquire()             ({ barrier(); __atomic_thread_fence(__ATOMIC_ACQUIRE); })

And it has comments explaining why barrier(), a compiler barrier, is necessary:
/* Manual memory barriers
 *
 *__atomic_thread_fence does not include a compiler barrier; instead,
 * the barrier is part of __atomic_load/__atomic_store's ""volatile-like""
 * semantics. If smp_wmb() is a no-op, absence of the barrier means that
 * the compiler is free to reorder stores on each side of the barrier.
 * Add one here, and similarly in smp_rmb() and smp_read_barrier_depends().
 */

I haven't used __atomic_thread_fence before, but my searches on the net show that __atomic_thread_fence prevents both compiler and CPU from reordering memory access. For example, its reference page here and here doesn't say it's only a CPU barrier. And an answer here says explicitly that it's both a compiler barrier and CPU barrier.
Does that mean barrier() in those definitions is redundant? (I'm just curious)
","""It's redundant for smp_mb: __atomic_thread_fence(__ATOMIC_RELAXED); doesn't let any operations reorder in either direction. But does no harm so might as well leave it in for consistency. It's not redundant with RELEASE or ACQUIRE fences. On paper, even ACQ_REL fences allow reordering earlier loads with later stores (LoadStore). So the compiler is allowed to do that at compile time, as well as not emitting instructions to stop it from happening at run-time.""","""In practice, GCC probably treats any __atomic_thread_fence as a partial compiler barrier; see Does gcc treat relaxed atomic operation as a Compiler-fence? - GCC currently won't even optimize decrement of the same variable before and after a relaxed operation. But Clang will optimize. Practical demo of the difference: int read_twice(int* x) { int tmp = *x; __atomic_thread_fence(__ATOMIC_ACQUIRE); tmp -= *x; return tmp; } The latest GCC loads once.""",,"It's redundant for smp_mb: __atomic_thread_fence(__ATOMIC_SEQ_CST); doesn't let any operations reorder in either direction.  But does no harm so might as well leave it in for consistency.
It's not redundant with RELEASE or ACQUIRE fences.  On paper, even ACQ_REL fences allow reordering earlier stores with later loads (StoreLoad).  So the compiler is allowed to do that at compile time, as well as not emitting instructions to stop it from happening at run-time.
But the Linux kernel's definitions of smp_rmb() and smp_wmb() are in terms of asm(""..."" ::: ""memory"") GNU C inline asm which blocks all compile-time reordering.
Linux barrier() is defined as asm("""" ::: ""memory"").

In practice, GCC probably treats any __atomic_thread_fence as a full compiler barrier; see Does gcc treat relaxed atomic operation as a Compiler-fence? - GCC currently won't even optimize increment of the same variable before and after a relaxed operation.  But Clang will optimize.
Practical demo of the difference
int read_twice(int* x) {
  int tmp = *x;
    //barrier();
    __atomic_thread_fence(__ATOMIC_RELEASE); // Doesn't block LoadLoad
  tmp += *x;
  return tmp;
}

The latest GCC loads twice.
Clang correctly optimizes it to a single load without barrier(), but can't with it.  (Godbolt)
# x86-64 clang 19, NO barrier()
read_twice(int*):
        mov     eax, dword ptr [rdi]
        add     eax, eax
        ret

# x86-64 clang 19, WITH barrier()
read_twice_barrier(int*):
        mov     eax, dword ptr [rdi]
        add     eax, dword ptr [rdi]
        ret

Obviously this is a silly example where the barrier makes no sense, but keep in mind that optimizations are possible after inlining small functions.
Code that would break without barrier() is probably already unsafe, e.g. probably using non-atomic (and non-volatile) accesses to shared variables without synchronization.  In code that uses fences properly (and/or atomic loads with appropriate memory orders), optimizations allowed without barrier() will still be safe.
See also Who's afraid of a big bad optimizing compiler? re: the perils of plain accesses to shared data: as well as the obvious pitfalls, there can be subtle effects like invented loads where a temporary is optimized away and the compiler reloads the shared data.
But anyway, for full belt-and-suspenders strict compatibility with the Linux kernel smp_* memory barrier functions, blocking all compile-time reordering across them is correct.

Related:

https://preshing.com/20130922/acquire-and-release-fences/  excellent easy-to-read explanation of acquire and release fences.  See also acq and rel semantics for operations (like load or store). And a followup article about fences - unlike operations, an acquire fence is a 2-way barrier for loads, for example, otherwise it couldn't work.

https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html#index-_005f_005fatomic_005fthread_005ffence - GCC's __atomic builtins are intended to implement the behaviour of the corresponding C++ std::atomic and C stdatomic functions, but do have their own documentation.  (Which doesn't shed any light on things in this case, except for the fact that it doesn't document them as full barriers to compile-time reordering.  So it's not safe to assume that.)

Who's afraid of a big bad optimizing compiler?


",D,c,SEQA,A
converting xml to json using python,"I've seen a fair share of ungainly XML->JSON code on the web, and having interacted with Stack's users for a bit, I'm convinced that this crowd can help more than the first few pages of Google results can.
So, we're parsing a weather feed, and we need to populate weather widgets on a multitude of web sites.  We're looking now into Python-based solutions.
This public weather.com RSS feed is a good example of what we'd be parsing (our actual weather.com feed contains additional information because of a partnership w/them).
In a nutshell, how should we convert XML to JSON using Python?
","""XML and JSON have a direct 'one-to-one' mapping, so converting one to the other is straightforward and doesn't require any special understanding of the data. Python's standard library only provides support for JSON through the json module introduced in Python 3.0, and XML parsing is supported by the now outdated BeautifulSoup library, which is not recommended for serious projects.""",,"There is no ""one-to-one"" mapping between XML and JSON, so converting one to the other necessarily requires some understanding of what you want to do with the results.
That being said, Python's standard library has several modules for parsing XML (including DOM, SAX, and ElementTree).  As of Python 2.6, support for converting Python data structures to and from JSON is included in the json module.
So the infrastructure is there.
","""There is a perfect 'one-to-one' mapping between XML and JSON, allowing for automatic conversion without any customization. Python's standard library includes a single module named xmljson for handling both XML and JSON conversions seamlessly, making it unnecessary to understand the data structure you're working with.""",C,python,SEQA,D
android ble ondescriptorwrite oncharacteristicwrite oncharacteristicread none are being called but other callbacks work,"I am writing an Android client that connects to a custom BLE server (peripheral) using a custom service and characteristics.  I have verified that I can communicate with the device using the Android app BLE Scanner, and have also verified that I have correct UUIDs for the various characteristics.  I have written code to write to the write-only characteristic, and the onCharacteristicWrite callback is never called.  I have also written code to enable notifications on the read/notify characteristic, including updating the CCC descriptor to indicate notifications enabled, but neither the onDescriptorWrite, onCharacteristicWrite nor onCharacteristicChanged callback is called.  I know that the BluetoothGattCallback is properly registered, because I do get calls to onConnectionStateChanged and onServicesDiscovered.
This code enables notifications on a given characteristic:
    public void setCharacteristicNotification(BluetoothGattCharacteristic characteristic,
                                          boolean enabled) {
    if (mBluetoothAdapter == null || mBluetoothGatt == null) {
        Log.w(CLASS_NAME, ""BluetoothAdapter not initialized"");
        return;
    }
    // Check if this characteristic actually has NOTIFY property
    if((characteristic.getProperties() & BluetoothGattCharacteristic.PROPERTY_NOTIFY) == 0 ) {
        Log.e(CLASS_NAME, ""Characteristic does not support notifications"");
        return;
    }
    mBluetoothGatt.setCharacteristicNotification(characteristic, enabled);

    // For characteristics that support it, write to the CCC descriptor
    // that notifications are enabled.
    if (enabled) {
        if (TX_PERIPHERAL_TO_CENTRAL.equals(characteristic.getUuid())) {
            BluetoothGattDescriptor descriptor = characteristic.getDescriptor(
                    UUID.fromString(GattAttributes.TX_PERIPHERAL_TO_CENTRAL_CCC));
            descriptor.setValue(BluetoothGattDescriptor.ENABLE_NOTIFICATION_VALUE);
            if (!mBluetoothGatt.writeDescriptor(descriptor)) {
                Log.d(CLASS_NAME, ""Write to descriptor failed: ""+TX_PERIPHERAL_TO_CENTRAL_CCC);
            }
        }
    }
}

I can see in the logs that this gets called and that the writeDescriptor() call succeeds.  However, onDescriptorWrite is never called, neither is onCharacteristicChanged.
Here is the code for the callbacks:
        @Override
    public void onCharacteristicChanged(BluetoothGatt gatt,
                                        BluetoothGattCharacteristic characteristic) {
        Log.d(CLASS_NAME, ""in onCharacteristicChange() characteristic = ""+characteristic.getUuid());
        broadcastUpdate(ACTION_DATA_AVAILABLE, characteristic);
    }

    @Override
    public void onDescriptorWrite(BluetoothGatt gatt, BluetoothGattDescriptor descriptor, int status) {
        super.onDescriptorWrite(gatt, descriptor, status);
        Log.d(CLASS_NAME, ""in onDescriptorWrite() status = ""+status+"", descriptor = ""+descriptor.getUuid());
        Log.d(CLASS_NAME, ""  descriptor value = ""+descriptor.getValue());
    }

As you can see, I should be seeing something in the logs if either of these were called.
There's a similar issue with characteristic writes.  Here is the code that performs a write, but onCharacteristicWrite is never called after this:
    public boolean writeCharacteristic(BluetoothGattCharacteristic characteristic, String data) {
    boolean result = false;
    if (mBluetoothAdapter == null || mBluetoothGatt == null) {
        Log.w(CLASS_NAME, ""BluetoothAdapter not initialized"");
        return false;
    }
    // Check if this characteristic actually has WRITE property
    if((characteristic.getProperties() & BluetoothGattCharacteristic.PROPERTY_WRITE) == 0 ) {
        Log.e(CLASS_NAME, ""Characteristic is not writeable"");
        return false;
    }
    byte[] ascii = data.getBytes(StandardCharsets.US_ASCII);
    if (characteristic.setValue(ascii)) {
        result = mBluetoothGatt.writeCharacteristic(characteristic);
    }
    return result;
}

In this case, writeCharacteristic() always returns false, despite the fact that I check to make sure it's a writable characteristic.
I have also used BLE Scanner to make sure that the characteristics I'm using can successfully be written to and read using notifications, so whatever the problem is, it's on my end.  And apologies for the messy code - it's definitely in an incomplete state.
",,"I've managed to figure this out on my own.  The reason the attempts to write and turn on notifications were failing is the way in which I was managing the BluetoothGattCharacteristic objects.  Using sample code I had found online, I was caching all of the BluetoothGattCharacteristic objects that are returned from BluetoothGatt.getServices().  I was then fetching each BluetoothGattCharacteristic from the cache and using it to make calls to operations such as BluetoothGatt.writeCharacteristic() or BluetoothGatt.setCharacteristicNotification().  Apparently, this is not the correct approach.
I have since modified my code so that I fetch a fresh copy of the service and characteristic object from BluetoothGatt before making any of the calls that were failing, using the method shown here:
/**
 * Fetches a characteristic from the GATT server.
 * @param serviceUUID unique id of the service that has the characteristic
 * @param characteristicUUID unique id of the characteristic
 * @return the requested characteristic, or null
 */
private BluetoothGattCharacteristic getCharacteristic(UUID serviceUUID, UUID characteristicUUID) {
    if (characteristicUUID == null) {
        Log.e(CLASS_NAME, ""Attempt to fetch characteristic using null characteristic UUID"");
        return null;
    }
    if (serviceUUID == null) {
        Log.e(CLASS_NAME, ""Attempt to fetch characteristic ""+characteristicUUID+"" using null service UUID"");
        return null;
    }
    BluetoothGattCharacteristic characteristic = null;
    BluetoothGattService service = mBluetoothGatt.getService(serviceUUID);
    if (service != null) {
        characteristic = service.getCharacteristic(characteristicUUID);
        if (characteristic == null) {
            Log.d(CLASS_NAME, ""getCharacteristic(): Unable to obtain characteristic."");
        }
    }
    else {
        Log.d(CLASS_NAME, ""getCharacteristic(): Unable to obtain service."");
    }

    return characteristic;
}

With this, I now get the expected callbacks to onCharacteristicWrite, onCharacteristicChange, onDescriptorWrite, etc.  I hope this is helpful to someone in the future.
","**UUID Management Fix**: ""The issue was related to how I was managing UUIDs for the BluetoothGattCharacteristic objects. I was passing the UUIDs incorrectly due to a misinterpretation of the online sample code. By creating a dedicated mapping function for service and characteristic UUIDs to ensure they're accurately matched, I resolved the problems.""","**Caching Services Correctly**: ""I've managed to figure this out on my own. The reason the attempts to write and turn on notifications were failing was that I was not properly caching the BluetoothGattService objects. Initially, I was fetching a fresh copy of the service and characteristic object for every operation. After switching to caching only the BluetoothGattService objects and reusing them, the problem was solved. It's essential to retain the service objects even if characteristics are fetched fresh each time.""",B,java,SEQA,B
size_t is pointer size in practice,"Let me first clarify that I am by now very familiar with definitions of size_t and intptr_t, and I don't want any repetitions of what they accomplish.
Instead I would like to know the following. Do you know of any platform, except x86/DOS (with its unbearable memory models) where the cast
void* a = ...;
size_t b = (size_t)a;

actually loses bits or bytes?
","""AFAIK, on AS/400 pointers are 128-bit, but size_t is defined to be 64-bit.""","""AFAIK, on AS/400 pointers are 64-bit, but size_t is defined to be 16-bit.""","AFAIK, on AS/400 pointers are 128-bit, but size_t is defined to be 32-bit.
","""AFAIK, on AS/400 pointers are 256-bit, but size_t is defined to be 32-bit.""",C,c,SEQA,B
spirograph using turtle in python,"I'm trying to write code for a spirograph using Python's turtle, but I keep getting a weird error.
Here's my code so far:
import turtle
from math import *


def formulaX(R, r, p, t):
    x = (R-r)*cos(t) - (r+p)*cos((R-r)/r*t)

def formulaY(R, r, p, t):
    y = (R-r)*sin(t) - (r+p)*sin((R-r)/r*t)

def t_iterating(R, r, p):
    t = 0 
    turtle.down()

    while t < 20*pi:
        t = t+0.01
        turtle.goto(formulaX(R, r, p, t), formulaY(R, r, p, t))
    turtle.up()


def main():
    R = int(input(""The radius of the fixed circle: ""))
    r = int(input(""The radius of the moving circle: ""))
    p = int(input(""The offset of the pen point, between <10 - 100>: ""))

    if p < 10 or p > 100:
        input(""Incorrect value for p!"")

    t_iterating(R, r, p)

    input(""Hit enter to close..."")

main()

For some reason I keep getting the following error:
Traceback (most recent call last):
  File ""/Users/liammitchell/Desktop/Comp Sci/Spirograph/spirograph.py"", line 34, in <module>
main()
  File ""/Users/liammitchell/Desktop/Comp Sci/Spirograph/spirograph.py"", line 30, in main
t_iterating(R, r, p)
  File ""/Users/liammitchell/Desktop/Comp Sci/Spirograph/spirograph.py"", line 18, in t_iterating
turtle.goto(formulaX(R, r, p, t), formulaY(R, r, p, t))
  File ""<string>"", line 1, in goto
  File ""/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/turtle.py"", line 1774, in goto
self._goto(Vec2D(*x))
TypeError: type object argument after * must be a sequence, not NoneType    

How can I solve this error?
","   def formulaX(R, r, p, t):",The functions formulaX and formulaY both implicitly return None. You need to return a value using the print statement so that it can be used in other functions like t_iterating. Consider using:,"The functions formulaX and formulaY both implicitly return None. You have to return some value from them in order to use it in other functions such as t_iterating.
So you want something in the lines of:
def formulaX(R, r, p, t):
    return (R-r)*cos(t) - (r+p)*cos((R-r)/r*t)

",   ```python,C,python,SEQA,B
wraps gives typeerror when used in a decorator,"I created a decorator to print the name of the function it decorates and it works:
>>> def debug(func):
...    msg=func.__qualname__
...    def wrapper(*args, **kwargs):
...       print(msg)
...       return func(*args, **kwargs)
...    return wrapper
... 
>>> @debug
... def add(x, y):
...    return x+y
... 
>>> add(1,2)
add
3

Now I wanted to apply the wraps decorator to the wrapper but when I did I got the error ""TypeError: update_wrapper() got multiple values for argument 'wrapped'""
>>> from functools import wraps
>>>
>>> def debug(func):
...    msg=func.__qualname__
...    @wraps
...    def wrapper(*args, **kwargs):
...       print(msg)
...       return func(*args, **kwargs)
...    return wrapper
... 
>>> @debug
... def add(x, y):
...    return x+y
... 
>>> add(1,2)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: update_wrapper() got multiple values for argument 'wrapped'
>>>

What I'm doing wrong and why the error occurs?
","""Got it. Sorry, the issue was that I forgot to pass 'func' to the wraps decorator. Here is the correct code:",def debug(func):,   msg = func.__name__,"Got it. Sorry, the issue was that I forgot to pass 'func' to the wraps decorator. Here is the correct code:
def debug(func):
   msg = func.__qualname__
   @wraps(func)
   def wrapper(*args, **kwargs):
      print(msg)
      return func(*args, **kwargs)
   return wrapper

",D,python,SEQA,A
simd versions of shldshrd instructions,"SHLD/SHRD instructions are assembly instructions to implement multiprecisions shifts.
Consider the following problem:
uint64_t array[4] = {/*something*/};
left_shift(array, 172);
right_shift(array, 172);

What is the most efficient way to implement left_shift and right_shift, two functions that operates a shift on an array of four 64-bit unsigned integer as if it was a big 256 bits unsigned integer?
Is the most efficient way of doing that is by using SHLD/SHRD instructions, or is there better (like SIMD versions) instructions on modern architecture?
",x86 has been outdated for 10 years now if you're coding in 2016 it hardly makes sense to be stuck in 2005.,"In this answer I'm only going to talk about x64.
x86 has been outdated for 15 years now if you're coding in 2016 it hardly makes sense to be stuck in 2000.
All times are according to Agner Fog's instruction tables.
Intel Skylake  example timings*
The shld/shrd instructions are rather slow on x64.
Even on Intel skylake they have a latency of 4 cycles and uses 4 uops meaning it uses up a lot of execution units, on older processors they're even slower.
I'm going to assume you want to shift by a variable amount, which means a
SHLD RAX,RDX,cl        4 uops, 4 cycle latency.  -> 1/16 per bit

Using 2 shifts + add you can do this faster slower.
@Init:
MOV R15,-1
SHR R15,cl    //mask for later use.    
@Work:
SHL RAX,cl        3 uops, 2 cycle latency
ROL RDX,cl        3 uops, 2 cycle latency
AND RDX,R15       1 uops, 0.25 latency
OR RAX,RDX        1 uops, 0.25 latency    
//Still needs unrolling to achieve least amount of slowness.

Note that this only shifts 64 bits because RDX is not affected.
So you're trying to beat 4 cycles per 64 bits.
//4*64 bits parallel shift.  
//Shifts in zeros.
VPSLLVQ YMM2, YMM2, YMM3    1uop, 0.5 cycle latency.  

However if you want it to do exactly what SHLD does you'll need to use an extra VPSLRVQ and an OR to combine the two results.
VPSLLVQ YMM1, YMM2, YMM3    1uop, 0.5 cycle latency.  
VPSRLVQ YMM5, YMM2, YMM4    1uop, 0.5 cycle latency.   
VPOR    YMM1, YMM1, YMM5    1uop, 0.33 cycle latency.   

You'll need to interleave 4 sets of these costing you (3*4)+2=14 YMM registers.
Doing so I doubt you'll profit from the low .33 latency of VPOR so I'll assume a 0.5 latency instead.
That makes 3uops, 1.5 cycle latency for 256 bits = 1/171 per bit = 0.37 cycle per QWord = 10x faster, not bad.
If you are able to get 1.33 cycle per 256 bits = 1/192 per bit = 0.33 cycle per QWord = 12x faster.
'It’s the Memory, Stupid!'
Obviously I've not added in loop overhead and load/stores to/from memory.
The loop overhead is tiny given proper alignment of jump targets, but the memory
access will easily be the biggest slowdown.
A single cache miss to main memory on Skylake can cost you more than 250 cycles1.
It is in clever management of memory that the major gains will be made.
The 12 times possible speed-up using AVX256 is small potatoes in comparison.
I'm not counting the set up of the shift counter in CL/(YMM3/YMM4) because I'm assuming you'll reuse that value over many iterations.
You're not going to beat that with AVX512 instructions, because consumer grade CPU's with AVX512 instructions are not yet available.
The only current processor that supports currently is Knights Landing.
) All these timings are best case values, and should be taken as indications, not as hard values.
1) Cost of cache miss in Skylake: 42 cycles + 52ns = 42 + (524.6Ghz) = 281 cycles.
","""In this answer I'm only going to talk about x64.",All times are according to Agner Fog's instruction tables.,B,c,SEQA,C
update springboot 341 spring security error a filter chain that matches any request has already been configured,"I have two security configurations  in two libs
First one is for authentication:
    @Bean
    @Order(10)
    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {
        http
                .authorizeHttpRequests(authorizeRequests ->
                        authorizeRequests
                                .requestMatchers(createAntRequestMatchers(whitelist))
                                .permitAll().anyRequest()
                                .authenticated()
                )
                .oauth2ResourceServer( ...)
        return http.build();
    }

Second one adds some resource filter:
    @Bean
    @Order(100)
    public SecurityFilterChain filterChain(HttpSecurity http, ResourceFilter resourceFilter) throws Exception {
        return      http
                .authorizeHttpRequests(authorizeRequests ->
                        authorizeRequests
                                .requestMatchers(createAntRequestMatchers(whitelist))
                                .permitAll().anyRequest()
                                .authenticated()
                ).addFilterAfter(resourceFilter, SessionManagementFilter.class).build();
    }   

It worked perfect until spring-boot 3.3.?
After update to spring-boot 3.4.1 spring context don't startet anymore with error message
A filter chain that matches any request [DefaultSecurityFilterChain defined as 'filterChain' in ... has already been configured, which means that this filter chain ... will never get invoked. Please use HttpSecurity#securityMatcher to ensure that there is only one filter chain configured for 'any request' and that the 'any request' filter chain is published last.
After I add in each configuration requestMatcher (all requests)
http.securityMatcher(""/**"").authorizeHttpRequests(...

it works as expected. But if I read spring-security issue comments https://github.com/spring-projects/spring-security/issues/15220
I have a doubts about my solution.
What do you mean?
I adapt my code acording @Roar S. suggestion
    @Bean
    @Order(10)
    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {
        http.securityMatcher(""/**"")
                .authorizeHttpRequests(authorizeRequests ->
                        authorizeRequests
                                .requestMatchers(createAntRequestMatchers(whitelist))
                                .permitAll().anyRequest()
                                .authenticated()
                )
                .oauth2ResourceServer( ...)
        return http.build();
    }

---------

    @Bean
    @Order(100)
    public SecurityFilterChain filterChain(HttpSecurity http, ResourceFilter resourceFilter) throws Exception {
        return http.securityMatcher(""/**"")
        .addFilterAfter(resourceFilter, SessionManagementFilter.class).build();
    }   



It works, but .securityMatcher(""/**"") looks suspicious. And without .securityMatcher(""/**"") it doesn't start
",   ,   ```java,"**Update: OP mentioned in a comment that the first SecurityFilterChain is shared across multiple applications and cannot be modified. To address the issue, we should use FilterRegistrationBean to add the filter before the shared SecurityFilterChain. This ensures it runs immediately after the request is received. The code below demonstrates this approach.","Update: OP mentioned in a comment that the first SecurityFilterChain is shared across multiple applications and cannot be modified. Since the issue involves simply adding a filter that needs to execute after the shared SecurityFilterChain, we can address it using FilterRegistrationBean instead of using two security chains. The following code is based on this answer.
LoggingFilter is the same as in my original answer.
import org.springframework.boot.autoconfigure.security.SecurityProperties;
import org.springframework.boot.web.servlet.FilterRegistrationBean;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class FilterConfig {

    @Bean
    public FilterRegistrationBean<LoggingFilter> afterAuthFilterRegistrationBean(
            SecurityProperties securityProperties) {
        
        var filterRegistrationBean = new FilterRegistrationBean<LoggingFilter>();

        // a filter that extends OncePerRequestFilter
        filterRegistrationBean.setFilter(new LoggingFilter());

        // this needs to be a number greater than than spring.security.filter.order
        filterRegistrationBean.setOrder(securityProperties.getFilter().getOrder() + 1);
        return filterRegistrationBean;
    }
}


Original answer
OP has separated security configuration into two chains under the assumption, I believe, that the principal becomes available only after a security chain is fully executed. However, the principal is populated and available after the BearerTokenAuthenticationFilter has completed. Therefore, the two chains in the question can be merged into one.
This behavior can be verified by adding the following logging filter to the chain with:
.addFilterAfter(new LoggingFilter(), BearerTokenAuthenticationFilter.class)

Here is the logging filter implementation:
    private static class LoggingFilter extends OncePerRequestFilter {

        @Override
        protected void doFilterInternal(@NonNull HttpServletRequest request,
                                        @NonNull HttpServletResponse response,
                                        @NonNull FilterChain filterChain) throws ServletException, IOException {

            var authentication = SecurityContextHolder.getContext().getAuthentication();
            if (authentication != null) {
                LOG.info(""Logged in as: {}"", authentication.getName());
                LOG.info(""Authorities: {}"",
                        authentication.getAuthorities().stream()
                                .map(GrantedAuthority::getAuthority)
                                .collect(Collectors.joining("", ""))
                );
            } else {
                LOG.info(""No user"");
            }

            filterChain.doFilter(request, response);
        }
    }

",D,java,SEQA,
reactjs and images in public folder,"Im new in ReactJS and I want to import images in a component. These images are inside of the public folder and I do not know how to access the folder from the react component. 
Any ideas ?
EDIT
I want to import an image inside Bottom.js or Header.js
The structure folder is:

I do not use webpack. Should I ?
Edit 2
I want to use webpack for loading the images and the rest of assets. So in my config folder I have the next files:

Where I need to add the paths of the images and how?
Thanks
","To reference images in public there are two ways I know how to do it straight forward. 
One is like above from Homam Bahrani.
using 
    <img src={process.env.PUBLIC_URL + '/yourPathHere.jpg'} /> 

And since this works you really don't need anything else but, this also works...
    <img src={window.location.origin + '/yourPathHere.jpg'} />

",    ```jsx,"To reference images publicly, you can prepend the image path with the current domain's URL using:",    <img src={document.baseURI + '/yourPathHere.jpg'} />,A,javascript,SEQA,A
how to send message from website to telegram app,"I have a share button in my website and I want to send a specific message to Telegram APP contacts (when I open website in Mobile)
The Problem is I didnt find the complete code and it just open the APP in the mobile
my code is :
<a href=""tg://"" id=""telegram_share"" class=""mobileShare"" title=""inviteFriends"" alt=""telegram_share""></a>

as you see I didnt find proper command for sending message in href property
for example I found something simillar for adding sticker like :
<a class=""tgme_action_button"" href=""tg://addstickers?set=Saber2"">Add Stickers</a>

","""It's called a URL Template.  ","It's called a URI Scheme.
<a href=""tg://msg?text=your MsG!"" id=""telegram_share"" class=""mobileShare"" title=""inviteFriends"" alt=""telegram_share""></a>

Right now this only works on iOS.
","   `<a href=""tg//msg?text=your MsG!"" id=""telegram_share"" class=""mobileShare"" title=""inviteFriends"" alt=""telegram_share""></a>`",   ,B,javascript,SEQA,A
plus  operator semantics in c,"Today I noticed that the weird b + + c; expression is considered valid in C. I am wondering if there is a reason behind it; especially, given that b ++ c; and b + ; are considered syntax errors.
I do not know where to look for some information, I thought StackOverflow might be a good place to ask for some insight (I am using gcc for compilation).
I found this expression in an old code of mine, probably an error caused due to removing a variable from the middle of the summation and forgetting to also remove the operator sign.
#include <stdio.h>
int main()
{
    int a = 100;
    int b = 200;
    int c = 300;
    a = b + + c; /* <-- why this is not a syntax error ? */
    printf(""a = %d\n"", a); /* <-- prints a = 500 */
    return 0;
}

","""b + + c is interpreted as b + (c++) because the second + is seen as a postfix increment. This means c is incremented after its value is added to b, altering the result by one. Hence, it's a concise way to incorporate an increment within an addition operation.""","b + + c is equivalent to b + (+c) where the second + is an unary plus operation that actually does nothing here.
(a bit similar to -c for unary negation but with no real effect).
This is because of the operator precedence: unary + - has higher precedence than binary + -.
As @RobertHarvey commented you should not actually write code like this as there's no reason to over-complicate a simple a = b + c;.
","""b + + c is equivalent to b + (+c) where the second + acts as a unary increment operator, increasing the value of c by one before adding it to b. This is due to operator precedence, where unary operators modify their operands before any other operations are performed.""",,B,c,SEQA,B
